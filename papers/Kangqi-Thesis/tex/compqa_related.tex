%# -*- coding: utf-8-unix -*-
% !TEX program = xelatex
% !TEX root = ../thesis.tex
% !TEX encoding = UTF-8 Unicode

\section{相关工作}%related
\label{sec:compqa-related}


% \KQ{
% be aware of new papers: \citet{cui2017kbqa},  \citet{hu2018answering},  \citet{abujabal2017automated}. 
% }

% \KQ{
% Part 1: QA system in categories: SP,  IR. 
% For the ``other'' papers like \citet{jain2016question},  \cite{cui2017kbqa}. 
% Brief talk about their main techniques,  in one sentence. 
% Our paper belongs to SP branch. 
% }




基于知识库的自动问答是最近几年的热门研究。
最主要的用于解决自动问答的方法可以分为两类：
基于信息抽取（Information Extraction）和基于语义解析（Semantic Parsing）。

%Knowledge Base Question Answering(KBQA) has been a hot research top in recent years.  Generally speaking,  the most popular methods for KBQA can be mainly divided into two classes: information retrieval and semantic parsing. 




%这里要看一下其他人的related work，FL写的还有些欠缺。
基于信息抽取的问答模型首先通过实体链接寻找句子中的相关实体，
将它们在知识库上邻近的实体抽取出作为候选答案。
对于候选答案的排序，则依赖以候选答案为中心的知识库子图与问句之间的关联特征。
早期的文献\parencite{yao2014information}利用特征工程进行训练，
而后一系列深度学习模型\cite{bordes2014question,dong2015question,hao2017end}
则通过神经网络学习答案在类型、谓词、上下文等多个不同维度与问句的语义关联程度，
并取得了明显的效果提升。
%Information retrieval based system tries to obtain target answer directly from question information and KB knowledge without explicit considering interior query structure.
%There are various methods \cite{yao2014information,bordes2015large,dong2015question,xu2016question} to select candidate answers and to rank results.  
% % treat a KB as a graph connecting different topics and extract the entities in the problem and obtain the knowledge base subgraph centered on those entities.  Each node or edge in the subgraph can be used as a candidate answer,  and the problem vector is extracted by observing the problem according to certain rules or templates.  The final answer can be selected from candidate answers with the help of problem vector.  IR method has the advantage of easy training and fast speed.  
% % However,  due to the lack of semantic encoding,  features in IR methods are hard to interpret and solve complex questions. 
基于语义解析的系统则会先生成带有复杂结构的候选查询图，
将查询图翻译为能在运行在知识库上的结构化查询语句，得到最终的答案。
%直接转换为查询图（DCS，以及之后的办法）
%早期：CCG作为中间过渡
早期的语义解析系统\cite{kwiatkowski2013scaling,cai2013large}根据PCCG文法
生成和具体知识库无关的中间表达形式，通常以$\lambda$算子的形式呈现，
再将$\lambda$算子中的谓词和常量，映射到知识库中的具体谓词和实体。
Liang提出的$\lambda$-DCS\cite{liang2013lambda}是对PCCG的简化，
语义解析树依然为自底向上的方式，但$\lambda$表达式由简单的相交、合并等规则生成，
大大降低了解析树生成的复杂程度。
最近的研究中，分阶段候选差选图的生成\cite{yih2015semantic,bao2016constraint}已证明了其有效性，
它利用深度搜索，通过由简到繁逐步扩展查询图，
不需要定义操作，也摆脱了自底向上生成过程中，组合顺序与单词顺序相关的限制。

%TODO:还是需要再调整，这个语句粗略了。
%TODO:聊一下cui2017和hu2018，还是要靠自己聊。

%Semantic parsing based approach focuses on constructing a semantic parsing tree or equivalent query structure that represents the semantic meaning of the question.  In terms of logical representation of natural language questions,  many methods have been tried,  such as query graph~\cite{yih2014semantic,yih2015semantic} or RDF query language~\cite{unger2012template,cui2017kbqa,hu2018answering}.  
%% For example,  (Yih et al. ,  2014~\cite{yih2014semantic}; Golub et al. ,  2016~\cite{golub2016character}; Yu et al. ,  2017~\cite{yu2017improved}) are based on Freebase. 

% \KQ{Cannot quite get the point of this paragraph. }
% One drawback of traditional semantic parsing method to sovle KBQA problem is that it needs to generate queries based on large amount of entities and predicates in the KB,  a large proportion of which are unseen during the training process.  Therefore,  some research has focused on solving this issue.  One solution is embedding based method,  which represents entities and relations in vector space and predict soundness of candidate triplets from these latent vectors,  such as  
% TransE(Bordes et al. ,  2013)~\cite{bordes2013translating},  TransH~\cite{wang2014knowledge},  TransR~\cite{lin2015learning} and other enhanced but similar models.  The general idea behind these models is training embedding vectors of entities and relations by the formula $h+r\simeq t$.  Besides,  recent work has also focus on character-level model to enhance the performance,  such as (Golub et al. ,  2016).  Golub uses character-level modeling to handle traditional out-of-vocabulary(OOV) problem.  Furthermore,  there are some research on combination of knowledge base and open vocabulary to improve semantic parsing performance.  For example,  (Gardner et al. ,  2017)~\cite{gardner2017open} try to leverage the information contained in both a formal KB and a large corpus to avoid the limit of the schema of the underlying KB.  \citet{qu2018question} goes even further.  It use RNN to capture semantic-level information in question and use an attention mechanism to keep track of the entities and relations in the same time.  However,  most of these approaches can only deal with single-relation questions,  having no ability to deal with ordinal questions and multi-relation questions,  such as ComplexQuestions.  

% \KQ{
% Part 2: NN techniques in QA system. 
% Could briefly talk about KB embedding based approaches,  check \citet{hao2017end} for more information. 
% Many works used NN techniques,  including Xu,  Yih,  Bao,  and lots of SimpQ papers. 
% Try talk about multiple papers in one or two sentences. 
% Bao is most similar to us,  could talk more,  but not so much. 
% Our main difference: encode multiple relations (paths) into a uniform query structure representation (semantic composition).  
% }

随着深度学习的发展，神经网络模型被广泛使用于知识库上的自动问答任务，并且展示出了优秀的结果。
这些方式的基本思路是利用神经网络的对特征表示的学习能力，将问句转换为连续空间上的
向量表示，同时再将查询结构（或答案实体）映射到同一语义空间，
并定义问句和答案的语义相似度，根据\textless 问题，答案\textgreater 对进行学习，
预测正确的查询。
处理简单语义的神经网络问答模型具有较多的变种，
例如
文献\parencite{yin2016simple,golub2016character}使用了字符级别的循环神经网络以及注意力机制，
对谓词序列和相关实体均进行相似度计算，对于未在训练数据中观察到的单词，模型依然具有鲁棒性；
Bordes等人\cite{bordes2014open}利用知识库向量学习，
关注候选答案的在知识库中的类型、相连谓词、相邻实体等信息，
学习它们在知识库上的向量表示，并以此对候选答案进行编码；
Yu等人\cite{yu2017improved}引入了多层循环神经网络，并通过残差连接的方式，
同时捕捉问句在词级别和整体级别与特定谓词序列的语义匹配；
Qu等人\cite{qu2018question}提出了AR-SMCNN模型，
除了利用循环神经网络捕捉问句和谓词序列在语义上的相关性，
还利用了类似与卷积神经网络处理二维图像的方式，
在词级别相似度矩阵中寻找纹理，学习问句和谓词序列的另一种相似度量。

%Recently, as the development of deep learning,
%NN-based approaches have been combined into the KBQA task \cite{bordes2014open}, showing promising result.
%These approaches tries to use neural network models to encode both questions and answers (or query structures) into the vector space.
%Subsequently, similarity functions are used to select the most appropriate query structure to generate the final answer.
%%In NN-based approaches,  different methods for the crucial step, learning representations of questions and answers(or query structures), have been tried,  especially for simple questions.
%For example,
%\citet{bordes2014open}  focuses on embedding the subgraph of the candidate answer;
%\citet{yin2016simple}  uses character-level CNN and word-level CNN to match different information;
%\citet{yu2017improved} introduces the method of hierarchical residual RNN to compare questions and relation names; 
%\citet{qu2018question} proposes the AR-SMCNN model, which uses RNN to capture semantic-level correlation and employs CNN to extract literal-level words interaction. 
% %  \citet{dong2015question}) takes the context and the type of the answer into account

%讲道理，Cui和Hu的论文也要在这里讨论一下
对于利用神经网络回答复杂语义的问题，已有的工作进行了不少尝试，
但并没有尝试学习查询图整体的语义表示。
例如文献\parencite{yih2015semantic,xu2016question}
侧重于用神经网络计算问句和查询图中主路径的匹配关系，相当于退化至简单语义场景。
对于查询图中，除去主路径的其余语义成分，
Yih等人\cite{yih2015semantic}利用人工定义特征捕捉少数特殊语义，
但基于特征工程的方法不具有较好的扩展性；
Xu等人\cite{xu2016question}则挖掘非结构化文本中的上下文信息，
对满足主路径的候选答案进行过滤，这种方式被视为模型计算之后的处理，而并没有从本质上解决问题。
Bao等人\cite{bao2016constraint}利用每个相关实体在问句中的上下文窗口表示局部语义，
并和查询图中的对应的谓词路径进行相似度匹配计算，但谓词路径之间仍缺少关联。


%Belonging to NN-based semantic parsing category, 
%our approach employs a novel encoding structure method to solve complex questions.
%Previous works such as \citet{yih2015semantic} and \citet{bao2016constraint}
%require a recognition of a main relation and regard other constraints as variables added to this main relation.
%Unlike their approaches, our method encodes multiple relations (paths) into a uniform query structure representation (semantic composition),  which allows more flexible query structures. 
%% To handle multi-relation questions,  recent research has focused on NN-based semantic parsing method.  This approach tries to use RNN or CNN network models to encode both questions and query structures into vector space.  Subsequently,  similarity functions,  such as cosine similarity or dot product,  can be used to select the most appropriate query structure to generate final answer.  For example,  the MulCG (Bao et al. ,  2016)~\cite{bao2016constraint} requires a recognition of a core chain and regards other constraints as variables added to this main relation.  After,  the MulCG uses Siamese CNN to calculate the similarity of question embedding and schema embedding to rank candidate query structures.  The latent problem is (1) six patterns are not adequate to support all kinds of multi-relational questions,  (2) answering all sub-questions separately can be redundant and (3) they can't solve ordinal questions until the final answer refinement step.  However,  this final step adds an additional resource wikipedia to select one answer from possible candidate answers,  which is not only slow but easy to mismatch.  Compared to the MCCNN,  our model avoids redundant work to answer sub-questions successively by fully representing the multi-relational question in a uniform way.  Besides,  our schema treats the ordinal constraints and other constraints equally thus don't need extra work like the refinement step. 

此外，依存语法分析可以描述一个句子中，词汇间的远距离依赖关系，
考虑到它与查询图的结构较为相似，
因此候选查询结构的生成可以基于依存分析树进行转换，
语义匹配过程也更多利用了结构上的相似关系，
例如文献\parencite{reddy2016transforming,hu2018answering}。
我们的模型同样使用了依存语法分析，但将其视为语义特征的信息来源，
而并非直接决定候选查询图的形状，因此我们可以生成更灵活的查询图。
%（这话可以反着说，别人怎么怎么不好）(或者说，如何优雅的xxx，成为了。。。的问题)

%
% \KQ{
% Part 3: Other related papers from solving complex questions,  mainly non-NN based. 
% Checkout these papers: \citet{reddy2016transforming},  \citet{hu2018answering},  \citet{abujabal2017automated}. 
% All of them used dependency information,  which is similar with ous. 
% our difference: dependency as feature,  not decide the shape of query structures, 
% which allows more flexible query structures. 
% }




%这一段简直了，写的啥玩意儿。。。

%There are also some works can't be simply classified in to IR based methods or SP based methods.   \citet{jain2016question}  introduces Factual Memory Network,  which tries to encode KB and questions in same word vector space,  extract a subset of initial candidate facts,  then try to employ multi-hop reasoning and refinement to find a path to answer entity.   \citet{reddy2016transforming},  \citet{abujabal2017automated}, and \citet{cui2017kbqa} try to interpret question intention by templates,  which learned from KB or QA corpora.   \citet{talmor2018web}  attempts to answering complex questions by decomposing them into a sequence of simple questions. 




% However,  due to the limit of data and the complexity of knowledge graph,  the results of these methods are not very competitive.  
%  

 % However,  it seems inflexible in the MulCG that this model manually classifies constraints into 6 types and needs to determine a main path. 

 % requires a recognition of a core chain (Yih et al. ,  2015~\cite{yih2015semantic}; Bao et al. ,  2016~\cite{bao2016constraint}; Yu et al. ,  2017) and  they regard other constraints as variables added to this main relation.  The MulCG (Bao et al. ,  2016) handles multiple constraints systematically and expands non-entity constraints which develops the staged graph (Yih et al. ,  2015).  However,  they all treats constraint a variable added to a node of main relation,  while our model doesn't have to detect the main relation and treats constraints and relations parallel.  Moreover,  our model is word-based,  in other words,  we don't need KB information to generate our schema.  Our model represents every path a word sequence ended with the final answer entity and merges them together to form an overall schema.  The word sequence path only takes word features into account thus concise and uniform thus prevent an overfit problem. 

% In terms of schema generation,  the MulCG (Bao et al. ,  2016) is not flexible enough by mapping explicitly the exact word proof to detect and match constraints,  while our model applies the attention mechanism which can collect other textual evidences to help detecting constraints. 

% For the model and the ranking step,  the MulCG (Bao et al. ,  2016) embedss question and schema together in feature-based then uses learning to rank,  which requires feature engineering thus not flexible.  And our model embeds respectively question(word-based RNN) and schema then trains with neural networks to get a score. 

% The MCCNN (Dong et al. ,  2015~\cite{dong2015question};Xu et al. ,  2016~\cite{xu2016question}) proposed a dependency tree based method to handle multi-relational questions.  They decompose the original question into simple sub-questions using six dependency patterns,  and the intersection of answer sets of all the sub-questions will be selected as the final answer.   

%Attention
% The attention mechanism~\cite{vaswani2017attention} is widely used for NLP tasks in recent days. (Yin et al. ,  2017~\cite{yin2017type}).  

% % IARNN (Wang et al. ,  2016)~\cite{wang2016inner} is an inner attention RNN that the attention was imposed directly to the input therefore can avoid biased attention problem caused by outer attention RNN.  Nevertheless,  it is unidirectional  and it doesn't consider the mutual influnce of the question and the answer. 
 
% % The ABCNN model proposed by (Yin et al. ,  2015)~\cite{yin2015abcnn} integrates attention into CNNs in order to solve sentence pair modeling problem.  This ABCNN model sets up mutual influence between the sentence pairs into CNNs,  therefore the output embedding of each sentence contains the information of its counterpart.  This ABCNN model gives an intuition of cross attention which takes mutual influence into account. 
 
% Hao~\cite{hao2017end} proposes another cross attention model focus on KBQA task.  This cross-attention mechanism consists of two parts: one answer-towards-question attention part and one question-towards-answer attention part.  It focuses on different answer aspects of each question word and calculates the similarity score of the question and the four different candidate answer aspects.  The final score will be composed of the weighted sum of these four similarity score.  This model well develops the attention mechanism,  however,  the mutual interaction is still not fully established.  The reason lies below:  The four similarity vectors between question and answer aspect are independent to each other thus the mutual influence can't be fully expressed.  
 
% Our cross attention mechanism aims to represent both the question and the schema in a dynamic way.  We take each question word's embedding and each skeleton embedding as input and we import an attention matrix.  For the attention matrix,  each item $e_{ij}$ of this matrix denotes the weight of the \emph{i}-th skeleton and the \emph{j}-th question word.  Thus the \emph{i}-th row represents the contribution of each question word to the \emph{i}-th skeleton,  while the \emph{j}-th row represents the contribution of the \emph{j}-th question word to each skeleton.  This cross-attention mechanism fully takes the mutual influence of the question and the schema into account,  thus generates a more precise and meaningful representation of the schema.  

% In conclusion,  our model has a uniform framework,  and it is concise and flexible, also puissant to answer ordinal questions. 





%加一段我们与它们的区别，就像PL那样
%Unlike their approaches, our method encodes multiple relations (paths) into a uniform query structure representation (semantic composition),  which allows more flexible query structures. 
