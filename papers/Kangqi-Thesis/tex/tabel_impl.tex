%# -*- coding: utf-8-unix -*-
% !TEX program = xelatex
% !TEX root = ../thesis.tex
% !TEX encoding = UTF-8 Unicode

\subsection{模型实现细节}
\label{sec:tabel-impl}

模型的主要实现细节包括了候选生成过程，双语翻译层的预训练，以及调参细节，
下面将分别对这几个部分进行介绍。

\textbf{候选生成}：
我们使用
百度翻译\footnote{http://fanyi.baidu.com}，
谷歌翻译\footnote{http://translate.google.cn}以及
腾讯翻译\footnote{http://fanyi.qq.com}的API用于候选生成。
获取翻译结果之后，我们将英文字面描述与维基百科中的每一个实体进行比较，
计算粗略的链接置信度。
若某实体名称与字面描述完全匹配，或存在字面完全匹配的锚文本指向该实体，
则将其置信度设为1。
对于非完全匹配的情况，我们去掉字面描述和锚文本中的所有停用词，
并计算Jaccard相似度，作为字面描述与对应实体的链接置信度。
综合各种可能的英文翻译，
根据链接置信度对所有实体进行排序，
排名前$N_{cand}$的实体将被保留，作为原字面描述的候选集。

\textbf{双语翻译层预训练}：
我们利用必应翻译\footnote{http://www.bing.com/translator}的API
收集了一个双语词典，其中包含91,346个单词级别的中英文翻译对，
并且每对都关联了一个0到1范围的置信度。
为了从中选取有价值的信息，
我们保留那些置信度高于0.5，且中英文词语均完全匹配某维基百科实体的翻译对。
经过此法，我们总共收集了3,655个翻译词对用于转换矩阵的预训练。

\textbf{调参细节}：
%We implement RankNet~\cite{burges2010ranknet} as the pairwise ranking algorithm.
%we tune the following parameters in our joint model:
%we list the parameter tuning details as below.
\begin{itemize}
\item 每个单元格对应的候选实体数量（$N_{cand}$）的调参范围为\{1, 3, 5, 10, 20, 30, 40, 50\}；
\item 每个训练表格所生成的负样本表格数量（$N_{tab}$）范围为\{9, 19, 49, 99\}；
\item 模型中，指示、上下文、总体特征对应向量的维度（$d_{cell}$，$d_{cont}$，$d_{out}$）范围为\{20, 50, 100, 200\}；
\item 学习率$\eta$范围为\{0.0002, 0.0005, 0.001\}；
%\item The L1- and L2- regularization $l_1, l_2$ in \{0.0001, 0.0002, 0.0005, 0.001\}.
\item 我们在每一个隐含特征计算上使用dropout层\cite{srivastava2014dropout}，
保留概率$p$范围为\{0.5, 0.6, 0.7, 0.8, 0.9\}。
\end{itemize}

%All the parameters are tuned on the validation set, the detail evaluation metric is discussed in \secref{sec:exp-e2e-results}.



