%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Plain Cover Letter
% LaTeX Template
% Version 1.0 (28/5/13)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% Original author:
% Rensselaer Polytechnic Institute 
% http://www.rpi.edu/dept/arc/training/latex/resumes/
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[11pt]{letter} % Default font size of the document, change to 10pt to fit more text

\usepackage{newcent} % Default font is the New Century Schoolbook PostScript font 
%\usepackage{helvet} % Uncomment this (while commenting the above line) to use the Helvetica font

% Margins
\topmargin=-1in % Moves the top of the document 1 inch above the default
\textheight=8.5in % Total height of the text on the page before text goes on to the next page, this can be increased in a longer letter
\oddsidemargin=-10pt % Position of the left margin, can be negative or positive if you want more or less room
\textwidth=6.5in % Total width of the text, increase this if the left margin was decreased and vice-versa

\let\raggedleft\raggedright % Pushes the date (at the top) to the left, comment this line to have the date on the right

\usepackage{color}
\usepackage{times}
\usepackage{latexsym}

\usepackage{url}

\usepackage{soul}
\usepackage{algorithm}
\usepackage{algorithmic}
\urlstyle{same}

\usepackage{helvet}
\usepackage{courier}
\usepackage{color}
\usepackage{amsmath,amsfonts,amssymb,amsthm,amsopn}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{diagbox}
\usepackage{array}
\usepackage{multicol}
\usepackage{threeparttable}
\usepackage{epstopdf}
\usepackage{listings}
\usepackage{multirow}
\newcommand{\KZ}[1]{\textcolor{red}{Kenny: #1}}

\begin{document}
	
	%----------------------------------------------------------------------------------------
	%	ADDRESSEE SECTION
	%----------------------------------------------------------------------------------------
	
	\begin{letter}{Dr. Jim Jansen \\
			Editor-in-Chief  \\
			Information Processing and Management\\
			Dr. Ian Ruthven \\
			Associate Editor \\
			Information Processing and Management} 
		
		%----------------------------------------------------------------------------------------
		%	YOUR NAME & ADDRESS SECTION
		%----------------------------------------------------------------------------------------
        \begin{center}
        \large\bf Yizhu Liu, Xinyue Chen, Xusheng Luo and Kenny Q. Zhu \\ % Your name
        %\vspace{20pt} \hrule height 1pt % If you would like a horizontal line separating the name from the address, uncomment the line to the left of this text
        Department of Computer Science and Engineering \\ Shanghai Jiao Tong University \\ 800 Dongchuan Road, Shanghai, China 200240 \\
        liuyizhu@sjtu.edu.cn
         % Your address and phone number
        \end{center} 
        \vfill

        \signature{Yizhu Liu, Xinyue Chen, Xusheng Luo and Kenny Q. Zhu} % Your name for the signature at the bottom
		
		%----------------------------------------------------------------------------------------
		%	LETTER CONTENT SECTION
		%----------------------------------------------------------------------------------------
		
		\opening{Dear Dr. Jim Jansen, Dr. Ian Ruthven and Reviewer,} 
		
		We appreciate the opportunity to revise our manuscript. 
		Thank you for the editors' and reviewers' comments concerning our 
		manuscript entitled ``Reducing Repetition in Convolutional Abstractive Summarization". 
		Those comments are all valuable and very helpful
		for revising and improving our paper.
		A point-by-point response to the Editors' and Reviews' comments is below. 
		We believe that the revisions prompted by these comments have strengthened our manuscript.
		\newline\newline
		On behalf of all co-authors,\\
		Yizhu Liu, Xinyue Chen, Xusheng Luo and Kenny Q. Zhu
		\newline\hrule

		\flushleft
		\begin{enumerate}
		\textit{*The location labels in responses are the locations of revised manuscript.}
		    \item (1) Contribution of the proposed method: The authors claim that the proposed method can produce more ``informative'' and ``fluent'' summaries (ref. the abstract, Section 1, and Section 3.3). However, this claim is not well-justified, given the current evaluation criteria and experimental design. Perhaps the authors try to employ ``readability'' (ref. Section 4.2) as an evaluation criterion for the claim, however it only measures how readable each sentence is, rather than how the whole summary is ``informative'' and ``fluent''. Another criterion ROUGE may be related to the ``informative'' claim, however as noted by the authors in Sections 2 and 4.3, some state-of-the-art techniques that achieve better performance in ROUGE are not employed as the baselines in the experiment.

			\begin{itemize}
				\item[] \textbf{AUTHORS' RESPONSE}: 
				
				Considering the Reviewer's suggestion, 
				we have redefined the ``Readability'' (Section $4.2$: line 296-310, page $18$) 
				and explained why some techniques with better ROUGE scores are not taken 
				as the baselines (Section 2: line 141-148, page 8; Section 4.3: line 311-332, page 19-20;
				Section 4.4: line 362-367, page 21-22). The details are as follows: 
				\begin{itemize}
				\item Readability (Readable) is human evaluation. 
				We educate human annotators to assess each summary
				from three independent perspectives as follows: 
				(1) Informative: How informative the summary is? Is the summary logically consistent with source document? 
				(3) Coherent: How coherent (between sentences) the summary is? 
				(4) Fluent: How grammatical the sentences of a summary are? Are there any factual errors in the summary?
				Readability score will be judged on the following 5-point scale: Very Poor (1.0), Poor (2.0), Barely Acceptable (3.0), Good (4.0) and Very Good (5.0).
				The score reflects the fluency and readability of the summary.

                \hspace*{0.6cm} 
				We use \textit{readability} to complement ROUGE scores since Yao [20] showed that 
			    the standard ROUGE scores cannot capture grammatical or factual errors. 
				We randomly sample 300 summaries generated by each model and manually 
				check their readability. Each summary is scored by two judges proficient in English. 
                The Cohen's Kappa coefficient between them is $0.78$, indicating agreement. 
				Here we use the average annotation score.
                
				\item In this paper, we aim at reducing repetition in abstractive summarization.
                All of the existing repetition reduction techniques are shown in Table 4. 
                Our goal is to evaluate the effectiveness of our repetition reduction technique,
                so we need to compare our proposed approaches with others on the same seq2seq model, 
				to be fair.
                We did not take state-of-the-art (SOTA) seq2seq models with better ROUGE score 
				as baselines, 
				because these SOTA models 
				do not specifically deal with repetition problem in abstractive summarization.
                Since most SOTA models use attention of some sort,
                and our model deals with incorrect attention distribution, we can reasonably deduce
                that these SOTA models will benefit from our techniques as well.
				We did not implement the repetition reduction methods 
				on top of these SOTA seq2seq models, 
				because the tricks employed in these SOTA approaches may interact with the repetition 
				reduction methods and impact the evaluation results (ROUGE), 
				which complicates the analysis.
                
				\hspace*{0.6cm}
				We choose the vanilla CNN seq2seq model as our basic model to improve on,
                because it's fast and enjoys the best accuracy among the other vanilla seq2seq models 
				such as RNN seq2seq model and LSTM seq2seq model(Gehring, 2017). 
				Our main purpose is to evaluate the repetition reduction, which is not necessarily
				reflected in the ROUGE(See 2017; Paulus 2017; Fan 2018). 

                \hspace*{0.6cm}
				For example, 
				\begin{itemize}
                    
					\item 
					\textbf{source}: \small{justin timberlake and jessica biel, welcome to parenthood. 
	                        the celebrity couple announced the arrival of their son,
			                silas randall timberlake, ...
			                the couple announced the pregnancy in january, ...
			                it is the first baby for both .}
                   \item 
	               \textbf{reference summary}: \small{timberlake and jessica biel welcome son silas 
                   	                   randall timberlake. the couple announced the 
					                   pregnancy in january .}
                   \item 
	               \textbf{CNN+COV} (See 2017): \small{timberlake and jessica biel announced 
	                                    the pregnancy in january. 
                                        the couple announced the pregnancy in january. }
                   \item 
				   \textbf{CNN+ATTF+SBD (our)}: \small{the couple announced the arrival of their son, 
	                                      silas randall timberlake. the couple announced the 
					                      pregnancy in january. it is the first baby for both.}
                \end{itemize}
                The R-2 scores of above example (Table 6): CNN+COV $0.60$, CNN+ATTF+SBD $0.52$.
                CNN+ATTF+SBD obviously produces a better, logically more consistent summary despite 
                a lower ROUGE score.  
                Due to variable nature of abstractive summarization, 
				ROUGE is not the optimal evaluation metric.
				Readability (Human-evaluation) and Repeatedness score, 
                in our opinion, are important complementary metrics to ROUGE score.  
                Our evaluation mainly compares 
				the effectiveness of different repetition reduction techniques,
                such as ATTF, SBD, COV, etc, in terms of all three metrics above. 
				If these methods were applied on top of more advanced models 
				such as SOTA seq2seq models,
				the room for improvement on the ROUGE score will be
				very limited because the advanced models already achieves 
				very high ROUGE scores for any abstractive summarization techniques 
				(ROUGE is not very good at evaluating abstractive summarization anyway). 
				Consequently, the differences in ROUGE scores 
				by these repetition reduction techniques will indistinguishable. 
				Hence, in this work, we choose to implement these methods (Table 3) 
				on top of vanilla CNN models.
			   \end{itemize}
			\end{itemize}
			\item (2) Definition and justification of the evaluation criteria:
            (2.1) ``Repeatedness'' is an evaluation criterion that considers how similar sentences are in a summary (ref. Section 4.2). However, it is defined based on a similarity measure that has been employed by the proposed method to produce better results (i.e., Equation 12, ref. Sections 3.3 and 4.2). It may be inappropriate to employ the idea of the proposed method to evaluate the method. Moreover, the authors also presents an algorithm to compute repeatedness (ref. Algorithm 1), however it is not clear how the algorithm considers Equation 12.
			\begin{itemize}
				\item[] \textbf{AUTHORS' RESPONSE}: 
				
			    We are sorry that we did not explain ``Repeatedness''.
				Actually, ``Repeatedness'' contains three evaluation methods: 
				N-gram repeatedness, sentence repeatedness and total repeatedness. 
				Only sentence repeatedness requires the use of \textit{sim} 
				in Equation 12 to identify repetitive sentences. 
				If \textit{sim} is $1$, these two sentences are repetitive sentences.
				The Algorithm 1 is the algorithm to compute total repeatedness,
				which does not require Equation 12.
               
			    \hspace*{0.6cm}
				Considering Reviewer's comments, 
				we revised Equation 12 to remove the use of \textit{sim}.
				As any two sentences in one reference summary 
				almost never contain the same trigram (Paulus et al., 2017),
				we think that the sentences are ``repetitive sentences'' 
				when they contain the same trigram. 

			    \hspace*{0.6cm}
                Thus, the statements of ``Repeatedness''
				were changed as ``
				Repeatedness (Rep) includes N-gram repeatedness, sentence repeatedness
				and total repeatedness.
				\begin{itemize}
				\item[-] \textbf{N-gram repeatedness} is the percentage of repeated N-grams 
				in a summary:

				\begin{equation}
				\small Rep_{ngram} = \frac{n_{ngram}}{N_{ngram}} \nonumber
				\end{equation}
				where $n_{ngram}$ is the number of repeated N-grams, 
				$N_{ngram}$ is the total number of N-grams in a summary.
				\item[-] \textbf{Sentence repeatedness} is the percentage of repeated 
				sentences in a summary:
				\begin{equation}
				\small Rep_{sent} = \frac{n_{sent}}{N_{sent}} \nonumber
				\end{equation}
				where $n_{sent}$ is the number of repeated sentences, 
				$N_{sent}$ is the total number of sentences in a summary.
				For sentence repeatedness, if the sentences contain the same trigram,
				these sentence are repetitve sentences.
				(Here we insert a footnote 
				`Any two sentences in one reference summary almost never contain 
				the same trigram (Paulus et al., 2017).')
				\item[-] 
				\textbf{Total repeatedness} (Algorithm 1, page 17) is a comprehensive score
				that unifies word-level and sentence-level repeatedness.
				It is not computed by N-gram repeatedness score 
				and sentence repeatedness score. 
				\end{itemize}
				''
				(Section 4.2: line 265-276, page 16)
			\end{itemize}
			\item (2.2) ``Readability'' is employed as an evaluation criterion as well (ref. Section 4.2), however how readability of each sentence is integrated to produce a readability score of the whole summary is not defined. Moreover, the authors claim that two participants are recruited to evaluate the readability with high agreement, however it is not clear why and how the readability achieved by the ``gold'' (ref. Table 7) can be judged (by the two different participants) to be 1.0.
			\begin{itemize}
				\item[] \textbf{AUTHORS' RESPONSE}:  
			
		    	As Reviewer suggested that we redefine the ``Readability'' (Section 4.2: line 296-310, page 18)
				to produce a readability score of the whole summary. 
				The details are in first \textbf{AUTHORS' RESPONSE}.

			    \hspace*{0.6cm}
                The ``Gold'' in Table 7 (Table $8$ in revised manuscript, page 22) means reference summaries (golden standards). We think that
				reference summaries are the most \textit{readable}. The readability score of reference summaries
				should be 1.0 based on original readability metric 
				and 0.5 based on redefined readability metric. 
				In order to explain this problem, we add the explanation to the caption of Table 7
				as follows:
			    
				\hspace*{0.6cm}
				``
				The ``Gold'' denotes reference summaries, which are the most readable.
				By default, the readability score of reference summaries is judged to be 5.0.
				''
			\end{itemize}
			\item 
			(2.3) Three correlation measures are employed to estimate how the generated summaries are correlated to the golden standards (ref. Table 9), however how these correlation measures are computed is not defined and/or explained.
			\begin{itemize}
				\item[] \textbf{AUTHORS' RESPONSE}: 
			
		    	Considering the Reviewer's suggestion, we have added the explanation of
				correlation measures to evaluation metrics in Section 4.2 (line 277-295, page 17-18).
				The details are as follows:

			    \hspace*{0.6cm}
				``
				Repeatedness Correlation measures test how well 
				the total repeatedness scores of summaries generated by each model
				correlate with total repeatedness scores of reference summaries. 
				The correlation is evaluated with a set of
				three metrics, including Pearson correlation (r),
				Spearman rank coefficient ($\rho$), and Kendall's tau coefficient ($\tau$).

			    \hspace*{0.6cm}
				Given total repeatedness scores of reference summaries (ref) and 
				their corresponding generated summaries (gen),
				$X=score(ref)=(x_1, x_2,..., x_n)$ and 
				$Y=score(gen)=(y_1, y_2,..., y_n)$, 
				we can get paired data $(X,Y)={(x_1, y_1), (x_2, y_2),..., (x_n, y_n)}$.
				$n$ is the number of pairs.

				\begin{itemize}	
				\item[-] For Pearson correlation (r),
				\begin{equation}
				r = \frac{\sum_{i=1}^{n}(x_i - \overline{X})(y_i - \overline{Y})}
					{\sqrt{\sum_{i=1}^{n}(x_i - \overline{X})^{2}\cdot\sum_{i=1}^{n}(y_i - \overline{Y})^{2}}}
			    \nonumber
				\end{equation}
				where $\overline{X}$ and $\overline{Y}$ are the mean of variables of $X$ and $Y$.

				\item[-] For Spearman rank coefficient,
				\begin{equation}
			    \nonumber
				\rho = \frac{\sum_{i=1}^{n}(R(x_i) - \overline{R(X)})(R(y_i) - \overline{R(Y)})}
					  {\sqrt{\sum_{i=1}^{n}(R(x_i) - \overline{R(X)})^{2}
					  \cdot\sum_{i=1}^{n}(R(y_i)-\overline{R(Y)})^{2}}}
				\end{equation}
				where $R(x_i)$ and $R(y_i)$ are the rank of $x_i$ and $y_i$.
				$\overline{R(X)}$ and $\overline{R(Y)}$ are the mean rank of $X$ and $Y$.
				\item[-] For kendall's tau coefficient,
				\begin{equation}
				\tau = \frac{n_c - n_d}{n_c + n_d} = \frac{n_c - n_d}{n(n-1)/2} \nonumber
				\end{equation}
				where $n_c$ is the number of \textit{concordant} pairs.
				$n_d$ is the number of \textit{discordant} pairs.
				Any pair of total repeatedness scores $(x_{i},y_{i})$ and $(x_{j},y_{j})$, where $i<j$.
				They are said to be \textit{concordant},
				if both $x_{i}>x_{j}$ and $y_{i}>y_{j}$; or if both $x_{i}<x_{j}$ and $y_{i}<y_{j}$.
				They are said to be discordant, if $x_{i}>x_{j}$ and $y_{i}<y_{j}$; 
				or if $x_{i}<x_{j}$ and $y_{i}>y_{j}$. 
				If $x_{i}=x_{j}$ or $y_{i}=y_{j}$, the pair is neither concordant nor discordant.
				\end{itemize}
				''
			\end{itemize}
			\item 
			(2.4) Significance test is conducted to check whether the performance improvement is statistically significant (ref. Table 11), however this significance test is not conducted w.r.t. each baseline, and hence it cannot provide sufficient information about whether the proposed method really performs significantly better than each individual baseline.
			\begin{itemize}
				\item[] \textbf{AUTHORS' RESPONSE}: 
				
				In this paper, we use Kruskal–Wallis test as our significance test, 
		        which is used for comparing two or more independent samples 
				of equal or different sample sizes.

                \hspace*{0.6cm} 
				Considering Reviewer's comments, we have done the t-test significance test between 
				our best method (ATTF+SBD) and each baseline on R-1/R-2/R-L.
				All the p-values are as follows: 
			    \begin{itemize}	
				\item[-] CNN:  R-1 \textit{2.32e-35}, R-2 \textit{6.34e-48}, R-L \textit{3.68e-10}
				
				\item[-] ITA:  R-1 \textit{6.14e-34}, R-2 \textit{2.12e-48}, R-L \textit{5.67e-12} 

				\item[-] ITDA:  R-1 \textit{2.76e-32}, R-2 \textit{4.52e-44}, R-L \textit{3.94e-11}

				\item[-] COV:  R-1 \textit{4.14e-30}, R-2 \textit{4.61e-50}, R-L \textit{7.12e-12}

				\item[-] COVP:  R-1 \textit{2.51e-32}, R-2 \textit{3.17e-41}, R-L \textit{2.15e-10}

				\item[-] SCL:  R-1 \textit{3.11e-32}, R-2 \textit{3.29e-44}, R-L \textit{3.43e-15}
				
				\item[-] TRI: R-1 \textit{5.25e-30}, R-2 \textit{1.33e-43}, R-L \textit{3.67e-12}
				\end{itemize}
                
                The table about correlation are added in Section 4.4 (Table 12, page 26). 
				
				We revise:
				``We take Kruskal-Wallis test [43, 44] as our significance test to
				measure that the ROUGE scores are significant or not. As shown in Table 11, all
				p-values are less than 0.05.''
				
				to 
 
				`` We take t-test as our significance test to
				measure that the ROUGE scores between our proposed approach (ATTF+SBD) and each baseline
				are significant or not. As shown in Table 11, all
				p-values are less than 0.05.''(line 402-405, page 25)
			\end{itemize}
			\item 
			(3) Presentation of the main idea: The manuscript needs more careful proof-reading.

            (3.1) There are many grammatical problems and/or typos.
			\begin{itemize}
				\item[] \textbf{AUTHORS' RESPONSE}: 
				
				We are very sorry for our incorrect writing.
				We have proofreading the paper thoroughly and fixed those errors.

                \hspace*{0.6cm}
				For example,
				the statements of 
				``We expect that other natural language generation (NLG) tasks 
				with repetition problem can be enhances with our approach.''
				are changed as
				``We expect that other natural language generation (NLG) tasks 
				with repetition problem can be enhanced with our approach.''
			\end{itemize}
			\item 
			(3.2) Main equations in the paper are not defined and explained clearly. For example, in Equation 1, ``T'' is not defined, and the relationship between it and ``n'' is not explained either. In Equation 2, ``W'' and ``b'' are not defined. Both Equations 7 and 9 mentions ``vs'', which seems to have different meanings. In Equation 7, ``vs'' denotes a position, but in Equation 9, it becomes ``the maximum value in v that is smaller than i,'' and moreover ``i'' is not an index in Equation 9. Equation 12 should be revised as it returns a value (0 or 1) rather than a result by a logical operation (OR), and the variable ``o'' is actually determined based on two sentences (p and q) and hence it should be something like ``o(p,q)''.
			\begin{itemize}
				\item[] \textbf{AUTHORS' RESPONSE}: 
				
				We are very sorry that we did not explain the main equations clearly.
				According to Reviewer's comments, we explain in detail as follows:
				\begin{itemize}
				\item[-] ``T'' in Equation 1 is the length of output (summary), which is equal to ``n''.
				Thus, the Equation 1 is changed as (Equation 1, page 9):
						\begin{equation} 
						\small
						p(\textbf{y} | \textbf{x}) \!=\! {\prod^n_{t} {p(y_{t} | y_{1}, y_{2},..., y_{t-1}, \textbf{x}})} \nonumber
						\end{equation}
			    \item[-] Equation 2:
						\begin{equation}
						\small
							h _ { i } ^ { l } = GLU \left( W ^ { l } \left[ h _ {i-k/2 } ^ { l - 1 } , \ldots , h _ { i+k/2 } ^ { l - 1 } \right] + b _ { w } ^ { l } \right) + h _ { i } ^ { l - 1 } \nonumber
						\end{equation} 
				In Equation 2, ``W'' and ``b'' are trainable parameters (the first line after Equation 2, page 10).
				\item[-] ``$v_{s}$'' denotes the position in Equation 7 and Equation 9.
				$v_{s}$ is the $s$-th element of ``\textbf{v}''.
				``\textbf{v}'' denotes the positions of $<$S$>$ in summary (line 172, page 10).
				So, ``$v_{s}$ is the maximum value in \textbf{v} that is smaller than i''
				means that $v_{s}$ in Equation 9 still denotes a position.
				\item[-] Equation 9 is a part of Equation 10. 

				Equation 9:
				\begin{equation}
				\small
				    e_{s} = \min \limits_{A_{s}}\left(\frac{A_{sj}^{l}}{v_{s}-v_{s-1}-1}\right) \nonumber
				\end{equation}
				
				Equation 10:
				\begin{equation}
				\small
				    \tilde{a}_{ij}^{l} = a_{ij}^{l}\prod_{q=0}^{s}g_{qj} + e_{s}g_{sj}' \nonumber
				\end{equation}

				``i'' is the index in Equation 10.
				To eliminating ambiguity, we combine Equation 9 and Equation 10 as follows (Equation 9, page 12):
				\begin{equation}
				\small
					\tilde{a}_{ij}^{l} = a_{ij}^{l}\prod_{q=0}^{s}g_{qj} + \min \limits_{A_{s}}\left(\frac{A_{sj}^{l}}{v_{s}-v_{s-1}-1}\right)g_{sj}'
					\nonumber
				\end{equation}
				\item[-] We have re-written Equation 12 (Equation $11$ in revised manuscript) according to the Reviewer's suggestion.
				The details are as follows (Equation 11 and line 235-237, page 15):
				
				``
				To determine whether two sentences, 
				$p$ and $q$, are similar, we define a boolean function as:
				\begin{equation}\label{eq:s}
				\small
					sim(p,q) = 
					\begin{cases}
						   1 &\mbox{if $o(p,q) > n\text{ OR }o(p,q) > \frac{1}{2}\cdot l$}\\
						   0 &\mbox{others}
				   \end{cases}
				   \nonumber
				\end{equation}
				where $o(p,q)$ denotes the length of 
				the longest common substring (LCS) between $p$ and $q$, 
				$l$ is the minimum of the lengths of $p$ and $q$, and $n$ is a constant. 
				$sim(p,q)=1$ means the two sentence are similar.
				''
				\end{itemize}
             
                \hspace*{0.6cm} 
                We have made correction in Section 3.1 and 3.2 
				according to Reviewer's comments and above explanation.
			\end{itemize}
			\item
			(3.3) The main idea of Figure 4 should be explained more clearly, as the figure employs undefined notations (e.g., numbers, circles, … etc.) and it is hard to correlate the main idea to its corresponding paragraph in the main text.
			\begin{itemize}
				\item[] \textbf{AUTHORS' RESPONSE}: 

				To explain Figure 4 more clearly, 
				we revised the figure (shown in revised manuscript) and 
				added explanation of undefined notations to the caption of Figure 4 as follows:
				
				\hspace*{0.6cm}
				``
				This figure shows the progress of generating summary at test. The circles denote the
				candidate words (choices) in vocabulary, 
				which are sorted by the probability of being selected in
				descending order. Each circle at level $l$ has $N$ choices 
				at level $l+1$. $N$ is the number of words in vocabulary. 
				The number in circles is the order of these choices according to the
				probability. The generation order is from level 1 (top) to level 3 (bottom).
				''
				(page 13)

				\hspace*{0.6cm}
				The corresponding paragraph of Figure 4 are change as
				``
				However, this is sub-optimal 
				because the parents of the current top b choices may not include all
				the top b choices at the parent level. 
                Here b is the beam size.
				As shown in Figure 4, suppose that level 3 is the beginning of the repeated segment,
				the first choices at level 1 and 2 are excluded by beam search.

				\hspace*{0.6cm}
				An alternative approach (SBD-b2) backtracks all the way until the current top b
				choices all share the same prefix token sequence. ... 
				While this algorithm backtracks further and may include better
				choices, it doesn't completely solve the problem of SBD-b1.
				As shown in Figure 4, suppose that level 3 is the beginning of the repeated segment
				and the second candidate word in level 1 is the only prefix token sequence 
				of top b choices in level 2,
				the first and third choices at level 1 are excluded by beam search
				after generating words based on second choice in level 1.
				''
				(line 208-221, page 13-14)
			\end{itemize}
			\item 
			(3.4) The idea of the ``best approach (SBD)'' is not presented clearly. Perhaps an example and/or a figure can be employed to illustrate the idea.
			\begin{itemize}
				\item[] \textbf{AUTHORS' RESPONSE}: 
				
				According to Review's suggestions, we add an example to the corresponding paragraph
				of ``best approach (SBD)'' as follows (line 225-234, page 14):

				\hspace*{0.6cm}
				``
				Example:
				\begin{itemize}
				\item[-] \textbf{Basic CNN}:
				\small{
				the couple announced the arrival of their son.
			    the couple announced the pregnancy in january.
				\textit{the couple announced the pregnancy in january. (repeated segment)}
				}
				\item[-] \textbf{CNN+SBD-b1}:
				\small{
				the couple announced the arrival of their son.
				the couple announced the pregnancy in january.
				\underline{silas was the middle name of timberlake 's maternal grandfather.}
				}
				\item[-] \textbf{CNN+SBD-b2}:
				\small{
				the couple announced the arrival of their son.
				\underline{silas randall timberlake , died in 2012.}
				}
				\item[-] \textbf{CNN+SBD}:
				\small{
				the couple announced the arrival of their son.
                they announced the pregnancy in january, with an instagram post.
				}
				\end{itemize}

				As shown in above example (Table 4, page 14), 
				SBD-b1 and SBD-b2 backtrack the generator process
				to ``january.'' and ``son.'' respectively.
				The summaries generated by SBD-b1 and SBD-b2 
				are incoherence and inconsistent with the source document.
			    Our best approach (SBD) will save the sequence before repeated segment, i.e., 
				`\textit{
				the couple announced the arrival of their son.
				the couple announced the pregnancy in january.}
				'
				and backtrack to the beginning of the summary and regenerate the summary. 
				When the saved sequence appears in the beam, we remove the first word (``the'') in 
				repeated segment from the choices vocabulary. 
				Compared with SBD-b1 and SBD-b2, SBD generates more fluent and coherence summaries.
				
				''
			\end{itemize}
		\end{enumerate}
	
	
		We appreciate the hardwork by the editors and the reviewers,
		and hope that our revision meets their requirements.
		
		Once again, thank you very much for  your comments and suggestions.
		
		
		\closing{Sincerely yours,}
		
		
		%\encl{Curriculum vitae, employment form} % List your enclosed documents here, comment this out to get rid of the "encl:"
		
		%----------------------------------------------------------------------------------------
		
	\end{letter}
	
\end{document}
