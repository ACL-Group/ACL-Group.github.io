\section{Conclusion}
\label{sec:conclude}
Abstractive summarization plays an important part in natural 
language processing (NLP) tasks.
Its goal is to generate a short summary which expresses the main ideas 
of the source document.
Convolutional neural networks (CNNs) have
met great success in abstractive summarization.
Compared with recurrent neural networks, 
CNNs are more effective and can be trained much faster due to 
its intrinsic parallel nature and more stable gradients.
However, we find that repetition is a persistent problem in the task of CNN seq2seq abstractive summarization. 

In this paper, we focus on the repetition problem in abstractive summarization based on CNN seq2seq model with attention mechanism.
We analyze two possible reasons behind the repetition problem in abstractive
summarization: (1) attending to the same location in source,
and (2) attending to similar but different sentences in source. 
In response, 
we presented two methods to modify existing CNN seq2seq model, i.e.,
a section-aware attention mechanism (ATTF)
and a sentence-level backtracking decoder (SBD). 
The ATTF can record previously attended locations in the source document directly 
and prevent decoder from attending to these locations. 
The SBD prevents the decoder from generating similar sentences more than once via backtracking at test.
The proposed models are able to train a model that produces 
summaries with natural level repetition that are fluent and coherent. 
It means that the summaries generated by our model are more accurate and 
readable. This can help user quickly get the main information from large of textual data,
saving the reading time and improving reading efficiency.
As some other natural language generation (NLG) tasks based on seq2seq model with attention mechanism
are orthogonal to our proposed methods,
they can also be enhanced with our proposed models.
In order to assess the effectiveness of our proposed approaches in repetition reduction, 
we presented two evaluation metrics: \textit{Repeatedness} and \textit{Repeatedness correlation}.
Repeatedness measures the repetition rate of N-grams and sentences in summaries. 
Repeatedness correlation tests how well the repetition of generated summaries 
correlate with natural level repetition.
We also argue that ROUGE is not a perfect evaluation metric for the abstractive 
summarization. The standard ROUGE scores cannot capture grammatical or factual errors.
Thus, we proposed Readability score to complement ROUGE scores.
Readability is an human evaluation, which measures the fluency and readability of the
summary. 
Our approach outperforms the baselines in 
all evaluation metrics, including ROUGE scores, repeatedness, 
repeatedness correlation and readability.
