\section{Introduction}
\label{sec:intro}

Abstractive summarization is the task of creating a short, accurate,
informative and fluent summary from a longer text document.
It attempts to reproduce the semantics and topics of original text
by paraphrasing. 
Recently, sequence to sequence
models~\citep{RushCW15,ChopraAR16,NallapatiZSGX16,SeeLM17,PaulusXS17}
have made great progress on abstractive summarization.
A recent study~\citep{bai2018empirical} suggests that, 
without additional, complicated structures or features,
convolutional sequence to sequence 
(CNN seq2seq) models~\citep{gehring2017convs2s,FanGA18,LiuLZ18} 
are more effective and can be trained much faster due to 
their intrinsic parallel nature compared to recurrent neural networks (RNN).
Furthermore, unlike RNN-based models, 
the convolutional models have more stable gradients 
because of its backpropagation paths. 
Self-attention-based model is 
the basis of many recent state-of-the-art systems,
which always need multi-layer self-attention and have greater computational complexity than CNN seq2seq models \citep{CompareTrans}.
Thus, we take CNN seq2seq models as the target model to improve on and
compare with in this paper.

Unfortunately, just like RNN-based models, CNN-based models also produce
summaries with substantial repeated word sequences which impacts the reading efficiency.
\tabref{tab:example} illustrates one 
test case from the CNN/Daily Mail summarization dataset. 
In this case, the basic CNN produces two 
identical sentences (italicized) in the result. 
Unlike machine translation or paraphrasing in which the output words
and input words are almost one-to-one aligned, the output of summarization
is ``compressed'' from the input document. Naturally, every sentence or 
word sequence in the summary corresponds to one or more places in the source
document. If there were two identical word sequences in the summary,
they might be looking at and summarizing the same ``spots'' in the source.
This is evident from the attention map for the three sentences generated by 
CNN, shown in \figref{fig:attn_map}. The 1st and 3rd sentences attend to
the same location in the source (red boxes), 
while the 2nd sentence attends to another separate location in the source (green box). 
The two attention maps in the red boxes are very similar.

\begin{table}[th!]
\centering
%\captionsetup{justification=centering}
\caption{Summary generated by the basic CNN model. 
	The parts of source document and summary in the same color denote that they are aligned by the CNN.
}
\begin{tabular}{|l|}
\hline \bf Source Document \\
\hline ...manchester city are rivalling manchester united and arsenal for valenciennes \\
       teenage defender dayot upamecano . \textcolor{green}{the 16-year-old almost joined united in} \\
	   \textcolor{green}{the january transfer window ,} only for him to opt to stay in france for a few \\
	   more months . centre-back umecano has played for france at u16 and u17 \\
	   level . monaco , inter milan and paris stgermain had also expressed interest. \\
	   \textcolor{red}{fourth-placed city face aston villa at the etihad stadium on saturday .}...\\
\hline \bf Reference summary \\
\hline dayot upamecano was close to signing for manchester united in january . \\
       the 16-year-old, however , opted to stay in france with valenciennes . \\
	   centre-back upamecano has played for france at u16 and u17 level . \\
	   arsenal are also interested in the defender as man city join chase . \\
\hline \bf Basic CNN model (CNN) \\
\hline \textcolor{red}{\textit{manchester city face aston villa at the etihad stadium on saturday .}}\\
       \textcolor{green}{the 16-year-old almost joined united in the january transfer window .}\\
	   \textcolor{red}{\textit{manchester city face aston villa at the etihad stadium on saturday .}}\\
\hline
\end{tabular}
\label{tab:example}
\end{table}


\begin{figure}[th!]
\centering
\subfigure[Attention distribution]{
\includegraphics[width=0.9\linewidth]{map}
}
\quad
\subfigure[Green box]{
\includegraphics[width=0.44\linewidth]{map_1}
}
\quad
\subfigure[Red box]{
\includegraphics[width=0.44\linewidth]{map_2}
}
\caption{Attention for example on CNN model in \tabref{tab:example}}
\label{fig:attn_map}
\end{figure}

Driven by this intuition, a few efforts have been made on ``remembering''
what has been focused on before at decoding. 
For example, 
\cite{PaulusXS17} and 
\cite{FanGA18} use intra-temporal 
attention~\citep{NallapatiZSGX16} as well as intra-decoder attention to avoid
attending to the same parts in the source by 
revising attention scores while decoding. 
\cite{SeeLM17} and \cite{GehrmannDR18}
respectively propose coverage mechanism and coverage penalty,
which records the sum of attention distributions of all previously generated words 
%to keep track of what has been summarized in different way.  
in a different way to track the summarized information.  
While these approaches discourage repetition to some extent,
they do so in an indirect manner. That is, they do not 
make use of the attention information in source directly.
Consequently, they may still generate repeated phrases, 
especially in long sentences (shown in the first 5 sections of
\tabref{tab:strong_methods}).


\begin{table}[th!]
\begin{center}
\caption{\label{tab:strong_methods} Generated summaries of the source in \tabref{tab:example}. The sentences in \textit{italicized} are repetitve sentences.
Each summary segment and its attended POI in source document are in the same color.}
\begin{tabular}{|p{13cm}|}
\hline \bf Source Document \\
\hline ... \textcolor{blue}{manchester city are rivalling manchester united and arsenal for valenciennes teenage defender dayot upamecano .} \textcolor{green}{the 16-year-old almost joined united in the january transfer window ,} \textcolor{brown}{only for him to opt to stay in france for a few more months .}  \textcolor{purple}{centre-back umecano has played for france at u16 and u17 level .} \\
monaco , inter milan and paris stgermain had also expressed interest. \textcolor{red}{fourth-placed city face aston villa at the etihad stadium on saturday .} ...\\
\hline \bf Intra-temporal attention (ITA) \\
\hline \textcolor{red}{\textit{manchester city face aston villa at the etihad stadium on saturday .}} \\
          \textcolor{red}{\textit{manchester city face aston villa at the etihad stadium on saturday .}} \\
\hline \bf Intra-temporal $+$ Intra-decoder (ITDA) \\
\hline \textcolor{blue}{\textit{manchester city are rivalling manchester united and arsenal }for valenciennes teenage .}\\
        \textcolor{red}{manchester city face aston villa at the etihad stadium on saturday .} \\
	   \textcolor{blue}{\textit{manchester city are rivalling manchester united and arsenal }. }\\
\hline \bf Coverage model (COV) \\
\hline \textcolor{red}{\textit{manchester city face aston villa at the etihad stadium on saturday .}} \\
       \textcolor{blue}{manchester city are rivalling manchester united and arsenal for valenciennes .}\\
      \textcolor{red}{\textit{manchester city face aston villa at the etihad stadium on saturday .}} \\
\hline \bf Coverage penalty (COVP)\\
\hline \textcolor{red}{\textit{manchester city face aston villa at the etihad stadium on saturday .}} \\
      \textcolor{red}{\textit{manchester city face aston villa at the etihad stadium on saturday .}} \\
	   \textcolor{blue}{manchester city are rivalling manchester united and arsenal .}\\
\hline \bf Semantic cohesion loss (SCL) \\
\hline \textcolor{blue}{\textit{manchester city are rivalling manchester united and arsenal for} defender dayot upamecano .}\\
       \textcolor{blue}{\textit{manchester city are rivalling for} valenciennes teenage.} \\
\hline \bf Diverse Convolutional Seq2Seq  Model (DivCNN) \\
\hline \textcolor{red}{manchester city face aston villa at the etihad stadium on saturday . } \\
\underline{\textcolor{green}{the 16-year-old}} has played \textcolor{brown}{for} \underline{\textcolor{brown}{france}}  \textcolor{brown}{for a few months.}
\vspace{0.2mm} \\
\hline \bf Trigram decoder (TRI) \\
\hline \underline{\textcolor{blue}{defender dayot upamecano}} has played \textcolor{purple}{for} \underline{\textcolor{purple}{france}} \textcolor{purple}{at unk and unk level .}\\ 
       \textcolor{red}{manchester city face aston villa at the etihad stadium on saturday .} \\
\hline \bf Ours (Attention Filter + Sentence-level Backtracking decoder) \\
\hline \textcolor{red}{manchester city face aston villa at the etihad stadium on saturday .} \\
       \textcolor{green}{the 16-year-old almost joined united in the january transfer window .}\\
	   \textcolor{blue}{manchester city are rivalling manchester united and arsenal for teenage defender daypot upamecano .}\\
\hline
\end{tabular}
\end{center}
\end{table}

In this paper, we propose an attention filter mechanism that directly 
redistributes the attention from each word in the output summary to the source. 
It does so by computing the \textbf{parts of interest (POIs)} 
in the source per segment in the summary
%\footnote{In this paper, a segment means a sentence or clause delimited by punctuation.}, 
and then minimizing the attention scores of
words in these POIs that have already been attended to by the preceding 
segments during decoding. 
POIs are the segments of the source document that are attended by the segments in its corresponding summary, 
such as the green and red segments of source document in \tabref{tab:example} and \figref{fig:attn_map}.
Different segments in summary thus do not attend to the same semantic spots
of source, and repetition is reduced. 
%A segment means a sentence or clause delimited by punctuation,
%which carries syntactic and semantic information. 
%It is very simple but effective. Since punctuations 
%play an important role in written language to organize 
%the grammatical structures and to clarify the meaning of sentences.~\citep{briscoe1996,Kim19,LiWE19}
%Specifically, we calculate the attention in terms of segments, 
%larger semantic units than tokens, 
%which intuitively helps with emphasis of attention and POIs in source.
We can get segments in different ways.
%We use punctuations to separate the source or target into segments,
%since punctuations play an important role in written language to organize
%the grammatical structures and to clarify the meaning of sentences.~\citep{briscoe1996,Kim19,LiWE19}
As shown in \tabref{tab:punct}, we compare the segments in different types.
The baseline with sentence as a segment (sentence-level segment) 
always loses important information in reference summary, such as ``silas randall timberlake''.
The first sentence in generated summary based on sentence-level segment attends to 
the second sentence in source. 
The attention score of second sentence in source is minimized,
and this source sentence is no longer attended. 
So, the model with sentence-level segment loses the important information ``silas randall timberlake''
during decoding.
The baseline with N-gram as a segment (N-gram segment) may bring about grammatical and semantic problems.
Suppose that $N$ equals to 3~\footnote{We set $N$ as 3 because ground-truth summaries almost never contain the same trigram twice.}, 
as shown in \tabref{tab:punct},
the green part of generated summary based N-gram segment does not attend to the ``the couple announced''
in source document. 
As N-gram cannot be seen as a complete and accurate semantic unit,
the decoder of model with N-gram segment attends to the segment in source with inaccurate grammar and semantics.
Thus, the generated summary based on N-gram segment has grammatical and semantic errors.
We use punctuations to separate the source or target into segments,
since punctuations play an important role in written language to organize
the grammatical structures and to clarify the meaning of sentences.~\citep{briscoe1996,Kim19,LiWE19}
It is very simple but effective. 
In this paper, a segment means 
a sentence or clause delimited by punctuation,
which carries syntactic and semantic information. 
Specifically, we calculate the attention in terms of segments 
(larger semantic units than tokens and smaller semantic units than sentences)
which intuitively helps with emphasis of attention and POIs in source.
This is different from previous approaches
which all do not exactly pinpoint these parts in the source,
which we believe is critical in reducing repetition. 
%This kind of partial attention 
%can help us to pinpoint the corresponding location that each segment is
%attending to. Then we use attention filter to filter
%a partial attention from normal attention of each tokens in the other sections
%by minimizing the attention scores of attended location in source document.
%This can optimize the alignment relationship between source document and 
%summarization.  This is shown in \tabref{tab:attn_exp}. 

\begin{table}[th!]
\begin{center}
\caption{The summary generated by attention filter mechanism with different type of segments. 
The parts of text in different colors denote segments. The segments in the same color attend to the same POI in the source.}
\begin{tabular}{|l|}%{|p{7cm}|rl|}
\hline 
\textbf{Source} \\
\hline 
(1)justin timberlake and jessica biel , welcome to parenthood . \\
(2)the celebrity couple announced the arrival of their son , silas randall timberlake, ... \\
(3)silas was the middle name of timberlake ’s maternal grandfather bill bomar , who died in 2012 .\\
(4)the couple announced the pregnancy in january , ... \\
(5)it is the first baby for both .  \\
\hline 
\textbf{Reference} \\
\hline 
timberlake and jessica biel welcome son silas randall timberlake. \\
the couple announced the pregnancy in january . \\
\hline 
\textbf{Sentence-level segment} \\
\hline \textcolor{blue}{the couple announced the arrival of their son .} \\
	   \textcolor{brown}{it is the first baby for both} \textcolor{black}{.}  \\
\hline 
\textbf{N-gram segment} \\
\hline \textcolor{blue}{the couple announced} \textcolor{green}{silas randall timberlake} \textcolor{red}{pregnancy in january }  \textcolor{black}{.}\\
\hline
\textbf{Segment: a sentence or clause delimited by punctuation} \\
\hline \textcolor{blue}{the couple announced the arrival of their son ,} \textcolor{green}{silas randall timberlake .} \\
       \textcolor{red}{the couple announced the pregnancy in january .} \\ 
	   \textcolor{brown}{it is the first baby for both} \textcolor{black}{.} \\
\hline 
\end{tabular}
\label{tab:punct}
\end{center}
\end{table}

Despite the above effort, there are cases, where similar sentences 
exist in the same source document:
\begin{example}
\label{ex:repeatsrc}
%\fbox{
%\parbox{0.9\columnwidth}{
\small{``..the standout fixture in the league on saturday sees leaders 
	   chelsea welcome manchester united ... chelsea midfielder oriol romeu, 
\textbf{currently on loan at stuttgart}, ... romeu is 
\textbf{currently on a season-long loan at bundesliga side stuttgart.}''} 
%}}
\end{example}

In this case, even if the decoder attends to different POIs of 
source document as it produces words, repetition may still result.  
At different time steps, 
the decoder may attend 
to sentences that are similar in different positions.
One potential solution to this is semantic cohesion loss (SCL)~\citep{elikyilmazBHC18}
which takes the cosine similarity between two consecutively generated sentences
as part of the loss function. It may attend to the same POI
and generate similar sentences (SCL row in \tabref{tab:strong_methods}).  
The other is Diverse Convolutional Seq2Seq
Model (DivCNN)~\citep{DivC2C19}, 
which introduces Determinantal Point Processes (DPPs) \citep{DPPs11} into deep neural network (DNN) attention adjustment
DPPs can generate subsets of input with both high {\em quality} and high {\em diversity} (QD-score).
For abstractive summarization, DivCNN takes hidden states of DNN as QD-score.
DivCNN selects the attention distribution of the subsets of source with high QD-score
first and then adds selected attention distribution into model loss as a regularization.
DivCNN does not directly redistribut the attention,
so it may still attend to similar POIs.
In order to improve QD-score, DivCNN tends to attend to scattered subsets of sentences in source document,
which leads to semantic incoherence. 
As shown in \tabref{tab:strong_methods} (DivCNN row),
the content about the 16-year-old 
is inconsistent with source document.
Besides, trigram decoder (TRI)~\citep{PaulusXS17} 
directly forbids repetition of previously generated trigrams at test time. 
While this simple but crude method avoids the repeat of any kind
completely, 
it ignores the fact that \textit{some amount of repetition} may exist
in natural summaries.  
On the other hand, the meddling of the beam search at runtime causes another problem: 
it tends to generate sentences that are logically incorrect. 
In \tabref{tab:strong_methods} (TRI row), the defender dayot didn't
really play for France, according to the source.
That is, the subject and object are mismatched.
As trigram cannot reflect the complete semantic information, 
trigram decoder always generates logically incorrect summaries 
due to the trigram-based meddling of beam search 
during testing. 
In order to avoid the logical incorrectness caused by trigram decoder,
we introduce  a {\em sentence-level} backtracking decoder
that prohibits the repeat of same sentence at test time. 
Compared with trigram decoder, 
sentence-level backtracking decoder can avoid repetition and generate more logical summaries. 
Our summary produced for the example is shown in last section of 
\tabref{tab:strong_methods}.

%In multiple-sentence summarization task, we observe that more often than not, repetition 
%occurs in the form of the same or similar sentences, rather than repetitive phrases 
%inside sentences. 
%On the other hand, it is prone to grammatical and factual errors(\tabref{tab:attn_exp}).
%Because it detects repetitive trigrams only by setting the 
%probability of the third word to zero. 
%It ignores that there are some same N-gram in the target summaries.
%The natural generation of a sentence is disturbed, giving rise to, 
%for example, mismatch of subject and object, and wrong phrases. 
%summarization is not a text generation problem which are are almost
%one-to-one correspondence between input and output words, it requires the model 
%has the ability to decide where to attend and where to ignore.
%The reason for repetition in abstractive summarization based on CNN seq2seq models is
%that the models always attend to the same location in the source document.
%As shown \tabref{tab:attn_exp} 
%and \figref{fig:attn_map} are corresponding. 
%Sentence in blue has factual erro. and \figref{fig:attn_map}.
%In the attention map, the darker color, the higher attention score.
%the repeated sentence in summary attends to the same location
%with high attention score, and different sentences attend to different location in source document. 
%

%Zhou~\cite{ZhouYWZ17} pointed out that there is no obvious alignment relationship 
%between the source text and the target summary, 
%and the encoder outputs contain noise for the attention. 
%Thus, removing repetition in abstractive summarization on CNN seq2seq model
%need a strong attention mechamism that can get alignment relationship
%between source document and target summary and determine the summarized
%parts in source documents directly. 


Reducing repetition in abstractive summarization provides high-quality summaries for users and improves their reading efficiency.
We expect that other natural language generation (NLG) tasks suffered from repetition problem can be enhanced with our approach. 
Our contributions are summarized as follows:
\begin{enumerate}
\item We find the reasons behind repetition problem in abstractive summaries generated
by CNN seq2seq models.
\item We propose new metrics to evaluate this problem: Repeatedness and Readability.
\item We propose an effective approach that redistributes attention scores 
during training time, and prevents repetition by sentence backtracking
at runtime to reduce repetition in CNN seq2seq model.
\item Our approach
outperforms the state-of-the-art (SOTA) repetition reduction approaches on CNN-based models
substantially by all evaluation metrics, including ROUGE scores, 
repeatedness and readability.
\end{enumerate}

Next, we present the basic CNN seq2seq model and our extension, 
followed by the evaluation of our approach and a discussion of related work.
