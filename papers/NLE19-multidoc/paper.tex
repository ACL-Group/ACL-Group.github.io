% nleguide.tex
% v1.0, released 31 Jan 2019
% Copyright 2019 Cambridge University Press

\documentclass{nle}

\usepackage{natbib}
\usepackage{url}

\usepackage{soul}
\usepackage{algorithm}
\usepackage{algorithmic}
\urlstyle{same}

\usepackage{helvet}
\usepackage{courier}
\usepackage{color}
\usepackage{graphicx}
\usepackage{epsfig}
\usepackage{booktabs}
\usepackage{diagbox}
\usepackage{array}
\usepackage{multicol}
\usepackage{threeparttable}
\usepackage{epstopdf}
\usepackage{listings}
\usepackage{multirow}
\usepackage{subfigure}
\theoremstyle{definition}
\newtheorem{example}{Example}

\usepackage{amsmath}

\newcommand{\secref}[1]{Section \ref{#1}}
\newcommand{\figref}[1]{Figure \ref{#1}}
\newcommand{\eqnref}[1]{Eq. (\ref{#1})}
\newcommand{\tabref}[1]{Table \ref{#1}}
\newcommand{\exref}[1]{Example \ref{#1}}
\newcommand{\cut}[1]{}
\newcommand{\tabincell}[2]{\begin{tabular}{@{}#1@{}}#2\end{tabular}}

\newcommand{\KZ}[1]{\textcolor{blue}{Kenny: #1}}
\newcommand{\YZ}[1]{\textcolor{red}{Yizhu: #1}}


\begin{document}
\label{firstpage}

\lefttitle{\LaTeX\ Supplement}
\righttitle{Natural Language Engineering}

\papertitle{Article}

\jnlPage{1}{00}
\jnlDoiYr{2019}
\doival{10.1017/xxxxx}

\title{Natural Language Engineering: \LaTeX Guidelines for~authors}

\begin{authgrp}
\author{Cambridge Author}
\affiliation{Electronic Products and Composition Group,\\
        Printing Division, Cambridge University Press, CB2 2BS\\
        \email{texline@cambridge.org}}
\end{authgrp}

\history{(Received xx xxx xxx; revised xx xxx xxx; accepted xx xxx xxx)}
%\received{20 March 1995; revised 30 September 1998}

\begin{abstract}
Convolutional sequence to sequence (CNN seq2seq) models
have met great success in abstractive summarization. 
However, their outputs often contain repetitive word sequences and logical
inconsistencies, limiting the practicality of their application.
In this paper, we propose to reduce the repetition in output summaries
by dynamically redistributing attention over the input sequence as
the output sentences are generated.
The results show that this approach 
generates high-quality summaries with minimal repetition, 
and outperforms the baselines 
in terms of
ROUGE score, repeatedness, and readability.
\end{abstract}

\maketitle

%\input{intro}
%\input{approach}
%\input{eval}
\input{related}
\input{conclude}


\bibliography{summarization}
\bibliographystyle{nlelike}

\label{lastpage}

\end{document}
