Much appreciation to all reviewers for the valuable comments!
We'll release our improved datasets and open-source tool
to the web once the paper is accepted. 

## Review1
- To show the effectiveness of our lexicon, we conduct further experiments 
using the 3 other lexicons from WordNet, each with 3k~4k words, similar to ours. 

- ----Spearman|Pearson| MAP	  
- noun | 0.564 | 0.562 | 0.756
- verb | 0.615 | 0.618 | 0.779
- adj. | 0.636 | 0.639 | 0.800 
- Ours | 0.676 | 0.671 | 0.834

- We can see that our lexicon containing social terms clearly 
outperforms the other types of lexicons by all measures.
See ''Review3'' for comparisons with other methods. 

- We chose to annotate the data for experiment1 this way mainly to avoid
subjectivity and keep efficiency. 
We argue that since the shown words come from online social media, 
the "social elements" are already embedded in the choice of these words,
please consider the example of ``Nagoya'' in Tabel1.

- As bilingual lexicon induction for slang is still a novel and open problem, 
we believe both "dictionary explanation" and "direct mapping" are beneficial to 
the solution of the problem. In task 2, we actually first attempted the 
explanation task (given a slang term, find the most similar regular terms 
in another language), and then we take a step further to do 
direct mapping (find similar slang terms). The ground truth terms 
(“foolish” etc.) are only used for the quantitative evaluation for the former, 
hence they're regular terms.

- The word vectors used in ACS computation were obtained from a third-party pre-trained 
embedding (Stanford GloVe), over which we have no control. 
Table 6 actually shows “ACS sum” over 200 slang translations.  
(Many thanks! We'll explain these two details in the footnotes.)

- The asymmetry stems from the direction of obtaining the BL. 
We found that the quality of English-to-Chinese translation turns out better than Chinese-to-English translation, 
therefore we chose to build our framework in current direction.
If we had a better quality Chinese-to-English translation, we may very well
adopt your suggestion to design a symmetrical model.

## Review2 
- We followed the use of the term “socio-linguistic features/words” in 
Garimella(2016) (in our References). 
However, we'll follow your advice and perhaps rename it to "social terms", 
which essentially consists of terms describing various types of psychological processes(line 114-117 in paper). 
The annotators are Mandarin-English bilingual and this paper uses Chinese social media
on which Mandarin Chinese is almost exclusively used.
In conclusion, we'll emphasize the importance and application of this 
work such as the potential benefits to culture-sensitive machine translation, 
cross-cultural communication and sentiment analysis in bilingual texts.

## Review3
- In camera-ready, we'll put our work in a broader context of general bilingual word representation. Thank you very much. 

- We compared our method with Duong (2016), MultiCCA and MultiCluster using their code on GitHub. 
All these comparisons will be included in the final version.The results are as follows:

- ------------------Spearman---Pearson-----MAP
- MultiCCA(dim=150)-|0.278------0.298------0.623
- MultiCCA(dim=75)--|0.325------0.343------0.651
- MultiCCA(dim=50)--|0.337------0.364------0.656
- MultiClu(dim=100)-|0.365------0.388------0.693
- Duong(dim=100)----|0.618------0.627------0.785
- Ours--------------|0.676------0.671------0.834