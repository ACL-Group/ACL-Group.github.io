\chapter{Conclusion and Future work}
In this thesis, we introduced a new technology to recognize audio scene using knowledge base. Our system does not need manually labeled training data. Instead, we analyzed the drama scripts which can easily collected from Internet. At the same time, we used some knowledge base and sound search engine to build our audible events set, and downloaded and labeled audio clips automatically. When we analyzing the text data, we also built a probabilistic model between scenes and events. Then we trained GMM models for audible events. Using these models, we can infer scenes from an audio clip. In our experiments, our system can achieve $37\%$ accuracy in a 10-scene classification work.

Although our system achieved a good performance, there are still some improvements we could do:

\begin{itemize}
\item Enlarge text corpus to get more information.
\item Make the quality of training data higher, including audio clips and text corpus.
\item Use more relations found by Stanford NLP.
\item Besides using only events to recognize scene, take some global features in testing clips into consideration for recognition.
\item Use some other model like universal background model (UBM) to reduce the impact of noise.
\end{itemize}


