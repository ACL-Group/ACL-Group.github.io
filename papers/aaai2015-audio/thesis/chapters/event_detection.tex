\chapter{Environmental sound event detection}
There are thousands of common environmental sound event in our daily life. It is not a easy work to distinguish each of them. In this chapter, we will propose our method to detect sound event in an audio stream.

\section{Problem Description}
Given audio samples for each event, train a model to find out which audio events would most probably occur in a testing sample.

\section{Feature selection}
To train a model for each event, firstly we need to find a good way (feature) to describe out audio data. There are many features proposed by researchers. Usually, a piece of audio can be described by its temporal features and frequency features.

According some existing works\cite{1561288,1621215,mitrovic2010features, 4761905}, in audio processing, the mel-frequency cepstrum coefficients (MFCC) feature is a widely-used frequency domain feature, which can retain important information of audio and have good robustness. 

There are also some important temporal features. Short time energy is the energy of short segment. It is a simple and effective feature to distinguish voice segment and mute segment of an audio\cite{1181092}.

Zero crossing rate (ZCR) is another useful temporal feature. It is the rate at which the signal changes from positive to negative or back. ZCR can be used to distinguish sounds from environmental noise, since environmental noise usually have a larger ZCR.

In our work, we use short time energy to remove mute segments first. Then, we combine ZCR and MFCC as features, which will be used in our audio model proposed in next section.

\section{Model selection}
GMM and HMM are mostly used in these kind of problems. We will discuss both of them in the following sections.

\subsection{HMM-based event detection}
A type of audio event can be modeled as a left to right HMM, while each state of HMM is a GMM. This model is widely used, especially in automatic speech recognition. However, we implemented HMM for our problem and it does not work well. We believe HMM is not a good model for event detection, here are some reasons:
\begin{enumerate}
\item The quality of training samples is not good, unlike speech, it is very hard to collect good samples for environmental sound event.
\item For a given event, for example, {\em dog barking}, the training sample may contains several times of {\em dog barking}, repeatedly. It is not easy to break it to a {\bf single} {\em dog barking}. Although we can model the event as a cyclic HMM, it does not achieve good performance in practice.
\item We also find an interesting fact that for some of audio events, if we reverse the audio sample, it can still be recognized by human beings. Thus, we believe that markov process may not be able to describe an audio event.
\item HMM is a complex model, which may lead to overfitting when we do not have enough training data for some events.
\end{enumerate}
\subsection{GMM-based event detection}
A type of audio event can also be modeled as a GMM. We implement this and will discuss implementation details in chapter \ref{cha:sys}. To recognize events in an audio data, we can break the audio to some fixed length ($L$) pieces, with intersections. Then for each piece we have
\begin{equation}
\label{pp}
p(\mathbf{O}|\mathbf{\Theta}) = \prod_{i=0}^{L - 1}p(\mathbf{O_i}|\mathbf{\Theta}).
\end{equation}

According to equation \ref{GMM-p}, we can calculate the probabilities of each piece belonging to each event. After this, the events which are most probably occurring in an audio segment can be easily found.

