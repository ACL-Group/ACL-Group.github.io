\section{Taxonomy}
\label{sec:tax}
We use a taxonomy as the external classification knowledge for
conceptualizing the arguments of verbs.
A taxonomy is a directed graph $(V, E)$,
Here, $V$ is a set of terms, $E$ is a set of binary ``isA'' relations
\[E=\{(e,c)| e\in V, c\in V, e~ isA~ c\},\]
where $e$ is called an {\em entity},
$c$ is called a {\em concept}, and $c$ is said to {\em cover} $e$.
Most terms in $V$ are
both concepts and entities; terms with zero outdegree in the graph are entities only. 
In this paper, we consider two different taxonomies,
namely {\em WordNet}~\cite{miller1998wordnet} and {\em Probase}~\cite{wu2012probase}.
WordNet organizes words into sets of synonyms
(called {\em synsets}) along with ``isA'' relation between two synsets.
Each word may belong to multiple synsets and have multiple
hypernyms (concepts) or hyponyms (entities).
Probase covers a lot of named entities and multi-word expressions
(e.g., Microsoft, Star Wars) which may not be covered by WordNet.
This feature allows us to extract more precise arguments.

\section{Problem Formulation}
\label{sec:problem}

We begin with an informal definition of the
{\em argument conceptualization} problem.
Given a collection of argument instances of the same argument
type (e.g., object or subject) of a verb,
we want to pick $k$ concepts from the taxonomy
that subsume as many instances as possible.
We would also like these $k$ concepts to
have little overlap with each other.
The intuition is that each of the $k$ selected concepts represents a unique
sense with small semantics overlap and the $k$ concepts collectively cover the majority
uses of that verb.

We define semantics {\em overlap} between two concepts as:
$$Overlap(c_1,c_2)=\frac{|E_{c_1}\cap E_{c_2}|}{min\{ |E_{c_1}|,|E_{c_2}| \}},$$
where $E_c$ is the set of all entities covered by concept $c$ in
the taxonomy.

Then, we formulate the argument conceptualization problem as
a problem of finding maximum weighted $k$-cliques. Consider a \emph{concept graph}
$G=(C,L,W)$, which has a collection of concepts $C$ in a taxonomy,
and a set of edges $L$ in which each edge connects two concepts that
have an overlap less than a predefined threshold $\tau$. $W$ stands for
weights for the concepts in the graph.
Each weight intuitively represents the quality of
the concept with respect to the verb.

\figref{fig:graph_model} shows 4 concepts in an illustrative 2-dimensional
entity space (a), as well as their corresponding concept graph (b).
Each circle $c_i$ in (a) represents a set of entities covered by concept $c_i$.
Because the overlap between $c_0$ and $c_3$ and between $c_1$ and $c_3$ 
is high  ($>\tau$), (b) is a fully connected graph (clique) minus only
two edges: $l_{c_0,c_3}$ and $l_{c_1, c_3}$.

\begin{figure}[th]
\centering
\epsfig{file=figure/graph_model.eps,width=0.6\columnwidth}
\caption{(a) 4 concepts in the entity space
(b) corresponding concept graph
}
\label{fig:graph_model}
\end{figure}

The argument conceptualization problem is then transformed to
finding the $k$-clique with maximum combined weight.

A straightforward way to define the weight for each concept is
counting the number of argument instances it subsumes according to the
isA taxonomy (used as baseline method in \secref{sec:eval}).
This assumes that all argument instances of a verb are of
equal importance, which is not true in practice.
We thus generalize the importance of an argument $e$ to a verb $v$
by a quality function $Q_v(e)$, which we will discuss in detail
in \secref{sec:qe}.
Consequently, the weight of concept $c$ for verb $v$ is
defined as
\begin{equation}
w_v(c)=\sum_{e\in \{e|e\;\text{isA}\;c\}}{Q_v(e)}.
\end{equation}
The argument conceptualization problem is to find
a $k$-clique (which forms a concept set as $C_k$)
in the graph $G$ which maximizes
\begin{equation}
\label{eq:f}
f_v(C_k)=\sum_{c\in C_k}{w_v(c)}.
\end{equation}

We parameterize the number ($k$) of argument concepts of a
verb because i) different verbs have different number of senses; and ii)
even for the same verb, there is no agreement on the exact number of its
senses because one meaning can always be divided into a number of
finer-grain meanings.
For example, in Oxford English Dictionary~\cite{oxford},
the transitive verb ``eat'' has 4 senses (or definitions),
while in Cambridge Dictionary~\cite{cambridge} it has just one meaning.
