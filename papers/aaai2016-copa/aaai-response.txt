Thanks to the reviewers for their valuable comments. We clarify some
misunderstandings and doubts below.
 
# R1:
* "Eq(1) and Eq(2) are almost the same"

Eq1 and Eq2 are not the same. p(i_c|j_e) and p(j_e|i_c) capture necessity and sufficiency causality, respectively. For example, if (i_c,j_e) is pure necessity causality, ideally p(i_c|j_e) would be 1, because when we have j as effect(j_e), i must be its cause(i_c) due to its necessity, while p(i_c|j_e) becomes smaller when necessity decreases. Alpha is a penalty exponent for popular term i_c (Wettler,1993). Similarly, p(j_e|i_c) captures sufficiency.
 
* "not clear how was a causality network constructed...; Is it possible to acquire "knock" causes "invite"? not good at than verb-to-verb causality"
 
Verb causality (knock,invite) is acquired from the following sentences (identified by "If A, B" cue) in our corpus:
"I've wondered sometimes, if an angel knocked on my door, and I invited her in, and she asked me, ..."
 
Each term i (angel, knocked, ..) in the if clause (A) would be paired with each term j in B to form (i_c,j_e) causality pairs, including (knock,invite) with a high likelihood.
 
 
* "Hashimoto et al. would be relevant to this work"
Yes, we missed out these two papers and will include their references in Sec 4.1.
 
# R2:
* "I see that ... Or do you mean ratio? How did you compute the ratio and what is it supposed to show?"
Yes, this ratio is marked by the gray line in Fig 2, with the legend "ratio" at the bottom and tickers on the right hand side. We show diversity by the ratio between number of distinct pairs and number of total pairs in Fig. 2 (tickers on the left hand side).
 
* "When compared against ConceptNet..."
The non-causal pairs are those pairs related by "Causes", "CausesDesire" and "HasPrerequisite" in ConceptNet, but with negative votes. These pairs are specifically annotated by human to be false causal pairs (last para of Sec 3.1). In this work, we do not attempt to classify a pair of terms to be causal or non-causal,
but instead compute a causality strength between them. The effectiveness of this metric is illustrated by Fig. 4.
 
# R3:
 
* "In Table 2,..."
 
Ideally, we would evaluate different methods (i.e. PMI, CS and SVM) on all different data sources and compare the results. However, methods that require deep syntactic analysis cannot scale to some of the large data sources. Also, some methods are designed for certain data sources. Therefore we only show experiments where the method matches the data source.
 
* "can be useful for certain (simple) domains, like COPA, I don't see it really applies to many other (real) causal reasoning problems"
Causality knowledge is useful in solving commonsense reasoning problem, although it doesn't solve the problem by itself. The problems listed in Morgenstern 2015 are commonsense reasoning problems and not causal reasoning problem (e.g. COPA).

