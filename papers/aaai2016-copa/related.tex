\section{Related Work}
\label{sec:related}

We start by discussing previous work that extracts causal relation term
pairs from open domain text. Then we present various past attempts to 
solve the causality reasoning problem.
%and finally discuss earlier literature
%that motivates our method to computing causality strength between texts.
%Common ingredients in these
%approaches are word association or similarity measures, which are
%discussed last.

\subsection{Causal Relation Extraction}
Causal relation recognition and extraction
%are important for many NLP applications, such as
%text understanding, summarization and
can be seen as a pre-processing step of causal reasoning.
%Previous work on causal relation extraction is relatively sparse.
It naturally boils down to a binary classification problem of
causal/non-causal relations. Existing approaches focus on developing
hand-coded patterns and linguistic features and learning the
classifier to recognize and extract causal relation for their
systems~\cite{girju2003automatic,ChangC04,blanco2008causal}. 
Much of the work ignored how the text spans surrounding the causal cue
affects the semantics. Our causal relation extraction
step, instead,  benefits from these contexts and
constructs a much larger and more powerful causal network.
Moreover, previous work 
extracted specific types of causal pair, of either noun-noun, verb-verb or verb-noun
\cite{do2011minimally,riaz2014recognizing} 
causality. None of the previous work except for 
Do's~\shortcite{do2011minimally} 
provides a numerical metric to measure causal strength, 
hence cannot be extended to causal reasoning between short texts. 
Do's work is also of limited help because it only
measures causality strength between verbs. 
Our CausalNet contains causal strength between arbitrary texts, by using general web corpus and
extracting nouns, verbs, adjectives and
adverbs.

%%The existing approaches use hand-coded and domain-specific\ZY{?} patterns
%%to extract causal knowledge.
%Girju et al.
%\cite{girju2003automatic} were the first to work on causal relation discovery
%between nominals. They semi-automatically extracted causal cues, but only
%extracted noun category features for the head noun. Chang et al.
%\cite{ChangC04} developed an unsupervised method and
%utilized lexical pairs and cues contained in noun phrases as
%features to identify causality between them. Both of them ignored
%how the text spans surrounding the causal cue
%affects the semantics.  Our causal relation extraction
%step, instead,  benefits from these contexts and
%constructs a much larger and more powerful causal network.
%Blanco et al. \cite{blanco2008causal} used
%different patterns to detect the causation in long sentences that
%contain clauses.
%
%%We proposed numeric features based on that,
%%and get better results.
%Do et al. \cite{do2011minimally} introduced a form of association
%metric into causal relation extraction. They mainly focus on
%detecting causality between verbs and also worked with verb-noun
%causality in which nouns are drawn from a small predefined list.
%They used discourse connectives and similarity distribution to
%identify event causality between predicate, not noun phrases, but
%achieved a F1-score around 0.47. And most recently, Riaz et al.
%\cite{riaz2014recognizing} focus on noun-verb causality detection
%and extraction. None of the previous work except for Do's provides a
%causality metric, hence cannot be extended to commonsense causal
%reasoning task. Do's work is also of limited help because it only
%measures causality strength between verbs. Our CausalNet are
%constructed out of all types of words in web corpus, and as a result
%the framework on top of it can model the causal strength between
%arbitrary text units.

%\subsection{General Relation Extraction}
%Besides causal relations, much work has been done on extracting many
%other types of relations from text, e.g., hyponymy (isA)
%\cite{Etzioni:Web,12MSRA:Probase}; meronymy (part-whole)
%\cite{GirjuBM06}, metaphor \cite{LiZW13}, relatedness
%\cite{Zhang15:Assoc} as well as general relations
%\cite{Banko:TextRunner,S:YAGO,S:YAGO2,fader2011identifying,NakasholeWS12}.
%Relation extraction generally involves identifying the target terms
%or entities in text and then annotating the relations properly.
%Previous approaches are either supervised or semi-supervised.
%
%Supervised approaches usually treat the extraction as a
%classification problem, where the input is the sentence with marked
%target entities/terms, and the output is the classification into one
%of the predefined relations or none. Marking the entities often
%relies on syntactic patterns or named entity recognition. These
%approaches require labeled data and hence cannot be easily extended
%to new types of relations. They also make heavy use of NLP tools
%such as POS tagger and dependency parser which are all error-prone.
%Semi-supervised method often starts with a seed set of entity pairs,
%and uses a bootstrapping strategy to accumulate more pairs either by
%gradually discovering contextual patterns that represent the target
%relation \cite{Etzioni:Web}, or by using a fixed set of strong
%patterns and some logical rules to determine the plausibility of a
%pair in each iteration \cite{12MSRA:Probase}.
%
%In contrast, our extraction of causal pairs is completely
%unsupervised. This allows us to harness a web-scale evidences though
%with noises, which we eliminate using statistical evidences.
%
\subsection{Causality Reasoning}
The causal knowledge which encodes the causal implications of
actions and events is useful in solving causality reasoning problems
\cite{morganstern-commonsense}. 
%In other words, causal reasoning is a
%central problem for commonsense reasoning. Causal knowledge
%acquisition is an important first step of commonsense causal
%reasoning, which allows us to predict future events, make decisions
%and plan actions to achieve goals. 
Causality reasoning is thus a
grand challenge in artificial intelligence. Earlier attempts on the
problem were largely linguistic, for example, developing formal
theories to capture temporal or logical properties in causal
entailment \cite{LascaridesAO92,lascarides:asher:1993a}, but
they do not scale to board-ranging open domain reasoning. 
%These approaches were not effective due to the difficulty in handcrafting
%the theories for 

The NLP community has explored knowledge based approaches
that leverage structural representations of the general world knowledge. 
Much of the knowledge is hand-coded~\cite{lenat1995cyc} 
or crowd-sourced, such as the OMCS project by MIT~\cite{singh2002open}.
%Early approaches for
%construction of such knowledge bases were mostly hand-coded
%\cite{lenat1995cyc}. Another approach toward this goal is to accrue
%commonsense knowledge through crowd-sourcing. A prominent example
%along this line is the Open Mind Common Sense (OMCS) project by MIT
%\cite{singh2002open}. 
Some relations such as ``causes'' and
``causesDesire'' in the ConceptNet \cite{liu2004commonsense},
which is a sub-project under OMCS, can be used to identify causal
discourse in COPA task. However, such human curated knowledge
has limited size and comes with no or unreliable causality strength
scores (e.g., the votes in ConceptNet).
%still suffers from scalability bottleneck. In fact, the causality part of 
%ConceptNet is only a fraction of our causal network by the size after 
%15 years of community efforts. 

%Recently, several automatic, data-driven methods have
%been attempted to acquire commonsense
%knowledge\cite{schubert2002can,gordon2010learning,gordon2010mining,akbikweltmodell}.
%%Commonsense knowledge base is a structural representation of the general world
%% knowledge.
%These approaches focused on the acquisition of general
%worldly knowledge expressed as factoids, and not causality knowledge
%per se. Hence their coverage of causality knowledge is very limited.

More successful efforts arise from data-driven approaches
using correlational statistics \cite{gordon2012copa} such as pointwise mutual
information (PMI) between unigrams (words) or bigrams from large
text corpora \cite{Mihalcea2006:CKM}. Corpora attempted include LDC
gigaword news corpus \cite{goodwin2012utdhlt}, Gutenberg e-books
\cite{roemmele2011choice}, personal stories from Weblogs
\cite{gordon2011commonsense} and Wikipedia text
\cite{jabeen2014exploiting}.
%Previous research shows that the type of information source has a significant impact on the accuracy of such knowledge based approach.
This paper follows a similar direction, but instead proposed to extract 
causal signals from a more general, much larger web text corpus. 
CausalNet can be seen as a large graph-based representation of general
causality knowledge and can provide the relatively reasonable computation of 
causality strength between terms.
%\ZY{revised, pls check}

%compute a generalized PMI
%measure \cite{Washtell09:CWW} not from the plain text corpus but
%from a causal relation graph induced from large web text. 
%In addition, instead of fixing the target language units in the
%discourse sentences to either word or n-gram, we dynamically
%construct events which contain internal causality information and
%make use of these multi-word events in the computation of the final
%causal strength between two sentences.
%Causality computation requires considerable general causal
%knowledge which involves the proper modeling of causal dependency amongst text.
%We investigate the potential and effectiveness of large-scale data driven
%approaches for commonsense causal knowledge base construction.

\cut{
\subsection{Causal Strength Metrics}
Our generalized causality is inspired from association strength
measure proposed by Wettler et al.~\cite{Wettler:1993} and Washtell~\cite{Washtell09:CWW},
which introduced parameter $\alpha$ being $0.66$ and $0.5$ respectively.
Our causality strength considers both directions of the causality
relation. Causality strength is similar to
association strength to some degree, since association between term pair $(u,v)$ which also asymmetrical treated $u$ and $v$. We introduced an generalized
formula by introducing $\alpha$ and $\beta$ following the same intuition
for discounting high frequency causes and effects respectively.
\KZ{Jessie: add some description of the 1965 paper and related ones.}
}
%(Mention SCI?)
%parameter $\alpha$ PMI is lexical order based.

%SCI has a param of 0.5.
