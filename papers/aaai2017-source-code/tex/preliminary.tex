\section{Preliminaries}
Our starting point is the Allamanis bimodal model~\cite{allamanis2015bimodal}. This model is constructed
from the parse tree of source code where the internal nodes are
syntactic components such as if expression and while loops,
while the leaf nodes are all the variable names.
The model $P (C~ |~ T)$ is a generative one,
where $C$ is represented by a set of features extracted
from the parse tree, e.g., the n previous internal node types that are encountered by following the path from one node to the root,
%the first $n$ nodes in the code in the left-to-right in-depth traversal, 
and $T$ is the tag phrase made up of a number of words.

The core function is $s(v,T,C_{\leq n}) = (t \bigodot c)^{\top} r + b$, where
$\bigodot$ is an element-wise multiplication and $t$ and $c$ are
the representation vectors of $T$ and $C$, respectively.
The training is done by estimating the objective function as in
Mnih et al~\cite{mnih2013learning}. Allamains et al. used NCE method~\cite{gutmann2012noise} and AdaGrad method~\cite{duchi2011adaptive} to train model.

%During the implementation, we found that the parse tree of Allamains et al's model is too simple to contain enough information of source code. So we pay attention to improving the performance of parse tree and reconstruct the parse tree.
