\vspace{-10pt}
\section{Related Work}
\label{sec:related}
%Our work uses a bilingual 
%lexicon, socio-linguistic vocabularies and comparable documents.
%all of which are publicly available and easy to obtain. 
%Actually there are other interesting culture related applications such as the
%two tasks presented in this paper, which require special treatment from 
%sociolinquistic point of view.
%However, none of existing methods worked on it specifically. 
Cross-cultural studies have been conducted in 
sociology and anthropology for many years. 
Recently, some researchers propose 
studying cross-cultural analysis through text mining and NLP techniques.
Nakasaki et al. \shortcite{nakasaki2009visualizing} and 
Elahi et al. \shortcite{elahi2012examination} show that 
User Generated Contents (UGC), like microblog and user comment, 
are valuable and essential resources. 
The most relevant work to the Task 1 is Pennebaker 
et al.~\shortcite{Garimella2016IdentifyingCD}, which studies the cross-cultural 
differences in word usage between Australian and American English through 
their proposed ``socio-linguistic features'' (similar to our social words), with a supervised model which is dependent on large volume of training data. 
To the best of our knowledge, we are among the first to focus on cross-cultural differences in named entities and to propose a straightforward but effective unsupervised approach.
%While their supervised model is not generalizable to  cross-lingual differences and differences of named entities. 
%Their results show that socio-linguistic vocabulary 
%are essential in cross-cultural analysis of text. 
%However, their research, which uses traditional topic modeling and SVM classifier,
%cannot be applied directly to cross-lingual tasks. To our knowledge, 
%we are the first to focus on cross-cultural differences on named entities and 
%to propose an approach to conduct cross-lingual cross-cultural social studies 
%through vector representation of words. 

Previous computational work on slang mainly focuses on automatic 
discovering of slang terms~\cite{elsahar2014a} and normalization of noisy texts ~\cite{han2012automatically}. Research on automatic 
translation or explanation for slang terms in another language is missing from the literature. 
Our work on Task 2 fills the gap by directly computing cross-cultural 
similarities to find the most similar words in another language.


Most existing cross-lingual word representations  
rely on expensive parallel corpora with word or sentence 
alignments~\cite{klementiev2012inducing,kovcisky2014learning} or  a 
supervised model to learn a transformation matrix between two monolingual 
vector spaces~\cite{Mikolov:2013tp}. 
Such work often aims to improve monolingual tasks and cross-lingual 
document classification, which does not require cross-cultural signals. 
We put our work in a broader context of building bilingual word representations by positioning it in the survey of Ruder~\shortcite{ruder2017survey}: 
our work is ``monolingual mapping'' based, uses only lexicon resource and 
maps monolingual vector spaces into a common high-dimensional third space 
by incorporating social words as pivot, where orthogonality is 
approximated by setting clear meaning to each dimension 
of \textit{SocVec} space.
%However, they fail to  capture socio-linguistic information.  
