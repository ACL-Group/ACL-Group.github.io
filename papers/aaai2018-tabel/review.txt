----------------------- REVIEW 1 ---------------------
PAPER: 712
TITLE: Cross-Lingual Entity Linking for Web Tables
AUTHORS: Xusheng Luo, Kangqi Luo, Xianyang Chen and Kenny Zhu

Relevance to CIKM: 4 (good)
Originality of the Work: 5 (excellent)
Technical Soundness: 4 (good)
Quality of Presentation: 4 (good)
Impact of Ideas or Results: 4 (good)
Adequacy of Citations: 4 (good)
Reproducibility of Methods: 4 (good)
Reviewer's confidence: 4 ((high))
Overall Recommendation: 2 (Weak Accept)
Nominate for best paper: no

----------- Comments to the Author(s) -----------
This paper tries to solve the entity linking for web tables under the hood of cross-lingual setting. Given a webtable set with language A, the task is to identify cell entities that exist in knowledge base with language B (more likely English). The authors propose a neural network-based model that minimizes the pairwise ranking loss between positive training samples and randomly sampled negative candidates, where these pseudo negative candidates are generated by language translation.  Meanwhile, a translation layer is proposed to make entity embeddings and mention embeddings (different language) compatible.

The paper overall is well written. As far as I know, this is the first neural network-based approach to tackle the entity linking problem in webtables. The authors propose a joint model to incorporate cell feature (cell content), context feature (aggregated row, column content) and coherence features (variance of entity embeddings in the same column). Although the modeling of the coherence features seem odd to me, the model performance seems to be quite impressive.

Experiments are also solid. Various baselines have been compared with and the discussion for hinge loss is interesting. But I do have some suggestions.

1. In coherence computation, instead of modeling the variance, is it better to incorporate the entity collection/category available in knowledge base and use that as a regularizer to ensure that all the entities in the same column belong to similar categories?

2. Using hinge loss on the non-joint model doesn't look bad. One advantage is its efficiency. At prediction, it only needs to do cell-wise computation while Algorithm 1 is too slow considering that a table has n! combinations of all cell entities.

3. Algorithm 1 is not global optimal. Some smarter improvement can be achieved if the authors can consider better initialization and optimization algorithm.

----------- Summary -----------
I like this paper since it formulates a nice (likely also the first) neural network algorithm to tackle the entity linking problem in webtables.


----------------------- REVIEW 2 ---------------------
PAPER: 712
TITLE: Cross-Lingual Entity Linking for Web Tables
AUTHORS: Xusheng Luo, Kangqi Luo, Xianyang Chen and Kenny Zhu

Relevance to CIKM: 5 (excellent)
Originality of the Work: 4 (good)
Technical Soundness: 3 (fair)
Quality of Presentation: 4 (good)
Impact of Ideas or Results: 4 (good)
Adequacy of Citations: 4 (good)
Reproducibility of Methods: 4 (good)
Reviewer's confidence: 5 ((expert))
Overall Recommendation: 2 (Weak Accept)
Nominate for best paper: no

----------- Comments to the Author(s) -----------
Summary
This paper proposes a cross-lingual table linking method that finds a match between mentions in web table and entities in knowledge base in different languages. The proposed model is a neural network based joint model that uses three features: cell, context, and coherence feature, for computing the score of mention-entity pair from Chinese mention and translated English entity. To resolve the language gap problem, this paper uses vector space transformation and coherence features to capture the correlation between entities. Finally, this paper compares the proposed model with three state-of-the-art models to check mono-lingual table linking and cross-lingual table linking result.
 
Pros
-The problem studied is novel and useful.
-Three features used, cell, context, and coherence feature, are reasonable for the proposed neural network based joint model. 
-The model is evaluated for both mono-lingual and cross-lingual table linking. Also the paper well-justifies the joint model by comparing with non-joint model using a  hinge loss. In addition, various feature combinations are used in the experiment to justify the effectiveness of each feature.

Cons
-Adding Chinese PinYin does not seem to pay off (Table 1).
-Some useful references are not cited.

Detail comments
-In the paper, the author argues that some Chinese words (e.g. 春分) are incorrectly translated using translation tools, thus use PinYin. However, when using current Baidu and Google translation apps, the word presented as an example seems to be translated correctly, which may be an explanation of marginal performance gain from PinYin reported in (Table 1).
 
-In Section 3.3, author states that simply mention and entity names are represented as the average of embeddings of words without justification. In Section 3.4, author uses concatenation of context and entity embedding without explanation. [2] and [3] may be cited to justify each of these decisions. Also in Section 5.5, joint model versus non-joint model, it seems that the baseline used is [1] but the reference is missing.

Minor comments
The explanation in “Introduction” Section and “Figure 1” does not match. (“上海” and “Shanghai” are not in Figure 1) 
Typo. (Section 5.1, embedding dimennsion → embedding dimension and Eq.(5), range of i ∈ [0,R] → i ∈ [0,C])
 
[1] Sun, Yaming, et al. "Modeling Mention, Context and Entity with Neural Networks for Entity Disambiguation." IJCAI. 2015.
[2] Socher, Richard, et al. "Reasoning with neural tensor networks for knowledge base completion." Advances in neural information processing systems. 2013.
[3] Socher, Richard, et al. "Recursive deep models for semantic compositionality over a sentiment treebank." Proceedings of the conference on empirical methods in natural language processing (EMNLP). Vol. 1631. 2013.

----------- Summary -----------
This paper improves existing cross-lingual table linking work with deep learning. This paper was the strongest among my assigned papers.


----------------------- REVIEW 3 ---------------------
PAPER: 712
TITLE: Cross-Lingual Entity Linking for Web Tables
AUTHORS: Xusheng Luo, Kangqi Luo, Xianyang Chen and Kenny Zhu

Relevance to CIKM: 3 (fair)
Originality of the Work: 3 (fair)
Technical Soundness: 3 (fair)
Quality of Presentation: 3 (fair)
Impact of Ideas or Results: 3 (fair)
Adequacy of Citations: 3 (fair)
Reproducibility of Methods: 2 (poor)
Reviewer's confidence: 2 ((low))
Overall Recommendation: -2 (Weak Reject)
Nominate for best paper: no

----------- Comments to the Author(s) -----------
This paper presents an approach for entity linking of mentions in web tables under a multilingual scenario. Authors claim that this is so far the first work in the topic and results show improvements over “raw” entity linking systems as well as over web table entity linking systems (monolingual).
 
My main concern about this work is related with the impact of the proposed approach and its motivation. In general, the paper seems to contradict itself. For example, the paper starts with a cross-lingual entity linking example but fails to clearly show the problem. In the text, it is mentioned that the second row from figure 1 is linked with Shangai, but in the image the second row makes reference to “Wayne State University”. Maybe it is clearer for a native in chinese, but for a non-native the example is perplexing. Similarly, in the introduction is mentioned that useful information of chinese celebrities could be included in tables but that the English knowledge bases are comprehensive and accurate that the chinese versions. However, experiments are performed over popular non-chinese entities making hard to understand if the motivation is well grounded. Another contradiction is present in section 5.4 when authors mention that not all entities are in the English knowle!
 dge base. In this later case, it seems less interesting the use of cross-linguality. 
Problem and proposed approach are interesting, but authors lack to motivate their choices. Comparison against existing algorithms using their table linking dataset is well conducted. However, the dataset is not large enough (only 24 tables for test) to draw clear conclusions. Extra experiments using a non web table (e.g., AIDA dataset) and/or a non cross-lingual (e.g., WEB MANUAL dataset) setup could help to better understand the core contributions. Despite the ablation study of section 5.5, it is hard to conclude which components help to achieve performances comparable to the state-of-the-art (because a strong entity linking system is never tested). Indeed, little detail is given about the baselines. Larger datasets, such as WEB MANUAL (428 tables), are completely ignored. It is understandable that annotate more data could be expensive for you, but experiments with similar datasets (even knowing that they doesn’t fit perfectly the task) may help to understand the main con!
 tributions. 
 
Following a not exhaustive list of typos:
Section 3.3: “To solve this problem, We” -> “To solve this problem, we”
Section 3.6: last sentence “list for each .”-> “list for each.”
Section 4: missing breakline
Section 5.1: “dimennsion sets to” -> “dimension sets to”
Section 5.1: “In total,We” -> “In total, we”
Section 5.5: Out of the margin “How_to_Train_Your_Dragon”

----------- Summary -----------
My recommendation is that the paper must be improved to be accepted for publication.


-------------------------  METAREVIEW  ------------------------
PAPER: 712
TITLE: Cross-Lingual Entity Linking for Web Tables

This is a meta-review.

The reviewers agree that the paper address a novel and interesting problem but they also raise concerns about the soundness and robustness of the paper in its present form. For example, the presentation must be improved and clarified, some design choices need better justification, and the evaluation part should be more compelling.

This motivates the suggestion for rejection but with an encouragement to the authors to address the reviewers comments and resubmit to CIKM or another high-end venue.