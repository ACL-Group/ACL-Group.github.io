\section{Conclusion}
Towards the end goal of improving commonsense inference capacity of machines on short texts, 
we propose a new dataset CoCo which contains 9,299 pairs of short phrases. 
We describe a framework of shrinking human annotation scale and generating samples with contradictions automatically. 
We also evaluate two large pre-trained language models on our benchmark, 
showing that there is a large margin for machines to achieve the ability of judging commonsense contradiction in short text as humans do. 
We hope this benchmark can facilitate further research on how to integrate external commonsense knowledge into models, not only for helping understand short text, but also for learning common sense.