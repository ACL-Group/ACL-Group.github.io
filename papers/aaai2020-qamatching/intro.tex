\section{Introduction}
\label{sec:intro}
Question motivated dialogues are very common in daily life and 
they are rich sources for question-answer (QA) pairs. 
For example, in an online forum for health consultations, 
both the doctor and the patient tend to ask and answer questions to 
narrow down the information gap to reach the final diagnosis or 
recommendations. Matching QA pairs from such resources is a valuable task. 

QA matching is an important part of analyzing discourse structures 
for dialogue comprehension. Asher et. al~\shortcite{asher2016discourse} 
shows that in online dialogues where participants are prompted to 
communicate with others to achieve their goals, 24.1\% of the relations 
between elementary discourse units are QA pairs. 
Questions and answers are the main components of 
dialogue acts~\cite{stolcke2000dialogue}, which provide key features for 
dialogue summarization and decision detection~\cite{fernandez2008modelling}. 
Besides, figuring out the QA relations between these utterances can 
provide question answering 
models~\cite{ji2014information,vinyals2015neural,cui2017superagent} with 
high-quality QA pairs and contribute to the exploration of proactive questioning \cite{yan2017building}.

\begin{figure}[t]
	\centering
	\includegraphics[scale=0.29]{pictures/figure3.pdf}
	\caption{Questions and answers matching in dialogues from an online health forum. The identified pairs are painted in the same color and questions are underlined.}
	\label{fig:sample}
\end{figure}

However, many challenges exist. While it's relatively easy to distinguish
between questions and non-questions~\footnote{This can be done with a simple 
neural-based classifier with high accuracy.},
the non-questions may contain not only valid answers, but also chit-chats and
other informative statements. It is also a common phenomenon that a long and complete answer is broken up into several turns such as \{U5,U6,U8,U10\} in \figref{fig:sample}. Due to factors such as the network delay and differences in typing speed, the dialogue sequences are always mix-matched. Moreover,``personalized" orthography, ellipses, abbreviations, and missing punctuations are all difficulties for QA matching.



In this work, we focus on the task of matching questions and answers in two-party 
multi-turn dialogues. We found that the distance between the question and its answers 
isn't only caused by the mix-matching and fragmentation mentioned above, 
but by the very nature of the question. 
Some questions can be answered directly based on personal knowledge, 
such as U3, while others can not. For instance, when a patient asks questions 
such as ``what's wrong with me'' or ``what should I do'' just like U1, the doctor often has to ask follow-up questions \{U2,U3\} to seek additional information in order to give the final diagnosis or recommendation (U11) after several rounds of communications. 
We call this kind of QA pairs {\em incremental QA}. 
Such QA pairs often form the main idea of a dialogues or sub-dialogue, 
critical for dialogue comprehension. The answers are inherently far from the question for incremental QA pairs (distance $\geq$ 3 \footnote{There is at least one follow-up question and one corresponding answer between the question and answer of an incremental QA pair. So the distance for such QA pairs is larger or equal to 3.}), aggravating the difficulty of matching such pairs. 

Roughly, we can categorize QA pairs according to the distance between them. 
When distance $\leq$ 3, we call it short-distance QA pairs (SQA); 
otherwise, long-distance QA pairs (LQA). 
It is obvious that matching LQAs is more difficult than SQAs. 
We assume that a two-party multi-turn dialogue contains two types of turns, 
questions (Q) and non-questions (NQ), 
which are labeled in advance~\footnote{We implemented such a Q/NQ classifier
with accuracy of more than 96\%,
which will be released to the research community.}. 
Our task is to identify all answers from the set of NQs to a given Q. 

Previous methods on the task~\cite{ding2008using,du2017discovering,jiang2018learning} suffer from a major weaknesses: while classifying a pair of turns, they ignore the context of the turns in the dialogue. Meanwhile, their pre-defined features such as question words and answer words, are already implied by the Q and NQ labels in our definition and hence are not suitable for our task. He et al.~\shortcite{he2019learning} improves the above methods with a recurrent pointer network (RPN) model that takes the whole dialogue as an input sample. Their model was evaluated on a close-source customer service dialogue dataset. Although their model makes use of the context, they treat every utterance in the context equally with RNN-based networks which fails to capture the influences between turns especially with long distance. Besides, it encodes the distance information implicitly which downplays the effect of distance between the utterances. According to our experiments, none of the above approaches perform well on LQA pairs.


In this paper, we bring the dialogue context into the above simple models. 
For a given pair of Q and NQ to be matched, the context is defined as {\em history}, 
refering to the utterances between the Q and NQ. The critical part of our model 
is two simultaneous attention mechanisms that combine the history in a mutual way. 
Existing dialogue datasets, such as the Ubuntu dataset, do not contain
the QA matching labels. More over, they are either not two-party dialogues, or do not
contain long distance QA pairs. Therefore, we developed a new dataset based on
a Chinese online medical forum. We conducted experiments on this and the part of
the labeled Ubuntu dataset.  
%Compared with previous methods, our proposed models 
%increase the F1-score from 70.46\% to 77.43\% for overall performance. The F1-score for LQAs is 40.44\% and 24.80\% when distance is 4 and $\geq 5$ respectively.

Our main contributions are as follows:
\begin{itemize}
%    \item We focus on the task of matching questions and answers in two-party multi-turn dialogues, and we are the first to category QA pairs based on its distance to the best of our knowledge. (\secref{sec:problem})
    %the fragmentation phenomenon of answers and Complex QA relations which. 
    %It is meaningful for constructing question answering systems, figuring proactive questioning and doing dialog summarization.
    \item We aggregate dialogue history and distance information into a new deep
neural QA matching model. We show that distance is an important feature when encoded explicitly, and that utterances between Q and A can be effectively captured by a mutual attention mechanism.  %Based on Q-NQ labels, our approach can match non-questions to questions from both participants and solve different alignment situations in a unified manner 
    % which suggest to be encoded explicitly
    \item Since there is no open source dialogue datasets designed for
QA matching task, especially for long-distance QAs, 
we construct a reasonably sized dataset and will release it to the research community. 
    \item The experimental results show that our proposed method outperform 
other strong baselines, especially on LQAs. 
The techniques developed here are generic and can
be applied to other types of online dialogues.
    %Based on proposed approach, we automatically label QA relations for around 160,000 raw dialogues crawled online. Both
\end{itemize}

% The rest of this paper is organized as follows: The next section give a detailed description about the task, the dataset and challenges. Section \ref{sec:method} presentes the proposed technique for the pairwise alignment model. We evaluate our approach in Section \ref{sec:eval}. Section \ref{sec:relatedwork} discuss the related work and Section \ref{sec:conclusion} concludes this paper.
