Reviews #1

Thanks a lot!

1.
- Although we use the attention-based LSTM in our paper, the architecture of the model, especially the Mutual Attention, is novel and shown to be useful for the QA matching problem between two parties. The whole approach is an end-to-end model, divided into 4 parts (from Sec 3.1 to Sec 3.4) for better explanation. As mentioned in the last paragraph of Sec 4, the input of our model is a Q and NQ with associated information (history and distance), and the output of model is the probability of being True/False which indicates if the Q is the matched question of the NQ. Hence, the loss function is the cross entropy between the predicted probability and the Ground truth. The model is a binary classification model and all the parameters (of course include those in all LSTMs) are trained altogether.


- In section 3.3, we followed the conclusion in the original match-LSTM paper: use each of the attention-weighted representations of the premise for matching in the NLI task. We regard the processed Q as the premise and NQ as the hypothesis. 


- Section 3.5 is a post-processing based on the scores of Q-NQ pairs collected from the trained model during inference. It is a just an intuitive rule-based approach and is not related to the training process. Thanks a lot to your questions and we will clarify this better in the revised version!

2.
- The description of the baselines is mentioned in the Sec 5.1. GD1 and GDN are explained under the "Greedy Strategy", and they select 1 or more closest satisfying answers until meet another Q or disturbed by the other party.

- The Greedy Strategy is also proposed in the He's paper (He et al. 2019AAAI) and distance is an important feature based on the result of Distance, so we list it as a baseline approach for comparisons.

- The RPN model in (He et al. 2019) is proposed to attack the same problem as our paper, and it is currently the SOTA method on the problem hence it is our major comparison in
the evaluation. Due to space limitation, we only mentioned briefly the main differences and weakness of the RPN model compared to our method in 6th paragraph in Sec 1 and last paragraph in Sec 2. It takes the whole dialogue context into consideration to capture the QA relations between turns in dialogues, while our model outperforms it significantly according to the results in Table 4.

3. Sorry for the confusing labels H_RQ and H_RNQ which are explained in the 2nd paragraph of Sec 3.2. We will re-explain it as follows: We define the history as the turns between the given Q and NQ, and we divide the history into two parts according to their speakers. Given a Q-NQ pair, H_RQ refers to a part of history turns said by the speaker who poses Q. H_RNQ refers to the other part of history turns said by the speaker who poses NQ.


Reviews #2

Thank you very much. We will fix the suggestions in the revised version.

The U7, U9 and U12 in Fig 1 are grayed-out because they don't have a corresponding question or answers. They are not in any matching question-answer pairs.

For the ablation test on different ways of attending to the history, we conclude that NM is better than ID. It's due to better understanding on individual speakers which can help the understanding of the dialogue, similar to the idea in the AAAI2019 paper "A Deep Sequential model for Discourse Parsing on Multi-party Dialogues". Our work targets the QA relations in dialogues which are more related to the interactions between speakers. As a result, our full model is better than NM. The difference between our full model HDM and ID is that in ID both Q and NQ attend to all turns in the history regardless of who uttered those turns, whereas HDM employs a mutual attention mechanism that distinguishes turns by their speakers. Specifically, the Q only attends to those turns uttered by the NQ speaker, while the NQ attends to those turns by the Q speaker. This resembles to some extent the firm attention in NAACL2018 paper "Entity Commonsense Representation for Neural Abstractive Summarization". This will help the model to focus on the interactions between speakers. We will explain it better in the revised version.


Review #3

Thanks for your comments.

In this paper, we mainly focus on the variable distances of QA pairs and the performances of the models vary a lot on variable distances.

As for the length of the question or the answer or the sum of the question and the answer, we observed that there are no substantial differences on the results between the different length of questions/answers/the sum of the question and corresponding answer.

Since there are no labels for question types in the dataset and the classification criterion for QA types is not clear, we randomly selected 100 Q-NQ pairs and classified the questions into two classes: Yes/No/Choice questions and other questions. The accuracy of our full model HDM is almost the same on these two types of questions: 78.21% vs. 78.66%. Intuitively, we think that the Yes/No/Choice question should be easier to predict, but factors like the informal expressions and disordered turns make things more complicated. We will add this bit of insight into the revised version.