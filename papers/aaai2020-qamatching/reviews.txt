Reviewer #1
Questions
    * 1. [Summary] Please summarize the main claims/contributions of the paper in your own words.

        * The paper proposes a supervised method (in combination with a discrete feature like distance) for matching a pair of question and answer uttered by two parties respectively in a dialogue. The proposed method is implemented in a traditional LSTM integrated with an attention mechanism. Besides, in this paper, a new dataset is presented. The dataset is about multiple dialogues extracted from a Chinese online medical forum and is annotated with question, answer, other, and golden Q-NQ pair labels. Based on this dataset, multiple baseline models are evaluated to compare with the proposed model, where the authors show that the proposed model outperforms state-of-art baselines.
    * 2. [Relevance] Is this paper relevant to an AI audience?

        * Relevant to researchers in subareas only
    * 3. [Significance] Are the results significant?

        * Significant
    * 4. [Novelty] Are the problems or approaches novel?

        * Somewhat novel or somewhat incremental
    * 5. [Soundness] Is the paper technically sound?

        * Technically sound
    * 6. [Evaluation] Are claims well-supported by theoretical analysis or experimental results?

        * Sufficient
    * 7. [Clarity] Is the paper well-organized and clearly written?

        * Good
    * 8. [Detailed Comments] Please elaborate on your assessments and provide constructive feedback.

        * Reasons to accept:1. The paper deals with question-answer matching in a dialogue, which is an important and active area of focus in recent times for the community, given the high volume of work on dialogue systems. Particularly, in this work, the authors take long-distance into account and try to solve the problem that when being faced with a multiple-turn dialogue, some irrelevant utterances between the gold question-answer pairs would impair the performance the existed models.2. Since the existant dataset are not adaptive to the long-distance dialogue (especially between two parties), the authors try to establish a new dataset accordingly. The dataset is exacted from a Chinese medical forum and manually annotated with the gold labels. The dataset is useful to test the models when trying to recognize questions and their corresponding answers, which is helpful to the researchers in the community. 3. Results show improvement for recent baselines. The authors try to compare their work with precedent baseline models and conduct a thorough experiment to evaluate the effectiveness of different factors. Based on the experiment result, it is presented that the feature ‘distance’ is useful in a multi-turn dialogue, and the mutual attention mechanism designed in the model is working. Also, the authors try to implement all models (baseline models and proposed model) in another dataset, Ubuntu dialogue, to verify that their model can generalize on other datasets and could still get the best performance.Reasons to reject:1. The model proposed in this paper is a traditional attention-based LSTM, which is not a novel method. Also, the missing details of the models make it hard to understand. Especially, I am confused about how the model is training. 1). As mentioned in section 3.1, the hidden state of words in Q, ‘h^i’, is used to combine with the last step’s hidden state of RNQ, ‘d_t’, to get an integral vector ‘u’. By using an LSTM, the natural language input could be transformed into a hidden state. But will this LSTM train together with following LSTMs? How to train this LSTM? Will the parameters in this LSTM be optimized when training? If so, what are the supervision signals to train this LSTM? How to define the loss in training this LSTM? 2). In section 3.3, the authors further fuse the processed Q’ and NQ’ to form a sentence-pair representation ‘P’. By using attention mechanism, the context vector ‘c’ is a weighted sum of ‘f^q’ in Q’ and then is concatenated with ‘f^p’ in NQ’ to get the sentence-pair representation ‘P’. What is the intention of doing this? Why not producing ‘P’ in a reverse way, i.e., computing ‘c’ as a weighted sum of ‘f^p’ and concatenating ‘c’ with ‘f^q’? What’s the difference between these two ways of forming ‘p’? Is there any experiment to verify which one is better? 3). I am confused about how the discrete signal train the differential LSTM model. It seems that authors choose the NQ-Q pair with maximum probability in candidate pairs, as mentioned in section 3.5. If the chosen pair is truly a matching pair, what is the loss of this pair? How about the losses of other pairs? 4). Suppose we could get the loss from the discrete signals, and such loss could be used to optimize match-LSTM. What about the sentence encoder? What is the loss of training in this model? What about the loss of representation LSTM (which is used to embed a sequence of natural language words)? Are these three LSTM models integrated? Will one model be trained with backward propagation of errors propagated from the precedent model? 2. Some baseline models selected in this work are not convincing. The description of the baseline is not clear. 1). The authors did not describe how GD1 or GDN selects the satisfying answer(s).2). The authors use greedy strategy and distance methods as baseline models in this work, but it seems no previous work has ever used such methods as a baseline. Why? Is it reliable to choose such models as a baseline model?3). It seems that the paper is biased to compare with the Recurrent Pointer Network (RPN) but is lacking in the necessary details of RPN. What is the main task and problem that RPN tries to solve? By using what methods do they solve the problem? Is RPN suitable for this task, which is long-distance question-answer matching? If such details are missing, it is hard to judge the strengths and weaknesses of models are thus impair the rationality and validity of the experiments. 
    * 9. [QUESTIONS FOR THE AUTHORS] Please provide questions for authors to address during the author feedback period.

        * 1. See the summary above -- I think my main confusion is with the training paradigm, what is the design of loss and how to train three LSTMs. Are three LSTMs trained together with error propagation? How to train representation LSTM? I think this part of the paper would need to be rewritten to explain it much more clearly.2. In section 3.1, for H_RQ is a set of {d^q}, and the superscript q is used to represent NQ as mentions, I suppose H_RQ should consist of NQ sentences. But in section 3.2, it is said NQ would interact with H_RQ. And as what is depicted in figure 1, H_RQ consists of U3, U7, and U9, which are questions but not ‘NQ’. I am confused with the notion of H_RQ and H_RNQ with such a contradictory. 
    * 10. [OVERALL SCORE]

        * 5 - Marginally below threshold



Reviewer #2
Questions
    * 
1. [Summary] Please summarize the main claims/contributions of the paper in your own words.

        * 
The paper proposes a model which identifies the matching question-answers pairs from online forums. A major novelty of the model is the way of modeling the contexts in the prediction. Specifically, the model uses non-question contexts for encoding questions and question contexts for encoding answers. The paper also presents extensive evaluation results to show that the proposed method is effective.
    * 
2. [Relevance] Is this paper relevant to an AI audience?

        * 
Relevant to researchers in subareas only
    * 
3. [Significance] Are the results significant?

        * 
Moderately significant
    * 
4. [Novelty] Are the problems or approaches novel?

        * 
Novel
    * 
5. [Soundness] Is the paper technically sound?

        * 
Technically sound
    * 
6. [Evaluation] Are claims well-supported by theoretical analysis or experimental results?

        * 
Sufficient
    * 
7. [Clarity] Is the paper well-organized and clearly written?

        * 
Good
    * 
8. [Detailed Comments] Please elaborate on your assessments and provide constructive feedback.

        * 
(1) The way of modeling the contexts is interesting -- attaching RNQ (non-question contexts) to questions and RQ (question contexts) to answers. Initially, I wasn't sure as to why splitting the contexts into two would be effective. But, as the evaluation in Table 7 shows, the idea seems to work; it achieves a better performance than using the whole context. 

It would be interesting if the authors could provide some insights as to why using the whole context (i.e., ID in table7) is particularly low and the HDM approach is better.

(2) The evaluation is thorough and convincing. I also like several ablation test results. 

(3) He et al. (2019) is mentioned several times in the paper. But, its citation is incomplete. Please provide the full citation. 

(4) In Fig 2, U7, U9 and U12 are all grays. Are they a matching question-answer pair? If not, please differentiate the colors. 

(5) In Fig2, make it clear that Part1 consists of two encodings -- one encoding for question and another for answer. The figure has two planes but it is hard to notice. 

    * 
9. [QUESTIONS FOR THE AUTHORS] Please provide questions for authors to address during the author feedback period.

        * 
See my detailed comments.
    * 
10. [OVERALL SCORE]

        * 
7 - Accept



Reviewer #3
Questions
    * 
1. [Summary] Please summarize the main claims/contributions of the paper in your own words.

        * 
This article address a specific domain of Question-Answering: the matching Question-Answer.
The authors presents an approach base on LSTM to find the best QA pairs.
Since datasets for this task are difficult to find, they annotated QA and created a dataset.
Results show improvements which are significants.
    * 
2. [Relevance] Is this paper relevant to an AI audience?

        * 
Relevant to researchers in subareas only
    * 
3. [Significance] Are the results significant?

        * 
Significant
    * 
4. [Novelty] Are the problems or approaches novel?

        * 
Novel
    * 
5. [Soundness] Is the paper technically sound?

        * 
Technically sound
    * 
6. [Evaluation] Are claims well-supported by theoretical analysis or experimental results?

        * 
Sufficient
    * 
7. [Clarity] Is the paper well-organized and clearly written?

        * 
Good
    * 
8. [Detailed Comments] Please elaborate on your assessments and provide constructive feedback.

        * 
On one hand, the paper is well written and clear, since the approach is well described, as well as experiments and State-of-the-Art.
On the other hand, there are not enough analysis of the results.
For instance, which kind of question and answer are best paired?
    * 
9. [QUESTIONS FOR THE AUTHORS] Please provide questions for authors to address during the author feedback period.

        * 
- Do you have conducted analysis on question and answer pairing? For instance observing the score according the length of the question, and/or the answer?
- Which kind of question and answer are best paired (boolean, plain, etc.)?
    * 
10. [OVERALL SCORE]

        * 
7 - Accept

# Meta-Reviews

The paper studies q-a matching which has a lot of related work in the community. The new thing to me is the effort towards attacking long-distance challenge.

My major concerns include:
1) novelty: the model itself is nothing, both LSTM and attention have been widely used in various matching tasks. I encourage the authors to think about using Transformer (e.g., self-attention) for sentence encoding, since it is well known that it is more powerful than LSTM.

2) in real practice, there are no labels on Q and NQ, then does the method proposed work anymore? The authors claimed that they have a classifier with an accuracy 96%, and will release the classifier to the community. However, all the experiments in the paper are conducted with Q and NQ labeled by humans. This is too artificial. I would like to see an extra experiments in which the classifier is combined. This is the main reason I vote for ``weak reject''.

