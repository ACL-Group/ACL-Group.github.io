\section{Related Work}
\label{sec:related}

% Query Segmentation task has been studied in research community for a long time. \cite{risvik_query_2003} is the first work which defines such task. They propose a unsupervised approach based on a score calculated by the frequency count and mutual information (MI). Many following unsupervised approaches \cite{zhang_query_2009,kiseleva_unsupervised_2010,mishra_unsupervised_2011,hagen_power_2010,hagen_query_2011,parikh_segmentation_2013} are similar to \cite{risvik_query_2003} but use different index to computer their scores. Language models \cite{tan_unsupervised_2008,huang_exploring_2010} can also be used to do query segmentation. As for supervised approaches, various kinds of features are designed to train SVM \cite{bergsma_learning_2007}, CRF \cite{yu_query_2009} and Perceptron \cite{du_perceptron-based_2014} to adress QS task. Different from these feature-based approaches, \cite{kale_towards_2017} trains a simple binary classifier to predict segmentation boundaries only based on the word embedding. And \cite{lin_query_2017} applies the popular RNN Encoder-Decoder model, which encodes the query into a context vector, and decode the same query with some special segmentation signs. However, their experiments shows this Encoder-Decoder model not effective at all.



Query segmentation task has been studied in research community for a long time. As far as we know, \cite{risvik_query_2003} is the first work which defines such task. They proposed a unsuperised approach based on a score calculated by the frequency count and mutual information (MI). Many following unsupervised approaches \cite{zhang_query_2009,kiseleva_unsupervised_2010,mishra_unsupervised_2011,hagen_power_2010,hagen_query_2011,parikh_segmentation_2013} are similar to \cite{risvik_query_2003} but use different indexes to calculate their scores. \cite{zhang_query_2009} and \cite{mishra_unsupervised_2011} calculated scores based on the principal eigenspace similarity of frequency matrix and Hoeffding’s Inequality respectively. \cite{mishra_unsupervised_2011} argues that Hoeffding’s Inequality index can help to detect more rare units than MI approach. \cite{hagen_power_2010,hagen_query_2011,parikh_segmentation_2013} just use n-gram frequencies of the segments of queries in the unsupervised approach. \cite{kiseleva_unsupervised_2010} uses the user click data along with queries in an unsupervised manner. Especially, \cite{tan_unsupervised_2008,huang_exploring_2010} train language models using large unlabelled data to do query segmentation.

As for supervised approaches, various kinds of features are designed to train SVM \cite{bergsma_learning_2007}, CRF \cite{yu_query_2009} and Perceptron \cite{du_perceptron-based_2014} to adress query segmentation task. Different from these feature-based approaches, \cite{kale_towards_2017} trains a simple binary classifier to predict segmentation boundaries only based on the word embedding. And \cite{lin_query_2017} applies the popular RNN Encoder-Decoder model, which encodes the query into a context vector, and decodes the same query with some special segmentation signs. However, their experiments show this Encoder-Decoder model is not effective at all.

% As for supervised approaches, there are also many supervised approaches \cite{bergsma_learning_2007,yu_query_2009,du_perceptron-based_2014,kale_towards_2017,lin_query_2017}. Various kinds of features are designed to train SVM \cite{bergsma_learning_2007}, CRF \cite{yu_query_2009} and Perceptron \cite{du_perceptron-based_2014} to do query segmentation.  Different from these feature-based supervised approaches, \cite{kale_towards_2017} trained a simple binary classifier to predict segmentation boundaries only based on the word embedding. \cite{lin_query_2017} used the popular RNN Encoder-Decoder model. This model encodes the query into a context vector, and decode the same query with some special segmentation signs. However, their experiments shows this Encoder-Decoder works worse than all of their baselines.



