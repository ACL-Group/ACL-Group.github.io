Thanks for your reviews and suggestions.

Review #1
1. Ground truth: CEFR levels (A1, A2, B1, B2, C1, C2) is used as the groud truth which is an authoritative standard for second language learners and is corresponding labeled as 1-6. We used 6 levels for English task and the first 3 levels for German. The CEFR list for English is from "https://www.toe.gr/course/view.php?id=27" and CEFR list for German is from BerLiner Platz.

2. For the example in section 1, both of the frequency corpora COCA and SubtlexUS show that a single feature frequency can't predict word difficulty very well but we only show the result of COCA. However I think COCA with 450 million words is huge enough and representative. Thanks for you suggestion and we will show more details in the revised version.

3. Compared with the Complex word Identification task which is defined as detecting complex words in a sentence, our task is to predict the word difficulty levels under a specific standard like CEFR mentioned in this paper. These two tasks are different. But thanks for your comments and we will enrich our experiments and related work.


Review #2
Thanks for your questions and suggestions.
1. Explanations for figures and tables:
- Figure 1: The line for "Universal Cognition" shows in human's common sense, a more common word is easier. However the line for "Actual Situation" is the actual relation between word frequency and corresponding difficulty, which is not linear. This figure shows frequency is not the major factor to influence the word difficulty.

- Figure 4: The points are randomly chosen to display the relation between word difficulty and its log value of the frequency. "True label" means the point distribution of the groud truth. "FO" means the point distribution of frequency-based model, and "Prediction of Fix+Word2vec" is of our model. We used this figure to show the prediction of our multi-faceted model (Fix+Word2Vec) is more closer to the ground truth.

2. Model details:
The parameters for different model are shown as follows:
MLP : hidden layers = 3, hidden state = 512, learning rate = 0.01
SVM : C=0.1, kernel = 'linear'
logistic regression: C = 1
In these paper, we focus on exploring the effectiveness of different features, so we only showed the best result of MLP. For word embedding, we tried different context size (2-5) and different dimension (100-300) to find the best embedding.
Analoging Figure 8, the results for different models are shown as (Only the classification results on test set with Word2Vec):
|                | Nytimes | Gutenberg | Nytimes+Gutenberg | German |
| MLP            |  42.94  |   41.18   |       42.83       |  47.74 |
| SVM            |  40.60  |   38.52   |       40.14       |  42.39 |
| LR             |  39.84  |   38.52   |       40.60       |  42.80 |
| Human baseline |  49.28  |   49.28   |       49.28       |  44.44 |

3. Analysis of word embedding:
Word embedding encodes the word's syntactic and semantic features, including the word similarity, synonym and topical information. Thanks for your suggestion and we will add more qualitative investigations.

Review #3
Thanks for your questions. 
I implement the experiments on English and German which have explained that these research methods are effective. I agree with you that more experiments on other languages is also necessary and all these methods to extract word features can be implemented on different languages.