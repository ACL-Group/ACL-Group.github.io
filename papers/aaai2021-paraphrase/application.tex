\section{Application on Translation Tasks} \label{sec:app}
We apply our paraphrase generator to augment the training data of $X$-English 
translation task, where $X$ is a low-resource language. 
Since it is difficult to find high-quality test sets for low-resource 
languages, we use three commonly-studied languages and reduce their 
parallel training pairs to 150k and 300k to simulate low-resource languages. 
%Finally, we improve the test result by 1.53 to 2.17 BLEU with the set2seq-common+BT.

\subsection{Data Augmentation}
The size of training pairs for NMT tasks is of great importance to the final result. However, it is quite expensive to enlarge the dataset manually due to the high labor price and the huge workload, so data augmentation for NMT is a popular research topic in recent years. To this end, in the task of translating low-resource languages to English, we paraphrase the sentence in English to augment training pairs automatically.

For each language, we carry on two experiments with 150k data and 300k data respectively. For each experiment, we train the model with original data 
as the baseline. 
For each experiment, we train the model with the original
data as the baseline.

% \KZ{Don't understand this (you never mentioned truncate at 20 before): 
Regarding augmentation, we make 10 copies of the original sentences, 
construct 10 word sets with different seeds in random replacement from the 10 copies and generate 10 paraphrases 
with set2seq-common+BT.
% (\secref{sec:indomain})
To increase the diversity of the results, 
we use random sampling \citep{edunov2018understanding} during decoding. 
We take the 10 copies and 10 paraphrases as the augmented data.
% , which is 
% 20 times the original data.

For the set2seq-common model, considering the length of sentences 
in the NMT training set is longer, we truncate sentences longer 
than 50 words instead of 20 during the training stage and 
do not truncate any sentences during the inference stage.

\subsection{Experimental Setup and Results}
We experiment on German-English (de-en), Chinese-English (zh-en), and Russian-English (ru-en) translation pairs. For training data, we obtain the de-en data from WMT17-europarl\footnote{\url{http://www.statmt.org/europarl/}}\citep{koehn2005europarl}, the ru-en data from WMT17 news-commentary and zh-en data from LDC \citep{liberman2002emotional,huang2002multiple}. The reason for not using zh-en data from WMT17 is that we are already using the zh-en pairs from WMT17 to train 
the translation models.
For test sets, there are 3004 pairs for de-en, 2000 pairs for zh-en and 
3000 pairs for ru-en from the WMT17 news-test.

For each language, we learn a shared BPE of size 50000 
and extract vocabulary of up to 
50000 from the training set for both English and the target language 
with the shared BPE. 

We train translation models with a standard 
transformer-base model~\citep{vaswani2017attention}. 
For the result of each model, we take the average of test results from 5 checkpoints after convergence.

\begin{table}
\centering
\small
\begin{tabular}{p{1cm}ccc}
\hline
\\ [-1.8ex]
& \textbf{Size} & \textbf{Orig. Pairs} & \textbf{Augmented} \\
\\ [-1.8ex]
\cline{2-4} 
\\ [-1.8ex]
\multirow{2}{1cm}{De-En} & 150k & 12.89 & 15.06 \\
& 300k & 15.67 & 17.20 \\
\\ [-1.8ex]
\hline
\\ [-1.8ex]
\multirow{2}{1cm}{Zh-En} & 150k & 10.21 & 11.99 \\
& 300k & 12.10 & 14.07 \\
\\ [-1.8ex]
\hline
\\ [-1.8ex]
\multirow{2}{1cm}{Ru-En} & 150k & 16.88 & 18.55 \\
& 300k & 19.30 & 21.09 \\
\\ [-1.8ex]
\hline
\end{tabular}
\caption{\label{tab:augment}
Bleu scores of translating three languages into English; 
each task is trained with 150k/300k original pairs 
and 3M/6M pairs after data-augmentation.}
\end{table}

Table~\ref{tab:augment} shows the result. 
Paraphrase augmentation improves the model trained with original data pairs 
by anywhere from 1.53 to 2.17 BLEU. 

In the process of producing paraphrase, we use some additional data, such as monolingual English data and Chinese English translation data. There may be other methods to improve the final results based on these data, but our purpose is to show the effectiveness of our methods in long sentences since only paraphrases with both accuracy and diversity can construct perfect translation pairs.

