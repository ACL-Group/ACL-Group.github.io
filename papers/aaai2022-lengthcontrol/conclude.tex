\section{Conclusion}
\label{sec:conclude}
We presented a noval approach to produces 
summaries in desired length that are fluent and coherent. 
We create a pretrained dataset consisting of source documents and 
extractive summaries with evenly distributed lengths from original training dataset.
We train our proposed LAAM on pretrained dataset first and
fine-tune pretrained LAAM on original training datasets.
Compared with the existing
length-controllable summarization methods, we show that our model has the ability to generate high-quality summaries with desired length by information selection. Our approach can also generate better short summaries,
when there are no short reference summaries in the training datasets.
