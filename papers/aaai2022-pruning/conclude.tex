\section{Conclusion}
This study focuses on disentangling PLMs into dedicated relation-specific knowledge models. With a preliminary focus on  
commonsense knowledge, we find evidence of latent sparse subnetworks 
capable of representing grounded commonsense relations in various PLMs. Further experiments revealed 
that such subnetworks possess stronger knowledge transfer capability than original PLMs in scenarios requiring knowledge of single or multiple commonsense relations for reasoning. Our work raises a new viewpoint 
about the inner mechanism as well as practical utilization of relational knowledge in PLMs, opening up avenues to better understanding and adapting pretrained language representations.
%This study explores the latent commonsense knowledge in PLMs by opening up new possibilities for distilling ``more'' knowledge from ``less'' parameters. Our findings confirm the conjecture that varied relational knowledge is blended in one shared parameter space due to mini-batch-based optimization during pretraining, and it is feasible to perform unstructured weights pruning upon PLMs to recover the latent subnetwork ad hoc.
%
%To examine the practical utility of these softly disentangled subnetworks on knowledge-intensive tasks, we additionally conducted a suite of experiments. The results show that: (i)~given enough supervision, choosing the ``right'' subnetwork ensembling makes it a good prior for better fine-tuning. (ii)~subnetworks exhibit notably superior performance than their full-scale counterparts under zero-shot setting, including commonsense reasoning and knowledge base completion.
%


%Future work includes applying the proposed procedure to other relational knowledge upon PLMs trained with more advanced objectives and structure. Exploring pretrained auto-regressive  models remains another promising research direction. 

