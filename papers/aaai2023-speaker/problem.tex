\section{Problem Formulation}
\label{sec:problem}

Generally speaking, speaker name sensitivity is defined as the difference in generations of the same dialogue utterances with different speaker names from a model. To investigate it, we formulate the problem mathematically as follows.

A dialogue understanding dataset consisting of dialogues $d_i$ and other task-related stuff $o_i$, such as summaries and question-answering pairs, is denoted as $D=\{d_i, o_i\}_{i=1}^{N}$. Each dialogue is a stream of utterances $u_i$ uttered by two or more speakers $p_i=\{p_i^j\}_{j=1}^M$. $N$ represents the number of samples and $M$ represents speaker counts. We use subscripts $tr$, $va$ and $te$ to refer to training, validation and test sets.

For each sample, we randomly sample names from a pool of speaker names $P$ under the uniform distribution, discard the names in $u_i$ but not in $p_i$,
and construct $M$ one-to-one mappings to the original names, denoted as $p^\prime_i$. It should be noted that we avoid changing names mentioned during the conversation in case they are grounded entities. Genders should be consistent in each mapping if necessary. Then, a new $\{d^\prime_i, o^\prime_i\}$ can be obtained by switching $p_i$ to $p^\prime_i$. Predictions are exchanged back for evaluation.

Dialogue models are expected to perform identically on different switched $\{d^\prime_i, o^\prime_i\}$ and the original $\{d_i, o_i\}$, i.e., get the same scores with task-specific evaluation metrics $\rm{Score}(\cdot)$.

%We switch speaker names as follows.

%\begin{enumerate}[\textit{step}1:]
%	 \item Collect a pool of speaker names as $P$ which can be collected from $D_{tr}$, or other lists of names. % a list online,
%	 \item For $d_i$, we randomly sample names from $P$ under the uniform distribution, discard the names in $u_i$ but not in $p_i$,
%	  and construct a one-to-one mapping to the original names, denoted as $p^\prime_i$. We avoid changing names mentioned during the conversation in case they are grounded entities. Genders should be consistent in each mapping if necessary. %having strong correlations with the dialogue context
%	  \item A new $\{d^\prime_i, o^\prime_i\}$ can be obtained by switching $p_i$ to $p^\prime_i$. Predictions are exchanged back for evaluation.
%\end{enumerate}
%Dialogue models ar
%e expected to perform identically on $\{d_i, o_i\}$ and $\{d^\prime_i, o^\prime_i\}$ and get the same performance with task-specific evaluation metrics $\rm{Score}(\cdot)$.




