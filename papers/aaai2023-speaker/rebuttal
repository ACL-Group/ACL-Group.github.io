We appreciate all of the reviews.

R#2
Questions for us:
1.The motivation of our design is two-fold: a)Encoder states are contextual representations, which are supposed to be different given different input embeddings caused by different names; b)We did a pilot experiment and found that in 200 paired samples, 72.47% of 178 different pairs contain different contents from various part of the input. The cross attention, acting as an information selector among the input, is therefore expected to focus on the same contents.
2.It means the score calculated between the reference output(o) and the generated one(\hat(o)) given the dialogue(d). The score varies for different tasks, such as Rouge, Bleu, etc. We will rewrite it into Score(o^t_i, \hat(o)^t_i).
3.The empirical value of alpha is 0.9 for datasets with more frequent names and 0.7 with less frequent names. The model is not quite sensitive to alpha. For example, the variance of Ins D-BertS(2.22 in Table 2a) is 0.04 among different alpha. L_gen drops from 2.8 to 0.8. L_ins drops from 0.8 to 0.05. L_ins is not negligible and works as an auxiliary loss for training more fair models.

R#7
We will fix presentation issues, limit the scope and add statistical tests. 

R#9
Questions for us:
1.Online approaches are from previous work and we just classify them together.
2.Different data points are only used to provide supervision and calculate the insensitivity loss. The loss is backpropagated to the neural network for updating its parameters. All of the data and codes will be released.

R#10
Weakness:
We mainly focus on the differences of generations which can be easily reflected by the variance or range of evaluation metrics. However, it's difficult for human to measure differences especially among multiple outputs. We will add a human evaluation.

Questions for us:
1.Yes, the augmented samples are the same. With a larger K, the performance is expected to be better and then reach a bottleneck. Due to the limited computational resources, we only consider K=2.
2.All of the name lists are from online websites(https://www.ssa.gov) and previous publications(Tzioumis K, 2018). We will release the data containing the names.
3.The y-axis represents the gap between the performance of a group over the worst-performance group which is further averaged over three runs for each model. 

R#11
Summary: 
We didn't propose any new data augmentation approaches. We classify previous approaches into online ones and offline ones, where data augmentation is one of them. Then, we further propose a novel loss on top of the data augmentation approach. A list of approaches is:
offline
*data augmentation(Aug)
*Aug+our loss(Ins)
online
*replace with ID(ID)
*replace with frequent names(Fre)
*further add Aug and Ins on top of Fre(AugFre, InsFre)

Weakness:
1.We rephrase it to "online nicknames containing unknown words". Examples of nicknames are: JuJuBee_, zykotick9. Even though these names are meaningless, the model can still generate meaningful results after fine-tuning, such as "What system does JuJuBee_ use?". Names are just symbols and there is no inherent difference between a common name and a nickname. However, since the language model is pretrained on large corpora, it's likely to learn that common names represent human, while nicknames are tokenized into more tokens and their representations are not specialized for human. This is consistent with the different trends in Fig5, where datasets with more frequent names need less weight on the insensitivity loss(larger alpha), while the other is the opposite.(The trends in Fig3 are from the same dataset, illustrating the sensitivity with different speaker features.)
2.The difference between them is that online ones need extra data processing steps **during inference** while offline ones don't(Sec3.1&3.2). Data augmentation is an approach to improve the fairness by augmenting fine-tuning data. Differently, varying names in test data is for quantitively measuring the fairness. The additional test data is fixed once constructed and is used to compare different approaches.
3.The names are from previous work(refer to R#10-2). We will add an Ethical Consideration section.

Questions for us:
1.For example, a summary is "Alice is...Her...". If we replace Alice with a male name, the summary will be incorrect. We follow Khalifa et al.(2021)â€˜s work by using consistent gender in each mapping.
2.Unification contains sum() and pad(). The lengths of two distributions are different for two reasons. a)Names may be tokenized into different token counts. This is solved by sum() where we consider the total attention for a single name. b)Long inputs may be truncated at different words. Padding 0's at the end means that this part of contents is missing. The loss won't be very high(refer to R#2-3).
3.Refer to Summary and Weakness-2. Data augmentation only needs data processing during fine-tuning, while online approaches need it both during fine-tuning and testing.

%c)We compared the attention distance of the outputs generated by the vanilla model. It shows that the attention distance for pairs with different outputs is 1.3~2.3 times of the same ones.

%Doing coreference resolution on both dialogues and summaries automatically will bring inevitable errors.
