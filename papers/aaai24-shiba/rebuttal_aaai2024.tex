\documentclass[letterpaper]{article}
\usepackage[submission]{aaai24}
\usepackage{times}  % DO NOT CHANGE THIS
\usepackage{helvet}  % DO NOT CHANGE THIS
\usepackage{courier}  % DO NOT CHANGE THIS
\usepackage[hyphens]{url}  % DO NOT CHANGE THIS
\usepackage{graphicx} % DO NOT CHANGE THIS
\urlstyle{rm} % DO NOT CHANGE THIS
\def\UrlFont{\rm}  % DO NOT CHANGE THIS
\usepackage{natbib}  % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
\usepackage{caption} % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
\frenchspacing  % DO NOT CHANGE THIS
\setlength{\pdfpagewidth}{8.5in} % DO NOT CHANGE THIS
\setlength{\pdfpageheight}{11in} % DO NOT CHANGE THIS
%\usepackage{latexsym}
\usepackage{subcaption}
%\usepackage{subfigure}
\usepackage{hhline}
\usepackage{xcolor}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{amsmath}
%\usepackage{graphicx}
%\usepackage{makecell}
%\usepackage{bm}
\usepackage{url}
\usepackage{float}
\let\Bbbk\relax
\usepackage{amssymb}
\usepackage{tabularx}
\usepackage{makecell}
\usepackage{multicol}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{microtype}
\usepackage{inconsolata}
\newcommand{\secref}[1]{Sec. \ref{#1}}
\newcommand{\figref}[1]{Figure \ref{#1}}
\newcommand{\eqnref}[1]{Eq. (\ref{#1})}
\newcommand{\tabref}[1]{Table \ref{#1}}
\newcommand{\exref}[1]{Example \ref{#1}}
\newcommand{\KZ}[1]{\textcolor{blue}{(Kenny: #1)}}
\newcommand{\MY}[1]{\textcolor{orange}{(Mengyue: #1)}}
\newcommand{\AT}[1]{\textcolor{red}{(Arthur: #1)}}
\newcommand{\CH}[1]{\textcolor{green}{(Chunhao: #1)}}
\newcommand{\JY}[1]{\textcolor{purple}{(Jieyi: #1)}}
\usepackage[ruled,linesnumbered]{algorithm2e}
\usepackage{newfloat}
\usepackage{listings}
\usepackage{tipa}


\DeclareCaptionStyle{ruled}{labelfont=normalfont,labelsep=colon,strut=off} % DO NOT CHANGE THIS
\lstset{%
        basicstyle={\footnotesize\ttfamily},% footnotesize acceptable for monospace
        numbers=left,numberstyle=\footnotesize,xleftmargin=2em,% show line numbers, remove this entire line if you don't want the numbers.
        aboveskip=0pt,belowskip=0pt,%
        showstringspaces=false,tabsize=2,breaklines=true}
\floatstyle{ruled}
\newfloat{listing}{tb}{lst}{}
\floatname{listing}{Listing}
\pdfinfo{
/TemplateVersion (2024.1)
}
\setcounter{secnumdepth}{2} %May be changed to 1 or 2 if section numbers are desired.

\title{Towards Lexical Analysis of Dog Vocalizations via Online Videos}
\begin{document}
%\maketitle


\section{Reviewer 3}
%\MY{Better say that we admit that single-sourced data (Youtube) might be limited however this is the biggest video platform and we have tried to balance origin etc. to avoid bias. Single-breed focus is to ensure data unity and we are currently working on extension to other breeds and animals.}
Single-sourced data from YouTube might be limited, however, this is the biggest video platform and we have tried to balance our data. For example, we use single-breed focus to ensure data unity and we are currently working on extension to other breeds and animals. We will update the challenges of extracting meaningful sounds and context from videos in next version. 
%As YouTube is the biggest online video platform and it presents a large amount and great diversity of Shiba Inu videos, we choose YouTube as our data-source. We will add the challenges of extracting meaningful information in Appendix later\MY{This sentence is not clear regarding ``meaningful information'', which comment you are replying to?}. 

\paragraph{Data Construction}
We mainly concentrate on the youtubers who only own one dog so there is no mixed dog vocalisations. 
% 
This is indeed an assumption and has been partially supported by~\cite{jieyiacl2023}. As a full dog sound is long, filled with pauses and several isolated vocalisations, we propose a more fine-grained structure of sentence, word and subword. We will add this in the next version. 

To ensure the accuracy and consistency of our definition in dog vocalizations, we mainly use models and human evaluation.
%We mainly use pre-trained models and humain evaluation. For ``sentences'', we only extracted the audio tracks by an audio tagging model. For ``words'', we used finetuned model to extract short units and did human evaluation. For ``subwords'', we used the syllable-splitting algorithm and by calculating the similarity, we assign each ``subword'' with an IPA symbol.
%\MY{I don't think you are answering the correct question - it's not about how you segmented everything, but why? You can start by saying that this is indeed an assumption, and has been partially supported in previous papers. However, as a matter of fact, that a full dog vocalization is long, filled with pauses and several isolated vocalisations, we propose such a structure of sentence, word and syllable. Say that you will add this explanation in the next version to avoid confusion}

\paragraph{Methodology}
We choose Shiba Inu because it is widely adopted at home and plenty of videos is available on YouTube as mentioned in Introduction. 
%\MY{say that you will add it later on}
This framework mainly focuses on the dog itself. We think large amount of data can mitigate the influence of human interactions effectively. Each youtuber may present a specific preference, but large amount of users will even this bias. %For example, some hosts like filming dogs in a bath, other may not. 

\paragraph{Results}
This variation in phonetic symbols for the same word type may elucidate why one word type can convey multiple distinct meanings, akin to polyseme. %\MY{polyseme}. 

Given the dataset's web-based origin, determining breed, age, or individual personality presents challenges. We only focus on two available factors, location and activity. Our dataset presents an overall image of Shiba Inu instead of their respective characters. 

Our work can help further dividing current word types into finer ones that each type conveys an exact semantic meaning. For example, an dog sound interpretation application may be developed and hosts can use it to understand their dogs'. 

Our findings have consistently aligned with prior research and initial assumption. Our findings are listed in Table 2. 
%\MY{make your rebuttal self-contained - the reviewer does not know which question you are responding with ``no''}.


\section{Reviewer 4}
Most of our segmentation framework is based on existing methods, however this is because we disassemble a novel problem (deciphering animal language) into sub-steps that can be partially solved by SOTA methods, for the purpose of leveraging extensive research on humans. However, we don't think this weakens the novelty in our work as we are the first work to implement a web-data-driven approach to explore semantics of animal language. The pipeline we proposed is workable and reusable and we have promising results. 
%\MY{the meaning is here, but try to soften the tone by starting that Yes most of our segmentation framework is based on exsiting methods, however this is because we disassemble a novel problem (deciphering animal language) into sub-steps that can be partially solved by SOTA method, for the purpose of leveraging extensive research on humans. However, we don't think this weakens the novelty in our work as we are the first to ....}


\paragraph{Question 1}
A subword is akin to a syllable. A syllable is minimally composed of a local sonority maximum, typically represented by a vowel, and optionally, it may include less sonorous sounds in the onset and coda ~\cite{rasanen2018pre}. 
%Sonority typically exhibits a monotonic decrease from the nucleus towards the edges of the syllable ~\cite{hooper1976introduction}. 
``Sonority fluctuation'' means that the changes in the wave envelope of a sound with time caused by the variations in the sonority of a syllable. 

\paragraph{Question 2}

%0.59，该怎么讲呢？我们合并种类之后，准确率就高了；14个类，很多，且相似，可能之间有overlap，类和类之间有ambiguity，我们会在新的版本更新；我们标了两千多条，这个东西确实很难，从一千多数据到两千多，精度并没有提高很多。我们找的视频本来就很难，视角很低，人的肢体更丰富，画面中一大半都是狗，对狗的动作识别不充分，和人的差异性；人要是看的好，承认有gap？
% 狗的动作意图，镜头转换，有些动作复合在一起，
% 我们的test set是balance的，evaluation是严格的；
%\MY{say it upfront first: The accuracy of 61/4\% is not low, since the classification is on 14 different dog activities, with some exhibiting certain similarities between each other. then give the activity list, say that the reason why we utilized a fine-grained activity class taxonomy is because we would like to investigate precise correlations between vocalisation types and certain activity. }

We select the topmost prediction. 
Our newest activity classification accuracy is 61.4\% and this is not low, since the classification is on 14 different dog activities, with some certain exhibiting similarities between each other as shown in Appendix Figure 1 (b).  
%\MY{annotating more data looks dodgy - why do this? explain it. Otherwise i think this paragraph can be removed}
%In Appendix Figure 1 (b), we further explain that this low accuracy is due to the similarity of these activities themselves. 
A full activity list contains ``Mount Or Hump (beg)'', ``Play With People'', ``Sit'',
``Lay Down'', ``Walk'', ``Sniff'', ``Eat'', ``Stand'', ``Take a
Shower'', ``Run'', ``Be Touched'', ``Unknown'', ``Fight With Dogs'' and ``Show Teeth or Bit''. The reason we utilized a fine-grained activity class taxonomy is because we would like to investigate precise correlations between vocalization and certain activity. 
If we further integrate similar activities of dogs and define only 10 categories, its accuracy will grow to 74.3\%.

The dog's activity may undergo several changes in a short period of time, but we only label one activity as ground truth in the test set. The model may also notice other actions. Also, the prediction of dog activity is relatively difficult compared with human activity recognition. The shooting angle is often high, resulting in little variation in the movements of dogs. The distinction between dog movements is less obvious because dogs have shorter limbs. Due to the nature of YouTube videos, we also encounter low resolution of videos and frequent camera movement and transition. 


\section{Reviewer 6}

\paragraph{Question 1}
Please refer to Reviewer 4, Question 2. 

\paragraph{Question 2}
This pipeline can be easily reused to any other animal which makes it a valuable tool for other animal researchers. Our approach offers a new opportunity to explore animal language through large amount web-based data.

We explore ``word sequence'' to analyse the semantic inter-conversion of ``words''. 
We also try to decipher the meaning of dog words, and this work indicates the possibility of dividing words into finer semantic units. 
Our dataset is the biggest dog semantic dataset and will facilitate dog language understanding in the future. 
This work could help enhancing our communication with dogs.

\paragraph{Question 3}
The task is single-label. We admit that these labels may not be totally mutually exclusive, but in each scenario, there will must be only one main location and one main activity. We decide the label of location by considering the occupying proportion of the image. In Appendix Figure 5, we give pictures to illustrate these scenarios. 

\paragraph{Question 4} %\MY{still would suggest you concisely summarize each reviewer's question as they probably will forget their questions and didn't bother to check the record}
The findings is expected to generalize to other dog species. We are consider other species. In this work, we mainly concentrate on Shiba Inu. 


\bibliography{anthology,custom}
\end{document}
