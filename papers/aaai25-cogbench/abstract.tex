\begin{abstract}
    % With the rapid development of Large Vision Language Models (LVLMs), they 
    Large Vision-Language Models (LVLMs), despite their recent success, 
are hardly comprehensively tested for their cognitive abilities.
%are progressing towards human-level cognition ability.
    % Evaluating the cognitive ability of LVLMs becomes an important and urgent issue.
    % Effectively evaluating the cognitive ability of LVLMs has become an increasingly important concern.
%    Though there are a few evaluation benchmarks considering the cognitive ability of LVLMs, there is still a gap between cognitive evaluation methods for machines and those for humans.
    % \MY{you should mention in the first sentence that though there are a few evaluation benchmarks however there is still a gap in human/machine tests}
    % \XJ{fixed}
%    In cognitive function test with humans, a Cookie Theft picture description task is widely utilized to aid in the diagnosis of cognitive and language functions of humans. 
Inspired by the prevalent use of the ``Cookie Theft'' task in human cognition test, 
we propose a novel evaluation benchmark to evaluate high-level cognitive abilities of 
LVLMs using images with rich semantics\footnote{
The code and the data of CogBench is released at: %https://anonymous.4open.science/r/CogBench, while the full version of the code and data will be released after the paper is accepted.
% Code and data are available at \\
\url{https://anonymous.4open.science/r/CogBench-C5D6}.
}.
    % \MY{high-quality is imprecise, use complex, information-dense etc.}\XJ{fixed}
It defines eight reasoning capabilities and consists of an image description task and a visual question answering task.
Our evaluation on well-known LVLMs shows that there is still a large gap in cognitive abilities between LVLMs and humans. 
% \KZ{It's not a good idea to use colors in your main text. You can use boldface or italic.}
% \XJ{The colors are intended to match those in Fig. 1.}
\end{abstract}
