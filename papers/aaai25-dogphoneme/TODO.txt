1. Why are the phoneme accuracies by human judges not high enough (64%-70%)? The agreement between the judges seems high, so the phonemes are really not good enough. 

2. What is the quality of those phones that are deemed not phonemes? (140-35 of them). If the accuracy of those are on par with or even better than the final 35 of them, then it's a failure of our iterative algorithm. In this case, we have
to review our algorithms.

3. I think the reason why the phonemes are not good is the initial 140 phones 
from HuBERT are not high quality. And the reason for that, is the training data
is not good enough.

4. There are two routes to fixing the quality of the training data for HuBERT: 
i) enlarge the size of the data; ii) make the training data cleaner.

5. Why is there only 30k dog sentences left from more than 13,000 videos? 
On the one hand, can we get more videos, but on the other hand, and more 
importantly, can we keep more sentences from each video.
6. Can we compare the candidate words obtained from grammar induction and 
energy method? How many of them are similar? If they are very different, which
one is a better approach? What is wrong with grammar induction?

7. For this whole pipeline (representation -> candidate words finding -> refine the words), we address them seperately; should we merge them together and get a better HuBERT result?

8. For the whole pipeline, we can also apply this on human language first? And compare the results since we have the groundtruth of human results.
