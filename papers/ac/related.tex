\section{Related Work}
\label{sec:related}
We review three types of related work in this section.
They are selectional preference, semantic role labeling,
and automatic lexicon construction.

\subsection{Selectional Preference}
The most related work to our problem (AC) is
selectional preferences (SP), which
aims at computing preferences over arguments indicated by a verb,
given the fact that some arguments are more
suitable for certain verbs than others. For example,
``drink water'' is more plausible than ``drink desk''.
While our problem defines a controllable level of abstraction
for verb arguments, selectional preference
often outputs all possible classes for the arguments.
Moreover, SP doesn't consider the overlap between concepts
which results in highly similar classes/concepts.
We have compared our approach with SP
in \secref{sec:eval} and conclude that by adding the overlap constraint,
we can generate lexicons that are more suitable for semantic analysis.

There are several approaches to computing SP.
The most relevant ones to this paper are {\em class-based} SP approaches.
The idea of these approaches is to
generalize arguments extracted from corpus to human readable
high level concepts using a taxonomy such as WordNet\cite{wordnet}.
%They first extract class-representation of the verb's seen arguments
%and then generalize to unseen arguments according
%to extracted classes.
These classes can be seen as the conceptualization of verb arguments.
The first and most representative approach was proposed
by Resnik\cite{resnik1996selectional},
which is used as the baseline method for comparison purposes in this
paper.
%They used WordNet\cite{wordnet} as candidate set to find the classes for
%a verb's arguments.
They propose an preference score based on the entropy
called selectional association to measure the preferences
of a verb on classes. To measure the preference on words,
they use the maximum selectional association among
all classes that the word belongs to.
%He calculated preference score for a predicate as
%$$
%A(p,c)=\frac{p(c|p)log\frac{p(c|p)}{p(c)}}{\sum_{c'\in C}{p(c'|p)log\frac{p(c'|p)}{p(c')}}},
%$$
%where $p$ is predicate, $c$ is a WordNet synset and $C$ is the collection of WordNet synsets,
%thus obtained the associational strength of synset $c$
%on the predicate by measuring the difference between the prior for $c$
%and the probability of $c$ given predicate.
%To rank words, which belong to several synsets, for predicate,
%Resnik went through all the possible $c$ for word $w$,
%and assign the maximum preference score to $w$. We implemented
%this method and compared its accuracy with our algorithms.
Instead of WordNet,
Pantel et al.\cite{pantel2003clustering}
proposed a clustering method (named CBC) to
automatically generate semantic classes,
to overcome the problem of rare senses and the
lack of domain specific senses in WordNet.
They aim to find several tight clusters for words
which are distinct to each other in the feature (TF-IDF)
space to represent the semantic classes.

Li and Abe\cite{li1998generalizing} proposed a {\em cut-based} SP method,
aiming to find an appropriate level of generalization of classes
on WordNet hierarchy, to prevent class representation of arguments
from being too specific or too general. They induced the problem to
estimating a tree cut model on a thesaurus tree, and the method is
based on Minimum Description Length (MDL) principle.
The thesaurus tree was built on top of WordNet in which leaf nodes are
nouns and internal nodes are noun classes.
MDL serves as a criterion for the best cut, representing the
tradeoff between model complexity and goodness.
%They fitted the model
%by minimizing the sum of model description length and
%data description length.
The resulting best tree cut forms several sets of semantic classes
in the appropriate generalization level. Then, the same technique as
class-based SP was applied to compute the preference score.

The next category of methods are {\em similarity-based}.
Clark and Weir\cite{clark2001class} proposed another method
of determining the appropriate level of generalization.
They use Chi-square test to determine whether a class should
be selected or expended to some of its children in the taxonomy. Specifically,
Chi-test measures how similar the probabilities between the parent class
and children classes are, given the same argument and verb.
A significant difference indicates that the parent class is an appropriate
generalization. Otherwise, the algorithm
continues to test the child classes. Erk\cite{erk2007simple} proposed
to make use of the similarity between arguments to compute a
heuristic preferences score for ranking arguments.
These two distribution similarity based methods have no
ability to generalize, which is important for us.

Recently, a {\em generative model} approach called LDA-SP
was proposed by Ritter et al.\cite{Ritter:2010}. They apply a Link-LDA model
to extract latent argument classes for each verb. However,
each latent class learned by this method is a word distribution,
which is not human readable.

%In CBC, the centroid of a cluster is constructed by
%averaging the feature vectors of a subset of the cluster members.
%And the subset is the committee that determines what
%other elements belong to the cluster. In the CBS algorithm,
%committee is constructed as follows: first compute each element's
%top-$k$ similar elements ($k$ is small), then construct
%a collection of tight clusters using the elements above,
%and now those elements serve as committee in each cluster.
%If a newly formed committee is similar to existed committee,
%then it is discarded. In the end, each element $e$ is
%assigned to its most similar clusters.

%Other approaches to solve SP include
%similarity-based methods \cite{dagan1999similarity, erk2007simple},
%discriminative approach \cite{bergsma2008discriminative},
%and generative probabilistic models \cite{rooth1999inducing,
%ritter2010latent, seaghdha2010latent}.
%These methods do not use classes as intermediate representation,
%thus less related to our work.

\subsection{Semantic Role Labeling}
Another related problem is Semantic Role Labeling (SRL), which aims at
assigning semantic roles to a verb's related arguments.
The set of roles are universal and predefined,
and consequently SRL provides coarse-grained output compared
to our action concepts. The task is commonly solved
by supervised learning algorithms with manually labeled data.
%which are two significant deviations from our problem.

Some proposals based on grammatical rules were first introduced to solve
the SRL problem, including Link parser\cite{sleator1995parsing} and
MiniPar\cite{lin1994principar}. Rule-based approaches require
a large mount of human efforts for building rules and are limited to specific domains.

FrameNet is a manually annotated semantic role lexicon,
which defines around 1200 semantic frames based on
the theory of Frame Semantics. Each semantic frame specifies an event
and all roles related to the event. Each role in the event
is also called a frame element.
For example, in the sentence ``Will you help the Government
find your brother?'',
``help'' evokes a frame {\em Assistance}.
{\em Assistance} has several frame elements,
including {\em Helper}: ``you'', {\em Benefited party}:
``the Government'', and {\em Goal}: ``find your brother''.
Different terms can evoke the same frame, e.g., ``assist''
and ``aid'' may also evoke frame {\em Assistance}.
%In our work, action frames which are similar can be generated
%automatically and the results was shown in \secref{sec:eval}.
PropBank labels verbs and their arguments
in the sentence without generalization.
VerbNet\cite{KipperDP00} focuses on verbs and provides mapping
between lexical resources such as FrameNet, PropBank and WordNet.

Several machine learning algorithms\cite{gildea2002automatic,pradhan2004shallow,pradhan2005semantic,
marquez2008semantic}
using large scale annotated
corpora, such as FrameNet\cite{baker1998berkeley}
and PropBank\cite{kingsbury2002treebank} as training data
are used to learn domain-specific, automatic semantic role labeller.

%In order to do SRL automatically, Jurafsky and Gildea\cite{gildea2002automatic} proposed one of the fundamental approaches to the problem by using WordNet and FrameNet. A supervised classifier is trained based on both syntactic and semantic features extracted from corpus, including
%\begin{description}\setlength{\itemsep}{-\itemsep}
%\item[phrase type]Directly from constituent parse
%\item [governing category] Indication if a Noun Phrase(NP) is subject or object of the verb
%\item [parse tree path] Path from target word
%\item [position] Where is the constituent regarding to the predicate
%\item [voice]Active/passive concluding from passive identifying patterns
%\item [head word]Head word of constituent
%\end{description}
%
%More works are done following the idea (\cite{pradhan2004shallow,
%pradhan2005semantic}), they cooperating more features in
%svm training including name entities in constituents, part of
%speech tag of the headword, etc, and explore more on automatic SRL
%by extending basic features and changing machine learning algorithms,
%and state-of-art performance is proposed by Marquez et al
%\cite{marquez2008semantic}.
%
%
%One of our approaches applying The Strength Pareto Evolutionary Algorithm 2 (SPEA2) to our problem, in which we induce our problem to a multi-objective issue and aiming at finding the approximation of the Pareto set. In our problem, we consider several different objectives to achieve both statistical representative and human plausible results. Considering objectives as vector, defined by Pareto dominance, objective vertor $y^1$ dominate objective vector $y^2$ indicate that all components of $y^1$ is larger or equal to $y^2$ and at least one component of $y^1$ is larger than that of $y^2$. Thus optimal solutions are solutions not dominated by any other solutions, i.e. Pareto set, and such solutions may not be unique. To deal with the large search space of optimal solutions, evolutionary process is introduced to approximate Preto Set. The basic idea is keeping good results while randomly generating new "population" expecting some of them are results worth remaining, during the procedure two selections have to be done:mating selection, which decides which solutions will be used in generating population; and environmental selection, which decides which solutions are survived.
%}

\subsection{Automatic Lexicon Construction}
Several efforts have been devoted to automatically
generating lexicons for semantic analysis.
PATTY\cite{nakashole2012patty} is a lexicon of binary relations
which are not limited to predicates.
%Similar to conceptualizing verb arguments in this paper,
Binary relation patterns in PATTY are represented by
%a linguistic pattern and ontological types, which is
semantic classes from YAGO2\cite{SuchanekKW07}.
PATTY can also generate subject-predicate-object triples from
the binary relations\cite{nakashole2013discovering}. However, PATTY
focuses on mining relations, with no constraints on the
numbers of possible semantic classes or the overlap between
them.
%This goes against our main objective of minimizing
%the number of concepts for each arguments.
%Moreover, there is also no constraint on overlap between two ontological
%types.

ReVerb is an open information extraction project, aiming to
extract relations between two terms. However, all the relations in
ReVerb are not generalized such that it cannot recognize any
relation that it has never witnessed before. Thus ReVerb
is often insufficient for large scale semantic analysis.
%During the construction of relational extractions knowledge base,
There exist several pieces of work to generalize ReVerb.
Velardi et al.\cite{velardi2013open} induce an ontology
using instances of relations in ReVerb.
%, thus extracting concept
%level relation.
Min et al.\cite{min2012ensemble} use ReVerb data
as corpus and extract relations in an unsupervised way.
ReVerb instances are then clustered to get semantic classes,
and the final output would be $\langle$semantic class,
relation, semantic class$\rangle$ triples.
The generalization processes in these proposals are only based
on the relation instances in ReVerb, without using external
knowledge, i.e., taxonomies. Therefore, these proposals still suffer
from a limited scale.

%\KZ{Is there any work that makes use of ReVerb or Google n-gram data
%to do verb semantic analysis in general?}

Google syntactic n-gram data, extracted from English books,
was also used for understanding the semantics of plain texts.
Polajnar et al.\cite{polajnar2013learning}, use the
verb's subjects and objects in the data
to construct verb tensors to represent the semantics
of transitive verbs; Welke et al.\cite{welkegrounded} focused
on using the prepositional relations between objects and locations
to make the robots understand the position of objects; others
\cite{borin2013mining,riedlscaling,kaiserextracting}
used the data as a general corpus. 
%We have also reported the action concepts
%extracted from the Google n-gram data. The lexicon learned from
%Google n-gram can achieve high accuracy and low overlap. 
However, this
data set is small compared to the web scale: we only extracted
2323 verbs, hence there are not as many verb-subject and verb-object pairs
as the web data. Moreover, books are written in formal
language and newly created terms are often not covered in this data.

%As for search algorithm, we apply Simulated annealing(SA) to solve our problem. SA is a probabilistic metaheuristic obtaining approximation of the global optimum in a large search space. SA gets satisfying approximation for our NLP problem within reasonable time comparing to other search algorithm such as gradient descent.



