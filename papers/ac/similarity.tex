\subsection{Term Similarity Computation}
\label{sec:sim}
% We need the lexicon for large number of verbs... This could be difficult.
%One popular way of computing term similarity is based on a predefined taxonomy.
When computing the similarity of two terms, a predefined taxonomy is often used to provide
hyponyms and hypernyms information of both terms.
Those hyponyms and hypernyms can be used to represent the terms in
set or vector forms, then Jaccard similarity or cosine similarity
can be applied to compute the similarity between two terms.
However, if two terms do not share common hyponyms or
hypernyms, then the taxonomy-based method may not work well.
An example is ``company'' and ``stock''. We
argue that by complementing our action concept lexicon with taxonomies, we
can obtain a better similarity result. In the example of ``company'' and
``stock'', the two terms can be connected by verb ``release'' or ``sell''
in our lexicon.
%can provide
%extra knowledge for calculating the similarity of these two terms.

Li et al.\cite{LiWZWW13} introduces a term similarity computation method
using Probase. We call it noun-based term similarity method.
In this experiment, we implement Li's method and also define our term similarity
function using our action concept lexicon.
Similar to Li's method, we apply different similarity
functions on terms according to their types (concepts or entities).
Our verb-based term similarity is computed as:
\begin{eqnarray*}
sim_{c}(c_1,c_2) &=& \frac{V_o(c_1)\cap V_o(c_2)}{V_o(c_1)\cup V_o(c_2)}, \\
sim_{e}(e_1,e_2) &=& \max_{\substack{c_i\in C(e_1),c_j\in C(e_2)\\c_i\neq c_j}}sim_{c}(c_i,c_j), \\
sim_{c\&e}(c,e) &=& \max_{c_i\in C(e),c_i\neq c}sim_c(c,c_i),
\end{eqnarray*}
where $V_o(c)$ is the set of verbs taking concept $c$ as object in action concept lexicon, $V_s(c)$
is the set of verbs taking $c$ as subject. $C(e)$ is the set of concepts for entity $e$ in
Probase.
We compute the similarity score between two terms by
averaging over the similarity scores computed by both
the verb-based method and noun-based method:
$$
sim(t_1,t_2)=(sim_{verb}(t_1,t_2)+sim_{noun}(t_1,t_2))/2,
$$
where $sim_{verb}(t_1,t_2)$ and $sim_{noun}(t_1,t_2)$ refer to the verb-based and noun-based similarity scores,
respectively.
We compare our method (Verb-based) with Li's method (Noun-based) and a combination of both
methods (Combined) on a word similarity label dataset
``Word Similarity 203''\cite{LiWZWW13}, and use Pearson correlation as the evaluation metric.
The result is shown in \tabref{tab:sim}.
\begin{table}[th]
\small
\centering
\caption{Pearson Correlation for Term Similarity Computation}
\begin{tabular}{|c|c|c|}
\hline
Noun-based & Verb-based & Combined \\
\hline
\hline
0.72 & 0.57 & {\bf 0.76} \\
\hline
\end{tabular}
\label{tab:sim}
\end{table}

We can see that, by combining knowledge provided by Probase taxonomy and our action concept
lexicon, we can get a better similarity result.

