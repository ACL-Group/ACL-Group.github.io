\section{Approach}
\label{sec:algo}
%In this section we first give an overview of a probabilistic taxonomy
%that provides the vocabulary of concepts to abstract the verb arguments.
%as well as probabilistic scores for computing various rankings.
We first present the way to compute the quality of
arguments and the quality of concepts, and then
a branch-and-bound algorithm to solve the
action conceptualization problem in large scale.
Finally, we propose a method to solve the action
conceptualisation problem on triplets.
%Finally, we provide a method to rank the
%output action concepts from solution of action conceptualization.
In the rest of this section, the term ``argument'' refers to either
the object or the subject of a verb.

\subsection{Measuring Quality of Arguments}
To obtain a large set of arguments for each verb, we extract the arguments
using a dependency parser on a large text corpus. However, all dependency
parsers would have errors. When the sentences come with clauses, the
accuracy of dependency parser would be worse. Due to our observations,
some errors have the same patterns. \KQ{For example, ``food'' in ``food to eat''
is incorrectly labeled as the subject of ``eat'', and the same error patterns
appear in ``water to drink'', ``game to play'', etc. 
Similarly, ``time'' in ``play this time'' is incorrectly labeled as object of ``play''.} Also, we discover that the
wrong arguments often appear in only a few patterns. Notice that, when an
argument is correct for the verb, it could appear in different patterns.
Consider the object of ``eat'', ``meat'' appears in ``eat meat'', ``eat expensive meat'', ``eat not only meat'',
etc., while ``time'' only appears in ``eat this time'', ``eat next time''.
\KQ{maybe need to consider a good example.}
We define a pattern as a subtree in the dependency tree
according to the following rules:
\begin{itemize}
\item The argument and one of its child
forms a pattern:
$$\{POS_{arg}, DEP_{arg}, POS_{child}, DEP_{child}\},$$
where $POS$ and $DEP$ stand for POS tag and dependency type, respectively.
\item The argument and its sibling forms another pattern:
$$\{POS_{arg}, DEP_{arg}, POS_{sib}, DEP_{sib}\}.$$
\end{itemize}

For each argument $e$ of verb $v$, we collect the set of its patterns $M_{e,v}$,
and argument that appears in more patterns has higher probability to be correct,
and thus has higher quality. We use entropy to measure the correctness. Higher
entropy means that the argument is less informative,
the higher probability that it is a correct argument. The entropy is defined as:
\begin{equation}
\text{Entropy}_v(e)=-\sum_{m\in M_{e,v}}{P(m)\log{P(m)}}
\end{equation}

Moreover, the relatedness of each argument to the verb is different. For example,
``fruit'' may be highly related to verb ``eat'', but ``thing'' may appear in the objects
of many verbs. Therefore, we use mutual information to measure the relatedness
between two terms. The mutual information $MI_v(e)$ is defined as:
\begin{equation}
\text{MI}_v(e)=p(v,e)\log \frac{p(v,e)}{p(v)p(e)}
\end{equation}

Entropy measures the correctness of the argument while mutual information measures
the relatedness to the verb. Therefore, we compute the quality of an argument by
combining these two measures:
\begin{equation}
Q_v(e)=\text{Entropy}_v(e)\times \text{MI}_v(e)
\label{eq:qe}
\end{equation}


%\subsection{Confidence Functions}
%To define the confidence function $g_v$ for a verb $v$,
%we suppose that the arguments that are relevant and correct to the verb
%are more ``informative'' than those that are not.
%For example, as direct objects, ``basketball'' is more informative to the verb
%``play'' than ``weekend'',
%because ``basketball'' appears frequently in the context of the ``play'', but
%not as frequently in the context of many other verbs; while ``weekend''
%appears frequently not only next to ``play'' but also to many other
%verbs, such as ``go'', ``spend''.
%%but does not appear in the context of many other verbs.
%%However, ``weekend'' can appear in the context of many
%%verbs according to the wrong parsing (e.g., recognized as the object of
%%``play'', ``go'', ``buy'', etc.). According to the above observations,
%Inspired by such observation, we propose two confidence functions.
%
%\textbf{Mutual Information} is a measure in information theory which can
%capture the strength of mutual connection between two terms.
%In this paper, we can use the binary version of
%the mutual information $MI_v$ in place of $g_v$:
%\begin{equation}
%MI_v(e)=
%\begin{cases}
%1 & \mbox{if}~\ p(v,e)\log \frac{p(v,e)}{p(v)p(e)}> 0,\\
%-1 & \rm{otherwise}
%\end{cases}
%\end{equation}
%The probability $p(v,e)$ is the co-occurrence probability
%of $v$ and $e$ in the corpus, $p(v)$ and $p(e)$ are
%the occurrence probabilities of $v$ and $e$ in corpus.
%\KQ{Concepts cover less informative instances
%(with negative mutual information) would be penalized}
%
%%\textbf{TF-IDF} is a confidence scoring function in information
%%retrieval for identifying the importance of a term to a document.
%%We use TF-IDF to measure the confidence of $e$ as the importance
%%of $e$ to verb $v$. Specifically, $g_v$ is defined as:
%%\begin{equation}
%%TFIDF_v(e) = freq(v,e)\cdot \log\frac{\rm{\#\ of\ verbs}}{|\{v|e\in A_v\}|},
%%\end{equation}
%%where function $freq$ is the number of times $v$ and $e$ co-occur
%%in the corpus.

\subsection{Measuring Quality of Concept}
To conceptualize the arguments of a verb, we need a taxonomy that contains
abundant of concepts. However, the granularity of each concept could be
very different. Concepts like ``item'' and ``thing'' can cover many arguments
of the verb, but they could be too vague, because most of the entities in those
concepts do not appear as arguments of the verb. Although there
is no direct connection between the entity distribution of concepts and
the arguments, we find that the entities that appear most frequently
as arguments of the verb, also appear most frequently in the concept used
to summarize the arguments. For example, the most frequent objects of ``eat''
are ``food'', ``bread'', ``meal'', ``meat'', etc. Under concept ``food'',
a proper selection to summarize the objects of ``eat'', the most frequent entities
could be ``fruit'', ``meat'', and ``bread'' in the taxonomy. But for a less
proper concept ``item'', the most frequent entity could be ``clothing'', ``book'',
``furniture''. Although ``meat'' and ``bread'' are also entities of ``item'',
they are not the majorities. According to the above observation, we assume that
the higher similarity between the distribution of entities in the concept and
that in the arguments, the higher quality is the concept.
Specifically, we compute the quality of a concept as the cosine similarity between the
entity distribution of the concept and the argument set:
\begin{equation}
Q_v(c)=\text{Cosine}(V(c),V(A_v)),
\label{eq:qc}
\end{equation}
where $V(c)$ is the vector of probabilities $p(e|c)$ given by the taxonomy
for all entities in the taxonomy.
Vector $V(A_v)$ comprises of $p(e|A_v)$ the probability of each entity $e$
appearing in $A_v$.

%\subsection{A Probabilistic IsA Taxonomy}
%In this work, we use a probabilistic isA taxonomy called Probase
%\cite{WuLWZ12} which is public for download.
%Probase is a large collection of concept-subconcept (e.g., company vs.
%tech company) or concept-entity (e.g., company vs. microsoft) pairs
%which were extracted automatically by the Hearst pattern \cite{Hearst92}
%from a large web corpus.
%Probase also associates with each pair: a {\em frequency} in which
%the pair appears in the corpus, a {\em typicality score} which is
%essentially the conditional probabilities $p(e | c)$ and $p(c | e)$,
%where $c$ and $e$ represent ``concept'' and ``entity'', respectively.
%This taxonomy provide a large universe of concepts which
%our algorithms will search against to find the minimum set of concepts
%to cover a verb's arguments. Furthermore, the typicality score allows
%the algorithms to determine the importance of a concept given an entity
%and vice versa.

%\subsection{A Greedy Solution}
%\label{sec:greedy}
%The greedy solution comes up with greedily select the concept with
%smallest score according to \eqnref{eq:objfunc}.
%%Our first attempt at the NP-hard action conceptualization problem
%%is a greedy algorithm.
%%It follows a heuristic to select one concept from a candidate set
%%at a time until the final concept set is formed that covers all
%%the input arguments.
%%The candidate set can be all concepts in Probase.
%%The algorithm first creates two argument sets
%%$L$ and $D$. $L$ contains all arguments waiting to be covered
%%and $D$ contains all the arguments already covered. Initially,
%%$L$ is the set of all input arguments, and $D$ is empty.
%%In each iteration, the algorithm selects and remove a concept from
%%the candidate set which covers most arguments
%%in $L$ and least objects in $D$ while satisfy the overlap constraint
%%(see \eqnref{eq:overlap}) at the same time.
%%
%%For practical purpose, we use a reduce candidate set which contains only
%%those concepts that are in Probase and are also in the input
%%argument set. We do this primarily to speed up the computation and
%%our experiment shows that it doesn't affect the overall quality of
%%the solution.
%%%If an object is a concept in Probase, like ``clothing'', ``jewelry'' for
%%%verb ``wear'', and ``food'', ``meal'' for verb ``eat'', we put them
%%%in the candidate concept set for ``wear'' and ``eat''.
%%% \KZ{But where do we select this concept from? What is the candidate set?}
%%The newly selected concept is added to the {\em selected concept list}
%%(SCL) and all the arguments covered by the selected concept are moved
%%from $L$ to $D$ before the next iteration starts.
%%The iteration ends when $L$ is empty.
%%If $L$ is not empty, and there's no concepts in the candidate set
%%that doesn't violate the overlap constraint, then there's no
%%solution to the problem. The details of this greedy solution is shown
%%in Algorithm \ref{vega}.
%%no more
%%concepts can be added to $SCL$ because all the remaining concepts
%%violate the overlap constraint with concepts in $SCL$.
%%$L$ may be non-empty when the iteration ends.
%%As a special case, objects still in $L$ are selected as
%%concepts without considering the overlap constraint.
%
%\begin{algorithm}[th]
%\caption{Greedy Solution}
%\label{vega}
%\begin{algorithmic}[1]
%%\Function{CalcCover}{concept,E}
%%\State $coverage \leftarrow 0$
%%\For {$e \in E$}
%%\If {$e\ isA\ concept$}
%%\State $coverage \leftarrow coverage+1$
%%\EndIf
%%\EndFor
%%\State \textbf{return} $coverage$
%%\EndFunction
%%\Statex
%%\Function{PickConcept}{leftE,doneE,candidateC}
%%\State $pickC \leftarrow NULL$, $masCover \leftarrow 0$
%%\For {$c \in candidateC$}
%%\State $leftCover \leftarrow calcCover(c,leftE)$
%%\State $doneCover \leftarrow calcCover(c,doneE)$
%%\State $cover \leftarrow leftCover-doneCover$
%%\If {$cover>maxCover$}
%%\State $maxCover \leftarrow cover$
%%\State $pickC \leftarrow c$
%%\EndIf
%%\EndFor
%%\State \textbf{return} $pickC$
%%\EndFunction
%%\Statex
%%\Function{Process}{corpusE,candidateC}
%%\State $L \leftarrow corpusE$, $D \leftarrow \emptyset$
%%\State $SCL \leftarrow \emptyset$
%%\Repeat
%%\State select $c$ from $candidateC$ covering most arguments in $L$ and least in $D$ which satisfies constraint
%%\For {$e$ isA $c$}
%%\State delete $e$ from $L$
%%\State add $e$ to $D$
%%\EndFor
%%\State add $c$ to $SCL$
%%\State delete $c$ from $candidateC$
%%\Until{$L = \emptyset$}
%%\State \textbf{return} $SCL$
%%\EndFunction
%%\end{algorithmic}
%%\end{algorithm}
%\Function{Process}{corpusE,candidateC,K}
%\State $SCL \leftarrow \emptyset$
%\Repeat
%\State $S\leftarrow \emptyset$
%\For {$c\not\in SCL$}
%\State $Score\leftarrow 0$
%\For {$c'\in SCL$}
%\State $Score\leftarrow Score + Overlap(c,c')$
%\EndFor
%\State $Score\leftarrow (1-w)*Score - w*Coverage(c)$
%\State Insert $<c,Score>$ to $S$
%\EndFor
%\State Insert $c_{max}$ with smallest score to $SCL$
%\Until{$SCL.size = K$}
%\State \textbf{return} $SCL$
%\EndFunction
%\end{algorithmic}
%\end{algorithm}

%When we collect new objects, we need to update our action knowledge. Given
%a set of new collected objects, we first conduct our \emph{Action Extraction}
%on these objects to get a list of proper concepts; then we merge these concepts
%with concepts in our previous action knowledge.

%\input{algo_cluster}

%\input{algo_ls}

%\input{rank}

%\subsection{Approximation}
%Solving AC is much more time consuming than finding $k$-cliques in the
%concept graph $G$ because in AC, the choice of the $n$-th node in an $n$-clique
%depends on the configurations of all $(n-1)$-cliques.
%%rather than some summary information.
%The difficulty lies in the submodular function, which acts
%as the objective function.
%We thus approximate the problem to a maximum weighted $k$-clique finding
%problem by changing the objective function
%to a summation. Specifically, we change $f$ in Definition \ref{def:acw} to
%\begin{equation}
%\tilde{f}(C_k)=\sum_{c\in C_k}{\sum_{e\in E_c\cap A_v}{g_v(e)}}.
%\label{eq:approxf}
%\end{equation}
%
%This new objective function tends to over-estimate due to the
%possible overlaps between the $k$ concepts.
%However, since the overlaps are bounded by $\tau$,
%we can obtain a bound for the over-estimation.
%
%%\begin{lemma}
%%The score of approximated action conceptualization problem is no
%%larger than $k$ times of the original action conceptualization problem.
%%\end{lemma}
%%\begin{proof}
%%Compared to the original scoring function $f$, we repeatedly compute
%%the score of an entity $g_v(e)$ for $|\{c|c\in C_k, e\in E_c\}|$ times
%%in the new function $f'$.
%%i.e., the number of selected concepts that cover the entity $e$ in $A_v$.
%%Then we have the following relation between the two problems:
%%$$
%%f'(C_k)=f(C_k)+\sum_{e\in \cup_{c\in C_k}{E_c}\cap A_v}{(|\{c|c\in C_k, e\in E_c\}|-1)g_v(e)}
%%$$
%%In the worst case, each entity is covered by all of the $k$ selected
%%concepts, i.e., $|\{c|c\in C_k, e\in E_c\}|=k$. Then we obtain a simpler
%%bound: $f'(C_k)<=f(C_k)+(k-1)f(C_k)=kf(C_k)$.
%%\end{proof}
%
%\begin{lemma}
%The approximation ratio of $\tilde{f}(C_k)$ over $f(C_k)$ is
%\[\max \left\{
%	\frac{2k + (k^2 + k) \tau}{2k - (k^2 + k) \tau},
%	\frac{(k-1)\tau + 2}{(k-1)\tau}\right\}.\]
%\end{lemma}
%\begin{proof}
%First, let us assume that for any $c \in C_k$, $E_c \cap A_v$ is a uniform
%sample of $E_c$.\footnote{This is a reasonable assumption because the arguments
%are extracted from large text corpus which is independent from the taxonomy.}
%Therefore, the maximum overlap ratio $\tau$ applies
%to $E_c \cap A_v$, which we call $\tilde{E_c}$ for brevity.
%
%Next we estimate the number of times function $g_v(e)$
%is calculated in $\tilde{f}(C_k)$. For ease of presentation,
%we consider the average case where for all $c \in C_k$,
%$\tilde{E_c}$ is of the same size, say $s$. Since then maximum overlap
%between any two sets $\tilde{E_{c1}}$ and $\tilde{E_{c2}}$ is $s\tau$,
%$g_v(e)$ is thus computed at most $ks + {k\choose 2}s\tau$ times.
%Whereas in the original $f(C_k)$,
%$\bigcup_{c \in C_k} E_c \cap A_v$
%is as small as $\min\{ks - {k\choose 2}s\tau, {k\choose2}s\tau\}$.
%Therefore the approximation ratio is
%\[\frac{\tilde{f}(C_k)}{f(C_k)} = \max \left\{
%	\frac{2k + (k^2 + k) \tau}{2k - (k^2 + k) \tau},
%	\frac{(k-1)\tau + 2}{(k-1)\tau}\right\}
%\]
%\end{proof}
%
%We further define a {\em weighted score} for each concept $c$ under verb
%$v$ as
%\begin{equation}
%ws_v(c) = \sum_{e\in E_c \cap A_v} g_v(e),
%\label{eq:ws}
%\end{equation}
%which is a component in \eqnref{eq:approxf}. Intuitively, this score measures
%the importance of a concept as a type of argument to a verb.

\subsection{A Branch-and-Bound Algorithm}
Because the concept space is large,
we propose a branch-and-bound algorithm to solve the
action conceptualization problem.
The complete algorithm is shown in Algorithm \ref{al:backtrack}.
%We model each solution as a binary vector of size $|C|$ in which exactly
%$k$ elements of the vector are set to 1 while others are set to 0.
%Backtracking is a general algorithm
%that incrementally builds candidate solutions, and
%abandons each partial candidate $c$ (``backtracks'') when it determines
%that $c$ cannot be completed to a valid solution.
The search space can be represented by a binary decision tree
where the nodes at each level indicate the decision of whether to include a concept in
the solution or not. The complete search space contains $2^{|C|}$ nodes.
Take the concept graph in \figref{fig:graph_model} as an example.
The corresponding search space is shown in \figref{fig:search_tree},
in which $d_i=1$ means to include $c_i$ in the solution, and $d_i=0$ means
otherwise. For $k=3$, the concept set $\{c_0,c_1,c_2\}$ is
a valid solution, which is marked by the path
$(d_0=1) \rightarrow (d_1=1) \rightarrow (d_2=1)$. The key of this algorithm
is that, even though the search space is exponential, a subtree can be
pruned if its path from the root already contains a valid solution, or
if the current path does not have the potential to produce a better solution
than the current best.
%A path in the tree is a potential solution.
%The leaf node with a star label means that we reach to an potential solution
%(the concept set decided by the path from root node to this leaf node),
%while the leaf node with a plus sign means we reach to an illegal solution,
%so that we don't need to do searching in the subtree.

\begin{algorithm}[th]
\small
\caption{Action Conceptualization}
\label{al:backtrack}
\begin{algorithmic}[1]
\Function{AC}{$A_v, C, L, k$}
\State $\{c_0,...,c_{|C|-1}\}\leftarrow$ Sort concepts $c\in C$ in\ the\ descending\ order\ of $ws_v(c)$.
\State $\pi_{max} \leftarrow 0,\pi_{c} \leftarrow 0,ck \leftarrow 0$
\State $d_{max}\leftarrow\{0,...,0\},d\leftarrow\{0,...,0\}$
\State BB($0$)
\If{$ck = k$}
\State \textbf{return} $d_{max}$
\Else
\State \textbf{No solution}
\EndIf
\EndFunction
\Statex
\Function{BB}{$i$}
\If{$i\geq |C|$}
\State \textbf{return}
\EndIf
\If{$ck = k$}
\If{$\pi_{c}>\pi_{max}$}
\State $\pi_{max} \leftarrow \pi_{c}, d_{max} \leftarrow d$
\EndIf
\State \textbf{return}
\EndIf
\If{ISCLIQUE($L,i$) $= TRUE$ and BOUND($i$)$>\pi_{max}$}
\State $ck \leftarrow ck+1, \pi_{c} \leftarrow \pi_{c}+ws_v(c_i), d_i \leftarrow 1$
\State BB($i+1$)
\State $ck \leftarrow ck-1, \pi_{c} \leftarrow \pi_{c}-ws_v(c_i), d_i \leftarrow 0$
\EndIf
\If{BOUND($i+1$) $> \pi_{max}$}
\State $d_i \leftarrow 0$
\State BB($i+1$)
\EndIf
\State \textbf{return}
\EndFunction
\Statex
\Function{ISCLIQUE}{$L, i$}
\For{$j$ from $0$ to $i-1$}
\If{$d_j = 1$}
\If{$(c_i, c_j)\not\in L$ and $(c_j, c_i)\not\in L$}
\State \textbf{return} $FALSE$
\EndIf
\EndIf
\EndFor
\State \textbf{return} $TRUE$
\EndFunction
\Statex
\Function{BOUND}{$i$}
\State $b \leftarrow \pi_{c}$
\For{$j$ from $i$ to $\min\{i+k-ck-1, |C|-1\}$}
\State $b \leftarrow b+ws_v(c_{j})$
\EndFor
\State \textbf{return} $b$
\EndFunction
\end{algorithmic}
\end{algorithm}


\begin{figure}[th]
\centering
\epsfig{file=figure/search_tree.eps,width=0.6\columnwidth}
\caption{A Snapshot of the Binary Decision Tree with $k=3$}
\label{fig:search_tree}
\end{figure}

Suppose the partial solution of the first $i$ levels in the tree
are $(d_0, d_1, ..., d_{i-1})$ and
the current best solution has a score (computed by \eqnref{eq:objective}).
We use $d_{max}$ and $\pi_{max}$ to store the
best solution and its score found thus far; and use $d$ and $\pi_{c}$ to
represent the current partial solution and its partial score.
Variable $ck$ stands for the number of concepts that have been set to
1 in the current decision path, i.e.,
$ck=\sum_{n=0}^{i-1}d_n.$

The main function BB($i$) searches through the tree in a depth-first manner.
%It returns when it reaches the leaf node or when it has found a
%solution.
%If the solution is better than the current best,
%the current best solution is updated.
It traverses one
more level to include concept $c_i$ if it forms
a clique with the currently chosen concepts (ISCLIQUE function)
and if the maximum possible score with $c_i$ is better than
the current best score (BOUND function). It backtracks to exclude $c_i$
when the left branch is searched.
We sort all concepts at the beginning to help compute
the bound in linear time by adding up the score of the
next $k-ck$ concepts in the search tree.

%A crucial optimization in this algorithm is that we first sort
%all concepts in $C$ decreasingly by their weighted scores.
%This allows us to quickly
%compute the bound (Line 33-34) in linear time (against $k$), i.e., simply
%the total score of the next $k-ck$ concepts down the decision
%tree hierarchy, rather than sorting all the remaining concepts,
%which is a much larger set.

%For pure illustration purpose, we explore
%the search space and the pruning ratio (number of nodes traversed with
%bounds versus without bounds) by simulating the execution
%of the algorithm on proportionally smaller inputs, i.e., smaller
%number of concepts, smaller concepts and fewer edges in the graph.
%The pruning ratio versus the average concept size and
%the input $k$ is shown in \figref{fig:complexity}.
%In practice, pruning search space by this bounding mechanism turns
%out to be very effective. The execution times of the algorithm are
%very reasonable under various experimental settings,
%shown in \secref{sec:efficiency}.
%
%%\vspace*{-10mm}
%\begin{figure}[th]
%\centering
%\epsfig{file=figure/complexity_data.eps,width=0.7\columnwidth}
%\caption{Pruning Ratio over Average Concept Size and $k$}
%\label{fig:complexity}
%\end{figure}

%The decision tree is pruned under two conditions:
%1) if the subgraph formed by the selecting concept $i$ is not a
%clique or the size is larger than $k$,
%then do not need to check the $i+1$ concept (Line 10-17);
%2) if the maximum possible score for the decision that \emph{without} selecting concept $i$
%is smaller than $\pi_{max}$, then do not need to check the $i+1$ concept (Line 18-20).
%The computation of maximum possible score on a path with less than $k$
%concepts selected is to choose the top $k-ck$ concepts with maximum scores.
%%Otherwise, we stop traversing the subtree under the decision $d_i=1$.
%In order to efficiently find the top $k-ck$ concepts, we first
%compute all the $ws_v(c)$ for all the concepts and sort the
%concepts in the descending order of $ws_v(c)$. When we search for top $n$ concepts
%in the descendants of the $i$-th concept,
%we pick the ($i+1, i+2, ..., i+n$) concepts.

%\subsection{Weighted Sum Solution}
%\label{sec:algo_weightedsum}
%
%As our problem is a multi-objective programming problem, we can solve it by a Weighted Sum Solution. A weight $w$ which demonstrates the optimization preference to \textbf{Coverage} and \textbf{Overlap} is first given by the decision maker. So the problem can be reformulated to a single-objective problem and is formalized as follow, we call it AC-QP.
%\begin{eqnarray}
%\min_{x} && (1-w)x^TPx-wd^Tx \label{eq:objfunc}\\
%\rm{subject~to} && x_s(x_s-1)=0\\
%&&\sum_{s\in S}{x_s}=k
%\end{eqnarray}
%
%In the definition above, the equation $x_s(x_s-1)=0$ is non-convex quadratic constraint, so the problem is a case of non-convex QCQR.
%
%Then the equivalent SDP(semidefinite programming) formulation of AC-QP can be indicated as following, we call it AC-SDP.
%\begin{eqnarray}
%\min_{X,x} && Q\bullet X+c^Tx \label{qcqpsubj}\\
%\rm{subject~to} && e^Tx=k\\
%&&diag(X)=x\\
%&&X=xx^T
%\end{eqnarray}
%where $Q\bullet X=trace(QX)=\sum\limits^n_{i=1}\sum\limits^n_{j=1}{Q_{ij}X_{ij}}$ and $Q=(1-w)P, c=-wd$.
%
%Because we have nonconvex constraints in AC-SDP, so $X=xx^T$ is relaxed to $X-xx^T\succeq 0$. And then the semidefinite relaxation of AC-QP is obtained as following, we call it AC-SDR.
%\begin{eqnarray}
%\min_{X,x} && Q\bullet X+c^Tx \\
%\rm{subject~to} && e^Tx=k\\
%&&diag(X)=x\\
%&&\left[
%\begin{array}{cc}
%1 & x^T\\
%x & X
%\end{array}
%\right]\succeq 0
%\end{eqnarray}

%\subsection{Quadratic Convex Reformulation}
%Since our problem has non-convex constraints, we use a \emph{Quadratic Convex Reformulation} (QCR)
%to reformulate the problem to a convex one. This method apply a continuous relaxation to the 0-1
%constraint, i.e., we weaken the 0-1 constraint to $0\leq x_i \leq 1$. After continuous relaxation,
%we need to reformulate the original problem to make the lower bound of continuous relaxation equal
%to the lower bound of Semi-Definite Program relaxation. Suppose strong duality holds for the SDP relaxation
%and a dual optimal solution ($\lambda^*, \mu^*$) exists, if we perturb the objective function
%\ref{qcqpsubj} by:
%\begin{itemize}
%\item adding $x^Tdiag(\lambda^*)x-(\lambda^*)^Tx$ and $\mu^*(e^Tx-k)$
%\item changing the equality constraints to inequality constraints with opposite sign,
%\end{itemize}
%then the reformulated problem is convex and the lower bound of the continuous relaxation equals to
%the lower bound of SDP relaxation. The reformulated problem is shown as follows:
%\begin{eqnarray}
%\min_{x} && (1-w)x^TPx-wd^Tx \nonumber \\
%&&+x^Tdiag(\lambda^*)x-(\lambda^*)^Tx \nonumber\\
%&&+\mu^*(e^Tx-k) \\
%\rm{subject~to} && e^Tx\leq k\\
%&& e^Tx\geq k\\
%&& 0\leq x_s \leq 1, for all s\in S
%\end{eqnarray}

%\subsection{Graph Based Approach}
%\begin{eqnarray*}
%\max_{x} && \sum_{s\in S}{Coverage(s)\cdot x_s} \\
%\rm{subject~to} && x_s\cdot (x_s-1)=0\\
%&&\sum_{s\in S}{x_s}=k\\
%&& Overlap(s,t)\cdot x_t\cdot x_s\leq \tau, for\ all\ s,t\in S, s\neq t
%\end{eqnarray*}
%
%\subsubsection{Graph Representation}
%Let us consider the following graph representation of a set $S$ of concepts. Let $G_{S,\tau}=(V,E)$ be an undirected graph such that there is a vertex $v_i\in V$ for each concept $s_i\in S$ with the weight $w(v_i)=Coverage(s_i)$ and an edge $(v_i,v_j)\in E$, if and only if, $Overlap(s_i,s_j)\leq \tau$ for the corresponding concepts $s_i,s_j,s_i\neq s_j$. An example is shown in \figref{fig:graph_model}.
%\begin{figure}[th]
%\centering
%\epsfig{file=figure/graph_model.eps,width=1.0\columnwidth}
%\caption{(a) Concept set $S$ with overlap constraint $\tau$ as the radius and (b) the corresponding graph representation $G_{S,\tau}$}
%\label{fig:graph_model}
%\end{figure}
%
%Let us recall a couple of graph-related definitions. A \emph{complete subgraph} $D$ in a graph $G$ is a subgraph of $G$ such that every two vertices in $D$ are joined by an edge. And a \emph{maximum complete subgraph} is such a subgraph of $G$ with the maximum sum of vertices weight.
%
%Considering the definition of \emph{action conceptualization} problem, solving such problem is equivalent to finding a \emph{maximum complete subgraph} with $k$ vertices in the corresponding graph  $G_{S,\tau}$, we call it \emph{graph based action conceptualization} problem.


%\subsection{Determining Parameter $k$}
%\label{sec:dpk}
%The number of action concepts $k$, which controls the granularity,
%is modeled as an input of our problem. In practice, to build a lexicon,
%we need to know the value of $k$ for each verb. Our observation from
%sampled data shows that the objective function (\eqnref{eq:f}) generally
%increases with $k$, but with diminishing returns. Therefore, in this paper,
%instead of fixing a $k$ for all verbs, we can fix a threshold gradient
%defined as \eqnref{eq:gradient}.
%\begin{equation}
%\frac{\Delta \tilde{f}(C_k)}{\Delta k} \approx \tilde{f}(C_k)-\tilde{f}(C_{k-1})
%\label{eq:gradient}
%\end{equation}
%We hence run AC algorithm for $k=1$, $k=2$,
%etc., and compute $\tilde{f}(C_k)$ for each $k$.
%%Due to the fact that each verb may have different $k$
%%in a certain granularity, deciding $k$ for each verb is a labour-intensive
%%work.
%%Therefore, we decide $k$ using a global gradient measure which
%%considers the trends of the objective value (\eqnref{eq:f}) w.r.t. $k$.
%%Specifically, we run AC from $k=1$ to $k=10$ (AC with $k=10$ achieves
%%almost maximum objective value due to our observation)
%%and compute the objective values according to \eqnref{eq:f}.
%%For each $k$ from $k=2$, we compute its gradient, i.e., the increment of the
%%objective value. In order to give a global gradient measure for all verbs, we
%%normalize the objective value to $[0,1]$.
%Assuming that $\tilde{f}(C_k)$ is usually monotonic w.r.t. $k$,
%we select the smallest $k$ that has a gradient smaller than the
%threshold.  Under such scheme, each verb will be associated with
%a different $k$, suitable for the construction of the lexicon.

%\KQ{
%\subsection{Generative Story of the Model}
%\begin{equation}
%P(A_v)=\prod_{e \in A_v}{(\lambda\sum_{c \in C}{P(e|c)P(c|v)}+(1-\lambda)P(e))}
%\end{equation}
%It is hard to get a close form of $P(c|v)$ using maximum likelihood estimation.
%Therefore, we use least square estimation to maximize the likelihood:
%\begin{equation}
%\begin{split}
%&\argmin_{P(c|v)}\frac{1}{2}\sum_{e \in A_v}{(\sum_{c \in C}{P(e|c)P(c|v)}-P(e|v))^2}\\
%&\text{subject to} \sum_{c\in C}{P(c|v)}=1
%\end{split}
%\end{equation}
%where $P(c|v)$ is the proportion of concept $c$ for verb $v$, and $P(e|v)$ is the
%probability of term $e$ appears as the argument of verb $v$.
%}

\subsection{Triplet Conceptualization Method}
Once we solve the action conceptualization problem in both subjects and objects,
we are able to use the resulting concepts to construct a valid solution for
the action conceptualization problem on triplets.
Since the search space of subject-object concept pairs is much larger,
we build the triplet concept graph only on the concepts selected in the
action conceptualization problem for each argument. Because the selected
concepts satisfy the overlap constraints, and cover most of the high quality
arguments, we can achieve a good approximation.

We can compute the solution for triplet conceptualization in an efficient way.
Let $C_{k,s}$ and $C_{k,o}$
be the set of $k$ concepts summarizing the subjects and objects of the verb,
respectively. We then have $k\times k$ concept pairs.
For any two concept pairs $p_1=\{c_{s1}\in C_{k,s}, c_{o1}\in C_{k,o}\}$
and $p_2=\{c_{s2}\in C_{k,s},c_{o2}\in C_{k,o}\}$,
$p_1$ and $p_2$ satisfy
the overlap constraint when either $c_{s1}\neq c_{s2}$ or $c_{o1}\neq c_{o2}$.
This means every two different concept pairs $p_1$ and $p_2$ satisfy the
overlap constraint, and the triplet concept graph becomes a clique.
To select the $k$ concept pairs to conceptualize the triples, we only need
to select the top-$k$ concepts with highest score of
$f_{v,s}(c)\times f_{v,o}(c)$ computed as in \eqnref{eq:objectivetri}.




