\subsection{Verb Similarity Computation}
\label{sec:sim}
Our action concepts can be used for verb similarity computation. Once
we get $k$ concepts with scores computed by \eqnref{eq:objective}
on each argument, as well as the conceptualized triplet
\{subject concept, verb, object concept\}, we adopt
two methods to construct the vector in concept space for a verb.
First, we concatenate the subject concept vector and the object
concept vector learnt independently,
to form the concept space for the verb (AC). Second,
we use the pairwise subject-object concepts learnt on
triplets to build the vector for the verb, in which each
pair of subject-object concept is a dimension (AC+T).

We conduct the experiment on the 130-verb pairs data set provided by
Yang and Powers\shortcite{Yang06verbsimilarity}.
We compare our action concept vector to vectors learnt by skip-gram
algorithm\cite{Levy-acl14} using bag-of-word contexts (BOW with window
size=2) and dependency contexts (DEPS). We compute the cosine similarity for
verbs on both action concepts and vectors learnt from skip-gram algorithms,
and use Spearman's correlation to evaluate the results.
For SP, we adopt the same strategy as our algorithm to generate the
concept vector (SP and SP+T). We also compare
our result with a state-of-the-art algorithm proposed by
Meyer et al.~\shortcite{C12-1108}.
The results are reported in \tabref{tab:sim}.

\begin{table}[ht]
\small
\centering
\caption{Spearman's Correlation on the 130-Verb Pairs Dataset}
\begin{tabular}{|l|r|}
\hline
Method & Correlation \\
\hline
\hline
BOW (window=2) & 0.39 \\
\hline
DEPS & 0.44 \\
\hline
Meyer et al. & 0.73 \\
\hline
SP($k=5$) & 0.15  \\
\hline
SP($k=10$) & 0.19  \\
\hline
SP($k=15$) & 0.20  \\
\hline
SP($k=20$) & 0.20  \\
\hline
SP+T($k=5$) & 0.42 \\
\hline
SP+T($k=10$) & 0.31 \\
\hline
SP+T($k=15$) & 0.22 \\
\hline
SP+T($k=20$) & 0.22 \\
\hline
AC($k=5$) & 0.26 / {\color{red}0.18}\\
\hline
AC($k=10$) & 0.27 / {\color{red}0.17}\\
\hline
AC+T($k=5$) &  0.42 / {\color{red}0.29}\\
\hline
AC+T($k=10$) &  0.40 / {\color{red}0.31}\\
\hline
\end{tabular}
\label{tab:sim}
\end{table}

%% We need the lexicon for large number of verbs... This could be difficult.
%%One popular way of computing term similarity is based on a predefined taxonomy.
%When computing the similarity of two terms, a predefined taxonomy is often used to provide
%hyponyms and hypernyms information of both terms.
%Those hyponyms and hypernyms can be used to represent the terms in
%set or vector forms, then Jaccard similarity or cosine similarity
%can be applied to compute the similarity between two terms.
%However, if two terms do not share common hyponyms or
%hypernyms, then the taxonomy-based method may not work well.
%An example is ``company'' and ``stock''.
%We argue that by combining ActionNet with taxonomies, we
%can obtain a better similarity result. In the example of ``company'' and
%``stock'', the two terms can be connected by verb ``release'' or ``sell''
%in our lexicon.
%%can provide
%%extra knowledge for calculating the similarity of these two terms.
%
%Li et al.\cite{LiWZWW13} introduces a term similarity computation method
%using Probase. We call it noun-based term similarity method.
%In this experiment, we implement Li's method and also define our term similarity
%function using ActionNet(PB).
%Similar to Li's method, we apply different similarity
%functions on terms according to their types (concepts or entities).
%Our verb-based term similarity is computed as:
%\begin{eqnarray*}
%sim_{c}(c_1,c_2) &=& \frac{V_o(c_1)\cap V_o(c_2)}{V_o(c_1)\cup V_o(c_2)}, \\
%sim_{e}(e_1,e_2) &=& \max_{\substack{c_i\in C(e_1),c_j\in C(e_2)\\c_i\neq c_j}}sim_{c}(c_i,c_j), \\
%sim_{c\&e}(c,e) &=& \max_{c_i\in C(e),c_i\neq c}sim_c(c,c_i),
%\end{eqnarray*}
%where $V_o(c)$ is the set of verbs taking concept $c$ as object in ActionNet(PB).
%$C(e)$ is the set of concepts for entity $e$ in Probase.
%We compute the similarity score between two terms by
%averaging over the similarity scores computed by both
%the verb-based method and noun-based method:
%$$
%sim(t_1,t_2)=(sim_{verb}(t_1,t_2)+sim_{noun}(t_1,t_2))/2,
%$$
%where $sim_{verb}(t_1,t_2)$ and $sim_{noun}(t_1,t_2)$ refer to the verb-based and noun-based similarity scores,
%respectively.
%We compare our method (Verb-based) with Li's method (Noun-based) and a combination of both
%methods (Combined) on a word similarity label dataset
%``Word Similarity 203''\cite{LiWZWW13}, and use Pearson correlation as the evaluation metric.
%The result is shown in \tabref{tab:sim}.
%\begin{table}[th]
%\centering
%\scriptsize
%\caption{Pearson Correlation for Term Similarity Computation}
%\begin{tabular}{|c|c|c|}
%\hline
%Noun-based & Verb-based & Combined \\
%\hline
%\hline
%0.72 & 0.55 & {\bf 0.74} \\
%\hline
%\end{tabular}
%\label{tab:sim}
%\end{table}
%
%We can see that, by combining knowledge provided by
%Probase taxonomy and ActionNet,
%we can get a better similarity result.

