\subsection{Word Sense Disambiguation}
\label{sec:wsd}
We compare ActionNet(WN) with the lexicon extracted
using SP in the lexical sample
word sense disambiguation (WSD) task of
Senseval-3\cite{senseval3}. We use the WordNet as our
taxonomy because the standard dataset requires annotation with
WordNet classes.
Because we focus on using the relation between verbs and
nouns to help WSD,
we extract the training and test cases from Senseval-3
that contain a verb-argument relation
where the verb is in Verb-10k and the argument is the target noun to be
disambiguated. These relations form our dataset, which consists of
1156 cases for training and 564 cases for testing.

%\KZ{Mention IMS?}
We use the lexicon learned from WordNet in this experiment,
because the test data in Senseval-3 is based on WordNet senses.
For each target noun to be disambiguated, we extract
the corresponding verb in the context. We then use the
top 10 concepts/synsets of the verb and their
the corresponding scores (i.e., $\tilde{f}(C_k)$ in
\eqnref{eq:approxf} for AC and the selectional
association score for SP) in the lexicon as the only features
to train a linear classifier to classify the sense
for the target noun. The lexicon learned by AC achieves
$F_1 = 0.2407$ versus $F_1 = 0.2189$ by SP.
This is because SP has higher
overlap in the top 10 concepts/synsets, which dilutes
the difference between features.
