\section{Conclusion}
\label{sec:conclude}
%We presented a distributed attention mechanism to modify existing CNN seq2seq model 
%and were able to train a model that produces 
%summaries without repetition that are fluent and coherent. 
We analyze two possible reasons for the prevalent repetition problem in the task of summarization.
Correspondingly, we present a section-aware attention mechanism as well as a sentence-level backtracking decoder. Our model is able to produce fluent and coherent summaries with minimal repetitions.
Besides, the summaries generated by our model are more accurate and achieve higher ROUGE score. 
%We find that the basic CNN seq2seq model 
%still has some problems, such as generating repeated word sequence. 
%We also argue that ROUGE is not a perfect evaluation metric for the abstractive 
%summarization. Our future work will focus on these two aspects.

