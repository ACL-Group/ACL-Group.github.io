Dear Zilu Guo:

We are sorry to inform you that the following submission was not selected by the program committee to appear at ACL 2020:

Unsupervised Paraphrasing via Sentence Reconstruction and Back-translation

The selection process was very competitive. Our selection process was not based solely on the reviewers' assessment and scores, but also on discussions among reviewers, careful assessment by Area Chairs and Senior Area Chairs, and our goal to assemble a diverse, interesting and high-quality program.   We have enclosed the reviewer comments for your perusal.

Additionally, in response to COVID-19 we will be holding ACL2020 online, on the same July 5-10 dates.  We know that many in our community are suffering or may suffer hardships from this pandemic. We hope that we can work together in this difficult time to build a new kind of ACL meeting this year, one that offers more sustainability, expanded opportunities for exchange of knowledge, and increased inclusion of diverse contributions from around the globe.  We'll have pre-recorded talks and the full set of tutorials and workshops and will be planning all sorts of live events like Q&A sessions, mentoring, job fairs, and spaces for hallway conversations.

We'll be sending you more details on registration in the next few weeks and more on the mechanics of the virtual conference soon.  We hope that you can attend.

If you have any additional questions, please feel free to get in touch.

Best Regards,

Joyce Chai, Natalie Schluter and Joel Tetreault (Program Chairs, ACL 2020)

ACL 2020


============================================================================ 
ACL 2020 Reviews for Submission #1629
============================================================================ 

Title: Unsupervised Paraphrasing via Sentence Reconstruction and Back-translation
Authors: Zilu Guo, Zhongqiang Huang, Kenny Zhu, Guandan Chen, Kaibo Zhang, Boxing Chen and Fei Huang
============================================================================
                            META-REVIEW
============================================================================ 

Comments: AC#1: An unsupervised paraphrase generation approach based on a hybrid decoder that combines outputs of two unsupervised paraphrasing models; one is, a set-to-sequence model that generates sentences from a set of content words (synonyms+content words from the original input sentence), the other is a back-translation -based paraphrasing model.

The approach is simple (though a bit incremental), exploits existing resources/corpora/models and shows good results in automatic metrics. The paper is well written, very clear exposition of the approach. Evaluation is done on several relevant well-known benchmarks and includes sota systems. 

A weak point is the human evaluation which is rather limited; only variants of the proposed models are evaluated instead of comparing against more competitive comparison systems.

AC#2: 1) The models are heavily trained (multiple V100s for days) and there is no mention at all how their baselines are trained. What data was the VAE trained? How much ParaNMT/ParaBank data was used? What architectures were used? There is no information about these baselines and I am skeptical these were adequately tuned based on results in Table 2. For instance, the set2seq is so much better when it completely ignores word order...part of this is possibly due to automatic metrics evidenced by how in human evals set2seq performs much worse than other approaches but better in Table 2. This largely invalidates Table 2 in my opinion as this model is completely unaware of word order and should not be able to generate paraphrases for complex sentences in contrast to the baselines. Note that these datasets are primarily based on short sentences...

2) Their human evals are only on ablations of their model - what about comparisons to other models? This would be especially true since Table 2 isn't all that reliable as seen by my earlier comment.

3) Using a bag of words is not a new idea for generation as a way to represent content and this paper is just adding this to round-trip backtranslation, combining two ideas. Though to be fair, using a bag-of-words in this exact way is new as far as I can tell and a quick lit search.

4) Data augmentation for MT is flawed to me because their gains are probably largely due to having more English data. Since they are translating X->En having a better decoder helps a lot, especially in low resource settings. Therefore adding 20x more English data alone would be helpful whether paraphrases or not. Notice that no baselines were used for this experiment as well.

============================================================================
                            REVIEWER #1
============================================================================

What is this paper about, what contributions does it make, what are the main strengths and weaknesses?
---------------------------------------------------------------------------
This work proposes a system for unsupervised paraphrase generation. The system consists two components, a back-translation model and a keyword-to-text generation model. The back-translation model generates a paraphrase by pivot translation; while the keyword-to-text generation model, which is essentially a set2seq model. The keywords are extracted with heuristics-based method and augmented by their synonyms. The final paraphrase is generated via the mixture of the prediction of decoders in translation and set2seq model. Extensive experiments has been done in multiple datasets to show the superior performance of the proposed method than other baseline models. This presented method is quite effective, but it is also very computational expensive.
---------------------------------------------------------------------------


Reasons to accept
---------------------------------------------------------------------------
1. The proposed method is simple and effective, which is a big plus for the task of paraphrase generation / data augmentation.
2. The experiments done in this work are very thorough and solid. The ablation study clearly shows the contribution of each component.
---------------------------------------------------------------------------


Reasons to reject
---------------------------------------------------------------------------
1. The most significant problem is the heavy usage of computation resources. There are totally three encoder-decoder networks in the proposed system. This make the method a little bit too incremental.
2. It would be better to include the performance of the strongest baseline in the data augmentation section.
3. This method still relies on at least two large-scale and high-quality parallel dataset for two well-trained NMT models; while some other baseline model like UPSA and VAE do not need them.
4. I am not sure whether the keyword-to-text method can still work when the source sentence are long. In that case, seems that there would be significant information loss with only a set of words. All of the datasets employed by this paper consists short sentences.
---------------------------------------------------------------------------


---------------------------------------------------------------------------
Reviewer's Scores
---------------------------------------------------------------------------
                  Overall Recommendation: 3.5


============================================================================
                            REVIEWER #2
============================================================================

What is this paper about, what contributions does it make, what are the main strengths and weaknesses?
---------------------------------------------------------------------------
The paper suggests a hybrid decoder to introduce diversity in
automatically-generated paraphrases. One path to generate paraphrase is
round-trip translation; an alternate path is to reduce words to a selected
word set, perturb those words, then generate some a sentence from this
bag. The perturbation is done using wordnet synonyms, a potentially
limited set of operations.

The authors evaluate on a set of paraphrase tasks and compare against many
baselines -- good evaluation.

The translation system is only one sample and not large -- a
Chinese-English system trained on WMT data -- and yet the authors make
claims about back-translation as a whole. This may be misleading.

Adding diversity through WordNet synonyms seems like a good baseline, but
I'm concerned about the converage of WordNet (what's the OOV rate on each
of these sets?) as well as the accuracy of the synonym replacements.
I wish there were more experiments about the qualitative and quantitative
impact here.
---------------------------------------------------------------------------


Reasons to accept
---------------------------------------------------------------------------
Good thinking about how to generate interesting paraphrases.

Good evaluation setup, with many reasonable baselines.

Some human evaluation, although limited.

Evaluation in MT setting.
---------------------------------------------------------------------------


Reasons to reject
---------------------------------------------------------------------------
The authors group all back translation methods together, and use a
potentially challenging language pair (Chinese-English).  At least one
other paper has found back translation with  Chinese-English produces
lesser quality paraphrases when compared to other language pairs:
https://www.aclweb.org/anthology/D19-5503/

The word set method seems appropriate for shorter sentences, but may
struggle to retain semantics of longer sentences.
---------------------------------------------------------------------------


---------------------------------------------------------------------------
Reviewer's Scores
---------------------------------------------------------------------------
                  Overall Recommendation: 3.5

Questions for the Authors(s)
---------------------------------------------------------------------------
What's the quality of your English-Chinese machine translation set,
compared to the state-of-the-art?

What are the out-of-vocabulary rates for words in WordNet? That is, given
a word set, what percentage of the tokens have synonynms?

Have you considered some "bias" -- not replace every word, but replace
words at random, and change the random threshold? 

Have you considered alternate methods for generating paraphrase words,
like using BERT but masking the token and letting BERT suggest
replacements? Or sampling within a distance given GloVe embeddings?
Something that is smoother than synsets?

What is the value of alpha in iBLEU? Could you include that?
---------------------------------------------------------------------------


Typos, Grammar, and Style
---------------------------------------------------------------------------
Will follow up later.
---------------------------------------------------------------------------



============================================================================
                            REVIEWER #3
============================================================================

What is this paper about, what contributions does it make, what are the main strengths and weaknesses?
---------------------------------------------------------------------------
This paper introduces a new ways to train paraphrase generation model. This works combines popular back-translation methodology with word-set to sentence model using a common decoder. The word-set to sentence model is trained in "unsupervised" manner through creating an input by taking a sentence and removing stop words and randomly replacing each word with its synonyms and training the model to reconstruct the original sentence. The paper presents comparison against many different paraphrase generation methodologies as well as thorough ablation studies, human evaluation, and evaluation of generated paraphrase using an external task (using them to augment machine translation training data.)

The presented methodology is simple yet effective and the presented experiments are convincing. However, it lacks analysis on cases where removing stop words impacts semantics (negative polarity) and the method cannot be applicable to languages without resources like wordnet.
---------------------------------------------------------------------------


Reasons to accept
---------------------------------------------------------------------------
The new method introduced method for unsupervised paraphrase generation is simple yet effective. People who are building paraphrase models can immediately benefit from the presented method. The paper is reasonably clearly presented.
---------------------------------------------------------------------------


Reasons to reject
---------------------------------------------------------------------------
Some may view the newly introduced methodology uninspiring and perhaps the paper needs to be more thorough such as exploring different "perturbation" methods and different aspects of domain adaptation.
---------------------------------------------------------------------------


---------------------------------------------------------------------------
Reviewer's Scores
---------------------------------------------------------------------------
                  Overall Recommendation: 3.5

Questions for the Authors(s)
---------------------------------------------------------------------------
* how does removing some stop words impacts output? (e.g., words such as "not") Does the back-translation model prevents such cases from reversing the polarity? what were the exact list of stop words that were removed from word sets?
* have you tried different word perturbation methods? (more model-based methods and not based on heuristics)
* "KWS is randomly replaced with one of its synonyms, including itself" -> some clarification is needed. Does this mean that every word is replaced? or does "including itself" mean that some word stay the same?
---------------------------------------------------------------------------


Missing References
---------------------------------------------------------------------------
In the first paragraph in the introduction, authors state that "such as question answering, machine translation, and information retrieval." It would be nice if citations can be added for how paraphrase generations helps each use cases.
---------------------------------------------------------------------------


Typos, Grammar, and Style
---------------------------------------------------------------------------
last paragraph in the introduction: "our method to argument" -> augment.
in "evaluation metrics" paragraph: "evaluation matrics" -> metrics
---------------------------------------------------------------------------


--
ACL 2020 - https://www.softconf.com/acl2020/papers