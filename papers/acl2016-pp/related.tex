\section{Related Work}

%\KZ{First discuss AAAI 2012 and EMNLP 2015, their pros and cons and how
%we stack up with them. Then discuss other less similar work. Finally
%applications that can benefit from this work, eg. QA, etc.}
% introduce AAAI2012, analyze pros and cons
%is based on such a procedure called ontology mapping. Given a user-specified relation along with its labeled instances, ontology mapping actually generates several complex SQL expressions over types and relations on the KB's schema. This procedure is quite difficult since the space of possible SQL views can be extremely large. In order to reduce the search space and select the best views, the authors first generates several constraints (hard rules) described in Markov Logic. This step actually is the a procedure to generate simple candidates schemas. Then, the probability of mappings is described using Markov logic Network after adding different rules into the network. Through weight training and relaxing the optimization problem to a linear problem, those candidate schemas with a high probability form to the mapping result. This work is able to show a set of best schemas for a target relation. However, the authors add several hand-crafted soft rules to Markov Logic Network which limits the dimension of feature space. Besides, the complex SQL views can actually be transformed to simple schemas (paths) which can not be able to handle complex relations in natural language form.
% introduce emnlp 2015 SFE
Previous work~\cite{zhang2012ontological,gardner2015efficient,gardner2014incorporating,lao2011random} has attempted to map a relation to 
background KB skeletons. 
The goal of these works is to complete the imperfectly extracted KB 
\textit{NELL} \cite{carlson2010toward} by predicting all concept $b$ 
which potentially have the relation $R(a, b)$ given a concept $a$. 
Lao et al. \shortcite{lao2011random} use a random walk path 
finding algorithm to inference new relation instances by 
mapping the target \textit{NELL} relation to a join of 
several basic relations. The state-of-art system \cite{gardner2015efficient} 
examines the disadvantage of Path Ranking Algorithm (PRA)\cite{lao2011random} 
and proposes a technique called subgraph feature extraction (SFE). 
It firstly runs local search to characterize the graph around 
each input node of KB. Then SFE runs a set of feature extractors 
over these subgraphs to get the feature vectors for each node. 
SFE outperforms other KB completion methods as it uses 
more advanced features. However, all of the above work only 
considers the simple path representations. 
In contrast, our approach adopts complex schema 
with constraints, which can describe more sophisticated NL relations. 
Moreover, when solving KB completion problem, we use only schemas
of NL relations as features, whereas previous work use many other
features.
%Natural language relations always have more complex meaning 
%than KB predicates and using our system, 
%a target human raised relation can be mapped into an 
%explicit readable schema graph.

%To solve the paraphrasing problem between natural language relations and KB predicates, we aim to represent a human raised relation with several explicit schemas. One major difference between our technique and others is that during the procedure of generating candidate schemas for target relations, we do not limit the schemas to be simple only. We fully utilize the information of KB, adding extra constraints to the simple schemas and resulting in more complex schemas. Specifically, we perform a breadth-first search to construct the skeleton of a specific relation schema which is similar as the path finding procedure in the previous works \cite{gardner2015efficient,gardner2014incorporating,lao2011random,zhang2012ontological}. Beyond relation path, we use a depth-first search to further add more information attributes to the relation path generated in the first step and transform it into a more specific and complex graph form, under the guidance of \textit{Minimum Description Length} (MDL) \cite{fisher2008dirt,grunwald2007minimum} principle. MDL principle is used as a trade-off since it measures the cost of transmitting both schemas and entity pairs.

% query synthesis
Besides, our work is similar to query synthesis in 
database~\cite{niehren2013query,das2010synthesizing,cheung2012inferring,cheung2013optimizing}. 
Given a set of input relations and an output relation,
query synthesis automatically produces a relational query that produces the 
output relation when applied to the input. 
This problem is similar to ours as the query is analogous to the schema
while the database is similar to the KB. 
Typically, Zhang and Sun \shortcite{zhang2013automatically} 
address query synthesis 
using a three-steps technique. First they create an incomplete 
query skeleton which captures the basic structure of the result query 
and then complete the skeleton by adding some concrete and accurate rules 
and generate a list of candidates. 
These two steps share the same goals as our candidate schema generation 
procedure where BFS aims to find the skeletons of a schema,
and DFS aims to add more constraints. 
The last step is to rank the candidates though different strategies are used. 

% question and answering via paraphrasing
In question answering by paraphrasing \cite{harabagiu2006methods,berant2013semantic,fader2013paraphrase,kwiatkowski2013scaling,berant2014semantic}, 
as a representative, Berant and Liang~\shortcite{berant2014semantic} attack 
semantic parsing by mapping natural language utterances into logical forms 
to be executed on a KB using a paraphrase model and furthermore 
improved QA performance. We compared our results to theirs in the experiments
section. 

% other parts
Other related work includes unsupervised systems such as 
\cite{zou2014natural}, which calculates scores of candidate skeletons
using TF-IDF and then choose the best one to represent the target relation. 
%As for concrete mapping format, MapOnto \cite{an2006discovering} uses Horn clauses when produces mapping rules between two schemas. Others \cite{zhang2012ontological} generate complex SQL queries consisting of operations like join, union, project and select as mappings.
Graph-based representations \cite{reddy2014large} is usually 
used in exploiting structural and conceptual similarity between NL 
and KB. Zou et al. \shortcite{zou2014natural} interpret a natural language 
question as a semantic query graph where each vertex represents an argument 
and each edge is associated with a relation phrase.  
Compared to these works, our schema graph is more complex with constraints.
