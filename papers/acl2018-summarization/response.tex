Review 1:
Thanks for your comments. We will explain the merits of our
method and our directions for future research in more details
in the camera ready.

Review 2:
Thanks for your comments. 
EOS is trained as other words in vocabulary at training time.
As seen in Equation 7, we add length information at first 
layer in CNN model. The information attenuation occurs in GLU
(mentioned in sec 2) layer by layer. Different desired lengths
have different degrees of information attenuation. Therefore the model 
is able to learn the probability of generating 
EOS with its own length information attenuation. 

ROUGE is the most popular evaluation method in abstractive 
summarization work. The semantic cosine similarity was never 
attempted by any previous abstractive summarization work. 
We are not claiming this as a contribution, but use it to complement
the ROUGE score. Empirically, we have found that such semantic
similarity measure correlates quite well with human assessment on 
the TAC data. We can put this in camera ready.

Review 3:
Thanks for your comments. 
In the first paragraph of Introduction section, we have thoroughly
discussed why we chose to use a convolutional network instead of
a recurrent one.

The calculation of similarity is presented in Equation 9. 
Each color in Table 3 means a different entities. 

As for the evaluation part, it is well known that ROUGE is the 
standard evaluation metric in summarization while BLEU is 
more commonly used in machine translation. Because most of the 
previous work in abstractive summarization use ROUGE as the key measure, 
using ROUGE score enables easy comparison with their results. 
Today, summarization is an important sub-field in NLP research,
which is evident from the number of papers on the subject in all
key NLP conferences.

We will proofread the paper carefully before the camera ready.
