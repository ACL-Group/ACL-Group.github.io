\section{Evaluation}
\label{sec:evaluation}
We use the above approach to translate two popular English knowledge graphs, \con and \pro into \zhcon and \zhpro, respectively. In this section, we evaluate the coverage and accuracy of \zhcon and \zhpro, respectively.

%\KZ{Instead of using \\paragraph, use subsubsection* instead because
%some of your paragraph is not really paragraph but span into 
%multiple paragraphs.
%}
\subsection{\zhcon}
\zhcon is a mixed Chinese common sense knowledge graph, which comes from two sources, 
the original Chinese part of \con and the translation result of \con's English part.
\subsubsection*{Coverage}
ConceptNet is a multilingual knowledge graph containing 369,354 edges with both Chinese nodes. As shown in Table \ref{tab:conceptnet_coverage}, 
the size of \zhcon is \textbf{5.6} times as large as the original Chinese part of \con, 
which is a substantial increase in quantity. 
To our best knowledge, there are no other Chinese knowledge graphs dedicated to common sense. Such a huge resource can be a valuable asset for Chinese NLP research based on common sense.
\begin{table}[ht]
\small
\centering
\begin{tabular}{|l|l|}\hline 
\textbf{Dataset}&\textbf{Size}\\\hline\hline
1. Original Chinese Part in \con &369,354(x1.0)\\
2. Translated English part in \con &1,716,327(x4.6)\\
\zhcon (Merge 1 and 2)&\textbf{2,085,681(x5.6}) \\ 
	\hline
\end{tabular}
\caption{Size of \zhcon.}
\label{tab:conceptnet_coverage}

\end{table}

\subsubsection*{Accuracy}
To evaluate the quality of \zhcon, 
we randomly sample 500 samples from original Chinese part in \con, 
direct translation result of English part in \con, translation result of English part in \con based on our approach(direct translation plus revision), and \zhcon(which merges the Chinese part in \con and translated English part in \con based on our approach), respectively.
We ask two annotators to evaluate these samples. 
As Table \ref{tab:conceptnet_accuracy} shown, there exists 1\% error in original Chinese part in \con, which comes from human errors.
%Since approximately 86\% of the data in \con comes from collaborative datasets, such as Wiktionary, DBpedia, etc 
Compared with the direct translation, the accuracy in the translation based on our approach has a relative gain of \textbf{2.8\%}.
The accuracy of \zhcon has also been improved to \textbf{89.6\%} due to the high quality of the merged original Chinese part in \con.

\begin{table}[ht]
\small
\centering
\begin{tabular}{|l|l|}
	\hline
	Approach & Accuracy \\ \hline\hline
	1. Original Chinese part in Conceptnet& 98.3\%(0.58) \\\hline
	2. Direct translation of English part                 & 84.5\%(0.85) \\\hline
	3. Translation based on our approach & 87.3\%(0.85) \\\hline
	Zh-Conceptnet (Merge 1 and 3) & \textbf{89.6\%(0.79)} \\\hline
\end{tabular}
\caption{Accuracy of different approaches. The Kappa coefficients \cite{landis1977measurement} of two annotators in brackets suggest the substantial agreement.}
\label{tab:conceptnet_accuracy}

\end{table}
\subsubsection*{Qualitative results}
We present sample translation results in Table \ref{tab:conceptnet_case}. 
Our approach can easily distinguish the multiple meanings of the polysemous words.

\begin{table*}[th]
\small
\center
\begin{tabular}{|l|l|l|}\hline
\textbf{Node1(Subject)} & \textbf{Relation} & \textbf{Node2(Object)} \\ \hline\hline
	\begin{tabular}[c]{@{}l@{}}植物(vegetation)/plant\end{tabular} & /r/Desires & 水和太阳/water\_and\_sun \\ \hline
	\begin{tabular}[c]{@{}l@{}}植物(vegetation)/plant\end{tabular} & /r/AtLocation & \begin{tabular}[c]{@{}l@{}}污垢/dirt,花盆/flower\_pot,花园/garden,地球表面/surface\_of\_earth\end{tabular} \\ \hline
	
	\begin{tabular}[c]{@{}l@{}}植物(vegetation)/plant\end{tabular} & /r/Antonym & 矿物/mineral,动物/animal,矿物/mineral \\ \hline
	
	\begin{tabular}[c]{@{}l@{}}植物(vegetation)/plant\end{tabular} & /r/NotCapableOf & \begin{tabular}[c]{@{}l@{}}移动/move,跑/run,想想/think,走路/walk,四处走动/walk\_around\end{tabular} \\ \hline
	
	\begin{tabular}[c]{@{}l@{}}工厂(factory)/plant\end{tabular} & /r/RelatedTo & \begin{tabular}[c]{@{}l@{}}设施/facility,制造业/manufacturing,起动器/starter\\ 制造工厂/manufacturing\_facility,机械/machinery\end{tabular} \\ \hline
	%					工厂(factory)\\/plant & /r/IsA & \begin{tabular}[c]{@{}l@{}}包装厂/packinghouse,回收厂/recycling\_plant,\\ 炼油厂/refinery\end{tabular} \\ \hline
	\begin{tabular}[c]{@{}l@{}}植物(vegetation)/plant\end{tabular} & /r/CapableOf & \begin{tabular}[c]{@{}l@{}}绽放/bloom,花瓣/flower\_petals,成长/grow,无性繁殖/reproduce\_asexually\\有根/have\_roots,光合作用/photosynthesis,产生氧气/produce\_oxygen\\
	导致过敏/cause\_allergies,长叶/grow\_leaves,在花园里生长/grow\_in\_garden\end{tabular}  \\\hline
\end{tabular}
\caption{Some examples triples in \zhcon}
\label{tab:conceptnet_case}
\end{table*}

\subsection{\zhpro}
\zhpro is a Chinese taxonomic knowledge graph, which is the translation result of the English \pro. 
Since taxonomic knowledge can be easily extracted from text, there are many other existing Chinese taxonomic knowledge graphs. 
Two well-known Chinese taxonomic knowledge graphs are CN-Probase \cite{Xu2017} and zhishi.me \cite{Niu2011}.
We compare \zhpro with them in terms of coverage and accuracy.
\subsubsection*{Coverage}
CN-Probase is the largest existing Chinese taxonomic knowledge graph.
Its data comes from Baidu Baike, Hudong Baike and Chinese Wikipedia (three largest Chinese encyclopedia websites), more specifically, comes from the well-formed information, such as abstract, infobox, category information. 
However, the data source of \pro is massive text corpora in online webpages, which is freer compared with the source of CN-Probase.
This explains why the size of the concepts in \zhpro (2,094,825) is \textbf{8} times larger than that in CN-Probase(270,000), as shown in Table \ref{tab:probase_coverage}.
We further validate this fact with a concrete example.
The top-10 instances of concept ``人/person'' in \zhpro are all sub-concepts, such as ``老人/old people'', ``朋友/friend'', ``医生/doctor'', etc., 
while, in CN-Probase, seven of the top-10 instances of concept ``人/person'' are specific person names, such as ``曹操'', ``崔健'', ``李清云'', etc.
Therefore, one of the advantages of \zhpro, which has numerous concepts, is that it can provide much broader coverage of different topics than existing Chinese taxonomic knowledge graphs.
A larger concept space also exhibits a stronger ability in capturing the implied semantics, as demonstrated in \cite{wang2010toward}.

We further evaluate the overlap between \zhpro and existing Chinese taxonomic knowledge graphs.
The ratio of pairs in CN-Probase, which are also in \zhpro, is \textbf{6\%}, while the ratio of ``IsA'' pairs in \zhpro, which are also in CN-Probase, is less than \textbf{1\%}.
This is the sampling estimate via the public API interface of CN-Probase, since it is not open-source.
The intersection of \zhpro and zhishi.me is only \textbf{5243} pairs. 
We can conclude that although the number of ``IsA" pairs in CN-Probase is 3 times larger than that in \zhpro, \zhpro can still greatly enrich existing taxonomic knowledge graphs because of the small overlap.

%\KZ{The style and font size of all tables must be consistent. You can't use 
%resizebox to scale everything into one column so that the fontsizes are
%different.}
\begin{table}[ht]
	\small
	\centering
	\begin{tabular}{|c|c|c|c|}
		\hline
		\textbf{}&\textbf{\zhpro}&\textbf{CN-Probase}&\textbf{zhishi.me}\\ \hline\hline
		concepts  &\textbf{2,094,825}&270,000&17,936\\
		instances  &4,532,110&17,000,000&511,667\\
		con-ins pairs &\textbf{7,054,382}&-&959,581\\
		con-subc pairs&\textbf{4,238,111}&-&2,003\\
		IsA pairs&11,292,493&33,000,000&961,587 \\ \hline
		\end{tabular}
		\caption{Size of existing taxonomic knowledge graphs. (`-' means we can not get it. ``con-ins'' means ``concept-instance'', ``con-subc'' means ``concept-subconcept'')}
		\label{tab:probase_coverage}
\end{table}

\subsubsection*{Accuracy}	
To detect the quality of \zhpro, 
we randomly sample 500 samples from \pro, direct translation of \pro, translation result based on our approach (direct translation plus revision), respectively.
We ask two annotators to evaluate these samples. 
The results are shown in Table \ref{tab:probase_accuracy}. 
Compared to direct translation, the accuracy based on our approach has increased by \textbf{1.4\%} (from 85.2\% to 86.6\%).
It is less than the improvement(2.8\%) of translation result based on our approach in
Zh-ConceptNet, because most nodes in \pro are multi-word and less ambiguous.
In addition to the inherent error around 7\%(accuracy 93.0\%) in \pro, our translation approach only introduces an additional error of 6.4\%(accuracy 86.6\%).

\begin{table}[ht]
\small
\centering
	\begin{tabular}{|l|l|}
		\hline
		\textbf{Knowledge Graph} & \textbf{Accuracy} \\ \hline\hline
		\pro    & 93.0\%(0.75) \\ \hline
		Direct translation of \pro    & 85.2\%(0.84) \\ \hline
		Zh-Probase & 86.6\%(0.88) \\ \hline
		CN-Probase     & 95.0\% \\ \hline
		zhishi.me     & 100\% \\ \hline
	\end{tabular}
	\caption{The accuracies of existing Chinese taxonomic graphs. The Kappa coefficients of two annotators in brackets suggest the substantial agreement.  }
	\label{tab:probase_accuracy}
\end{table}

\paragraph{Qualitative results}
We present sample translation results in Table \ref{tab:probase_case}. It shows the effect of translated knowledge graph is satisfactory.
\begin{table}[H]
\small
\begin{tabular}{|l|l|l|}
	\hline
	\textbf{Instance} & \textbf{Subconcept} & \textbf{Concept} \\ \hline\hline
	\begin{tabular}[c]{@{}l@{}}番茄(tomato)\\玉米(maize, corn)\\大豆(soy, soybean)\end{tabular} & 
	\begin{tabular}[c]{@{}l@{}}植物\\(plant, flora)\end{tabular} &
	\begin{tabular}[c]{@{}l@{}}有机体(organism)\\ 生产者(producer)\end{tabular} \\ \hline
	
	%		\begin{tabular}[c]{@{}l@{}}无水乙醇/(anhydrous ethyl alcohol)\\ 合成乙醇/(synthetic ethyl alcohol)\end{tabular} & 
	%		\begin{tabular}[c]{@{}l@{}}乙醇\\(alcohol,ethanol)\end{tabular}&
	%	    \begin{tabular}[c]{@{}l@{}}生物燃料/(biological fuel)\\ 有机溶剂/(organic solvent)\\ 化合物/(compound)\end{tabular} \\ \hline
	
	\begin{tabular}[c]{@{}l@{}}橡胶厂(rubber plant)\\
		炼油厂(oil refinery)\\ 电厂(power plant)\end{tabular} & \begin{tabular}[c]{@{}l@{}}工厂\\(factory, mill)\end{tabular} & \begin{tabular}[c]{@{}l@{}}资产(asset)\\地方(spot,place)\end{tabular} \\ \hline
	
	\begin{tabular}[c]{@{}l@{}}狗(dog),猫(cat,feline)\\ 牛(cattle,cow,ox)\end{tabular} &
	\begin{tabular}[c]{@{}l@{}} 动物\\(animal)\end{tabular} & \begin{tabular}[c]{@{}l@{}}类别(category)\\
		主题(theme)\\ 
		生物(creature)\end{tabular}\\ \hline
\end{tabular}
\caption{Some ``IsA'' samples in \zhpro}
\label{tab:probase_case}
\end{table}


