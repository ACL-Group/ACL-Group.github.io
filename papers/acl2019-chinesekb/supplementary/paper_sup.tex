%File: formatting-instruction.tex
\documentclass[letterpaper]{article} %DO NOT CHANGE THIS
\usepackage{times}  %Required
\usepackage{helvet}  %Required
\usepackage{courier}  %Required
\usepackage{url}  %Required
\usepackage{graphicx}  %Required
\frenchspacing  %Required
\setlength{\pdfpagewidth}{8.5in}  %Required
\setlength{\pdfpageheight}{11in}  %Required
%PDF Info Is Required:
\pdfinfo{
	/Title (Supplementary File for Construction of Chinese Knowledge Graphs via Translation)
	/Author (Haijun Zhang, Yang Li, Kenny Zhu)}
\setcounter{secnumdepth}{0}  
\usepackage{float}
\usepackage{CJKutf8}
\usepackage{color}
\usepackage{url}
\usepackage{amsmath,amssymb,amsfonts}
%\usepackage{algpseudocode}
%\usepackage{algorithmic}
%\usepackage{algorithm}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{CJKutf8}
%\renewcommand\baselinestretch{1.2}
\usepackage{xcolor}


\usepackage{multirow}
\usepackage[ruled,vlined,boxed,linesnumbered]{algorithm2e}
\usepackage[font=footnotesize]{subfig}
\usepackage{xspace}
\DeclareMathOperator*{\argmax}{argmax}
\newcommand{\TD}[1]{\textcolor{red}{#1}}
\newcommand{\AF}[1]{}
\newcommand{\zhcon}{Zh-ConceptNet\xspace}
\newcommand{\con}{ConceptNet\xspace}
\newcommand{\zhpro}{Zh-Probase\xspace}
\newcommand{\pro}{Probase\xspace}

\begin{document}
	% The file aaai.sty is the style file for AAAI Press 
	% proceedings, working notes, and technical reports.
	%
	\title{Supplementary File}
	\maketitle
	
	\begin{CJK}{UTF8}{gkai}


%title: supplementary detail
%Free style, not aaai.

%implemention details:
%disscusion on the result:
	
%	The overlapping between Chinese-Probase and CN-Probase
\section{Discussion}

\subsection{The Overlapping Between CN-Probase and Zh-Probase}
%Up to now, the Chinese taxonomic Knowledge graphs similar to Probase are CN-Proabse\cite{Xu2017} and zhishi.me\cite{Niu2011}.
CN-Probase is the largest  Chinese taxonomic Knowledge graphs.
Its data source comes from Baidu Baike, Hudong Baike and Chinese Wikipedia (which are three largest Chinese encyclopedia website), more specifically, comes from the structured information, such as abstract, infobox, category information. 
While data source of Probase comes from the massive unstructured text corpora, which is not that normal compared with structured data in encyclopedia, this explains why the concepts in translated Probase (2,094,825) is 8 times the size of CN-Probase(270,000). 
A big advantage of numerous concepts is that it can provide a much broader coverage on diverse topics. We look through a specific example to verify this opinion, The top-10 instances of concept ``人/person'' in Probase are all concepts such as ``老人/old people'', ``朋友/friend'', ``医生/doctor'', etc. 
While in CN-Probase, seven of the top-10 instances of concept ``人/person'' are specific person names, such as ``曹操'', ``崔健'', ``李清云'', etc.
So, the \zhpro can greatly enrich the CN-Probase.


%\section{Implementation Detail}
%wicket is made of stumps

\subsection{ Is the relation really that important?}
	Given triples such as (``apple", ``IsA", ``fruit"), (``apple'', ``AtLocation'', ``greengrocer"), (``date'',``RelatedTo'',``tree''), we pack them as contextual strings such as ``apple, fruit'', ``apple, greengrocer'', ``date, tree''. Then, feed them into the Translator.  This approach ignores the relation, but it has some advantages:
	
	1. \textbf{Convenience}. Unpacking the translated result is very easy by using the uniform pattern for all the relations. Since the translator is very unstable and sensitive to the input sentence, Adding relation information to input sentence causes lots of patterns to be designed.
	
	2. \textbf{Competitive Effectiveness}. Packing the relation information into sentence like ``apple is located at greengrocer'' don't have much additional gain compared with the naive form ``apple, greengrocer'', which can already disambiguate the word senses with context.  for  (``date'',``RelatedTo'',``tree''), constructing ``date is related to tree'' still can't translate ``date'' well.
	
\subsection{ Which result should we choose to revise?}
	The naive translation approach can't disambiguate the low-frequency word sense well such as ``date'' in (``date'', ``RelateTo'', ``tree''), where the ``date'' is about the fruit, so we need to revise the translated result. Here, we choose the pairs which contain at least one node which is only a single word, and this approach can avoid massive computation. We collect the word senses for each word using translator, and filter the word senses, whose confidence is less than 0.001. Using the remaining word senses to calculate the semantic similarity, then choose the best pair as the revised result.

%Table \ref{tab:conceptnet_revision} shows the effect of revision in ConceptNet.

%\section{Case in Translated ConceptNet}	
%\begin{table}[ht]
%\centering
%\begin{tabular}{|c|c|c|}\hline
%\textbf{Total} & \textbf{Revision Size}&\textbf{Revision Precision}  \\ \hline
%	369,354          & 1,716,327    & 2,085,681 \\ \hline
%\end{tabular}
%\caption{The Effect of Revision in ConceptNet}
%\label{tab:conceptnet_revision}
%\end{table}

%\section{Case in Translated Probase}
%\begin{table}[ht]
%\centering
%\begin{tabular}{|c|c|c|}\hline
%\textbf{Total} & \textbf{Revision Size}&\textbf{Revision Precision}  \\ \hline
%369,354          & 1,716,327    & 2,085,681 \\ \hline
%\end{tabular}
%\caption{The Effect of Revision in Probase}
%\label{tab:probase_revision}
%\end{table}
%\bibliographystyle{aaai}
%\bibliography{library}
%		
	\end{CJK}
\end{document}





