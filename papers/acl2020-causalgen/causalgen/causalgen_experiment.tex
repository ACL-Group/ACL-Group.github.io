\section{实验设计与分析}
\label{sec:causalgen-experiment}
本节先给出我们使用的语料的统计信息，
并评估我们抽取的因果对质量。
我们介绍实验中使用的两种评估数据集
以及评估准则。
接着，我们比较并分析各种方法在因果生成任务
上的结果。实验结果表明我们的方法
可以生成更合理的因果。

\subsection{数据集}
\label{sec:causalgen-datasets}
我们首先描述了抽取因果对所使用的文本语料，
然后引入了后续实验用到的两个评估数据集。

\paragraph{因果生成数据集}
\label{sec:causalgen-corpus}
我们创建的因果生成数据集来自于小说文本，
这些小说是由作家创作的高质量文本语料。
近期的工作~\cite{}表明，相比于其他文本数据，
来自于小说及书籍的故事文本数据
对常识性推理等更有帮助。
因此，我们收集了大量的小说文本语料作为数据源，
按\secref{sec:causalgen-extraction}
中所描述的方法从中抽取因果对构建因果生成数据集。

\noindent 我们首先从Library Genesis\footnote{\url{libgen.is}}，
一个免费检索文章和书籍的搜索引擎，
中爬取原始小说故事语料。
为了保证我们语料的质量，我们主要收集那些出现在
获奖列表以及各种最佳推荐列表中的小说作品，
例如，诺贝尔文学奖作品和《时代》杂志有史以来的100部
小说。
由此，我们爬取了1,9000部小说，
在对原始数据进行清洗和过滤后，共得到约1亿个句子。
我们按\secref{sec:causalgen-extraction}
中描述的抽取步骤，在收集的小说语料上
共抽取出539,930个因果对，
并按照80\%，10\%，10\%的比例将数据划分为
训练集、验证集和测试集，
各包含431,944、53,933和53,933个因果对。
注意，我们又为每个因果对分别创建了正向因果推理和反向因果推理两个数据实例（如\figref{fig:causalgen-example}所示），用于训练、验证及测试。

\paragraph{评估数据集}
\label{sec:causalgen-eval-dataset}
我们实验中使用了两种评估数据集，
来评估模型在因果生成任务上的表现。
第一个评估数据集是前面因果生成数据集
中的测试集，它与训练
数据具有相同的数据源，都源于小说语料，记为NOVTest。
具体数据实例如\figref{fig:causalgen-example}所示。
我们使用的第二个评估数据集是COPA的测试集，
一个被广泛研究的常识性因果推理标准数据集。
COPA共包含1000个因果推理问题，
每个问题给定前提和推理方向，并给出
两个候选选项，要求模型选出最合理的选项
作为推理结果。
我们按照\secref{sec:causalgen-extraction}中描述的输入格式转换
方法（示例如\figref{fig:causalgen-example}）处理各问题，即
将给定前提作为输入序列，然后根据因果推理方向
初始化目标序列的首个输出词，生成目标序列输出。
若为正向因果生成，则将其初始化为$\left< f\right>$；
若为反向因果生成，则将其初始化为$\left< b\right>$。
我们使用的COPA测试集
共500个问题，
在经过输入格式转换之后，我们
构建的COPA评估集由1000个因果生成
数据实例，记为COPATest。

\subsection{比较方法}
\label{sec:causalgen-baselines}
本小节介绍实验中涉及到的各种比较方法，
大致分为基于选择的方法和基于生成的方法两类。

\paragraph{基于选择的方法}
为了完成因果生成任务，基于选择的方法
首先为给定输入源序列$s$自动生成一个
目标候选集$C^t$，然后从中选取
最好的候选作为生成结果。
以正向因果生成为例，
给定$s$作为原因，为生成结果集$C^t$，
我们先将$s$与因果生成
训练数据集（见\secref{sec:causalgen-datasets}）
中的所有源事件进行匹配，
为$s$选出10个语义上最相近的原因事件
构成$C^s$，而每个源$s' \in C^s$
所对应的结果事件构成了目标候选集$C^t$。
我们利用CausalNet计算
$s$和各候选$t \in C^t$之间的因果强度，
选择分值最大的作为生成结果。
我们提出了三种语义匹配生成$C^s$的方法。
单元词匹配法\textbf{OUniMat}（\textbf{O}riginal \textbf{Uni}gram \textbf{Mat}ches）
计算$s$与训练数据中各原因事件中
单元词的匹配个数（并除以事件长度进行归一化）
挑选最匹配的事件构成$C^s$；
它的一个变种是\textbf{PUniMat}
（\textbf{P}rocessed \textbf{Uni}gram \textbf{Mat}ches），
即我们先对各事件进行预处理，去除停用词再进行
匹配；我们还考虑用二元词代替单元词进行匹配，
即\textbf{BiMat}（\textbf{Bi}gram \textbf{Mat}ches）。

\paragraph{基于生成的方法}
我们将基于卷积神经网络的序列到序列学习模型框架用于因果生成。
这种基于生成的方法，不需要预先生成候选集
$C^t$，因而更加灵活。
我们将使用多层软注意力机制的模型记为\textbf{MultiSAttn}（\textbf{Multi}-step \textbf{S}oft \textbf{Att}ention）;
将使用\secref{sec:causalgen-causal-attention}中的因果注意力机制替代多层软注意力机制的模型记为
\textbf{CAttn}（\textbf{C}ausal \textbf{Att}ention）。
最后，我们设计融合机制将两种注意力相结合得到
\textbf{FAttn}（\textbf{F}used \textbf{Att}ention）模型。

%\subsection{评估准则}
%\label{sec:causalgen-metrics}
%本小节我们介绍了实验中使用的四种评估标准。
%\paragraph*{BLEU}
%BLEU分数，包括BLEU-1，BLEU-2和
%BLEU-3，结合了模型生成序列与标准目标序列的n-元词的匹配精度并考虑了
%句子

\subsection{结果比较及分析}
\label{sec:causalgen-results}
本节我们比较\secref{sec:causalgen-baselines}
中各方法在因果生成上的实验结果。
我们用\secref{sec:causalgen-corpus}
中创建的因果生成数据集
的训练集来训练模型各模型，
然后对NOVTest和COPATest
评估数据集进行端到端测试。
实验所用的评价指标为
BLUE分数
（包括BLEU-1，BLEU-2和BLEU-3）
和准确率。
对于COPATest，我们直接使用标注好的数据集；
而对于NOVTest，我们聘请
三名标注者对各模型的因果生成结果
进行人工评估，即根据给定的原因或结果
判断模型生成的结果或原因是否合理，
当有两名及两名以上的标注者觉得合理
才认为是正确的，以此标注结果来计算
模型因果生成在NOVTest数据集上的准确率。

\begin{table}[th]
	\centering
	\begin{tabular}{lccccc}
		\hline
		Model &   BLEU-1  & BLEU-2 & BLEU-3 & Human Accuracy \\
		\hline
		OUniMat   & 17.71  & 1.17  & 0.0  &  0.26  \\
		PUniMat   &  17.54 &  - & -  &  0.22   \\
		BiMat        & 19.95  &  2.55 & 0.01  &  0.23  \\
		CAttn  & 15.96 & 0.61 & 0.04 & 0.18 \\
		MultiSAttn & 23.64 & 4.06 & 0.92 & 0.21 \\
		FAttn & \bf 24.53 & \bf 4.07 & \bf 0.94 & \bf 0.35 \\
		\hline
	\end{tabular}
	\bicaption{各方法在NOVTest数据集上因果生成的结果比较。}{Comparisons of results on NOVTest dataset. }
	\label{tab:causalgen-novel-eval}
\end{table}


\begin{table}[th]
	\centering
	%	\small
	\begin{tabular}{lcccccc}
		\hline
		Model &   BLEU-1 & BLEU-2 & BLEU-3 & Human Accuracy \\	\hline
		OUniMat & 11.15 & 0.14 & 0.0 & 0.26 \\
		PUniMat & 12.35 & -  & - & 0.17 \\
		BiMat & 13.42 & 0.41 & 0.0 & 0.26 \\
		CAttn & 18.90 & 0.12 & 0.0 & 0.21 \\
		MultiSAttn & \bf 42.14 & 17.19 & 2.10 & 0.25 \\
		FAttn & 40.60 & \bf 17.51 & \bf 2.31 & \bf 0.52 \\\hline
	\end{tabular}
	\bicaption{各方法在COPATest数据集上因果生成的结果比较。}{Comparisons of results on COPATest dataset. }
	%{BLEU score, Causality strength score and Accuracy on COPA}
	\label{tab:causalgen-copa-eval}
\end{table}

\begin{table*}[th!]
	%	\small
	\begin{center}
		\bicaption{因果生成结果案例分析。
		}{The influence of attention mechanism for causality generation.}
		\label{tab:causalgen-cases}
		\small
		\subfloat[Forward causality generation case.]{
			\label{tab:causalgen-forward-case}
			\begin{tabular}{l|l}%{|p{7cm}|rl|}
				\hline
				\begin{tabular}[c]{@{}l@{}}
					Source \\ (Cause) \end{tabular}
				& the husband discovered that the husband wife was having an affair \\\hline
				\begin{tabular}[c]{@{}l@{}}
					Reference \\ (Effect) \end{tabular}
				& the husband filed for divorce \\\hline\hline
				\begin{tabular}[c]{@{}l@{}}
					CAttn Hypothesis \\ (Effect) \end{tabular}
				& <f> i was n't sure what to say \\\hline
				\begin{tabular}[c]{@{}l@{}}
					MultiSAttn Hypothesis \\ (Effect) \end{tabular}
				& <f> the husband was not in the least concerned \\\hline
				\begin{tabular}[c]{@{}l@{}}
					FAttn Hypothesis \\ (Effect) \end{tabular}
				& <f> the husband was disappointed \\\hline
			\end{tabular}
		}
		\qquad
		\subfloat[Backward causality generation case.]{
			\label{tab:causalgen-backward-case}
			\begin{tabular}{l|l}%{|p{7cm}|rl|}
				\hline
				\begin{tabular}[c]{@{}l@{}}
					Source \\ (Effect) \end{tabular}
				& the little boy forward was always in the shelter of her arms \\\hline
				\begin{tabular}[c]{@{}l@{}}
					Reference \\ (Cause) \end{tabular}
				& lien pushed the little boy forward and inched herself along on her heels \\\hline\hline
				\begin{tabular}[c]{@{}l@{}}
					CAttn Hypothesis \\ (Cause) \end{tabular}
				& <b> the unk had been so much more than a year ago \\\hline
				\begin{tabular}[c]{@{}l@{}}
					MultiSAttn Hypothesis \\ (Cause) \end{tabular}
				& <b> she was so small \\\hline
				\begin{tabular}[c]{@{}l@{}}
					FAttn Hypothesis \\ (Cause) \end{tabular}
				& <b> the little boy was so fond of her \\\hline
			\end{tabular}
		}
	\end{center}
\end{table*}

首先，我们对与训练数据同源的测试集NOVTest
进行端对端因果生成测试，实验结果
如\tabref{tab:causalgen-novel-eval}所示。
我们可以看到
而仅使用
因果注意力的CAtnn模型
在基于生成的方法中表现较差，
这是因为CAttn模型强制的将
第一解码层和编码层的注意力
赋为基于全局因果强度的因果注意力分数，
这会在一定程度上破坏之前学习到的分布，
使其不能有效利用编码器和解码器的层级结构；
而使用多步软注意力机制的MultiSAttn模型
可以将注意力代表的语义映射信息在层与层之间
有效传递，表现稍好；
FAttn模型使用提出的因果注意力融合机制
将多步软注意力与因果注意力相结合
得到了更好的效果。


然后，我们还对常识性因果推理测试集COPATest
中的因果对进行端对端因果生成测试。
由于训练数据集是小说语料，与COPATest不同源，
因而我们需要在COPA的开发集上对模型进行精化训练。
我们在\tabref{tab:causalgen-copa-eval}展示了
各模型实验结果。
其中，PUniMat模型由于去除了停用词，
因而无法统计二元词和三元词，即无法
测评BLEU-2和BLEU-3。
我们可以看到因果注意力融合方法FAttn
在各指标上的表现均为最优，
除了BLEU-1略低于MultiSAttn模型，
但BLEU值对因果生成结果的测评是一种合理性验证，
最可信的还是人工评估，即准确率。


在前两个实验中，我们可以看出相比于基于选择的方法，基于生成的方法更灵活有效，在端对端的实验中表现更好。最后，我们展示并比较基于生成的模型的因果生成结果，分析不同的注意力机制对生成模型的影响，
如\tabref{tab:causalgen-cases}所示。
%我们分别为正向因果生成和反向因果生成各举一个案例，
其中，\tabref{tab:causalgen-forward-case}是正向因果生成案例，
\tabref{tab:causalgen-backward-case}是反向因果生成案例。
我们可以看到多层注意力机制的表现明显更优，
而无法利用层级信息的CAtnn模型生成的结果比较泛化，
不是很具体，信息量较少。
而MultiSAttn和FAttn两种多层注意力机制相比，
FAttn生成的结果因果关系更强更合理，
比如当“妻子出轨”时（\tabref{tab:causalgen-forward-case}）
丈夫更合理的表现是“失望”（FAttn的生成结果）而不是“毫不在意”
（MultiSAttn的生成结果）。
这是由于基于外部知识的因果注意力
可以捕捉到“出轨”与“失望”之间的全局因果关系，
缓解训练数据资源匮乏的问题，增强模型因果表达。
