\section{Evaluation}
\label{sec:eval}
\section{Evaluation}
\label{sec:eval}
In this section, we first give some statistics of our 
corpus, and evaluate the quality of our extracted 
cause-effect causal training pairs.
We then introduce two evaluation datasets and 
a bunch of evaluation metrics we adopted in our experiments. 
Next, we compared our results on the commonsense causality generation task against a number of baselines. 
The result shows that the causes (or effects) generated by our methods are more reasonable.

\subsection{Datasets}
\label{sec:datasets}
We first describe the text corpus we used for 
cause-effect pairs extraction, and then introduce
two evaluation datasets for the following experiments.

\paragraph{Novel Corpus}
\label{sec:novel_corpus}
We create a new cause-effect dataset from the novels,
which are a good source of commonsense causal information.
Recent works~\cite{gordon2011commonsense, trinh2018simple} show that 
the data of stories texts from novels and books benefit the commonsense reasoning tasks more than other sources.
Thus, we collect a large number of novels as data source and extract cause-effect pairs 
through the method described in \secref{sec:causal_pairs}.

\noindent We first crawl raw novel corpus from Library Genesis\footnote{\url{libgen.is}}, 
a search engine for articles and books which allows free access. 
To maintain the quality of our corpus, 
we collect a group of prize-winning lists and top-x lists for novels, 
for example Nobel Prize in Literature and Time Magazine All Time 100 Novels.
The resulting 19000 novels are splitted into around 100 million sentences, 
which served as our data source after filtering and text cleaning. 
According to the extraction method in \secref{sec:causalgen-extraction}，
we obtain 539,930 cause-effect pairs from novels.
We split them into training set (431,944 examples, 80\%), validation set (53,993 examples, 10\%) and test set (53,993 examples, 10\%).
Note that, each cause-effect pair can be transformed into two examples of forward causality and backward causality
(as shown in \figref{fig:example})
for training, validation and testing.

\paragraph{Evaluation Datasets}
\label{sec:causalgen-eval-dataset}
In this experiment, 
we use two evaluation datasets to evaluate the performance of the models on causality generation task.

\textbf{NOVTest.}
We use the test set in~\secref{sec:novel_corpus} as the first evaluation dataset,
which is from the same data source with the training data.
The specific examples are formated as shown in~\figref{fig:example}. 

\textbf{COPATest.}
To better understand the performance of our model against related research, we also use 
the Choice of Plausible Alternatives (COPA) 
as test dataset, which is a widely-attempted causal reasoning benchmark. 
It consists of one thousand multiple-choice questions.
Each question is composed of a premise and two alternatives,
where the task is to select the more plausible alternative as a cause (or effect) of the premise. 
We do the input transformation on each question according to the methods in \secref{sec:causalgen-extraction}, 
which takes the premise (or more plausible alternative) as input and initialzes the first word of output.
\begin{itemize}
\item[-] For \textit{forward} causality generation, 
      we put the special token $\left< f\right>$ in front of the premise or alternative.
\item[-] For \textit{backward} causality generation, 
      we put the special token $\left< b\right>$ in front of the premise or alternative.
\end{itemize}
We use the test set of COPA~\cite{gordon2011commonsense}
which contains 500 questions.
After the input transformation,
the built COPA evaluation dataset consists of 1000 cause-effect pairs. 

\subsection{Baselines}
\label{sec:causalgen-baselines}
There are five baselines in the evaluation experiments
which can be divided into two categories:
the selection-based methods and the generation-based methods. 

\begin{itemize}
\item{Selection-based}
To perform the causality generation task, 
the selection-based models first automatically generate a set of target candidates $C^t$ for the given source $s$, 
then select the best answer from those candidates to reason about causalities. 
We take forward causality generation as an example.
Given the source $s$, we automatically match $s$ with the sources extracted from 
the novel corpus (as shown in \secref{sec:novel_corpus}) and select 10 most similar sources constituted $C^s$. 
Then, the set of target candidates $C^t$ is composed by the corresponding target of each source in $C^s$.
Then we compute the causal strength between 
$s$ and each $t$ in $C^t$ to select the best answer 
and generate it as the target.
We design three selection-based baselines as follows,
among which the main difference is 
the matching approach when generating the candidates set $C^s$ for $s$.
给定$s$作为原因，为生成结果集$C^t$，
我们先将$s$与因果生成
训练数据集（见\secref{sec:causalgen-datasets}）
中的所有源事件进行匹配，
为$s$选出10个语义上最相近的原因事件
构成$C^s$，而每个源$s' \in C^s$
所对应的结果事件构成了目标候选集$C^t$。
我们利用CausalNet计算
$s$和各候选$t \in C^t$之间的因果强度，
选择分值最大的作为生成结果。
我们提出了三种语义匹配生成$C^s$的方法。
单元词匹配法\textbf{OUniMat}（\textbf{O}riginal \textbf{Uni}gram \textbf{Mat}ches）
计算$s$与训练数据中各原因事件中
单元词的匹配个数（并除以事件长度进行归一化）
挑选最匹配的事件构成$C^s$；
它的一个变种是\textbf{PUniMat}
（\textbf{P}rocessed \textbf{Uni}gram \textbf{Mat}ches），
即我们先对各事件进行预处理，去除停用词再进行
匹配；我们还考虑用二元词代替单元词进行匹配，
即\textbf{BiMat}（\textbf{Bi}gram \textbf{Mat}ches）。

\paragraph{Generation-based}
我们将基于卷积神经网络的序列到序列学习模型框架用于因果生成。
这种基于生成的方法，不需要预先生成候选集
$C^t$，因而更加灵活。
我们将使用多层软注意力机制的模型记为\textbf{MultiSAttn}（\textbf{Multi}-step \textbf{S}oft \textbf{Att}ention）;
将使用\secref{sec:causalgen-causal-attention}中的因果注意力机制替代多层软注意力机制的模型记为
\textbf{CAttn}（\textbf{C}ausal \textbf{Att}ention）。
最后，我们设计融合机制将两种注意力相结合得到
\textbf{FAttn}（\textbf{F}used \textbf{Att}ention）模型。

%\subsection{评估准则}
%\label{sec:causalgen-metrics}
%本小节我们介绍了实验中使用的四种评估标准。
%\paragraph*{BLEU}
%BLEU分数，包括BLEU-1，BLEU-2和
%BLEU-3，结合了模型生成序列与标准目标序列的n-元词的匹配精度并考虑了
%句子

\subsection{结果比较及分析}
\label{sec:causalgen-results}
本节我们比较\secref{sec:causalgen-baselines}
中各方法在因果生成上的实验结果。
我们用\secref{sec:causalgen-corpus}
中创建的因果生成数据集
的训练集来训练模型各模型，
然后对NOVTest和COPATest
评估数据集进行端到端测试。
实验所用的评价指标为
BLUE分数
（包括BLEU-1，BLEU-2和BLEU-3）
和准确率。
对于COPATest，我们直接使用标注好的数据集；
而对于NOVTest，我们聘请
三名标注者对各模型的因果生成结果
进行人工评估，即根据给定的原因或结果
判断模型生成的结果或原因是否合理，
当有两名及两名以上的标注者觉得合理
才认为是正确的，以此标注结果来计算
模型因果生成在NOVTest数据集上的准确率。

\begin{table}[th]
	\centering
	\begin{tabular}{lccccc}
		\hline
		Model &   BLEU-1  & BLEU-2 & BLEU-3 & Human Accuracy \\
		\hline
		OUniMat   & 17.71  & 1.17  & 0.0  &  0.26  \\
		PUniMat   &  17.54 &  - & -  &  0.22   \\
		BiMat        & 19.95  &  2.55 & 0.01  &  0.23  \\
		CAttn  & 15.96 & 0.61 & 0.04 & 0.18 \\
		MultiSAttn & 23.64 & 4.06 & 0.92 & 0.21 \\
		FAttn & \bf 24.53 & \bf 4.07 & \bf 0.94 & \bf 0.35 \\
		\hline
	\end{tabular}
	\bicaption{各方法在NOVTest数据集上因果生成的结果比较。}{Comparisons of results on NOVTest dataset. }
	\label{tab:causalgen-novel-eval}
\end{table}


\begin{table}[th]
	\centering
	%	\small
	\begin{tabular}{lcccccc}
		\hline
		Model &   BLEU-1 & BLEU-2 & BLEU-3 & Human Accuracy \\	\hline
		OUniMat & 11.15 & 0.14 & 0.0 & 0.26 \\
		PUniMat & 12.35 & -  & - & 0.17 \\
		BiMat & 13.42 & 0.41 & 0.0 & 0.26 \\
		CAttn & 18.90 & 0.12 & 0.0 & 0.21 \\
		MultiSAttn & \bf 42.14 & 17.19 & 2.10 & 0.25 \\
		FAttn & 40.60 & \bf 17.51 & \bf 2.31 & \bf 0.52 \\\hline
	\end{tabular}
	\bicaption{各方法在COPATest数据集上因果生成的结果比较。}{Comparisons of results on COPATest dataset. }
	%{BLEU score, Causality strength score and Accuracy on COPA}
	\label{tab:causalgen-copa-eval}
\end{table}

\begin{table*}[th!]
	%	\small
	\begin{center}
		\bicaption{因果生成结果案例分析。
		}{The influence of attention mechanism for causality generation.}
		\label{tab:causalgen-cases}
		\small
		\subfloat[Forward causality generation case.]{
			\label{tab:causalgen-forward-case}
			\begin{tabular}{l|l}%{|p{7cm}|rl|}
				\hline
				\begin{tabular}[c]{@{}l@{}}
					Source \\ (Cause) \end{tabular}
				& the husband discovered that the husband wife was having an affair \\\hline
				\begin{tabular}[c]{@{}l@{}}
					Reference \\ (Effect) \end{tabular}
				& the husband filed for divorce \\\hline\hline
				\begin{tabular}[c]{@{}l@{}}
					CAttn Hypothesis \\ (Effect) \end{tabular}
				& <f> i was n't sure what to say \\\hline
				\begin{tabular}[c]{@{}l@{}}
					MultiSAttn Hypothesis \\ (Effect) \end{tabular}
				& <f> the husband was not in the least concerned \\\hline
				\begin{tabular}[c]{@{}l@{}}
					FAttn Hypothesis \\ (Effect) \end{tabular}
				& <f> the husband was disappointed \\\hline
			\end{tabular}
		}
		\qquad
		\subfloat[Backward causality generation case.]{
			\label{tab:causalgen-backward-case}
			\begin{tabular}{l|l}%{|p{7cm}|rl|}
				\hline
				\begin{tabular}[c]{@{}l@{}}
					Source \\ (Effect) \end{tabular}
				& the little boy forward was always in the shelter of her arms \\\hline
				\begin{tabular}[c]{@{}l@{}}
					Reference \\ (Cause) \end{tabular}
				& lien pushed the little boy forward and inched herself along on her heels \\\hline\hline
				\begin{tabular}[c]{@{}l@{}}
					CAttn Hypothesis \\ (Cause) \end{tabular}
				& <b> the unk had been so much more than a year ago \\\hline
				\begin{tabular}[c]{@{}l@{}}
					MultiSAttn Hypothesis \\ (Cause) \end{tabular}
				& <b> she was so small \\\hline
				\begin{tabular}[c]{@{}l@{}}
					FAttn Hypothesis \\ (Cause) \end{tabular}
				& <b> the little boy was so fond of her \\\hline
			\end{tabular}
		}
	\end{center}
\end{table*}

首先，我们对与训练数据同源的测试集NOVTest
进行端对端因果生成测试，实验结果
如\tabref{tab:causalgen-novel-eval}所示。
我们可以看到
而仅使用
因果注意力的CAtnn模型
在基于生成的方法中表现较差，
这是因为CAttn模型强制的将
第一解码层和编码层的注意力
赋为基于全局因果强度的因果注意力分数，
这会在一定程度上破坏之前学习到的分布，
使其不能有效利用编码器和解码器的层级结构；
而使用多步软注意力机制的MultiSAttn模型
可以将注意力代表的语义映射信息在层与层之间
有效传递，表现稍好；
FAttn模型使用提出的因果注意力融合机制
将多步软注意力与因果注意力相结合
得到了更好的效果。


然后，我们还对常识性因果推理测试集COPATest
中的因果对进行端对端因果生成测试。
由于训练数据集是小说语料，与COPATest不同源，
因而我们需要在COPA的开发集上对模型进行精化训练。
我们在\tabref{tab:causalgen-copa-eval}展示了
各模型实验结果。
其中，PUniMat模型由于去除了停用词，
因而无法统计二元词和三元词，即无法
测评BLEU-2和BLEU-3。
我们可以看到因果注意力融合方法FAttn
在各指标上的表现均为最优，
除了BLEU-1略低于MultiSAttn模型，
但BLEU值对因果生成结果的测评是一种合理性验证，
最可信的还是人工评估，即准确率。


在前两个实验中，我们可以看出相比于基于选择的方法，基于生成的方法更灵活有效，在端对端的实验中表现更好。最后，我们展示并比较基于生成的模型的因果生成结果，分析不同的注意力机制对生成模型的影响，
如\tabref{tab:causalgen-cases}所示。
%我们分别为正向因果生成和反向因果生成各举一个案例，
其中，\tabref{tab:causalgen-forward-case}是正向因果生成案例，
\tabref{tab:causalgen-backward-case}是反向因果生成案例。
我们可以看到多层注意力机制的表现明显更优，
而无法利用层级信息的CAtnn模型生成的结果比较泛化，
不是很具体，信息量较少。
而MultiSAttn和FAttn两种多层注意力机制相比，
FAttn生成的结果因果关系更强更合理，
比如当“妻子出轨”时（\tabref{tab:causalgen-forward-case}）
丈夫更合理的表现是“失望”（FAttn的生成结果）而不是“毫不在意”
（MultiSAttn的生成结果）。
这是由于基于外部知识的因果注意力
可以捕捉到“出轨”与“失望”之间的全局因果关系，
缓解训练数据资源匮乏的问题，增强模型因果表达。
