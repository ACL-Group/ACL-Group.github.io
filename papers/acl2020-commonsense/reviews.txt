Review #1

ConceptNet不具代表性：
what is 'As such, it is highly prone to overfit to the idiosyncrasies of the two resources (which are also somewhat dated), and the input text corpora.'?

If the paper would take efforts to show that the two resources are representative for their classes this limitation might be acceptable

ConceptNet仅小于10%是commonsense


TupleKB [2] and Quasimodo的predicate/relation更多，可能导致不同结论

should be a domain corpus rather than a general one

should include OpenIE

table7: 除了label种类之外并无区别，而且label种类多不意味着更难
ans: didn't say 'harder' but 'require more training data'

Review #2

1. q:should add 'application of commonsense knowledge'

2. q: in sec 3, explanation of OpenNRE is in order
a: a brief task definition is in sec 2

3. q: examples of the 54 and 27 relation types

4. q: explanation of MRR

5. q: why wiki(FB) is not good
a: training data of wiki(FB) is much smaller, and most of NYT(FB) test data is 'NA' (and model tends to predict 'NA'), which leads to better performance

6. q: findings not surprising

Review #3

1. q: quite obvious

2. q: But the most important point is that no real information is added at this level of generality. One could have to dig into particular classes of concepts and entities to better classify the complexity of the extraction of references to it.

3. q: reasons to accept: 'presents some datasets'???

4. q: what is 'absolute truth' and 'always false'
a: this is not a fact

5. q: corpus not enough

6. q: how to retrieve sentences
a: exact match

7. q: define 'head' and 'tail'
a: 'head' and 'tail' are commonly used terms in KB. We will expand the abbreviation of Line28 to '(head, relation, tail)'

8. q: define 'negative example'
a: following the convention, 'negative example' means random combination of entities in the KB.

9. q: Should explain model part including how to use GloVe. Cite and explain PCNN+ATT. 
a: We briefly explain the model in Line 121-123 and it's cited in Line 176. PCNN+ATT collect sentences containing the same entity pair as a set and use CNN to represent each sentence as embedding. It uses attention to calculate the weighted sum of these sentences as the set vector. After a representation matrix of relations, it outputs the probability distrition over all relations. We use GloVe as word embeddings to feed in CNN.

10. Q: Define entropy.
A: Definition is in Line 232-243.

11: Q: 'when the number...decreases'
A: We didn't consider this statement as a discovery but an explanation of why we only focus on single-word triples in Section 4.2.

12: Q: Define DPL and DT. Say the tool for parsing and POS tagging.
A: Definition is in Table 7 caption (Line 356-358). The tool is Stanford CoreNLP. We will add the citation.