\section{Experiments}
\subsection{Dataset}
We adopt our proposed FRM dataset and the FewRel dataset \citep{han-etal-2018-fewrel} for experiments.
~\\
~\\
\textbf{FRM Dataset} FRM Dataset is our proposed Chinese few-shot relation classification dataset in medical domain. The FRM Dataset consists of 27 relations with 50 instances per relation. The relations are grouped into 6 categories according to the entity types, forming 6 tasks with one group being the test set and other 5 groups serving as training set. The average length of a sentence in FRM dataset is 67.31, and there are totally 2,197 unique characters.
~\\
~\\
\textbf{FewRel Dataset} FewRel dataset \citep{han-etal-2018-fewrel} is a few-shot relation classification dataset. FewRel dataset is constructed through distant supervision and human annotation. The FewRel dataset consists of 100 relations with 700 instances per relation. The relations are split into groups of size 64, 16 and 20 for training, validation and testing respectively. The average length of a sentence in FewRel dataset is 24.99, and there are totally 124,577 unique tokens.

\subsection{Evaluation Metrics}
On the FRM Dataset, for each group of relations, we adopt $x$ way 5 shot and $x$ way 10 shot test configurations, where $x$ is the number of relation classes within the group. During training episodes, we conduct 5 way 15 shot training tasks. Thus totally 6 experiments are done. 

%On the FewRel dataset, firstly, following \citep{han-etal-2018-fewrel, ye-ling-2019-multi}, we conduct four few-shot learning configurations, 5 way 1 shot, 5 way 5 shot, 10 way 1 shot and 10 way 5 shot. During training episodes, we conduct 20 way 10 shot training tasks. Additionally, under 5 way 5 shot scenario, we set the training instances per relation to 700, 100, 50, 30 10 respectively and evaluate the model on the original validation set.
%Following \citep{han-etal-2018-fewrel, ye-ling-2019-multi}, each experiment on the FewRel dataset is tested with 2,000 independent samples.

On the FewRel dataset, we shirk the training set size to 30 classes with 100 sentences per class, 20 classes with 50 sentences per class, 15 classes with 30 sentences per class and 10 classes with 10 sentences per class respectively to form 4 tasks with extremely few training data. During training, we select random tasks of 5 way 15 shot, 5 way 15 shot, 5 way 10 shot and 5 way 5 shot correspondingly. Following \citet{han-etal-2018-fewrel, ye-ling-2019-multi}, for each task we test with 4 configurations: 5 way 1 shot, 5 way 5 shot, 10 way 1 shot and 10 way 5 shot.

%All test results are represented as mean and standard deviation values of 10 repetitions.
%\subsection{Baselines}
%Prototypical networks(CNN)(PCNN) core
%MLMAN
%\textbf{Prototypical Network} Prototypical network is first proposed by \citet{proto}. The model assumes that there exists a prototype for each class that can represent the meaning of the class. The prototype vector of each class is calculated by averaging the representation vectors of the support instances in this class. When classifying a query instance into certain class, the model chooses the relation with the nearest prototype vector to be the prediction. \citet{han-etal-2018-fewrel} combined prototypical network with CNN/PCNN core to handle few-shot relation classification tasks.
%~\\
%~\\
%\textbf{MLMAN} Multi-Level Matching and Aggregation Network(MLMAN)\citep{ye-ling-2019-multi} also assumes that prototypes exist. The MLMAN model encodes both each query sentence and each support sentence in an interactive way by adding mutual information at both local and instance levels. The prototype of each relation class is calculated by attentively aggregating the support vectors of this relation. The weight of each support sentence is calculated regarding to the query instances.
\subsection{Implementation Details}
\begin{table}[h]
\centering
\small
\begin{tabular}{|c|c|c|}
\hline
\textbf{Component} & \textbf{Parameter} & \textbf{Value} \\ \hline
ENG word embed & dimension & 50 \\ \hline
CHN char embed & dimension & 100 \\ \hline
\multirow{2}{*}{position embed} & max relative distance & $\pm80$ \\ \cline{2-3}
& dimension & 5 \\ \hline
\multirow{2}{*}{CNN} & window size & 3 \\ \cline{2-3}
& filter number & 200 \\ \hline
dropout & dropout rate & 0.2 \\ \hline
unidirectional LSTM & hidden size & 100 \\ \hline
\multirow{3}{*}{fast learner} & strategy & SGD \\ \cline{2-3}
& initial learning rate & 0.1 \\ \cline{2-3}
& learning rate decay & False \\ \hline
\multirow{3}{*}{slow learner} & strategy & SGD \\ \cline{2-3}
& initial learning rate & 0.1 \\ \cline{2-3}
& learning rate decay & True \\ \hline
\end{tabular}
\caption{Hyper-parameters chosen in experiments.}
\label{hyper}
\end{table}
During implementation, we choose MLMAN\citep{ye-ling-2019-multi} as the core model to provide the context encoder and class matching function. The context encoder consists of a CNN for encoding and a unidirectional LSTM for adding local and instance-level attention.

The hyper parameters chosen are shown in Table \ref{hyper}. The supplementary data for FRM dataset are from Chinese Literature NER RE dataset \citep{dnerre} (13,297 sentences covering 10 relations) and \url{https://github.com/crownpku/Information-Extraction-Chinese/tree/master/RE_BGRU_2ATT/origin_data} (1,100 sentences covering 12 relations). Supplementary data for FewRel dataset is from NYT-10 dataset \citep{NYTdataset} which contains 143,391 instances over 57 relation classes (class \emph{NA} is removed during augmentation).

\subsection{Results and Analysis}
\begin{table*}[ht]
\centering
\small
\begin{tabular}{|l|c|c|c|c|c|c|c|}
\hline
\multirow{2}{*}{\textbf{Method}} & \multirow{2}{*}{\textbf{Group}} & \textbf{D-D} & \textbf{D-S} &\textbf{D-F} & \textbf{D-N} & \textbf{F-N} & \textbf{S-F} \\ 
& & \emph{N=5} & \emph{N=2} & \emph{N=6} & \emph{N=6} & \emph{N=2} & \emph{N=6} \\ \hline
\multirow{3}{*}{Prototypical Network}      & \emph{K=~~5} & 30.03&63.27 &31.35 &33.95 & 54.99& 26.97\\
& \emph{K=10} & 31.68& 67.22&34.09 &36.27 &56.78 &29.18 \\
& \emph{K=15} & 33.80& 70.29&34.57 &37.41 &57.03 &29.72 \\ \hline
\multirow{3}{*}{MLMAN}      & \emph{K=~~5} &31.22 &60.58 &44.97 &47.11 &61.04 &44.78 \\ 
&\emph{K=10} & 36.66&64.96 &49.44 &52.49 &66.68 &50.57 \\
& \emph{K=15} & 40.65&68.14 &52.44 &56.00 &70.32 &53.13 \\ \hline \hline
\multirow{3}{*}{MLMAN+D$_{(ours)}$}      & \emph{K=~~5} &36.05 & \textbf{64.98}& 45.24&50.03 &61.34 & 46.82\\ 
& \emph{K=10} &42.04 & \textbf{70.02}& \textbf{50.83} &54.85 &67.57 &52.47 \\ 
& \emph{K=15} & 46.55& 71.95&54.18 &58.19 &72.01 &55.28 \\  \hline
\multirow{3}{*}{MME$_{(ours)}$}      & \emph{K=~~5} &33.48 &62.34 & 44.93&49.49 &62.40 &45.90 \\ 
& \emph{K=10} &38.89 & 67.30& 50.09& 54.09&68.39 &50.77 \\ 
& \emph{K=15} &43.05 & 69.41&53.82 &57.23 &72.02 & 52.87\\ \hline
\multirow{3}{*}{MME+D$_{(ours)}$}      & \emph{K=~~5} &\textbf{38.17} &64.68 & \textbf{45.32}& \textbf{51.30}& \textbf{64.24}& \textbf{48.34} \\
& \emph{K=10} &\textbf{44.89} &69.93 & 50.75& \textbf{56.60}& \textbf{70.79} &\textbf{53.69} \\ 
& \emph{K=15} &\textbf{49.23} & \textbf{72.41}& \textbf{54.25}& \textbf{59.67}& \textbf{74.58}& \textbf{56.67} \\ \hline
\end{tabular}
\caption{Classification accuracy(\%) on FRM dataset under N way K shot configuration.D, S, F and N stand for Disease, Symptom, Food and Nutrient respectively.}
\label{FRMresult}
\end{table*}

\begin{table*}[ht]
\centering
\small
\begin{tabular}{|l|c|c|c|c|}
\hline \textbf{Method} & \textbf{5 Way 1 Shot} & \textbf{5 Way 5 Shot} & \textbf{10 Way 1 Shot} & \textbf{10 Way 5 Shot}\\ \hline
%Matching the Blanks & $93.86 \pm 0.08$ & $97.06 \pm 0.04$ & $89.20 \pm 0.13$ &  $94.27 \pm 0.07$\\ \hline
Meta Network & $64.49 \pm 0.54$ & $80.57 \pm 0.48$ & $53.96 \pm 0.56$ & $69.23 \pm 0.52$ \\ 
GNN & $66.23 \pm 0.75$ & $81.28 \pm 0.62$ & $46.27 \pm 0.80$ & $64.02 \pm 0.77$ \\ 
SNAIL & $67.29 \pm 0.26$ & $79.40 \pm 0.22$ & $53.28 \pm 0.27$ & $68.33 \pm 0.26$ \\ 
Prototypical Network & $69.20 \pm 0.20$ & $84.79 \pm 0.16$ & $56.44 \pm 0.22$ & $75.55 \pm 0.19$ \\ 
Proto-HATT & - - & $90.12 \pm 0.04$ & - - & $83.05 \pm 0.05$ \\ 
MLMAN & $82.98 \pm 0.20$ & $92.66 \pm 0.09$ & $73.59 \pm 0.26$ & $87.29 \pm 0.15$  \\  \hline
MME$_(ours)$& & & & \\ \hline
\end{tabular}
\caption{Classification accuracy(\%) on FewRel test set.}
\label{FewReltest}
\end{table*}

\begin{table*}[ht]
\centering
\small
\begin{tabular}{|l|c|c|c|c|c|}
\hline
\multirow{2}{*}{\textbf{Method}} & \multirow{2}{*}{\textbf{(N,K)}} & \multicolumn{4}{c|}{\textbf{Training set size(\#cls, \#inst per cls)}} \\ \cline{3-6}
& & (100,30) & (50,20) & (30,15) & (10,10) \\ \hline
\multirow{4}{*}{MLMAN} & (~~5,1) &69.98 &69.69 &64.63 &57.70 \\
& (~~5,5) &84.40 &83.64 & 79.71&72.62 \\
& (10,1) &57.96 &56.48 & 50.60&43.61 \\
& (10,5) &74.51 &72.42 & 67.52&58.62 \\ \hline \hline
\multirow{4}{*}{MLMAN+D$_{(ours)}$} & (~~5,1) &\textbf{72.97} & 68.36& 66.97&\textbf{67.22} \\
& (~~5,5) &86.41 &83.98 & 83.05&81.39 \\
& (10,1) &61.32 & 55.82& 53.45&\textbf{53.74} \\
& (10,5) &76.27 & 72.48&71.05 &70.26 \\ \hline
\multirow{4}{*}{MME$_{(ours)}$} & (~~5,1) & 72.92& 70.58&65.24 &59.15 \\
& (~~5,5) & 86.26& 83.71&80.20 & 74.71\\
& (10,1) &\textbf{61.55} & 58.49&51.42 & 44.45\\
& (10,5) & 76.45& 73.64&67.93 & 61.20\\ \hline
\multirow{4}{*}{MME+D$_{(ours)}$} & (~~5,1) &72.89 &\textbf{72.45} & \textbf{68.84} &66.49 \\
& (~~5,5) & \textbf{86.49} & \textbf{85.92}& \textbf{84.21} &\textbf{81.87} \\
& (10,1) &61.16 &\textbf{60.00} & \textbf{56.02} &53.19 \\
& (10,5) &\textbf{76.64} & \textbf{76.00}& \textbf{73.55} &\textbf{70.31} \\ \hline
\end{tabular}
\caption{Classification accuracy(\%) on FewRel validation set under N way K shot configuration.}
\label{FewRelval}
\end{table*}

Table \ref{FRMresult} shows the experimental results on the FRM dataset. Prototypical network is first proposed by \citet{proto} for image classification. Multi-Level Matching and Aggregation Network (MLMAN) \citep{ye-ling-2019-multi} is the state-of-the-art light model on the FewRel dataset. From Table \ref{FRMresult} we can see our proposed MME framework outperform all the baselines. We claim that our MME framework is especially suitable for solving \emph{hard tasks}.
The test group \emph{DISEASE-DISEASE} is \emph{hard} because the test relations in this group are quite different from others. Group \emph{SYMPTOM-FOOD} is relatively easier because other groups like \emph{DISEASE-FOOD} contains similar relations. For easier tasks, only extracting lexical shallow knowledge may contribute to a good performance. But for hard tasks, only digging deep underlying knowledge can a model achieve good results. Experimental results show our proposed MME framework helps with digging deep information of training data.

Table \ref{FewReltest} shows the experimental results of light models on the FewRel dataset. High consumption models like matching the blanks \citep{baldini-soares-etal-2019-matching} achieve high performance but is incomparable since it is trained based on mass data.  The results of prototypical network \citep{proto}, SNAIL \citep{snail}, GNN \citep{gnn} and meta network \citep{metanet} are reported in \citep{han-etal-2018-fewrel}. Proto-HATT \citep{hatt} reinforced the prototypical networks with hybrid attention mechanism. Our MME framework achieves competitive results on the FewRel dataset among the light models.

To show the ability of MME to work on extremely few data, for further experiments, we shrink the training set size of the FewRel dataset and conduct experiments on the FewRel validation set. As is shown in Table \ref{FewRelval}, our model beats the baseline models when limited training data is given, illustrating that our model can extract more deep information with limited data.

%
%\begin{table*}[h]
%\centering
%\begin{tabular}{|l|cccc|cccc|cccc|cccc|cccc|cccc|}
%\hline
%\multirow{2}{*}{\textbf{Method}} & \multicolumn{4}{c}{\textbf{D-D(5)}} & \multicolumn{4}{c}{\textbf{D-S(2)}} & \multicolumn{4}{c}{\textbf{D-F(6)}} & \multicolumn{4}{c}{\textbf{D-N(6)}} & \multicolumn{4}{c}{\textbf{F-N(2)}} & \multicolumn{4}{c}{\textbf{S-F(6)}} \\ \hline
% & 1 & 5 & 10 & 15 &1 & 5 & 10 & 15 & 1 & 5 & 10 & 15 & 1 & 5 & 10 & 15 & 1 & 5 & 10 & 15 & 1 & 5 & 10 & 15 \\ \hline
%Proto(CNN)              & & & &33.80 & & & &71.88 & & & &34.57 & & & &37.41 & & & &57.03 & & & &29.72 \\ \hline
%MLMAN                   & & & &39.80 & & & &67.44 & & & &51.88 & & & &55.27 & & & &70.17 & & & &53.42 \\ \hline
%MLMAN+data              & & & &46.44 & & & &71.51 & & & &53.93 & & & &57.79 & & & &71.54 & & & &55.49 \\ \hline
%MLMAN+classifier        & & & &43.14 & & & &68.67 & & & &54.10 & & & &57.17 & & & &72.73 & & & &53.56 \\ \hline
%MLMAN+data+classifier   & & & &50.33 & & & &76.20 & & & &55.91 & & & &56.46 & & & &71.44 & & & &52.72 \\ \hline
%\end{tabular}
%\caption{Health dataset(15shot)}
%\end{table*}

%\begin{table*}[h]
%\centering
%\begin{tabular}{|l|cccc|cccc|cccc|cccc|cccc|cccc|}
%\hline
%\multirow{2}{*}{\textbf{Method}} & \multicolumn{4}{c}{\textbf{D-D(5)}} & \multicolumn{4}{c}{\textbf{D-S(2)}} & \multicolumn{4}{c}{\textbf{D-F(6)}} & \multicolumn{4}{c}{\textbf{D-N(6)}} & \multicolumn{4}{c}{\textbf{F-N(2)}} & \multicolumn{4}{c}{\textbf{S-F(6)}} \\ \hline
%                        & 1   &   5 & 10  &   15 &   1 &   5 &  10 &   15 &   1 &   5 & 10  &   15 &   1 &   5 &  10 &   15 &   1 &   5 &  10 &   15 &   1 &   5 &  10 & 15 \\ \hline
%Proto(CNN)              &24.30&30.03&31.68&33.80 &59.70&65.27&67.22&70.29 &24.06&31.35&34.09&34.57 &25.64&33.95&36.27&37.41 &50.95&54.99&56.78&57.03 &21.66&26.97&29.18&29.72 \\ \hline
%MLMAN                   &24.14&31.22&36.66&40.65 &54.90&60.58&64.96&68.14 &33.10&44.97&49.44&52.44 &36.42&47.11&52.49&56.00 &53.89&61.04&66.68&70.32 &34.12&44.78&50.57&53.13 \\ \hline
%MLMAN+data              &26.62&36.05&42.04&46.55 &57.04&64.98&70.02&71.95 &48.78&45.24&50.83&54.18 &37.65&50.03&54.85&58.19 &52.37&61.34&67.57&72.01 &33.14&46.82&52.47&55.28 \\ \hline
%MLMAN+classifier        &25.56&33.48&38.89&43.05 &54.65&62.34&67.30&69.41 &31.88&44.93&50.09&53.82 &38.17&49.49&54.09&57.23 &53.57&62.40&68.39&72.02 &34.13&45.90&50.77&52.87 \\ \hline
%pretrainon classifier   &27.37&38.17&44.89&49.23 &56.09&64.68&69.93&72.41 &30.02&45.32&50.75&54.25 &38.05&51.30&56.60&59.67 &53.92&64.24&70.79&74.58 &33.70&48.34&53.69&56.67 \\ \hline
%\end{tabular}
%\caption{Health dataset(15shot)}
%\end{table*}


%\begin{table*}[h]
%\centering
%\begin{tabular}{|l|c|c|c|c|c|}
%\hline \textbf{Method} & full & 100sen30cls & 50sen20cls & 30sen15cls & 10sen10cls \\ \hline
%MLMAN & & 70.03-84.98-58.25-74.51 & 70.08-84.43-56.48-72.44 & 64.63-79.71-51.17-67.52 & 57.70-73.26-43.61-58.62 \\ \hline
%MLMAN+data & & 72.97-86.41-61.32-76.27 & 68.36-83.98-55.82-72.48 & 66.97-83.05-53.45-71.05 & 67.22-81.87-54.04-70.26 \\ \hline
%MLMAN+classifier & & 73.11-86.26-64.96-76.81 & 70.58-83.71-58.49-73.64 & 65.24-80.20-51.42-67.93 & 59.15-74.71-44.45-61.20\\ \hline
%MLMAN+data+classifier & & 72.59-86.58-60.34-76.39 & 69.66-84.38-58.00-74.30 & 68.40-83.28-55.71-71.58 & 66.39-81.43-53.62-69.90\\ \hline
%MLMAN+data+classifier & & 72.45-86.49-61.16-76.64 & 72.45-85.92-60.00-76.00 & 68.84-84.21-56.02-73.55 & 66.49-81.87-53.19-70.31\\ \hline
%\end{tabular}
%\caption{FewRel validation set(5 way 5 shot)  51 55 101 105}
%\end{table*}

