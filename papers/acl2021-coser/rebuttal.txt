## review 1

### Core Review

This paper proposes an energy-based model for abductive language generation, where the task is to place a hypothesis to chain together two observations. 
The proposed method contains three stages: 1) initial model training, 2) EBM training, 3) desired model training. After the three steps of training, the model is able to 
generate a hypothesis more coherent and reasonable under abductive reasoning.
However, this paper is really hard to follow, mostly because it's a short paper. I think the paper should be extended to a long format to address my following concerns.

1. In line 170, what is \hat{\mu}? is this something predicted by a model or something generated by an evaluation script?
2. IN line 202, is \hat{\mu} a fixed number or an optimizable number? It only makes sense if it's a fixed number, then you are doing regression. 
Then what is the dimension of \lambda? How many samples are you using to perform this regression? How is the variance?
3. The "desired optimal ...", what is \pi_{\theta}, do you mean the generation model? So you basically have two generation models, one is a(x), one is the \pi, is that the case?
4. Equation (2) is somewhat not intuitive, I'm familiar with EBM discussed by Yann in http://yann.lecun.com/exdb/publis/pdf/lecun-06.pdf. 
The EBM is the family of distribution maximizing the entropy under certain moment-constraints. It has a rigorous form of p(x) = e^{E{x}}/Z. 
Why do you add a(x) in the front? How do you justify your design?
5. Equation (5) is the most confusing part. I tried to derive the formula by myself, it seems that D_{KL} = -log(z)/z + 1/z * E_{x ~ q} \hat{P}/q log (\hat{P}/q). 
While your equation doesn't show the 1/Z in your first component, and you use P instead of \hat{P}. I thought the normalized P is not computable, right? 
Could you please verify this part as well?

Honestly, I don't have too much idea about how the ART score is computed, the paper should be self-contained and explain the ART score with some paragraphs.

Your proposed model seems not restrictive to abductive generation, it seems more like a principled approach to tackle any generation problem with an explicit 
discriminator doing the evaluation job. It would be great if you could extend your approach to other problems as well.

The experimental results are too coarse, which did not ablate each part of Algorithm 1. What do the three stages play in the final results? 
What if I remove some of them, will the performance drop significantly?

### Reasons to Accept

The proposed method uses EBM model to connect the generator and discriminator, which seems like a novel design. 
Algorithm1 seems to implement well their methodology, with no simplification involved. The experimental results on ARTScore are quite good.

### Reasons to Reject

I have listed enough reasons above. The proposed method seems novel and well justified, I appreciate its connection to EBM. But the paper is simply way too short, 
it's impossible to follow the details and justify the results. I would suggest the author extend it to a longer format and perform more experiments on other generation tasks. 
I would definitely vote for acceptance if the author could elucidate the framework clearly.

### Overall recommendation: 2.5

# ------------------------------------ Response to Review # 1 --------------------------------------------- #

1. It is a score output by a discriminator model. We gave the definition of ART score from line 147-149 and how it is computed from line 182-188.
2. I think you mean \bar{\mu}, then it is a fixed number. In this paper, the dimension is 1, which means we only use one discriminator model. The sampling number is
20000 following Khalifa et al.(ICLR2021). 
3. We tried to approximate the "desired optimal model" by the policy model \pi_{\theta}, while a(x) is the initial generation model fine-tuned on the aNLG dataset.
If we use a vanilla generation model, the training would be much more slower.
4-5: The rigorous form you mentioned is a general form of EBM, we need to adapt it to the generation tasks in this paper. For the feasibility and correctness of this
adaption and your concern about equation (5), you can refer to Khalifa's work(https://arxiv.org/abs/2012.11635) for detailed verification.

The three-stage training is integrated, we cannot remove any one of the stages. However, we can change the choice of initial model and the discriminator model used in
these stages. We have compared different combination in line 306-307 308-309 in Table 1.

Our main motivation is to address abductive natural language generation task in a teacher-student setting, which we believe would bring more interpretability.
Khalifa's work showed us a promising direction, though they only focused on controlling the sentiment of comments or the sexuality of generated bibliography.
We tried to adapt their algorithm to more challenging task, like aNLG, and show preliminary effectiveness in this paper. 
In Khalifa's work, the discriminator is very simple, i.e., judging whether specific word appears in
the text or the sentiment of the comments. While in our work, the discriminator needs to judge whether the hypothesis fits the context well. Therefore to adapt this method 
to other generation task, a well-defined and good enough discriminator is critical. This observations can also be approved by Table 2.

@ ----------------------------------------------------------------------------------------------------------- @

## review 2

### Core review

The paper focuses on Abductive Commonsense Reasoning (ART), which is a new nlp task proposed in 2020, and proposes a new model for the task.
The architecture of the model in this paper is complicated. The author spends a lot of space on the details of the model, but does not discuss the 
design philosophy and motivation of the model. This makes it difficult for readers to learn knowledge from the paper and apply it to their own tasks.

The experiments of this paper show that the proposed model achieves good results. But the results of the baseline model (Table 1) given in the paper seem 
to have problems. According to the description of Table 1, some of the data in Table 1 come from Bha's paper i.e. Bhagavatula et al. (2020), but the author 
seems to have mistaken the correspondence between model names and scores in Bha's paper. In addition, for this task, Bert-score is an important evaluation 
metric (which is also reported in Bha's paper with other metrics like Bleu, Rouge, etc); why this paper does not report the original Bert-score but using other 
similar metrics (i.e. RoBERTa, L2R2, DeBERTa scores)?

### Reasons to Accept

This proposes an energy-based model architecture for the Abductive Commonsense Reasoning task and achieves good results.

### Reasons to Reject

This article is not easy to follow. The main reason is that the author has used a lot of words to introduce the implementation details 
of the model, but it is difficult to see the big picture.

### Overall recommendation: 3

# -------------------------------------- Response to Review # 2 --------------------------------------------- #

Our main motivation is to address abductive natural language generation task in a teacher-student setting, and we full-filled this idea by bring the help from recent
works from EBM and controlled text generation (mainly Khalifa ICLR 2021). Due to the limit 

We thank you for your careful check on the results of Table 1. The entry of `GPT2-fixed` should be `O1-O2-only` in Bha's paper. We will correct this typo in next edition.

BERTScore leverages the pre-trained contextual embeddings from BERT and matches words in candidate and reference sentences by cosine similarity. Essentially it is still
a metric to evalute the closeness between generated and reference text. We think that BLEU-4, METEOR, ROUGE-L and CIDEr is enough for evaluation. The baseline model (Ji et al. EMNLP 19)
didn't report this metric, either.

ARTScore is different from BERTScore, the definition can be found in line 147-149, 182-188. It measures how well the generated hypothesis fits into the context according to
the aNLG task definition itself. Since a well-fit hypothesis doesn't necessary have lots of overlap with the references, we think this metric is a good complement for traditional scores.

@ ------------------------------------------------------------------------------------------------------------ @

## review 3

### Core Review

This paper addresses the task of abductive natural language generation, where a model generates plausible hypotheses based on the given observations. The main idea of the paper is to improve 
the generated hypotheses regarding the coherency and consistency, measured by an NLI model. It uses a model finetuned on abductive NLI task as part of the energy-based model(EBM), 
and uses the representation(or score) from the EMB to train another language model through reinforcement learning.

Strengths:

Applied the latest controlled text generation technics on the task of abductive reasoning.
Tested multiple combinations of pretrained models, as the NLI scorer and generator respectively
Included some side discovery, such as the effect of the teacher model, and a human evaluation

Weakness:

The writing of the method part relies too heavily on sections 2.2 and 2.3 from "A DISTRIBUTIONAL APPROACH TO CONTROLLED TEXT GENERATION".
No statistical significance was reported, nor do the reader know if the results are from multiple trials and robust to randomness. No qualitative analysis on the generated samples.
The method uses NLI datasets during the training. When evaluated with an NLI classifier as a scorer, it seems to be unfair regardless of the network structure of the classifier.

### Reasons to Accept

This paper applies the latest (ICLR 2021) controlled text generation technics on abductive text generation tasks. It has done comprehensive experiments covering 
a range of popular language models. It is shown to be effective by the scorers trained for the NLI task, and by human evaluation.

### Reasons to Reject

The motivation of some design choices is not well explained, such as why choosing EMB to infuse the prior knowledge from NLI models. No statistical significance was reported, nor do 
the reader know if the results are from multiple trials and robust to randomness. It also lacks qualitative analysis or showcase of the generated output. The method part is 
poorly organized with possible plagiarism.

### Overall recommendation: 2.5

# ------------------------------------------------ Response to Review 3 ------------------------------------------------------ #

We appreciate for your concerns about the statistical significance of experiments. Though in those papers of the baseline models(Bha et al. 2019, Ji et al. 2020), they didn't
report the statistical significance either, we agree that this reports is necessary.

As for your concerns about the methods part, we think detailed illustartion is necessary since the algorithm from Khalifa et al. is complicated, and we have added reference
as required.
