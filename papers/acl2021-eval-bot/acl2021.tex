%
% File acl2021.tex
%
%% Based on the style files for EMNLP 2020, which were
%% Based on the style files for ACL 2020, which were
%% Based on the style files for ACL 2018, NAACL 2018/19, which were
%% Based on the style files for ACL-2015, with some improvements
%%  taken from the NAACL-2016 style
%% Based on the style files for ACL-2014, which were, in turn,
%% based on ACL-2013, ACL-2012, ACL-2011, ACL-2010, ACL-IJCNLP-2009,
%% EACL-2009, IJCNLP-2008...
%% Based on the style files for EACL 2006 by 
%%e.agirre@ehu.es or Sergi.Balari@uab.es
%% and that of ACL 08 by Joakim Nivre and Noah Smith
\documentclass[11pt,a4paper]{article}
\usepackage[hyperref]{acl2021}
%\hypersetup{draft}
\usepackage{times}
\usepackage{latexsym}
\usepackage{bm}
\usepackage{pifont}
\usepackage{amsmath}
\usepackage{amssymb}
%\usepackage{mathbbol}
\usepackage{amsfonts}
\usepackage{graphicx}
\usepackage{calligra}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{algorithm}
\usepackage{algorithmicx}
\usepackage{enumerate}
\usepackage{diagbox}
%\usepackage[algo2e]{algorithm2e} 
\usepackage[noend]{algpseudocode}
\usepackage[title]{appendix}
\usepackage[normalem]{ulem}
\usepackage{multirow}
\useunder{\uline}{\ul}{}
\renewcommand{\UrlFont}{\ttfamily\small}
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}
\usepackage{color}
\usepackage{tabu}
\newcommand{\JQ}[1]{\textcolor{green}{JQ: #1}}
% This is not strictly necessary, and may be commented out,
% but it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

%\aclfinalcopy % Uncomment this line for the final submission
%\def\aclpaperid{***} %  Enter the acl Paper ID here

%\setlength\titlebox{5cm}
% You can expand the titlebox if you need extra space
% to show all the authors. Please do not make the titlebox
% smaller than 5cm (the original size); we will check this
% in the camera-ready version and ask you to change it back.
\newcommand{\ssecref}[1]{Section \ref{#1}}
\newcommand{\secref}[1]{Section \ref{#1}}
\newcommand{\figref}[1]{Figure \ref{#1}}
\newcommand{\eqnref}[1]{Eq. (\ref{#1})}
\newcommand{\tabref}[1]{Table \ref{#1}}
\newcommand{\algoref}[1]{Algorithm~\ref{#1}}
\newcommand{\KZ}[1]{\textcolor{blue}{Kenny: #1}}

\newcommand\BibTeX{B\textsc{ib}\TeX}

\title{ChatMatch: Evaluating Chatbots by Autonomous Chat Tournaments}

\author{First Author \\
  Affiliation / Address line 1 \\
  Affiliation / Address line 2 \\
  Affiliation / Address line 3 \\
  \texttt{email@domain} \\\And
  Second Author \\
  Affiliation / Address line 1 \\
  Affiliation / Address line 2 \\
  Affiliation / Address line 3 \\
  \texttt{email@domain} \\}

\date{}

\begin{document}
\maketitle
\begin{abstract}
%One tough problem that still exists in conversational dialogue system is that there is no efficient, automatic and unified evaluation metric which reflects the real “ability” of a dialogue system.  Common automatic evaluation metrics always show poor correlation with human judgments. Human evaluation metrics seem more reliable than automatic metrics but is much more costly and time-consuming.

Existing automatic evaluation systems of chatbots mostly rely on static chat 
scripts as ground truth, which is expensive to craft and can evaluate only one turn
at a time. Interactive evaluation mitigates this problem but requires human
involvement. In our work, we propose an interactive chatbot evaluation framework 
in which chatbots compete with each other like in sports tournaments. This protocol
can efficiently rank any number of bots from any perspectives or in any domains. 
\end{abstract}

\input{introduction}
\input{approach}
\input{experiment}
\input{related}
\input{conclude}







\bibliographystyle{acl_natbib}
\bibliography{acl2021}

%\appendix



\end{document}
