============================================================================
                            REVIEWER #1
============================================================================

The core review
---------------------------------------------------------------------------
This paper proposes a way to construct semi-structured aspects and opinions from reviews as data augmentation methods to obtain pre-training data, and proposes a dual encoder model (takes inputs of opinion aspect and implicit sentences, respectively) to obtain context for another transformer-based seq2seq model. 

Strength:
The proposed model seems to achieve state-of-the-art performance on the two datasets tested: Yelp and Amazon.

Weakness:
1. The paper is hard to understand and written in a wordy and unclear style.
2. The contribution is not clear to me. If this is about data creation for augmentation, the authors did not release any sample of the semi-structured data they created. The data folder only has the model's output. I fail to access how much better it is compared to the previous data augmentation techniques commonly used.  
If the contribution is about the MB model (Training MAI based on pre-trained BAG).  It misses the details about how these two models are added together, clearly BAI is transformer-based and MAI seem to be LSTM based. How do you make sure the fine-tuning is appropriate. The ablation study fails to tell me the difference of adding the dual encoder model and what part is helpful for such improvements.
---------------------------------------------------------------------------


Reasons to Accept
---------------------------------------------------------------------------
The proposed model seems to achieve state-of-the-art performance on the two datasets tested: Yelp and Amazon.
---------------------------------------------------------------------------


Reasons to Reject
---------------------------------------------------------------------------
1. The paper is hard to understand and written in a wordy and unclear style.
2. The contribution is not clear to me. If this is about data creation for augmentation, the authors did not release any sample of the semi-structured data they created. The data folder only has the model's output. I fail to access how much better it is compared to the previous data augmentation techniques commonly used.  
If the contribution is about the MB model (Training MAI based on pre-trained BAG).  It misses the details about how these two models are added together, clearly BAI is transformer-based and MAI seem to be LSTM based. How do you make sure the fine-tuning is appropriate. The ablation study fails to tell me the difference of adding the dual encoder model and what part is helpful for such improvements.
---------------------------------------------------------------------------


---------------------------------------------------------------------------
Reviewer's Scores
---------------------------------------------------------------------------
                  Overall Recommendation: 2

Typos, Grammar, Style, and Presentation Improvements
---------------------------------------------------------------------------
typo line 87: treat them are summaries.  -》 treat them as summaries.
---------------------------------------------------------------------------



============================================================================
                            REVIEWER #2
============================================================================

The core review
---------------------------------------------------------------------------
In this paper, the authors observe that the leave-one-one multi-review objective has a downside of having an irrelevant target review.  They create a syntactic training dataset by first sampling a review as a pseudo-summary and then considering opinion-aspect pairs when producing input for the summary. They also propose a model adjustment to be more inline with opinion-aspects. They proposed methods yield improvements on Yelp and Amazon datasets. 

Overall:

- Poorly written, very hard to follow
- The syntactic dataset creation is not novel
- Model is not novel, just a minor adjustment to the known architecture
---------------------------------------------------------------------------


Reasons to Accept
---------------------------------------------------------------------------
I don’t think there are reasons to accept this work, as overall it lacks novelty and is substantially below the average quality of an ACL paper.
---------------------------------------------------------------------------


Reasons to Reject
---------------------------------------------------------------------------
- Poorly written, very hard to follow
- The syntactic dataset creation is not novel
- Model is not novel, just a minor adjustment to the known architecture
---------------------------------------------------------------------------


---------------------------------------------------------------------------
Reviewer's Scores
---------------------------------------------------------------------------
                  Overall Recommendation: 1


============================================================================
                            REVIEWER #3
============================================================================

The core review
---------------------------------------------------------------------------
This paper proposes a new method for abstractive opinion summarization that involves two components. First, a new approach for the creation of a synthetic summarization dataset that builds upon recent similar approaches for the task. Secondly, a summarization model that can be trained on the synthetic data, and latter used for the summarization of real reviews.

For the syntetic dataset creation, the authors propose to use a randomly sampled review as a pseudo-summary, similar to previous work. The novelty is on the creation of a set of input reviews for each pseudo-summary. The authors use two noising techniques to construct such reviews: 

i) opinion-aspect pair noising, which adds noisy opinion-aspect pairs to the input reviews, according to the content of the pseudo-summary
ii) implicit sentence noising, which adds sentences that don't explicitly mention an opinion about an aspect.

The authors claim that this creates a more realistic synthetic corpus for summarization training. The synthetic data are then used to train a set of model variants that demonstrate increasing complexity in the way they encode the opinion-aspect and implicit sentence information.

In their experimental sectoin, the authors demontrate that their method achieves better performance (according to ROUGE) compared to existing approaches. An ablation study shows the performance of different variation of their approach.

Overall, the paper further explores and develops ideas that have originated in previous work about synthetic dataset creation for the task of opinion summarization. Although some of the ideas are interesting and their evaluation shows improved summarization performance, the paper suffers from its confusing writing. The argumentation and methodology is at times very hard to follow, and the writing quality is not up to ACL's standards at the moment.

Strengths:
 - Further exploration into synthetic dataset creation for opinion summarization
 - Good results
 
Weaknesses:
 - Subpar writing which makes it hard for the reader to follow the methodology used, especially in part 2.1 about synthetic dataset creation
 - No proper justification about parts of their approach
 - No Evidence shown about the synthetic data created, especially the use of opinion-aspect vs. implicit sentences which is novel
---------------------------------------------------------------------------


Reasons to Accept
---------------------------------------------------------------------------
1) Very relevant to the recent reseach work being published in the field
2) Good results
---------------------------------------------------------------------------


Reasons to Reject
---------------------------------------------------------------------------
1) Poorly written and presented, the paper is at times very hard to follow and doesn't meet the ACL standards.
---------------------------------------------------------------------------


---------------------------------------------------------------------------
Reviewer's Scores
---------------------------------------------------------------------------
                  Overall Recommendation: 2

Questions for the Author(s)
---------------------------------------------------------------------------
1) Your title mention weak supervision, but there is no further mention of weak supervision in the text. Which part of the model is weakly supervised and in which way?

2) Are synthetic multi-reviews created from scratch, or are OAs and ISs added to existing reviews? It is very hard to follow that part of your methodology
---------------------------------------------------------------------------

