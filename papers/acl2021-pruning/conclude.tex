\section{Conclusion}
We apply network pruning, a novel approach to explore the latent 
relational knowledge hidden in PLMs. With a preliminary focus on  
commonsense knowledge, we find evidence of latent sparse subnetworks 
capable of representing grounded commonsense relations in a 
plethora of PLMs. Further experiments on downstream tasks showed 
that such subnetworks can be effectively utilized as auspicious neural knowledge bases, fine-tuning 
starting points, and robust zero-shot reasoners. Our work raises a new viewpoint 
about the inner storage scheme as well as practical utilization of relational knowledge in PLMs, opening up avenues to future work on better understanding and adapting pretrained language representations.
%This study explores the latent commonsense knowledge in PLMs by opening up new possibilities for distilling ``more'' knowledge from ``less'' parameters. Our findings confirm the conjecture that varied relational knowledge is blended in one shared parameter space due to mini-batch-based optimization during pretraining, and it is feasible to perform unstructured weights pruning upon PLMs to recover the latent subnetwork ad hoc.
%
%To examine the practical utility of these softly disentangled subnetworks on knowledge-intensive tasks, we additionally conducted a suite of experiments. The results show that: (i)~given enough supervision, choosing the ``right'' subnetwork ensembling makes it a good prior for better fine-tuning. (ii)~subnetworks exhibit notably superior performance than their full-scale counterparts under zero-shot setting, including commonsense reasoning and knowledge base completion.
%


%Future work includes applying the proposed procedure to other relational knowledge upon PLMs trained with more advanced objectives and structure. Exploring pretrained auto-regressive  models remains another promising research direction. 

