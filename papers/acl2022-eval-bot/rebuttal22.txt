Many thanks to the reviewers comments and suggestions. And thank you, senior area chair, for reading our responses.

1. First, we would like to clarify two factual errors made by the meta reviewer Area Chair DD9g, who seems to have merely summarized the reviews without validating them from our paper. 

1) "No code attached". 
Reviewer VLY4 complained “the paper does not mention any plans to open-source any of its implementations,” while Area Chair DD9g in the meta review claimed one of the limitations of our paper is that “there is no code in the supplementary material”. Both of these claims were wrong as we have attached our source code of the full implementation in a zip file to the ARR submission system, and plan to open-source both the code and data. Contrary to these claims, the other two reviewers both acknowledged that the software we provided was useful for further research. 

2) “Limited evaluation on DailyDialog dataset”. 
Area Chair DD9g remarked in the meta review that “The authors evaluate the bot generation on only the DailyDialog dataset, while a much large number of datasets are available for evaluation”. This was a gross misunderstanding of our work, since the proposed chatmatch framework evaluates chatbots not on any particular datasets but through automatic interactions among the bots themselves. We only use the DailyDialog dataset to show how the traditional script-based baseline evaluation approaches work.

2. Despite the borderline assessment given by Reviewer VLY4, most of their negative comments were minor: such as the use of acronyms for bots and baseline methods, and the styles of tables and figures. These comments can be easily addressed by making minor changes to the text. Finally, their comment that "the tournament needs to be re-run from scratch every time a scoring function is changed or a new bot is to be evaluated" is *not* true, because: a) the scoring is done on the chat log created by the bots' conversation, so a new scoring function can be applied on previously recorded chat logs; b) if a new bot needs to be evaluated, it only needs to chat with all the existing bots, while those existing bots do not need to chat with each other anymore. In either case, it is not a re-run at all.


