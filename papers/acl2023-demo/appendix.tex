\section{Training Parameters for the Experiments}

Table \ref{tbl:Params} details the parameters used to train the GPT2 model described in Section \ref{sec:approach}. Note that the main difference between vanilla finetuning and causal language modeling is the tokens counted in the loss, but the loss function remains the same.

\begin{table}[h]
\begin{center} 
\begin{tabular}{lcc}  
	\toprule  %\vspace{-1mm}
	 Parameter &  \\
	\midrule 
     Optimizer & AdamW  \\ 
     Learning rate & 5e-5\\ 
     Weight decay & 1e-2\\ 
     Loss function & CrossEntropy \\
     Epochs & 4 \\
     GPU & yes \\
	%\bottomrule
\end{tabular}
\caption{\label{tbl:Params} Training Parameters for the GPT2 model}
\end{center}
\end{table}
