% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}

% Remove the "review" option to generate the final version.
\usepackage{acl2023}
% Standard package includes
\usepackage{times}
\usepackage{latexsym}

% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}
\usepackage{natbib}  % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
\usepackage{caption} 
% This is not strictly necessary, and may be commented out,
% but it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{graphicx}
\usepackage{multirow,array}
\usepackage{bm}
\usepackage{bbm}
\usepackage{algorithm,algorithmicx}
% \usepackage{algorithmic}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{verbatim}
\usepackage{booktabs}
\usepackage{amsfonts,amssymb} 
\usepackage[noend]{algpseudocode}
\newcommand{\minitab}[2][l]{\begin{tabular}{#1}#2\end{tabular}}


\newcommand{\secref}[1]{Section \ref{#1}}
\newcommand{\figref}[1]{Figure \ref{#1}}
\newcommand{\eqnref}[1]{Eq. (\ref{#1})}
\newcommand{\tabref}[1]{Table \ref{#1}}
\newcommand{\exref}[1]{Example \ref{#1}}
\newcommand{\KZ}[1]{\textcolor{blue}{Kenny: #1}}


% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.

\title{Pruning  Pre-trained Language Models with Principled Importance and Self-regularization}

% Author information can be set in various styles:
% For several authors from the same institution:
\author{Siyu Ren \hspace*{1cm} Kenny Q. Zhu\textsuperscript{\rm}\thanks{\hspace{2mm}The corresponding author.}\\
	Shanghai Jiao Tong University\\
	Shanghai, China\\
	roy0702@sjtu.edu.cn, kzhu@cs.sjtu.edu.cn}
% if the names do not fit well on one line use
%         Author 1 \\ {\bf Author 2} \\ ... \\ {\bf Author n} \\
% For authors from different institutions:
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \And  ... \And
%         Author n \\ Address line \\ ... \\ Address line}
% To start a seperate ``row'' of authors use \AND, as in
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \AND
%         Author 2 \\ Address line \\ ... \\ Address line \And
%         Author 3 \\ Address line \\ ... \\ Address line}

%\author{Siyu Ren \\
%	Affiliation / Address line 1 \\
%	Affiliation / Address line 2 \\
%	Affiliation / Address line 3 \\
%	\texttt{email@domain} \\\And
%	Kenny Q. Zhu \\
%	Affiliation / Address line 1 \\
%	Affiliation / Address line 2 \\
%	Affiliation / Address line 3 \\
%	\texttt{email@domain} \\}

\begin{document}
	\maketitle
	\begin{abstract}
		 
Iterative pruning is one of the most effective compression methods for pre-trained language models. We discovered that finding the optimal pruning decision is an equality-constrained 0-1 Integer Linear Programming problem. 
The solution to this optimization problem leads to a principled importance criterion which we use to rank parameters during iterative model pruning.
To mitigate the poor generalization at high sparsity levels, we propose a self-regularization scheme 
where model prediction is regularized by the latest checkpoint with 
increasing sparsity throughout pruning. 
Our experiments on natural language understanding, 
question answering, named entity recognition, and data-to-text generation 
with various Transformer-based PLMs show the
effectiveness of the approach at various sparsity levels.
	\end{abstract}
	
	% Entries for the entire Anthology, followed by custom entries
	% \bibliography{anthology,custom}
	
%	
	\input{intro}
	\input{related}
	\input{method}
	\input{experiment}
	\input{conclusion}

%	\input{limitations}
\section*{Acknowledgments}
This work was generously supported by the CMB Credit Card Center \& SJTU
joint research grant, and Meituan-SJTU joint research grant.

	\bibliography{acl2023}
	\bibliographystyle{acl_natbib}
	\newpage
	\appendix
\input{appendix_final}
%	\clearpage
%	\input{appendix}
\end{document}
