\section{Background}

\subsection{Speaker Name Sensitivity}
\label{sec:problem}

\textit{speaker name sensitivity} is the differences in the generations by a model, given the 
identical dialogues except for different speaker names. We define it as follows.
%We setup the problem specifically as follows. %the same dialogue utterances

%We first define the speaker name sensitivity of a model on a sample as follows:

Let $d$ denote the input dialogue. $c$ denotes other input content, which can be empty for tasks like dialogue summarization, or a piece of text such as a question for reading comprehension. $p$ refers to the set of speakers names in $d$. $f$ is a one-to-one mapping which maps $p$ into a set of names $p'$ from a name pool $\mathcal{P}$ consisting of a set of candidate names to be substituted into the samples. The names $p'$  are sampled under the uniform distribution without the loss of generality.
\textit{The speaker name sensitivity $SS$ of a generation model $\mathcal{M}(\cdot)$ on this sample} is:
\begin{equation}
	\label{eq:ss}
	\begin{aligned}
	SS(\mathcal{M} | d, c) = \delta(&\{\mathcal{M}(Rep(d, c | f )) \\
	&| \forall f: p\rightarrow p', p'\subseteq \mathcal{P} \})
	\end{aligned}
\end{equation}
where $Rep(\cdot)$ replaces names in the sample given $f$, i.e., from $p$ to $p'$. $\delta(\cdot)$ quantifies the differences among generations.

Then, \textit{the sensitivity $SS$ of a model $\mathcal{M}(\cdot)$} is the expectation $\mathbb{E}$ of over all samples from the real-world distribution $D$:
 \begin{equation}
 		SS(\mathcal{M}) = \mathbb{E}_{(d,c)\sim D} [ SS (\mathcal{M} | d,c) ] 
 \end{equation}

In practice, a dialogue dataset is regarded as a sampling from $D$ for evaluations.  Each sample in the dataset is provided with a reference output $o$ for supervised training. We use $D_{tr}$, $D_{va}$ and $D_{te}$ to refer to training, validation and test sets.
See detailed implementation and metrics in Sec.~\ref{sec:quatification}.



%other task-related stuff
%A dialogue dataset, consisting of input dialogue $d_i$, other input content $c_i$ and output text $o_i$, is denoted as $D=\{d_i, c_i, o_i\}_{i=1}^{N}$. $c_i$ can be empty for tasks like dialogue summarization, or a piece of text such as a question for reading comprehension.
%$d_i$ is a stream of utterances $u_i$ uttered by two or more speakers $p_i=\{p_i^j\}_{j=1}^M$. $N$ representsis the number of samples and $M$ is speaker counts. We use subscripts $tr$, $va$ and $te$ to refer to training, validation and test sets.

%For each sample, we randomly sample names from a pool of names $P$ under the uniform distribution, discard the names in $u_i$ but not in $p_i$,
%and construct $M$ one-to-one mappings to the original names, denoted as $p^\prime_i$. It should be noted that we avoid changing names mentioned during the conversation in case they are grounded entities. %Genders should be consistent in each mapping if necessary following~\citet{khalifa2021bag}. 
%Then, a new $\{d^\prime_i, c^\prime_i, o^\prime_i\}$ can be obtained by switching $p_i$ to $p^\prime_i$. Predictions are changed back for evaluation.

%Dialogue models are expected to perform identically on different switched $\{d^\prime_i, c^\prime_i, o^\prime_i\}$, and get the same scores with task-specific evaluation metrics compared with $o_i$. In a word, the speaker name sensitivity of a model can be reflected by the differences in generations or the variation of scores averaged with a number of samples from $D_{te}$(see metrics in Sec.~\ref{sec:quatification}). 
%We switch speaker names as follows.

%\begin{enumerate}[\textit{step}1:]
%	 \item Collect a pool of speaker names as $P$ which can be collected from $D_{tr}$, or other lists of names. % a list online,
%	 \item For $d_i$, we randomly sample names from $P$ under the uniform distribution, discard the names in $u_i$ but not in $p_i$,
%	  and construct a one-to-one mapping to the original names, denoted as $p^\prime_i$. We avoid changing names mentioned during the conversation in case they are grounded entities. Genders should be consistent in each mapping if necessary. %having strong correlations with the dialogue context
%	  \item A new $\{d^\prime_i, o^\prime_i\}$ can be obtained by switching $p_i$ to $p^\prime_i$. Predictions are exchanged back for evaluation.
%\end{enumerate}
%Dialogue models ar
%e expected to perform identically on $\{d_i, o_i\}$ and $\{d^\prime_i, o^\prime_i\}$ and get the same performance with task-specific evaluation metrics $\rm{Score}(\cdot)$.




