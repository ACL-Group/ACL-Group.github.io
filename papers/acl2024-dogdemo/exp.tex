\section{Evaluation}


Many factors influence the performance of our transcription system: noise present in the training data, performance degradation due to the lack of ground truth, among others. To validate whether our proposed baseline adequately transcribes canine sounds based on acoustic features, in this section, we demonstrate the performance of the baseline pipeline using our proposed canine lexical discovery system from three perspectives: phoneme, vocabulary, and transcription.



\subsection{Phoneme Evaluation}


\begin{table}[th]
\centering
\small
\begin{tabular}{lcc}
\hline
\textbf{Tester} & \textbf{dog voice label} & \textbf{total label}\\
\hline
\verb|Tester 1| & 72.0\% & 66.67\% \\
\verb|Tester 2| & 70.5\% & 64.89\% \\
% \verb|Tester 3| & AudioSep & \pmb{0.7755} \\
\verb|Agreement| & 80.5\% & 74.22\% \\\hline
\end{tabular}
\caption{Accuracy and agreement result on testing the reliability of phonemes discovery}
\label{tab:phonetestresult}
\end{table}

From an acoustic perspective, the performance of our method in phoneme discovery is reflected in the similarity of audio segments assigned to the same phoneme. We randomly selected 120 sets of audio clips from different dogs, each containing the same Phoneme, as well as 120 sets of audio clips from different dogs, each containing different Phonemes and assigned these test data to two testers after shuffling the data. Both two testers are graduate male students majoring in computer science and were tasked with annotating whether each set of audio clips belonged to the same Phoneme. The results are presented in the \tabref{tab:phonetestresult}.

The ``dog voice label'' indicates that the test data only includes canine phonemes, while the ``total label'' encompasses all 50 phonemes. ``Agreement'' refers to the proportion of pairs where the testers reached a consensus, relative to the total test data. This result suggests that with a high level of agreement between the two testers, the phoneme results are relatively accurate. Additionally, the Phonemes page of the canine lexical discovery system provides a schematic diagram of phoneme nodes and randomly selected audio examples for researchers to assess the quality of phonemes.

\subsection{Vocabulary Evaluation}

\begin{table}[th]
\centering
\small
\begin{tabular}{lccc}
\hline
& \textbf{Sentences} & \textbf{Words} & \textbf{Phonemes} \\
\hline
\verb|Pauses duration| & 873 ms & 85 ms & 39 ms  \\\hline
\verb|Length duration| & 2602 ms & 206 ms & 90 ms \\\hline
\end{tabular}
\caption{Average pauses duration time between sentences, words and phonemes in canine vocalization and average duration of sentences, words and phonemes.}
\label{tab:vs}
\end{table}

To evaluate the discovered vocabulary without ground truth for dog language words, we assessed whether a word in canine language is usually indivisible into smaller units capable of independent use from an acoustic perspective. For this purpose, we calculated the average duration of non-word phonemes on both sides of each word in sentences parsed from the training data, representing the pauses \citet{zellner1994pauses} duration for each word. Additionally, we computed the pauses duration for sentences and phonemes using the same method and the length duration of sentences, words and phonemes, as shown in the \tabref{tab:vs}. 

The pause duration on both sides of words can indirectly indicate the indivisibility of the combination of these phonemes. Furthermore, comparing sentences, we observe that for sentences with more pronounced pauses, the ratio of pause duration to length duration for words is similar to that of sentences. This confirms the reliability of the words in the vocabulary.


\subsection{Transcription Evaluation}

\begin{table}[th]
    \centering
    \small
\begin{tabular}{lcc}
    \hline
    \textbf{Tester} & \textbf{Transcription Quality}\\
    \hline
    \verb|Tester 1| & 38.57\% \\
    \verb|Tester 2| & 48.70\%  \\
    \verb|Agreement| & 68.50\% \\\hline
    \end{tabular}
    \caption{Transcription quality result on testing the reliability of transcription}
    \label{tab:tr}
    \end{table}


    In the scenario where the vocabulary is determined, the performance of the parsing algorithm directly determines the quality of the transcription. We evaluated the performance by manually judging whether each word parsed in the sentence is acoustically complete, meaning it contains a complete energy peak. Two male graduate students majoring in computer science from university were randomly assigned 100 sentences from the training dataset as testers. They were asked to determine whether each word in each sentence was acoustically complete. Finally, we calculated the proportion of complete words to the total number of words in these 100 sentences, the results are shown in the \tabref{tab:tr}.

    After go through 100 canine sentences, testers finally examine a total of 854 words, with 68.5\% agreement. The results indicate that the 
transcription quality is not high, which is consistent with the fact that 
there is still noise in the sentences even after the denoising process. 
Some of these noices were incorrectly recognized as phonemes and creep into
the transcript as words.  Nevertheless, the testers provided feedback indicating that nearly half of the words were deemed acoustically complete from the perspective of the energy plot, validating that the parsing method along with the vocabulary could reflect a portion of the true transcription results of canine language.
