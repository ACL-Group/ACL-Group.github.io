\begin{table}
    \centering
    \scriptsize
    \caption{Prompt Template of ChatGPT for predicting prison terms. $N$ denotes the number of training samples.}
    \begin{tabular}{p{0.1\textwidth}|p{0.35\textwidth}}
    \toprule
       \multirow{2}{*}{Example 1}  & Case Fact: <demo facts>\\
       & In the absence of mentioned circumstances, presumed nonexistence, based on the aforementioned facts, the judgment is:<demo label>\\
       \multirow{1}{*}{Example $\cdots$}  & Case Fact: <demo facts>\\
       & In the absence of mentioned circumstances, presumed nonexistence, based on the aforementioned facts, the judgment is:<demo label>\\
       \multirow{2}{*}{Example N}  & Case Fact: <demo facts>\\
       & In the absence of mentioned circumstances, presumed nonexistence, based on the aforementioned facts, the judgment is:<demo label>\\
       \multirow{3}{*}{Test Case}  & Case Fact: <test facts>\\
       & In the absence of mentioned circumstances, presumed nonexistence, based on the aforementioned facts, the judgment is:\rule{1cm}{0.4pt}\\
       & Please estimate a specific length of sentence, providing only a numerical conclusion.\\
       \bottomrule
    \end{tabular}
    \label{tab:gpt_input}
\end{table}

\section{Setting Details of ChatGPT for Prison Term Prediction}
\label{sec:b}

Prompt plays a crucial role when applying LLMs to a specific task. For Prison Term Prediction (PTP) task, ChatGPT may return unexpected response, such as refusing to answer and providing rough prediction. We need to avoid these responses before evaluating the performance of ChatGPT. Inspired by the idea of in-context learning, we find it helpful to incorporate some training samples into the prompt. We then iterate through several types of prompt templates and analyze the unexpected responses. Finally, we figure out a prompt template to eliminate unexpected answers from ChatGPT, which is shown in Table~\ref{tab:gpt_input}. We use the same prompt template for ChatGPT-3.5 and ChatGPT-4.

Intuitively, the straightforward prompts can be \emph{Predict imprisonment} or \emph{Give the sentence}. Given these prompts, ChatGPT would refuse to predict the imprisonment term for reasons like \textit{Providing an exact sentencing prediction without knowing the full details of a case and the specific application of legal provisions is inaccurate. In actual judicial practice, courts consider factors such as the nature of the crime, the circumstances, the degree of harm caused to the victim, and the attitude after committing the crime to determine the sentence}.

We then modify the prompt to ask ChatGPT to ignore the content not mentioned and direcly predict the imprisonment, such as \emph{If the circumstances not mentioned are considered to be non-existent, the sentence is given}. Given this prompt, ChatGPT may return a possible imprisonment range instead of a particular number. For instance, the responses could be: \textit{In the absence of any other aggravating or mitigating circumstances, the predicted sentencing might lean towards the lighter end within the range allowed by law. Therefore, a rough estimate could be imprisonment from three to seven years, with the specific sentence being determined by the judge's discretion and the specifics of the case. Please note that this is merely a speculation based on the information provided, and the actual sentence may vary.}

We analyze the ambiguous response and manage to reach the final prompt: \emph{In the absence of mentioned circumstances, presumed nonexistence, based on the aforementioned facts, the judgment is:\rule{1cm}{0.4pt}
Please estimate a specific length of sentence, providing only a numerical conclusion.}