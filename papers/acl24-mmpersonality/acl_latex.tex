% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}

% Change "review" to "final" to generate the final (sometimes called camera-ready) version.
% Change to "preprint" to generate a non-anonymous version with page numbers.
\usepackage[review]{acl}

% Standard package includes
\usepackage{times}
\usepackage{latexsym}
\usepackage{svg}
% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary, and may be commented out,
% but it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}
\newcommand{\MY}[1]{\textcolor{teal}{[MY: #1]}}
\newcommand{\KZ}[1]{\textcolor{blue}{[Kenny: #1]}}

% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.

\title{MMPD: A Multimodal Personality Dataset}

% Author information can be set in various styles:
% For several authors from the same institution:
% \author{Author 1 \and ... \and Author n \\
%         Address line \\ ... \\ Address line}
% if the names do not fit well on one line use
%         Author 1 \\ {\bf Author 2} \\ ... \\ {\bf Author n} \\
% For authors from different institutions:
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \And  ... \And
%         Author n \\ Address line \\ ... \\ Address line}
% To start a separate ``row'' of authors use \AND, as in
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \AND
%         Author 2 \\ Address line \\ ... \\ Address line \And
%         Author 3 \\ Address line \\ ... \\ Address line}

\author{First Author \\
  Affiliation / Address line 1 \\
  Affiliation / Address line 2 \\
  Affiliation / Address line 3 \\
  \texttt{email@domain} \\\And
  Second Author \\
  Affiliation / Address line 1 \\
  Affiliation / Address line 2 \\
  Affiliation / Address line 3 \\
  \texttt{email@domain} \\}

\begin{document}
\maketitle
\begin{abstract}
This document is a supplement to the general instructions for *ACL authors. It contains instructions for using the \LaTeX{} style files for ACL conferences. 
The document itself conforms to its own specifications, and is therefore an example of what your manuscript should look like.
These instructions should be used both for papers submitted for review and for final versions of accepted papers.
\end{abstract}

\section{Introduction}

Personality refers to the individual differences in characteristic patterns of thinking, feeling, and behaving. The study of personality has a broad and varied history in psychology with an abundance of theoretical traditions. The major theories include dispositional (trait) perspective, psychodynamic, humanistic, biological, behaviorist, evolutionary, and social learning perspective. At the very beginning, the personality prediction problem is viewed simply as a text classification, which aims to identify one's personality traits from online corpus he/she creates.

With the advent of advanced computational techniques and the burgeoning field of multimodal deep learning, using multimodal models to predict personality types becomes an hot topic in user profile research. But most of the existing datasets are text-based scraping from the social media blogs or comments. To meet the requirement of lacking other modality information, a lot of multimodal dataset were released in recent years. Jiang et al. (2019) published a multimodal dataset called FriendsPersona which concludes more than 700 dialogues and 7 characters based on famous TV series \textit{Friends}. There are also many multimodal datasets used to perform other tasks and some of the personality prediction works will modify their datasets to adapt the personality context. For instance, TVQA is a large dataset which is initially designed to do the visual question answering task. It is used frequently in our research field because of the its large scale.

However, on one hand, whatever the datasets are used for, they have always had a problem: the \textbf{accuracy} of the personality traits annotations. They just invited three or four people who are interested in that program to annotate the personality mannually and the results are highly depend on the volunteers' comprehension of the characters. Zhu et al. (2023) found that personality database website has marked thousands of virtual characters in movies and TV shows and they scraped the personality data from it to annotate TVQA dataset. On the other hand, most of the multimodal personality prediction works focus on images rather than videos because of the roughly division of the scenes and absence of annotations for each utterance in existing datasets. From the psychological perspective, people's personality is always changing based on the environment. So we should not consider the personality prediction in isolation and relationship networks are integral to personality prediction because they provide a rich context in which individual behaviors, preferences, and traits are manifested and observed.

In this work, we aim to provide a brand new multimodal dataset MMPD that contains enough dialogues and videos, accurate annotations and relationship networks between characters as well as focus on multimodal compositionality. We collected the personality annotations from a popular voting website, because each personality type are determined by thousands of people which is more reliable than mannually annotating. MMPD is built on 298 movies and 10 TV series in different genres, including more than 35k dialogues, 170k utterances, 4016 characters and 963 hours videos. With the rich annotation, our dataset supports 4 personality traits models (MBTI, Big Five, Enneagram and Instinctual Variant), 7 kinds of social relationship and 8 attitudes for the emotional relationship.

Our contributions are as follows:

\begin{itemize}
  \item We propose the largest and diverse multimodal dataset MMPD comparing the existing works. 
  \item We divide the scenes according to the original scripts and design a method to annotate for each utterance reaching 87\% accuracy.
  \item We firstly define several relationship types to represent the interaction between the character scene by scene.
\end{itemize}

\begin{table*}
\centering
\begin{tabular}{lllll}
  \hline
  \textbf{Dataset} & \textbf{Field} & \textbf{Dialogues} & \textbf{Characters} & \textbf{Source}\\
  \hline
  MEmoR & Emotion Recognition & 8.53k & 7 & The Big Bang Theory \\
  \hline
  FriendsPersona & Personality Recognition & 0.71k & 7 & Friends\\
  \hline 
  CPED & Emotion and Personality Recognition & 12k & 392 & 40 TV shows\\
  \hline
  UDVIA & Social Interaction Analysis & 188 & 147 & Dyadic Interaction\\
  \hline
  The ChaLearn FI & Personality Recognition & 10k & 3000 & Youtube\\
  \hline
  TVQA & Temporal and Spatial Localization & 29.4k & Unknown & 6 TV shows\\
  \hline
  Our Dataset & Personality Recognition & 70k & 4000 & 300+ Movies and 10 TV Shows\\
  \hline
\end{tabular}
\caption{Comparison of different datasets and our MMPD, there should be utterances of each dialogues}
\label{tab:accents}
\end{table*}
\section{Dataset Design}

This paper introduces a new multimodal personality dataset, MMPD, consisting of 303 movies and 18 TV shows, which is the largest of existing multimodal datasets. In this section, we provide a specific description about our dataset in terms of design principles and the structure in details.

\subsection{Design Principles}

In constructing such a dataset for personality prediction, incorporating four distinct personality models, provides a comprehensive framework for undersatanding the multifaceted nature of human Personality:
\begin{itemize}
  \item Myers–Briggs Type Indicator (MBTI): The MBTI is utlized for its popular four dimensional categorization of personality types, offering a straightforward way to undersatand how individuals engage with the environment and make decisions.
  \item Big Five: The Big Five personality trait model is included for its empirical support and broad acceptance within the psychological community. It covers a range of personality dimensions (Openness, Conscientiousness, Extraversion, Agreeableness, Neuroticism) that are universally recognized and have been linked to various outcomes in personal and professional contexts.
  \item Enneagram: The Enneagram adds depth to this dataset by introducing a typology of nine interconnected personality types, offering a dynamic perspective on individual differences. Its inclusion is strategic, as it provides insights into core motivations, fears, and desires that underpin behavior, thus allowing for a more detailed exploration of personality dynamics and potential growth paths for individuals.
  \item Instinctual Variant: The concept of Instinctual Variants (or Subtypes) within the Enneagram framework enriches the dataset by addressing the fundamental survival drives—Self-Preservation, Social, and Sexual (One-to-One)—that influence an individual's priorities and interactions.
\end{itemize}

Each model offers unique insights and covers different aspects of personality making them collectively valuable for a multidimensional approach personality prediction. Besides these personality models, we introduce two main categories of relationship among characters.

The first one is social relationship, which provides a comprehensive canvas on which to observe and interpret the nuances of personality in action. We conclude 7 social relationship from the perspective of psychology and socialogy, which recognizes that personality is not only a matter of internal traits and instincts but also fundamentally shaped and expressed through interactions with others in various domains of life. 
\begin{figure}[h]
  \centering
  \includesvg{images/sample.drawio.svg}
  \caption{A sample of MMPD}
\end{figure}
\begin{table*}
\centering
\begin{tabular}{ll}
  \hline
  \textbf{Relationship type} & \textbf{Description}\\
  \hline
  Family Relationship & Parents (grand parents) and children, siblings, etc.\\
  \hline
  Friendship & Based on common interest, mutual respect and affection, but not related to the blood\\
  \hline
  Romantic Relationship & Based on emotional attraction and include dating, marriage, etc.\\
  \hline
  Professional Relationship & Formed in a work environment, such as colleagues, superiors and subordinates, etc.\\ 
  \hline
  Social Relationship & Formed in a broader social context, such as neighbors, club members.\\
  \hline
  Academic Relationship & Formed in an educational setting, such as between teachers and students, classmates.\\
  \hline
  Online Relationship & Established in online spaces or through social media platforms.\\
  \hline
\end{tabular}
\caption{This is the chart to represent the social relationship}
\end{table*}

The social relationships above are relatively non-changable, not depicting the attitudes towards someone else. So we define another 8 types for the emotional relationships, as the aid for the comprehension of personality. 

We choose affection, jealousy, dislike, pity, respect, hostility, envy and gratitude as our annotators for the emotional relationship, which concludes the diverse attitudes in human's daily life.

Thus, we select a binary tuple to annotate the pair of characters for each scene, as well as emotional relationship tag for each utterance.
\begin{table*}
  \centering
  \begin{tabular}{ll}
    \hline
    \textbf{Relationship type} & \textbf{Description}\\
    \hline
    Affection or Fondness & Parents (grand parents) and children, siblings, etc.\\
    \hline
    Jealousy & Based on common interest, mutual respect and affection, but not related to the blood\\
    \hline
    Dislike or Aversion & Based on emotional attraction and include dating, marriage, etc.\\
    \hline
    Pity or Sympathy & Formed in a work environment, such as colleagues, superiors and subordinates, etc.\\ 
    \hline
    Respect & Formed in a broader social context, such as neighbors, club members.\\
    \hline
    Hatred or Hostility & Formed in an educational setting, such as between teachers and students, classmates.\\
    \hline
    Envy & Established in online spaces or through social media platforms.\\
    \hline
    Gratitude & This is the emotion of being thankful for someone else's help or kind actions.\\
    \hline
  \end{tabular}
  \caption{This is the chart to represent the emotional relationship}
  \end{table*}
  

\subsection{Structure of MMPD}

MMPD has a very large scale for the three modalitie: video, audio and text. We built a fine grained structure describing the interactions and corresponding personality traits for each utterance based on the original scripts.

Firstly, we divide the scripts into several scenes according to the coherence in language of camera instead of ramdonly clipping in a certain time period. For each scene, we match the time stamps in the subtitle files to the raw scripts' utterances in dialogues. Additionally, ChatGPT model is used to determine the relationship types of characters for each scene. And then we clip the corresponding movie and TV show according to the time stamps that we matched before. Finally we put the four types of personality models to the corpus, as shown in Fig. 1.

Aiming to deliver a tidy and readable structure, there is no more suitable file types than json format. We distribute different scenes in a single json file with index. For each movie or TV show, the video clips and corresponding json files are stored in the same directory.

Example illustrating in a picture

\section{Methodology}

\subsection{Source of Data}

Considering the unreliable labeling method of existing works, we collect the personality annotations from personality database website as well as the voting distribution that indicates the credibility of current personality type. We used some python scripts to scrape the personality data from the website and annotate them to the corresponding scripts. As for the scripts and subtitles, we also find some open-source websites for research offering the free scripts and subtitles of many famous movie and television programs. To represent the diversity of the real world scenarios, we select various genres of the movies and TV series which includes action, thriller, romance, comedy, science fiction, etc.

Explain where and how to collect the data. 

\subsection{Data Alignment Process}

As subtitle contain temporal information and original scripts associate utterances with characters, we are supposed to align them properly as efficient as possible. However, most of the existing multimodal datasets annotate the timestamps mannually with taking up a great deal of time. There are also some works which utlize different automatic tools to align the utterances with their corresponding information. For instance, Shen, et al (2020) get the 

So we designed a fuzzy matching algorithm to match utterances with their corresponding timestamps and speakers. 

Based on the subtitle file we collected, our main idea is that we already have the precise timestamp for each utterance so we just need to put the corresponding character's name into the right position. At the beginning, we set a threshold like 0.8 to represent the simlarity between the utterances in scripts and subtitles. And then we compare each utterance from scripts and subtitle to figure out whether their simlarity reach the threshold. If it does, the corresponding character will be marked to the utterance. 

\subsection{Annotation Process}


\begin{quote}
\begin{verbatim}
\documentclass[11pt]{article}
\end{verbatim}
\end{quote}

To load the style file in the review version:
\begin{quote}
\begin{verbatim}
\usepackage[review]{acl}
\end{verbatim}
\end{quote}
For the final version, omit the \verb|review| option:
\begin{quote}
\begin{verbatim}
\usepackage{acl}
\end{verbatim}
\end{quote}

To use Times Roman, put the following in the preamble:
\begin{quote}
\begin{verbatim}
\usepackage{times}
\end{verbatim}
\end{quote}
(Alternatives like txfonts or newtx are also acceptable.)

Please see the \LaTeX{} source of this document for comments on other packages that may be useful.

Set the title and author using \verb|\title| and \verb|\author|. Within the author list, format multiple authors using \verb|\and| and \verb|\And| and \verb|\AND|; please see the \LaTeX{} source for examples.

By default, the box containing the title and author names is set to the minimum of 5 cm. If you need more space, include the following in the preamble:
\begin{quote}
\begin{verbatim}
\setlength\titlebox{<dim>}
\end{verbatim}
\end{quote}
where \verb|<dim>| is replaced with a length. Do not set this length smaller than 5 cm.

\section{Evaluation}

accuracy of methodology

Provide statistics about the dataset, such as size, number of instances, diversity of languages or dialects, and any other relevant metrics.

\subsection{Footnotes}

Footnotes are inserted with the \verb|\footnote| command.\footnote{This is a footnote.}

\subsection{Tables and figures}

See Table~\ref{tab:accents} for an example of a table and its caption.
\textbf{Do not override the default caption sizes.}


\subsection{Hyperlinks}

Users of older versions of \LaTeX{} may encounter the following error during compilation: 
\begin{quote}
\tt\verb|\pdfendlink| ended up in different nesting level than \verb|\pdfstartlink|.
\end{quote}
This happens when pdf\LaTeX{} is used and a citation splits across a page boundary. The best way to fix this is to upgrade \LaTeX{} to 2018-12-01 or later.

\subsection{Citations}

\begin{table*}
\centering
\begin{tabular}{lll}
\hline
\textbf{Output} & \textbf{natbib command} & \textbf{ACL only command}\\
\hline
\citep{Gusfield:97} & \verb|\citep| &  \\
\citealp{Gusfield:97} & \verb|\citealp| & \\
\citet{Gusfield:97} & \verb|\citet| &  \\
  \citeyearpar{Gusfield:97} & \verb|\citeyearpar| &  \\
  \citeposs{Gusfield:97}	&	& \verb|\citeposs|\\
\hline
\end{tabular}
\caption{\label{citation-guide}
Citation commands supported by the style file.
The style is based on the natbib package and supports all natbib citation commands.
It also supports commands defined in previous ACL style files for compatibility.
}
\end{table*}

\section{Conclusion}

\section{Copyright}

Table~\ref{citation-guide} shows the syntax supported by the style files.
We encourage you to use the natbib styles.
You can use the command \verb|\citet| (cite in text) to get ``author (year)'' citations, like this citation to a paper by \citet{Gusfield:97}.
You can use the command \verb|\citep| (cite in parentheses) to get ``(author, year)'' citations \citep{Gusfield:97}.
You can use the command \verb|\citealp| (alternative cite without parentheses) to get ``author, year'' citations, which is useful for using citations within parentheses (e.g. \citealp{Gusfield:97}).

A possessive citation can be made with the command \verb|\citeposs|.
This is not a standard natbib command, so it is generally not compatible
with other style files.

\subsection{References}

\nocite{Ando2005,andrew2007scalable,rasooli-tetrault-2015}

The \LaTeX{} and Bib\TeX{} style files provided roughly follow the American Psychological Association format.
If your own bib file is named \texttt{custom.bib}, then placing the following before any appendices in your \LaTeX{} file will generate the references section for you:
\begin{quote}
\begin{verbatim}
\bibliography{custom}
\end{verbatim}
\end{quote}

You can obtain the complete ACL Anthology as a Bib\TeX{} file from \url{https://aclweb.org/anthology/anthology.bib.gz}.
To include both the Anthology and your own .bib file, use the following instead of the above.
\begin{quote}
\begin{verbatim}
\bibliography{anthology,custom}
\end{verbatim}
\end{quote}

Please see Section~\ref{sec:bibtex} for information on preparing Bib\TeX{} files.

\subsection{Appendices}

Use \verb|\appendix| before any appendix section to switch the section numbering over to letters. See Appendix~\ref{sec:appendix} for an example.

\section{Related Works}
\label{sec:bibtex}

Unicode cannot be used in Bib\TeX{} entries, and some ways of typing special characters can disrupt Bib\TeX's alphabetization. The recommended way of typing special characters is shown in Table~\ref{tab:accents}.

Please ensure that Bib\TeX{} records contain DOIs or URLs when possible, and for all the ACL materials that you reference.
Use the \verb|doi| field for DOIs and the \verb|url| field for URLs.
If a Bib\TeX{} entry has a URL or DOI field, the paper title in the references section will appear as a hyperlink to the paper, using the hyperref \LaTeX{} package.

\section*{Acknowledgements}

This document has been adapted
by Steven Bethard, Ryan Cotterell and Rui Yan
from the instructions for earlier ACL and NAACL proceedings, including those for 
ACL 2019 by Douwe Kiela and Ivan Vuli\'{c},
NAACL 2019 by Stephanie Lukin and Alla Roskovskaya, 
ACL 2018 by Shay Cohen, Kevin Gimpel, and Wei Lu, 
NAACL 2018 by Margaret Mitchell and Stephanie Lukin,
Bib\TeX{} suggestions for (NA)ACL 2017/2018 from Jason Eisner,
ACL 2017 by Dan Gildea and Min-Yen Kan, 
NAACL 2017 by Margaret Mitchell, 
ACL 2012 by Maggie Li and Michael White, 
ACL 2010 by Jing-Shin Chang and Philipp Koehn, 
ACL 2008 by Johanna D. Moore, Simone Teufel, James Allan, and Sadaoki Furui, 
ACL 2005 by Hwee Tou Ng and Kemal Oflazer, 
ACL 2002 by Eugene Charniak and Dekang Lin, 
and earlier ACL and EACL formats written by several people, including
John Chen, Henry S. Thompson and Donald Walker.
Additional elements were taken from the formatting instructions of the \emph{International Joint Conference on Artificial Intelligence} and the \emph{Conference on Computer Vision and Pattern Recognition}.

% Bibliography entries for the entire Anthology, followed by custom entries
%\bibliography{anthology,custom}
% Custom bibliography entries only
\bibliography{custom}

\appendix

\section{Example Appendix}
\label{sec:appendix}

This is an appendix.

\end{document}
