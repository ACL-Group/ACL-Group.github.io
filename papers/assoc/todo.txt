To-do list (for camera-ready) :

1. Add word embedding in.
	* add results reported on WS-353
	* inplement short text similarity algorithm for word embedding (for example, using word2vec) and report results on Li-06
	* briefly discuss in related work

2. Clarify the story line and adjust the writing accordingly. We use five types of co-occurrences to better simulate and extend free association, which can be used to solve semantic relatedness problems. (Instead of combining signals from five types of co-occurrences as well as free association to better solve semantic relatedness problems.) 

3. Revise section 2.3 (similarity algorithm) to make it clearer.

4. Maybe we want to emphasize that association graph is not relatedness graph to address the concern about why we do not directly read the scores along the edges as relatedness scores. But maybe not... I'm not sure.

5. Correct the typos and inaccurate wordings.





Previous (14.08.26) to-do list:

1 (ongoing). Show the effectiveness of the free assiciation data in measuring semantic relatedness through reasoning and/or experiment.

2. Show our graph's advantages over the "free association graph" through reasoning and/or experiment. These primary advantages are:

	* we overcome the sparsity problem of the "free association graph"
	* we can choose to disambiguate surface forms to concepts (and also can build "synset")
	* we can introduce much more new nodes like named entities in our graph, which performs like an extension of the small "free association graph"

3 (done). end-to-end applications:

	* term similarity/relatedness, on ws-353 and M&C
	* stss (short text semantic similarity), on stss-131, experiment both on the top of LSA

4 (done). Check if our LSA tool reporting 0.60 pearson and the LSA paper reporting 0.68 pearson are based on the exactly same algorithm, and if that is the case, try to find/implement the system described in the paper and conduct our stss experiment on the top of this "0.69 LSA". However, if the LSA paper reporting 0.69 pearson is not a "normal paper", for example if published in some workshop, maybe we don't have to pay that much attention to it.

5 (ongoing). After expansion, the performance on stss-131 is roughly 0.65, which could still be further optimized.

6. Show the scalablity of our system by filtering nodes/edges, still using our two end-to-end applications to conduct experiments.

7. Find more people (maybe 15 or so) to lable the paths on 353.

8 (done). Check the quality of our disambiguation process. Compare the quality of the graph before and after disambiguation.

9. Organize the raw material collected before and start to write related work.





Previous (14.05.22) to-do list:
1. Revise our HMM (done)
2. Find applications and evaluation methods for the path (kailang)
	profile expansion vs. path explanation
	when we expand:
	i) which terms to expand
	ii) how to expand, minimum spanning tree, cluster of graphs?
	ii) how to rank or score the expanded terms
3. tradeoff: (keyang)
   size vs. quality 
   num of contexts vs. quality
   size vs. num of contexts
4. try to improve the efficiency of our algorithm (done, keyang)
5. check our data and try to conduct experiments on larger co-occurrence map (ongoing)
6. Disambiguate different concepts under the same page and re-calculate the co-occurrence under different contexts (kailang)
7. Fix those grammatical mistakes, and revise sec.2(Data source part) and sec.3(HMM part) of our paper (ongoing, kailang)
