Reviewer #3: The paper proposes a declarative language to describe and extract structured textual information from one or more medical images of the same format preprocessed to extract OCR chunks of text as XML annotations with spatial positioning. It also describes a parser, which is used to evaluate the proposal on real data from several sources.
The language is fairly complete, and well tailored to the medical images domain, although it may be useful for other applications areas too. The running example of ECG exams helps to contextualize the contribution and guides its applicability.

The work tackles a very important area of textual data analysis and information retrieval, in a practical solution. The paper has two minor problems, whose correction can improve it.
1) It often refers to improving "user friendly" or "easy of use", but no real evaluation of usability is presented. Thus, experiments on health related personnel use should be reported, and a better explanation on how the usability evaluations were conducted should be described;

>>> Revised. We added more experimental detail, please refer to the "ODL Annotation" paragraph in section 5.1.
	Since our approach has not been applied in a large scale, the usability data of hospital employees is not available, which will be our future work.
	The term "user-friendly" is mentioned when we compare our method with baseline approaches: the ODL parser is based on a clear syntax, and there's no need to annotate every single image.
    Regarding the explanation of annotating step, we argue that ODL is easy to write, as it only requires basic data structure knowledge (struct / union / list), and the ability to understand all texts of an image into a hierarchy of spans.
    Since the annotation step is comfortable for undergraduate student, it should be easier for employees with CS background in hospitals.


2) Although there are comments about the system's efficiency and related properties, there is no experiment or description regarding resources required by the system, such as execution time or memory consumption. It would be interesting also to have an idea of the requirements about user's training and time involvement to prepare a ODL script.

>>> Revised. Please refer to the "ODL Annotation" paragraph in section 5.1 and the last paragraph in 5.2.
	The running time and memory consumption is acceptable, because in the real scenario, there is only limited amount of text in any medical image.


Editor-In-Chief: Abstract is mostly background and methods (revise).
>>> Revised. Now the abstract is made up of 4 parts of similar lengths: background, challenges, methods, results.


Editor-In-Chief: A formal Discussion section is needed to compare and contrast the study with published works in the literature, with citations. Separate Results and Discussion sections are needed. Cites needed in the Discussion, with compare and contrast.

>>> Revised. We have added a new section 5.4 for comparison and analysis, and it's separated from results.
	We mainly focus on the contrast between the ODL parser and directly comparable approaches: textual mapping (Exact Match), local area recognition (Zonal OCR) and Page Layout.
	Since these baseline approaches are designed from a more practical perspective, no direct citations need to be provided in this section.
	For literature related to information extraction but not directly comparable, we have put the discussion in the related work section.
