%%%%%%%%%%%%%%%%%%%%%%% file template.tex %%%%%%%%%%%%%%%%%%%%%%%%%
%
% This is a general template file for the LaTeX package SVJour3
% for Springer journals.          Springer Heidelberg 2010/09/16
%
% Copy it to a new file with a new name and use it as the basis
% for your article. Delete % signs as needed.
%
% This template includes a few options for different layouts and
% content for various journals. Please consult a previous issue of
% your journal as needed.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\RequirePackage{fix-cm}
%
%\documentclass{svjour3}                     % onecolumn (standard format)
\documentclass[smallcondensed]{svjour3}     % onecolumn (ditto)
%\documentclass[smallextended]{svjour3}       % onecolumn (second format)
%\documentclass[twocolumn]{svjour3}          % twocolumn
%
\smartqed  % flush right qed marks, e.g. at end of proof
%
\usepackage{graphicx}
%
% \usepackage{mathptmx}      % use Times fonts if available on your TeX system
%
% insert here the call for the packages your document requires
%\usepackage{latexsym}
% etc.
%
% please place your own definitions here and don't use \def but
% \newcommand{}{}
%
%Insert the name of "your journal" with
%\journalname{myjournal}
%

\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{times,epsfig,proof,url}
\usepackage{epsfig}
\usepackage{epstopdf}
\usepackage{listings}
\usepackage{subfig}
\usepackage{marvosym}

\newcommand{\secref}[1]{Section \ref{#1}}
\newcommand{\figref}[1]{Figure \ref{#1}}
\newcommand{\tabref}[1]{Table \ref{#1}}
\newcommand{\equref}[1]{Equation (\ref{#1})}


\begin{document}

\title{Fault-tolerant Information Extraction from Semi-structured OCR Images}
%\subtitle{Do you have a subtitle?\\ If so, write it here}

%\titlerunning{Short form of title}        % if too long for running head

\author{Kangqi Luo  \and
        Jinyi Lu    \and
        Kenny Q. Zhu    \and
        Weiguo Gao  \and
        Jia Wei     \and
        Meizhuo Zhang
}

%\authorrunning{Short form of author list} % if too long for running head

\institute{Kangqi Luo \and Jinyi Lu \and Kenny Q. Zhu (\Letter)
           \at Department of Computer Science, Shanghai Jiao Tong University, Shanghai, China \\
              \email{luokangqi@sjtu.edu.cn, JinyiLu93@gmail.com, kzhu@cs.sjtu.edu.cn}
           \and
           Weiguo Gao \and Jia Wei (\Letter) \and Meizhuo Zhang
           \at Research and Development Information, AstraZeneca R\&D, Shanghai, China \\
           \email{\{Weiguo.Gao,Jenny.Wei,Meizhuo.Zhang\}@astrazeneca.com}
}

\date{Received: date / Accepted: date}
% The correct dates will be entered by the editor


\maketitle

\begin{abstract}
Optical character recognition (OCR) has been widely used in digitizing scanned
documents into text. Good results have been achieved in applying OCR to textual
documents such as novels and reports where the 
content is virtually all words, and in many languages. 
For semi-structured documents that combine graphics and words,
such as medical images, extraction of useful textual information is difficult
due to the discontinuity of text flows. In this paper, we 
propose a spatial, fault-tolerant description language that allows users to 
specify a rough format of the image along with type information and
constraints. 
%Our work can be regarded as preprocessing of the information 
%extracting process since it takes the semi-structured data as the input 
%and transforms the data into a form which is more structured and 
%with useless noises removed so that the downstream extraction of 
%information can be easier. 
The evaluation engine of this language automatically generates a
reliable parser of the OCR output from an image according to 
its description. This parser extracts all useful textual components specified
by the description. Moreover, the system allows
the user to make incremental corrections to parsing results 
and learns from these corrections so as to make better parses in future. 
Our experimental results show
that this system outperforms existing academic and commercial systems by
substantial margins in terms of extraction accuracy.
%Insert your abstract here. Include keywords, PACS and mathematical
%subject classification numbers as needed.

%\keywords{First keyword \and Second keyword \and More}
\keywords{Information extraction \and Optical character recognition \and
          Document analysis \and Description language \and
          Fuzzy parser \and Spatial information \and 
          Medical images \and Medical information systems}
% \PACS{PACS code1 \and PACS code2 \and more}
% \subclass{MSC code1 \and MSC code2 \and more}
\end{abstract}

\input{intro}
\input{approach}
\input{syntax}
\input{semantics}
\input{correction}
\input{eval}
\input{discuss}
\input{related}
\input{conclusion}


\begin{acknowledgements}
This work is supported by the Joint research scheme funded by AstraZeneca R\&D China.
Kenny Q. Zhu and Jia Wei are the corresponding authors.
\end{acknowledgements}

% BibTeX users please use one of
%\bibliographystyle{spbasic}      % basic style, author-year citations
\bibliographystyle{spmpsci}      % mathematics and physical sciences
%\bibliographystyle{spphys}       % APS-like style for physics
\bibliography{ocr}   % name your BibTeX data base


\end{document}
% end of file template.tex

