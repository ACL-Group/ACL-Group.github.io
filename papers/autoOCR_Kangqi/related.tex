\section{Related Work}
\label{sec:related}

% In this section, we introduce related
% work in the data description language field, page layout analysis,
% optical character recognition and incremental manual correction.

\subsection{Textual Information Extraction}
% PART 1. mining the textual information from various images,
% such as xxx image, xx image and xxxx.
There has been a lot of research works for
extracting textual information from various images, such as book covers,
digital drawings, natural scenes, and video frames~\cite{jung2004text}.
More recent researches focus on the text recognition in specific domains.
% KQ: why shortcite doesn't work??? WTF..
Yin et al.~\shortcite{yin2014robust} conducted researches on the text
detection of natural scenes,
and Zhang et al.~\shortcite{zhang2015symmetry} further improved the
performance by leveraging the symmetric property of characters.
The ICDAR2017 Robust Reading Challenge~\cite{yang2017icdar2017}
aims at extracting texts from biomedical literature figures,
including the task of text detection and cropped word recognition.
% Jung et al.: Text information extraction in images and video: a survey. Pattern Recognition 37(5): 977-997 (2004)
%     >>> talk the detail of detecting, boundray, recognition ...
% Symmetry-Based Text Line Detection in Natural Scenes 2015
% >>> Scene text detection. Can be a choice
% Robust Text Detection in Natural Scene Images
% >>> Similar with Jung, and published in 2014.
%     Discussed the text detection method based on MSER.
% Yang et al: ICDAR2017 Robust Reading Challenge on Text Extraction from Biomedical Literature Figures (DeTEXT). In proc. 14th IAPR International Conference on Document Analysis and Recognition (ICDAR). DOI: 10.1109/ICDAR.2017.235 (2017)
%     >>> sharing task on medical images, including text detection,
%     cropped word recognition.
%     >>> BE CAREFUL OF THIS PAPER!

% 2. downstream applications (be very brief, shortcite is not allowed.)
With the growth of text recognition methods,
several researches belong to the downstream applications using OCR techniques,
such as content based image retrieval~\cite{wankhede2017different},
and lossless image compression~\cite{erguzen2017medical}.
% Wankhede P. A. and Mohod S. W.: A different image content-based retrievals using OCR techniques. In proc. 2017 International conference of Electronics, Communication and Aerospace Technology (ICECA). DOI: 10.1109/ICECA.2017.8212785 (2017)
%     >>> image retrieval based on contents.
% Erguzen A. and Erdal E.: Medical Image Archiving System Implementation with Lossless Region of Interest and Optical Character Recognition. Journal of Medical Imaging and Health Informatics: 7(6): 1246-1252 (2017)
Our presented work is regarded as another downstream application,
which converts the unstructured recognized texts into
the structured knowledge of medical records.
The OCR engine serves as the building block of the system,
but the main contribution of this work goes beyond the scope of OCR.

% 4. contributions of these works are seeking for a improved OCR software,
% for handling the task in the specific domains.
% 4. ours: in a different perspective.
% MORE LIKELY TO BE A DOWNSTREAM APPLICATION OF OCR.
% structured textual information is what we really want, rather than
% recognition only: stands on the shoulder of OCR techniques.
% Though OCR is a building block of the system,
% we are not focus on directly improving the recognition performance,
% it's a software for common use (not for medicals only), serving as a black box,
% but thinking how to use DSL for a better structure data extraction,
% as well as automatically fix errors.n

Another related research field is information extraction from free texts.
A series of OpenIE researches~\cite{carlson2010toward,fader2011identifying}
extract the (subject, predicate, object) relation triples from the
natural language sentences in the open domain.
There also exists information extraction system in specific domains,
such as cTAKES~\cite{savova2010mayo} in the clinical domain
and BioInfer~\cite{pyysalo2007bioinfer} in the biomedical domain.
While the goal of these tasks are learning extraction rules
for textual knowledge, our work targets on a different perspective:
The structured knowledge depends on the user's demand,
rather than concrete facts or pre-defined relations. Besides,
the input texts of our work are separated text boxes with recognition errors,
which is far more challenging than ordinary free texts.
Therefore, our research targets on using description languages for
data representation and parsing, which is a non-trivial task.


% Learning Information Extraction Rules for Semi-Structured and Free Text (1999)
% 	>>> mine rules for information extraction from unstructured text. (maybe similar to our task)
% OpenIE series =v=
% 	>>> another knowledge with SPO format.
% A Brief Survey of Text Mining: Classification, Clustering and Extraction Techniques (2017)
% 	>>> talked about text mining for bio and health. like ontologies,
% 		but ours are more ad-hoc, not commonly defined knowledge, but related to user's demand.
% we can't learn rules, as instead, let users to define structured data then perform a extracting process.
% 	1. error in OCR, but no such problem in text area.
% 	2. the extracting process (parser) is non-trivial: fuzzy alignment, both data & spatial.
% 	3. (leave to future work: label data from image, automatically learn ODL, or parsing process.)





\subsection{Data Description Language}
%To describe the text information on medical images, we design ODL,
%which is a declarative data description language for processing
%text data on the images.
In previous work, some declarative data description languages
were designed for different purposes.
For example, PADS~\cite{fisher2005pads} is a data description language to
handle the ad-hoc log data.
% The descriptions of PADS are concise and flexible.
With the help of the descriptions,
a compiler can be used to parse and print the data.
Further research including
the LearnPADS~\cite{fisher2008dirt,fisher2008learnpads},
which provides a fully automatic
system for generating the corresponding PADS descriptions.
ODL is inspired by PADS and uses the type system in programming
language integrated with fuzzy matching and spatial features
to handle the specific text data from medical images.

In ODL, in order to describe spatial information,
we enhance the syntax with spatial features in order to limit the
search area of the description and horizontal and vertical
skip to describe the spatial relation between the data.
There has also been some
previous work on describing the spatial information in the document,
such as LaTeX~\cite{lamport1986document} and
PostScript~\cite{taft1999post}.
In LaTeX,
lots of spacing parameters and spacing commands are used.
For example, ``$\backslash$vspace$\lbrace\langle$skip$\rangle\rbrace$'' and
``$\backslash$hspace$\lbrace\langle$skip$\rangle\rbrace$''
are two general spacing commands.
In PostScript, in order to manipulate the text, some
operations are designed, including \textit{ashow}, \textit{widthshow},
\textit{awidthshow} and so on. These operations take an input text
string and a separate specification for positioning the elements.
%The function of
%``$\backslash$vspace$\lbrace\langle$skip$\rangle\rbrace$''
%is to allocate vertical space and the function of
%``$\backslash$hspace$\lbrace\langle$skip$\rangle\rbrace$''
%is to allocate horizontal space.
%There are also some particular cases of these two commands to leave a
%vertical or horizontal space of some predefined amount, such as
%``$\backslash$smallskip'', and ``$\backslash$enskip''.
We use similar descriptions for spacing functions,
``\textit{hskip len}'' and ``\textit{vskip len}''.
But the way we interpret them is different.
The reason is ODL is a fuzzy description language so that it's easy for
humans to write in ODL. ODL will tolerate some error of the spacing
command by using the fuzzy matching strategies.
However, in LaTeX, spacing commands are interpreted as it is.

% Another language used to describe spatial information is PostScript.
% In PostScript \cite{taft1999post}, in order to manipulate the text, some
% operations are designed (for example, {\em ashow}, {\em widthshow},
% {\em awidthshow}, {\em kshow}, {\em xshow}, {\em yshow}, or
% {\em xyshow} operators). These operations take an input text
% string and a separate specification for positioning the elements.
% In contrast with ODL, such operations will paint the strings identified by the elements
% of the strings on the current page starting at given point, and also
% provide some spatial information like the $x$, $y$ coordinates. Spatial
% information, such as coordinates, is used in the painting of latter strings.
% It's much more detailed than ODL as one can attain all the coordinates
% for different strings if needed.
%In ODL, we only describe the relationship
%between different data components, so it's easier to describe such
%information in ODL than in PostScript.
% Simpler building blocks include Chapman Flack's Markup \cite{markup},
% which can be used as a front end to carry out simple text setting on its own.

\subsection{Page Layout Analysis}
A typical document analysis system consists of page segmentation,
optical character recognition, and logical structure identification.
The interest in the logical structure was inspired by the
emergence and popularity of common representation standards such as XML.
By using these common standards, we can encode structural information
together with the contents. \cite{o1993document}.
One of the key components used to help to understand a document is logical
labeling.
The task of logical labeling is to label segmented blocks on a document
image as title, author, header, text column, etc \cite{liang2002logical}.
% \cite{ishitani2002model}.
The set of labels will depend on the document classes or applications.
Logical labeling techniques can be roughly characterized as either
zone-based or structure-based. Zone-based
techniques classify zones individually based on the features of each zone
\cite{altamura2001transforming} \cite{palmero1999structured}.
Structure-based techniques incorporate global constraints such as the position
of the text.
In our work, instead of using zone or struct,
we describe the logical layout by making
use of the composition expressions.

Some style-directed layout analysis algorithms
also allow users to specify the physical layout~\cite{kanungo2003stochastic}.
In this case, a regular language, including terminal symbols,
non-terminal symbols and production rules, is proposed to express
the varieties of physical regions and help the physical layout analysis.
However, the basic terminal symbol is the text line instead of the word.
% The reason is that noises will mislead the producting rules for word.
The reason is that it is hard to distinguish word from noises based on the
image features alone, which result in inaccuracies when processing
the production rules. In our work, we introduce constraints to
handle such noises.

Another related work about page segmentation is VIPS \cite{cai2003vips}.
It's a vision-based page segmentation algorithm used to extract the semantic
structure of a web page.
% Such a semantic structure is hierarchical,
% meaning that each node will correspond to a block.
% The vision-based content structure of a page is obtained by combing the DOM structure
% and the visual cues. In VIPS, the web page is, first, segmented into
% several big blocks and the hierarchical structure of this level is
% recorded. For each big block, the same segmentation process is
% carried out recursively until we attain sufficiently small blocks.
In our work, the semi-structure output of the OCR engine is comprised of the
structured XML files. However, VIPS can't be directly used to analyze
these XML files since the errors in the recognition process will
lead to errors in the XML files about the visual cues
and the DOM structures.
% In this way, VIPS will be misled by
% the wrong visual cues in its analysis of the document. So
% we abandon use of the visual structure in the XML files and instead
% make use of the detailed coordinate information to reconstruct the
% structure.

Different from the solutions for web pages,
PATO \cite{bartoli2014semisupervised}
is a system for extracting predefined items from
printed documents in a dynamic, multisource scenario.
% It analyzes
% the text blocks in the printed documents and handles the fuzzy matching problem
% by calculating the matching probabilities of recognized blocks and elements in
% the schema, which are generated manually by selecting the
% items to be extracted with point-and-click GUI interface.
By focusing on the parameters of the text blocks, it pays little attention to the
relationship between different text blocks, that is, it is not able to
represent dependencies between text block, while our system does.

% \subsection{OCR}
% Optical character recognition (OCR) is the mechanical or electronic
% conversion of images of typewritten or printed text into machine-encoded
% text.
% It is widely used as a form of data entry from printed paper
% data records, e.g., invoices, bank statement, receipts, mail, or other documents.
% It is a common method
% of digitizing printed texts so that they can be electronically edited and searched.
% % This method also can be used in machine
% % processes such as machine translation, text-to-speech, key data and text mining.
% Early versions of the OCR system
% needed to be trained with images of each character, and
% worked on one character at a time \cite{mori1992historical}.
% More recent OCR systems have high rates of accuracy for
% characters in different fonts.
% Some systems can reproduce the formatted output that
% closely approximates the original page including images, columns, and
% other non-textual components \cite{smith2007overview}.
%
% Errors in the OCR text will greatly affect the effectiveness
% of other related tasks. For example, error correction is an important
% technique in OCR document retrieval \cite{darwish2007error} \cite{taghva1996evaluation}.
% Much work has been done to improve the performance of the OCR.
% For example, a language model is used in the post process of OCR
% \cite{kolak2003generative}.
% In this work, the content information is used to do the correction
% and achieve a good result particularly on the dataset of a long text
% document. However, the data sources we are handling here are often
% very short and the language model cannot achieve similar results.
% Also, some work has been done to design a system capable of extracting
% textual information from semi-structured documents, like invoices \cite{cesarini1998informys}.
% In these works, an important part is to recognize the form.
% % And the graphs are used to describe the form layout.
% However, the data source we are handling can't be described
% easily with a form template. The reason for this is that the textual information
% on medical images can appear in different places and be combined
% with images. So our system is flexible enough to only describe the localized
% textual data on them instead of describing the entire structure in the forms.
% % \JY{What's more, it's important}

% \subsection{Manual Correction}
% An important part of our system is making use of human effort
% to improve the performance of the whole system.
% There have been some previous efforts to explore the human power in
% digitizing the printed materials. For example, reCAPTCHA \cite{von2008recaptcha}
% is focused on channeling human effort to recognize CAPTCHA
% on the world wide web to decipher scanned words from books that computerized
% OCR process failed to recognize. In reCAPTCHA,
% instead of using the standard CAPTCHA, words taken from scanned texts
% are displayed. The solutions entered by humans are used to improve the
% digitization process.
% % However, to meet the goal of a CAPTCHA,
% % the system needs to be able to verify the user's answer.
% % To do this, reCAPTCHA gives the user two words,
% % the one for which the answer is not known and a
% % second ``control'' word for which the answer is known.
% In case of discrepancies among human answers, reCAPTCHA sends the word to
% ask for more human inputs and picks the answer with the highest
% number of votes.
% % where each human answer counts as one vote and each
% % OCR guess counts as one half of a vote (recall that these words all
% % have been previously processed by OCR).
% The reCAPTCHA system achieved an accuracy rate
% of 99.1\% at the word level (216 errors out of 24,080 words),
% whereas the accuracy of the standard OCR was only 83.5\% (3976 errors).
% However, reCAPTCHA achieved such an accuracy rate by making use of lots of human votes.
% It provides a solution to make use of a large catalogue of human inputs.
% And in our system, we make use of each human correction efficiently.
%
% Our manual correction policy is an incremental one, which means
% that our correction model can be incrementally learned from human
% efforts. Similar methods can be found in LearnPADS++ \cite{zhu2012learnpads++},
% which proposes an algorithm that incrementally infers PADS descriptions
% for ad hoc data sources. In LearnPADS++, records that fail to
% parse by the candidate description are collected. It then uses
% the original LearnPADS algorithm to infer descriptions for the
% aggregated portions of bad data, and merges these
% new sub-descriptions into the transformed description to produce a new
% one. In our system, we have a similar process whereby we handle the errors
% in the extraction, we collect all the errors and correct them with
% the correction model that learns from manual correction.
% After one round of correction, the remaining
% errors will go through a similar process again.

% \subsection{Preprocess}

% Our work mainly focus on the information extraction on medical images.
% We also design a new description language. The most related work is \cite{kameshiro1999document}, \cite{ishitani2002model} and \cite{ishitani2003document}.

% When a printed document is to be input to a computer system, the document must be converted to a computerreadable format. Then, the information required has to be recognized in documents and stored in the required format. In general, it is
% difficult to accurately extract required keywords and their relationship from printed documents, because such documents have unknown words such as proper nouns, com pound words, or incorrect words due to OCR errors. Furthermore, it is necessary to solve word segmentation problems for Japanese documents, because the boundaries between words are ambiguous.

% The required information may be extracted hierarchically from the texts that are obtained by the OCR process from a document image. Such texts are also obtained hierarchically from regions which are extracted by the layout analysis process. In this hierarchical analysis, some ambi guities cannot be reduced in the result obtained by a single functional process.


% To extract information from images rely on the OCR technique.


% We choose to design a description language to describe the image data.
% There are some related work, \cite{fisher2011pads}, \cite{fisher2008learnpads} and \cite{lamport1985i1}.
