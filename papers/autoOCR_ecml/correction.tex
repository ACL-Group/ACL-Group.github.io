\subsection{Human Correction}
\label{sec:correction}
The parse tree returned from the previous process may contain errors. 
Our system prompts the user to manually correct some of these errors
and such rectification goes into the correction model which improves the
overall accuracy.
% \item incremental learning model, features;
% \item How do we figure out which error should be corrected first;
% \item What will happen after an error been corrected and 
% why the process is incremental.

\subsubsection{Incremental Learning Model}
\label{sec:incremental}
The correction model mentioned in \secref{sec:corrmodel} 
is an incremental learning model. 
%The reason for this is that the model is incrementally changed 
%according to the corrections that humans make. 
The design of the correction model adheres to the scoring
policy in \secref{sec:score}.

\paragraph{Initial Model}
% \KZ{Correct all the backquotes!}
The initial model without any human correction
is generated using the candidate results of the OCR 
engine. For example, for ``QRS'' in the example image, based on the OCR 
engine, the most reliable result is ``ORS''. Other top candidates are 
``QPS'', ``QRS'' and ``OPS''. Thus the system learns that ``OR'' may
be corrected as ``QP'', ``QR'' or ``OP''. These three candidates 
will be added into the initial model. 

To calculate the probabilities of the correction candidates in the initial 
model, we count the occurrences of each correction. In the example, the 
probabilities for ``OR'' corrected as ``OR'', ``QP'', ``QR'' 
or ``OP'' are equal since such corrections only happened once. 

% \[
% P(newStr|oriStr) = \frac{occurrence ~of~ ()}{\sum_{tar \in all} occurrence ~of~ C(oriStr)=tar}
% \]

\paragraph{Training From Human Correction}
After generating the parsing results using the initial model, we have 
made full use of the OCR engine. To correct the remaining errors, 
human input is applied. 
%The incremental learning model is also suitable 
%for learning from human correction. 
For example, if a human corrects the error result ``1o.o'' to ``10.0'', 
we can learn from it ``o''s in the OCR results could have been
``0''s. Thus the correction strategy 
for ``o'' is modified and ``0" is the new correct candidate. 
We also calculate the occurrence 
of different human correction for the probability calculation. 

\paragraph{Application of the Model}
The model for correction is used in the scoring policy in the 
fuzzy parser. As shown in \secref{sec:score}, for each 
description, our system will consider all the potential  
results based on the correction strategies in the model. 
For the description ``QRS'' and the most confident results 
``ORS'', we try all the strategies in the model 
and consider both whether the corrected result satisfies the 
description and whether the correction strategy is 
feasible. In this example, since the four correction strategies 
have the same probability, we choose ``QR'' as the correction 
result for ``OR'', 
which has the lowest error score based on the description.  

\subsubsection{Manual Correction Policy}
In this section, we describe the policies for recommending 
errors to be manual corrected. When making use of human correction, 
some of errors have a greater impact on 
accuracy if they are corrected. The reason is some similar errors 
occur frequently. Which errors are recommended to a user 
for correction will affect the accuracy and the 
number of corrections that the user has to made. 

\paragraph{Random}
The baseline for correction recommendation is random 
recommendation. Based on the parsing results, we can randomly 
recommend the errors we found for humans to correct.  

% \subsubsection*{Most Frequently Error Type}

\paragraph{Most Frequent Error Description Elements}
Another more effective correction strategy is to 
recommend the description 
elements that contain the most frequent errors. For a set of images 
in similar formats and the corresponding ODL descriptions, 
we discovery which elements in the description are more likely 
to be parsed with errors. For those elements, similar errors 
are more likely to happen since the descriptions for them are the 
same. Consequently, such recommendations are more effective
than a random recommendation. 

% \end{enumerate}
