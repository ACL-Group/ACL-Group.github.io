\subsection{Evaluation of Patterns}
\label{EvalPatterns}

The pattern evaluation is a key step of \emph{PPISnowball} system. "Bad" patterns might extract erroneous tuples that in turn might bring about even more "bad" patterns in the next \emph{PPISnowball} iteration. To avoid Snowball evolving into "avalanche", we expect to eliminate patterns that tends to generate wrong triplets, in other words, we prefer to highlight patterns with high selectivity. Thus, all triplets matching one specific pattern have to be taken into consideration, and put together to weigh the selectivity of that pattern.

Since a pattern is expected to occur frequently, we use a preliminary filter to eliminate patterns which is supported by less than $\mathcal {T}_{sup}$ triplets. Then, we calculate the \emph{confidence} by associating all tuples included in triplets, regardless of their current status (Positive, Negative, Unknown).\\

\textbf{Definition} The confidence of a Pattern \emph{P} is:

\begin{equation}
\begin{aligned}
&Conf(P)= \frac{W_{pos}*P.pos}{W_{pos}*P.pos + W_{neg}*P.neg + W_{unkn}*P.unkn}
\label{eq:conf}
\end{aligned}
\end{equation}

\emph{where P.pos, P.neg and P.unkn refer to the number of positive, negative and unknown triplets matching Pattern P respectively; $W_{pos}$, $W_{neg}$ and $W_{unkn}$ are the weighting coefficient correspondingly.}\\

Considering \emph{P.unknown} is highly possible to be very large, compared to initial size of positive and negative seed tuples set, the \emph{confidence} is inclined to be biased by the overlarge denominator in equation of Conf(P). To make those patterns which possess more positive triplets stand out, one alternative approach is use the \emph{RlogF confidence} derived from the evaluation of extraction patterns generated by the Autoslog-TS information system\cite{DBLP:conf/aaai/Riloff96} as follows.\\

\textbf{Definition} The RlogF confidence of a Pattern \emph{P} is:

\begin{equation}
\begin{aligned}
Conf_{RlogF}(P)=Conf(P)*\log_{2}(P.positive+1)
\end{aligned}
\end{equation}

\emph{Here we use $\log_{2}(P.positive+1)$ rather than $\log_{2}(P.positive)$ to avoid the case of zero.} \\

Finally, since the selectivity of patterns would surely deteriorate through the process of \emph{PPISnowball} iterations, we should attach importance to the pattern confidence learnt from previous iterations as well. That is to say, the final pattern confidence is the weighted average confidence between the one achieved at current iteration and the one previous iterations. To be precise, the ultimate confidence of a Pattern \emph{P} is:

\begin{equation}
\begin{aligned}
Conf(P)&=Conf_{new}(P)*W_{updt}+ \\
&Conf_{old}(P)*(1-W_{updt})
\label{eq:ultraConf}
\end{aligned}
\end{equation}

The parameter $W_{updt}$ stands for the learning rate, if $W_{updt}<0.5$, that means \emph{PPISnowball} system put higher value on old patterns or in other words, look down on new triplets extracted at current iteration.
