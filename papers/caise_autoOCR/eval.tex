\section{Experimental Results}
\label{sec:eval}
In this part, we first show our datasets and methods of preprocessing. Then we give our experimental results of extraction accuracy and incremental correction.

\subsection{Dataset and Preprocessing}
%\JY{
%The dataset that we used for evaluation comes from real life ECG reports. 
%These reports come from different hospitals recorded at different times
%and they can be divided into many different formats. 
%For our experiment, we choose four different formats. 
%The examples about these formats are shown in \figref{fig:dataset}.
%One of the reason that we choose images in these four formats is 
%these four formats have the largest number of images. 
%Another reason is they contain different attributes, languages, and so on.
%}
The dataset which we use are from real ECG reports, which are recorded at different times and different hospitals. Those reports can be divided into several different categories. We chose four typical kinds of reports which have lots of images and contain many useful information such as attributes, languages so that we could extract more data from them.
%(see those reports in \figref{fig:dataset}).
% and they can be divided into four different formats with examples shown in \figref{fig:dataset}. 
The statistics about our dataset are 
shown in \tabref{tab:statis}; 

%\begin{figure}[ht]
%\centering
%\subfloat[Format 1]{
%\label{fig:dataset:1}
%\epsfig{file=figure/f1.eps, width=0.3\columnwidth}
%}
%% \hfill
%\subfloat[Format 2]{
%\label{fig:dataset:2}
%\epsfig{file=figure/f2.eps, width=0.3\columnwidth}
%}
%\hfill
%\subfloat[Format 3]{
%\label{fig:dataset:3}
%\epsfig{file=figure/f3.eps, width=0.3\columnwidth}
%}
%\subfloat[Format 4]{
%\label{fig:dataset:4}
%\epsfig{file=figure/f4.eps, width=0.3\columnwidth}
%}
%\caption{Examples for Four Kinds of ECGs}
%\label{fig:dataset}
%\end{figure}



As the examples shown, these ECG images are in different colors 
and have many noises like grid lines. 
Because these variations and noises
may affect the performance of the OCR engine, 
we preprocess the images to derive a clean version. 
%The detailed techniques are discussed in \secref{sec:discuss}. 

% we use auto thresholding to 
% preprocess the images to remove the noisy lines and 
% turn the color images into black and white. 
% An example of the preprocessing result is shown in \figref{fig:preprocess}. 
% Auto thresholding is to segment the images based on the colour 
% features automatically. In our system we make use of the tool 
% ImageJ\cite{schneider2012671} to do the preprocessing.  
% \begin{figure}[ht]
% \centering
% \subfloat[Before Preprocessing]{
% \label{fig:preprocess:1}
% \epsfig{file=figure/f1.eps, width=0.48\columnwidth}
% }
% % \hfill
% \subfloat[After Preprocessing]{
% \label{fig:preprocess:2}
% \epsfig{file=figure/pref1.eps, width=0.48\columnwidth}
% }
% \caption{Results of Preprocessing}
% \label{fig:preprocess}
% \end{figure}

\subsection{Extraction Accuracy}
Next, we compare our method with three other existing methods.
The first and most naive method for information extraction from medical images 
is to write a simple parser for the XML results of the OCR engine. 
We consider this approach to be the baseline for 
evaluation. In this parser, we didn't include any fuzzy matching 
strategies, but instead extracted all results using exact matches. 

The second competing method involves marking all zones of interest on images and 
getting all the OCR results in them. To adjust the small changes of 
zone areas between images, a marker zone is set so that 
all other zones of interest can be adjusted according to it as
a reference point. 
An example image after being marked with the zones of interest 
and the marker zone is shown in \figref{fig:othermethods} (Zones of interest 
are in blue and the marker zone is in red).

\begin{figure*}[ht]
\centering
\subfloat{
%% \label{fig:hc:1}
\epsfig{file=figure/17_zOCR.eps, width=5cm}
%\caption{Image Marked With Zones}
}
% \hfill
% \centering
\subfloat{
% \label{fig:hc:2}
\epsfig{file=figure/17_pl.eps, width=5cm}
%\caption{Page Layout Analysis Result}
}
\caption{Other approaches(1.Image Marked With Zones 2.Page Layout Analysis Result)}
\label{fig:othermethods}
\end{figure*}

%\begin{figure}[ht]
%\centering
%\epsfig{file=figure/17_zOCR.eps, width=0.5\columnwidth}
%\caption{Image Marked With Zones}
%\label{fig:zOCR}
%\end{figure}

The third approach is to use the page layout analysis technique. 
The page layout analysis technique is used to determine where the text 
resides on a page \cite{o1993document}\cite{kanungo2003stochastic} \cite{bartoli2014semisupervised}\cite{cai2003vips}. 
By using the page layout analysis technique, the hierarchy of physical components 
can be generated which we can use to match them to the predefined 
hierarchy of logical components. An example result of our page layout 
analysis is shown in \figref{fig:othermethods}.

%\begin{figure}[ht]
%\centering
%\epsfig{file=figure/17_pl.eps, width=0.5\columnwidth}
%\caption{Page Layout Analysis Result}
%\label{fig:pl}
%\end{figure}

The results of the comparison experiments are shown in \tabref{tab:compare}. 
We only calculated the accuracies for extracting the results of 
variables since we already know the exact values of constant 
expressions. Based on our experiment, our method of fuzzy matching 
outperforms all other methods on all 4 types of ECGs. 
%Here are reasons for that:
%Zonal OCR's performance will be highly affected by the setting of zones of interest. As for page 
%layout analysis, the performance will be affected by the granularity of the page layout unit and the misrecognition will affect the matching with the predefined 
%hierarchy of logical components. .
% The performance of 
%zonal OCR will be highly affected by the setting of zones of interest. 
%If the zones of interest are too large, it's possible that noises will 
%also be extracted, while if the zones of interest are too small, results 
%can be incomplete. For page layout analysis, the performance will be 
%affected by the granularity of the page layout unit and the 
%misrecognition will affect the matching with the predefined 
%hierarchy of logical components. For our method, the smallest 
%unit is word in text so our description can be very accurate. 
%At the same time, the fuzzy matching strategies also enable 
%the description to omit some unnecessary details.
% \KZ{Need focus on explaining why we are only slightly better, and what are
% the problems of the other three methods, despite that their accuracies are
% not that bad! e.g., efforts to mark the zones, I'm still not convinced
% how come without fuzzy match, zonal methods can be so good since the dist
% between the marker zone and the interesting zones can be slightly off in each
% image.}   

%Even though the two above competing approaches seem just marginally outperformed
%by our fuzzy matching approach, these two approaches have their own 
%important limitations. 
%In a zonal OCR, it's important to adjust the zones of interest 
%based on the marker zone. Misrecognition of the marker 
%is disasterous, as all the extracted information will be incorrect. 
%The other approach, page layout analysis, requires analyzing 
%the text boxes in images before conducting logical labeling. 
%If the text boxes are recognized incorrectly, some of the
%important information may be omitted from output. 
%As shown in \figref{fig:errorpl}, 
%text box recognition errors cause the OCR to overlook the unit and 
%other valuable information. 
%However, the fuzzy match design of our system can 
%tolerate these types of errors that the OCR engine made. 
%We seek to find an optimization solution which can extract 
%correct information as much as possible. 
%

%\begin{figure}[ht]
%\centering
%\epsfig{file=figure/2_pl.eps, width=0.5\columnwidth}
%\caption{An Error Page Layout Analysis Result}
%\label{fig:errorpl}
%\end{figure}

\begin{table}[!hbp]
\RawFloats
\centering

\begin{minipage}[b]{0.45\hsize}\centering
\tiny

%\scalebox{0.5}{
\begin{tabular}{|c|c|c|c|c|}
\hline
Format & 1 & 2 & 3 & 4\\
\hline \hline
Number of Images & 124 & 113 & 102 & 97\\ 
\hline
Number of Attributes per Image & 17 & 16 & 18 & 15 \\
\hline
\end{tabular}
\caption{Statistics for The Dataset}
\label{tab:statis}
%\end{table}
\end{minipage}
\hfill
\begin{minipage}[b]{0.45\hsize}\centering
%\begin{table}[!hbp]
\tiny
\begin{tabular}{|c|c|c|c|c|}
\hline
Format & 1 & 2 & 3 & 4\\
\hline \hline
Exact Match & 58.8\% & 56.3\% & 61.1\% & 53.4\% \\
\hline
Zonal OCR & 81.2\% & 79.8\% & 81.7\% & 80.6\% \\
\hline
Page Layout & 79.7\% & 80.2\% & 81.2\% & 81.1\% \\
\hline
Our Fuzzy Match & {\bf 85.5\%} & {\bf 83.8\%} & {\bf 84.9\%} & {\bf 84.0\%}\\ 
\hline
\end{tabular}
\caption{Accuracy For Different Methods}
\label{tab:compare}
\end{minipage}

\end{table}

\subsection{Incremental Manual Correction}
%In this section, we compare the performance of 
%the human correction part in our system. 
%Another important part of our system is the human correction 
%process. By making use of the human power, we can correct 
%the errors that occur due to the OCR engine. 
We compare two main policies for recommending errors for manual correction, 
which involve random recommendation and most frequent error 
description element recommendation. The relationship between the 
amount of corrections and the accuracy of different types of 
ECGs are shown in \figref{fig:humancorr}. For random correction, 
we randomly suggest that some errors be corrected each time. 
The accuracy of random correction is calculated by averaging 
the results 100 times. For the most frequent error 
description element recommendation, 
corrections for most frequently made errors will be suggested first. 

\begin{figure*}[ht]
\centering
\subfloat{
%% \label{fig:hc:1}
\epsfig{file=figure/hcf1.eps, width=3.5cm}
}
% \hfill
% \centering
\subfloat{
% \label{fig:hc:2}
\epsfig{file=figure/hcf2.eps, width=3.5cm}
}
\hfill
% % \centering
\subfloat{
% \label{fig:hc:3}
\epsfig{file=figure/hcf3.eps, width=3.5cm}
}
% % \centering
\subfloat{
% \label{fig:hc:4}
\epsfig{file=figure/hcf4.eps, width=3.5cm}
}
\caption{Comparison of Different Correction Recommendation}
\label{fig:humancorr}
\end{figure*}

% \KZ{Need to modify the figs so that lines don't touch into
% the legends, ad the caption don't overlap with the figs.}

As shown in \figref{fig:humancorr}, the more corrections we make, the better accuracy 
we can get. 
The improvement to the accuracy rate is better 
when using the most frequent recommendation, compared with random 
recommendation because using the most 
frequent recommendation is more efficient in making use of human judgment. 

%The reason is that, based on our learning model, 
%our system tends to get less useful information 
%from the correction. The corrections that will affect 
%the whole system should be made early, so 
%unusable corrections will be left. 
% \KZ{Need to explain why there's only limited improvement after 15 corrections.
% Maybe because the data size is not big enough, so there's not many repeated
% errors?}
%We also find that with more corrections made, the improvement of 
%accuracy tends to saturate, especially with regard to the most frequent error strategy. 
%The improvement of accuracy is limited after 15 corrections. 
%The main reason is that there are not many repeated errors due to 
%the small size of the data set and furthermore, our system can only make corrections 
%according to the correction model, which is sensitive to such errors.

% \begin{enumerate}
% \item Compare the description code with generated code to show our language is a simple one;
% \item Compare the accuracy with baseline, exact match on the OCR results, to show our language can tolerate the noises and errors;
% \item Compare the performance on different image formats;

% \item Compare the accuracy between our approach and others, including using related image position;


% \item Experiments about the relationship of the accuracy rate 
% and the number of errors corrected;

% \begin{table}[!hbp]
% \centering
% \caption{Most Frequent}
% \begin{tabular}{|c|c|c|c|c|}
% \hline
% Type & 1 & 2 & 3 & 4\\
% \hline
% Accuracy(0 errors) & 85.5\% & 83.8\% & 84.9\% & 84.0\%\\ 
% \hline
% Accuracy(1 errors) & 85.7\% & 84.0\% & 85.0\% & 84.2\%\\ 
% \hline
% Accuracy(5 errors) & 86.2\% & 84.6\% & 85.6\% & 84.8\% \\
% \hline
% Accuracy(10 errors) & 86.6\% & 85.2\% & 86.2\% & 85.5\% \\
% \hline
% Accuracy(15 errors) & 86.8\% & 85.7\% & 86.6\% & 85.9\% \\
% \hline
% % \caption{Most Frequent}
% \end{tabular}
% \end{table}

% 0 85.5 85.5
% 1 85.7 85.5
% 5 86.2 85.7
% 10 86.6 86.0
% 15 86.8 86.2

% 0 83.8 83.8
% 1 84.0 83.9
% 5 84.6 84.1
% 10 85.2 84.4
% 15 85.7 84.7

% 0 84.9 84.9
% 1 85.0 84.9
% 5 85.6 85.1
% 10 86.2 85.4
% 15 86.6 85.7

% 0 84.0 84.0
% 1 84.2 84.1
% 5 84.8 84.4
% 10 85.5 84.7
% 15 85.9 85.1

% \begin{table}[!hbp]
% \centering
% \caption{Random}
% \begin{tabular}{|c|c|c|c|c|}
% \hline
% Type & 1 & 2 & 3 & 4\\
% \hline
% Accuracy(0 errors) & 85.5\% & 83.8\% & 84.9\% & 84.0\%\\ 
% \hline
% Accuracy(1 errors) & 85.5\% & 83.9\% & 84.9\% & 84.1\%\\ 
% \hline
% Accuracy(5 errors) & 85.7\% & 84.1\% & 85.1\% & 84.4\% \\
% \hline
% Accuracy(10 errors) & 86.0\% & 84.4\% & 85.4\% & 84.7\% \\
% \hline
% Accuracy(15 errors) & 86.2\% & 84.7\% & 85.7\% & 85.1\% \\
% \hline
% % \caption{Random}
% \end{tabular}
% \end{table}


% \begin{figure}
% \centering
% \subfloat[ECG1]{
% \label{fig:hcre:a}
% \epsfig{file=figure/f1.eps, width=0.48\columnwidth}
% }
% \hfill
% \subfloat[ECG2]{
% \label{fig:hcre:b}
% \epsfig{file=figure/f2.eps, width=0.48\columnwidth}
% }
% \hfill
% \subfloat[ECG3]{
% \label{fig:hcre:c}
% \epsfig{file=figure/f3.eps, width=0.48\columnwidth}
% }
% \hfill
% \subfloat[ECG4]{
% \label{fig:hcre:d}
% \epsfig{file=figure/f4.eps, width=0.48\columnwidth}
% }
% % \caption{E}
% \label{fig:hcre}
% \end{figure}

% \item Compare different strategies for correcting errors, including most frequent error elements, most frequent error types.
% \end{enumerate}
