\documentclass[sigconf,anonymous]{acmart}
\settopmatter{printacmref=true}

%%
%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
	\providecommand\BibTeX{{%
			\normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
\setcopyright{acmcopyright}
\copyrightyear{2020}
\acmYear{2020}
%\acmDOI{10.1145/1122445.1122456}

%% These commands are for a PROCEEDINGS abstract or paper.
\acmConference[CIKM '20]{The 29th ACM International Conference on Information and Knowledge Management}{October  19--23, 2020}{Galway, Ireland}
\acmBooktitle{The 29th ACM International Conference on Information and Knowledge Management (CIKM '20), October 19--23, 2020, Galway, Ireland}
\acmPrice{15.00}
%\acmISBN{978-1-4503-XXXX-X/18/06}
\usepackage{times}
\usepackage{latexsym}
\renewcommand{\UrlFont}{\ttfamily\small}

% This is not strictly necessary, and may be commented out,
% but it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

%\aclfinalcopy % Uncomment this line for the final submission
%\def\aclpaperid{***} %  Enter the acl Paper ID here

%\setlength\titlebox{5cm}
% You can expand the titlebox if you need extra space
% to show all the authors. Please do not make the titlebox
% smaller than 5cm (the original size); we will check this
% in the camera-ready version and ask you to change it back.

\newcommand\BibTeX{B\textsc{ib}\TeX}
\usepackage{url}

\usepackage{soul}
\usepackage{algorithm}
\usepackage{algorithmic}
\urlstyle{same}

\usepackage{helvet}

\usepackage{courier}
\usepackage{color}
\usepackage{amsmath,amsfonts,amsthm,amsopn}
%\usepackeage{amssymb}
\usepackage{color}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{diagbox}
\usepackage{array}
\usepackage{multicol}
%\usepackage{threeparttable}
\usepackage{epstopdf}
\usepackage{listings}
\usepackage{multirow}
%\usepackage{subfigure}
\theoremstyle{definition}

\usepackage[inline]{enumitem}

%\usepackage[UTF8]{ctex}
\usepackage{subfig}
\usepackage{CJK}
\usepackage{tabulary}
\newcolumntype{P}[1]{>{\centering\arraybackslash}p{#1}}
\usepackage{titlesec}
\usepackage{tablefootnote}
\usepackage{threeparttable}
\usepackage{cleveref}

\setcounter{secnumdepth}{3}


\newcommand{\secref}[1]{Section \ref{#1}}
\newcommand{\figref}[1]{Figure \ref{#1}}
\newcommand{\eqnref}[1]{Eq. (\ref{#1})}
\newcommand{\tabref}[1]{Table \ref{#1}}
\newcommand{\exref}[1]{Example \ref{#1}}
\newcommand{\cut}[1]{}
\newcommand{\tabincell}[2]{\begin{tabular}{@{}#1@{}}#2\end{tabular}}
\DeclareMathOperator*{\argmax}{argmax} % thin space, limits underneath in displays
\DeclareMathOperator*{\argmin}{argmin}

\newcommand{\KZ}[1]{\textcolor{blue}{Kenny: #1}}
\newcommand{\EVE}[1]{\textcolor{red}{eve: #1}}
\makeatletter 
\newcommand\figcaption{\def\@captype{figure}\caption} 
\newcommand\tabcaption{\def\@captype{table}\caption} 
\makeatother

\title{Active Learning of Many-class Short Text Classification}


\author{Yuyi Gu}
\email{guyuyi@sjtu.edu.cn}
\affiliation{%
	\institution{Shanghai Jiao Tong University}
}
\author{Qianzi Liao}
\email{liaoqz@sjtu.edu.cn}
\affiliation{%
	\institution{Shanghai Jiao Tong University}
}
\author{Kenny Q. Zhu}
\email{kzhu@cs.sjtu.edu.cn}
\affiliation{%
	\institution{Shanghai Jiao Tong University}
}

\setlength{\textfloatsep}{5pt}

\begin{document}
\begin{abstract}
% \EVE{shall we change all the `method' to `strategy'?}
Active learning has been previously applied to few-class classification tasks
with success. This paper studies the effectiveness of active learning on
short-text classification with many classes which is presumably more difficult.
We apply the most popular query strategies plus some of our own
novel strategies with 4 commonly-used text classification models, 
namely fastText, CNN, LSTM and BERT, and evaluate them on a range of 
English and Chinese datasets. We discover that active learning 
works better on short-text classification with more classes and 
especially well with fastText which is simple to implement and more efficient. 
Our results provide a practical insight towards 
better understanding of interaction between active learning, 
the text classification model and the characteristics of task.   
%the increase of classes and different strategies. 
%We further propose a new query strategy along with frequency 
%adjustment feature which can be applied to earlier methods and 
%yields good results on many-class text classification.
\end{abstract}
\keywords{active learning, text classification, many-class, deep model}

\maketitle



\input{intro}
%\input{preliminaries}
\input{approach}
\input{eval}
% \input{leyan}
\input{related}
\input{conclude}

%\bibliography{emnlp2020}
\bibliography{active}
\bibliographystyle{abbrv}
% \bibliographystyle{ACM-Reference-Format}


\end{document}
