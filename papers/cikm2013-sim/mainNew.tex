\documentclass[fleqn]{sig-alternate}
%\documentclass{vldb}
%\documentclass[10pt,conference,letterpaper]{IEEEtran}
\usepackage{amsmath}
\usepackage{multicol}
\usepackage{algorithm}
\usepackage{algorithmic}
%\usepackage{hyperref}%[colorlinks, citecolor=blue, hyperindex]
\usepackage{graphicx}
\usepackage{url}
\usepackage{color}
%\usepackage{algorithm2e}
%\usepackage{subfigure}
\graphicspath{{figures/}}

%\usepackage{caption}
\begin{document}
\title{Clustering Concepts for Semantic Similarity between Terms}
\author{%
% author names are typeset in 11pt, which is the default size in the author block
{Peipei Li{\small $~^{\#*1}$}, Haixun Wang{\small $~^{*2}$}, Kenny Zhu{\small $~^{\dag3}$}, Zhongyuan Wang{\small $~^{*4}$}, Xindong Wu{\small $~^{\#5}$} } %
% add some space between author names and affils
\vspace{1.6mm}\\
\fontsize{10}{10}\selectfont\itshape
$~^{\#}$Hefei University of Technology\\
%Hefei, China\\
\fontsize{9}{9}\selectfont\ttfamily\upshape
$~^{1}$v-pli@microsoft.com\\
\fontsize{9}{9}\selectfont\ttfamily\upshape
$~^{5}$xwu@uvm.edu
% add some space between email and affil
\vspace{1.2mm}\\
\fontsize{10}{10}\selectfont\rmfamily\itshape
$~^{*}$Microsoft Research Asia\\
\fontsize{9}{9}\selectfont\ttfamily\upshape
$~^{2}$haixunw@microsoft.com\\
\fontsize{9}{9}\selectfont\ttfamily\upshape $~^{3}$Zhy.Wang@microsoft.com\\
\fontsize{10}{10}\selectfont\rmfamily\itshape
$~^{\dag}$Shanghai Jiao Tong University\\
%, Shanghai, China\\
\fontsize{9}{9}\selectfont\ttfamily\upshape
$~^{4}$kzhu@cs.sjtu.edu.cn\\
}
\maketitle
\begin{abstract}
Semantic similarity between terms is essential for a variety of text analytics and text understanding applications. To measure the semantic similarity between terms, there are mainly two approaches, namely the knowledge resource based and the distributional context based methods. However, these approaches are more suitable for the measuring of the semantic similarity between words, and the scalability problems due to manual tagging and corpora dependency and availability also limit their applicability.
Contrary to existing techniques, we propose a lightweight and effective approach for the semantic similarity between terms with any multi-word expression. To extend the data coverage, we first selectively collect the semantic contexts of terms from the Web data. Second, to measure the semantic similarity between terms accurately, we introduce the clustering approach to identify potential senses of terms instead of manually tagging, and then compare the term's sense based contexts to get the semantic similarity between terms. Extensive studies demonstrate our approach can accurately measure the semantic similarity between terms with multi-word expressions and ambiguity. The pearson correlation coefficient can be improved by 0.5 at least compared to the state-of-the-art approaches for the semantic similarity measurement between terms. Meanwhile, our approach is much more efficient and can be applied on measuring semantic similarity with a large scale of pairs.
\end{abstract}

% , and knolnumber
  % of conceptualization In order Meanwhile, in a massive corpus, a
  % substantial fraction of extractions appear infrequently. It is hence
  % a challenge for traditional information extraction techniques to
  % assess these large scale sparse extractions. Motivated by this
  % challenge, this paper shows how to assess the correctness of sparse
  % extractions by utilizing the semantic context-based assessment
  % approach. In our proposed method, we adopt three different semantic
  % contexts. Firstly, we use the conceptualization method to get a set
  % of representative concepts from the sentences as the
  % context. Secondly, we extract the attributes as the
  % context. Thirdly, we collects the isA concepts as the context. In
  % terms of these semantic contexts, we implement a similarity
  % evaluation to rank extractions by the likelihood that they are
  % correct. Lastly, we apply our approach into the Hearst pattern
  % database of Probase, which contains 2425558 concepts and 15805500
  % extractions extracted using Hearst patterns from 1.68 billion web
  % pages and two years' worth of Microsoft Bing's search
  % log.


% A category with the (minimum) three required fields
%\category{H.4}{Information Systems Applications}{Miscellaneous}
%A category including the fourth, optional field follows...
%\category{D.2.8}{Software Engineering}{Metrics}[complexity measures, performance measures]

%\terms{Theory}

%\keywords{ACM proceedings, \LaTeX, text tagging} % NOT required for Proceedings

\input{introductionNew.tex}
\input{BaselineApproach}
%\input{Knowledge}
%\input{semanticSimilarityFormula}
\input{Clustering}
\input{OurAlgorithm}
\input{Experiments}
\input{RelatedWorkShort}
\input{Conclusions}
%\input{ThreeExamples}
%
% The following two commands are all you need in the
% initial runs of your .tex file to
% produce the bibliography for the citations in your paper.
\bibliographystyle{abbrv}
\bibliography{context}  % sigproc.bib is the name of the Bibliography in this case
% You must have a proper ".bib" file
%  and remember to run:
% latex bibtex latex latex
% to resolve all references
%
% ACM needs 'a single self-contained file'!
%
%APPENDICES are optional
%\balancecolumns
%\appendix
%Appendix A
%\balancecolumns
% That's all folks!
%\end{multicols}
\end{document}
