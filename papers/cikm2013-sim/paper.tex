\documentclass{sig-alternate-2013}%{acm_proc_article-sp}%{sig-alternate}%
%\documentclass{vldb}
%\documentclass[10pt,conference,letterpaper]{IEEEtran}
\usepackage{amsmath}
\usepackage{multicol}
%\usepackage{algorithm}
\usepackage{algorithm}
%\usepackage[ruled,vlined]{algorithm}
\usepackage{algorithmic}
%\usepackage{hyperref}%[colorlinks, citecolor=blue, hyperindex]
\usepackage{graphicx,subfigure}
\usepackage{url}
\usepackage{color}
%\usepackage{algorithm2e}
%\usepackage{subfigure}
\graphicspath{{figures/}}
\newcommand{\KZ}[1]{\textcolor{blue}{[KZ: #1]}}
\renewcommand{\sim}[2]{\textsc{sim}(\textit{#1}, \textit{#2})}
\newcommand{\pair}[2]{$\langle #1, #2 \rangle$}
\newcommand{\LP}[1]{\textcolor{red}{[LP: #1]}}
\newcommand{\secref}[1]{Section \ref{#1}}
\newcommand{\figref}[1]{Figure \ref{#1}}
\newcommand{\eqnref}[1]{Eq. (\ref{#1})}
\newcommand{\argmin}{\operatornamewithlimits{argmin}}
\newcommand{\argmax}{\operatornamewithlimits{argmax}}
%\newcommand{\exref}[1]{Example \ref{#1}}

%\usepackage{caption}
\newfont{\mycrnotice}{ptmr8t at 7pt}
\newfont{\myconfname}{ptmri8t at 7pt}
\let\crnotice\mycrnotice%
\let\confname\myconfname%

\permission{Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from Permissions@acm.org.
}
\conferenceinfo{CIKM'13,}{October 27 - November 01 2013, San Francisco, CA, USA.}
\copyrightetc{Copyright 2013 ACM \the\acmcopyr}
\crdata{978-1-4503-2263-8/13/10\ ...\$15.00.\\
http://dx.doi.org/10.1145/2505515.2505567}

\clubpenalty=10000
\widowpenalty = 10000

\begin{document}
\title{Computing Term Similarity by Large Probabilistic isA Knowledge}
%\author{%
%% author names are typeset in 11pt, which is the default size in the author block
%{Peipei Li{\small $~^{\#*1}$}, Haixun Wang{\small $~^{*2}$}, Kenny Q. Zhu{\small $~^{\dag3}$}, Zhongyuan Wang{\small $~^{*2}$}, Xindong Wu{\small $~^{\ddag4}$} } %
%% add some space between author names and affils
%\vspace{1.6mm}\\
%\fontsize{10}{10}\selectfont\itshape
%$~^{\#}$Hefei University of Technology\\
%%Hefei, China\\
%\fontsize{9}{9}\selectfont\ttfamily\upshape
%$~^{1}$v-pli@microsoft.com\\
%% add some space between email and affil
%\fontsize{10}{10}\selectfont\rmfamily\itshape
%$~^{*}$Microsoft Research Asia\\
%\fontsize{9}{9}\selectfont\ttfamily\upshape
%$~^{2}$\{haixunw,zhy.wang\}@microsoft.com\\
%\fontsize{10}{10}\selectfont\rmfamily\itshape
%$~^{\dag}$Shanghai Jiao Tong University\\
%%, Shanghai, China\\
%\fontsize{9}{9}\selectfont\ttfamily\upshape
%$~^{3}$kzhu@cs.sjtu.edu.cn\\
%\fontsize{10}{10}\selectfont\rmfamily\itshape
%$~^{\ddag}$University of Vermont\\
%\fontsize{9}{9}\selectfont\ttfamily\upshape
%$~^{4}$xwu@uvm.edu }
\numberofauthors{5} %  in this sample file, there are a *total*
% of EIGHT authors. SIX appear on the 'first-page' (for formatting
% reasons) and the remaining two appear in the \additionalauthors section.
%
\author{
% You can go ahead and credit any number of authors here,
% e.g. one 'row of three' or two rows (consisting of one row of three
% and a second row of one, two or three).
%
% The command \alignauthor (no curly braces needed) should
% precede each author name, affiliation/snail-mail address and
% e-mail address. Additionally, tag each line of
% affiliation/address with \affaddr, and tag the
% e-mail address with \email.
%
% 1st. author
\alignauthor
Peipei Li\titlenote{Peipei Li was a student intern in Microsoft Research Asia when the paper was
developed.}\\
       \affaddr{Hefei University of Technology}\\
       \affaddr{Hefei, China, 230009}\\
       \email{peipeili\_hfut@163.com}
% 2nd. author
\alignauthor
Haixun Wang\\%\titlenote{The secretary disavows any knowledge of this author's actions.}\\
       \affaddr{Microsoft Research Asia}\\
       \affaddr{Beijing, China, 100080}\\
       \email{haixunw@microsoft.com}
% 3rd. author
\alignauthor
Kenny Q. Zhu\\%\titlenote{This author is the one who did all the really hard work.}\\
       \affaddr{Shanghai Jiao Tong University}\\
       \affaddr{Shanghai, China}\\
       \email{kzhu@cs.sjtu.edu.cn}
\and  % use '\and' if you need 'another row' of author names
% 4th. author
\alignauthor Zhongyuan Wang\\
       \affaddr{Renmin University of China}\\
       \affaddr{Beijing, China, 100872}\\
       \affaddr{Microsoft Research Asia}\\
       \affaddr{Beijing, China, 100080}\\
       \email{zhy.wang@microsoft.com}
% 5th. author
\alignauthor Xindong Wu\\
       \affaddr{University of Vermont}\\
       \affaddr{Vermont, U.S.A., 05405}\\
       \email{xwu@uvm.edu}
}
% There's nothing stopping you putting the seventh, eighth, etc.
% author on the opening page (as the 'third row') but we ask,
% for aesthetic reasons that you place these 'additional authors'
% in the \additional authors block, viz.
%\additionalauthors{Additional authors: John Smith (The Th{\o}rv{\"a}ld Group,
%email: {\texttt{jsmith@affiliation.org}}) and Julius P.~Kumquat
%(The Kumquat Consortium, email: {\texttt{jpkumquat@consortium.net}}).}
%\date{30 July 1999}
% Just remember to make sure that the TOTAL number of authors
% is the number that will appear on the first page PLUS the
% number that will appear in the \additionalauthors section.
\maketitle
\begin{abstract}
  Computing semantic similarity between two terms is essential for a
  variety of text analytics and understanding applications.
%  Currently, there are two main approaches for this task,
%  namely the knowledge based and the corpus based approaches.
 However, existing approaches are more suitable for
  semantic similarity between words rather than the more general multi-word
  expressions (MWEs), and they do not scale very well.
  % and scalability issues from manual tagging as well
  %as corpora dependency and availability also limit their applicability.
  %Contrary to these existing techniques,
  Therefore, we propose a lightweight and effective approach
  for semantic similarity using a large scale semantic network
  automatically acquired from billions of web documents.
  %The semantic
  %network consists of millions of concepts, which explicitly model the
  %context of semantic relationships.
  Given two terms, we map them into the concept space, and compare
  their similarity there. Furthermore, we introduce a clustering approach to
  orthogonalize the concept space in order to improve the accuracy of
  the similarity measure. %  identify potential senses of terms instead
  % of manually tagging, and then compare the term's sense based
  % contexts to get the semantic similarity between terms.
  Extensive studies demonstrate that our approach can accurately
  compute the semantic similarity between terms with MWEs and ambiguity,
  and significantly outperforms 12 competing methods.
%  Comparison with 12 similarity methods
%  shows that our approach on average outperforms the best existing
%  method by 17.6\% on word pairs and 34.6\% on MWEs
%  in terms of {\color{red}{Pearson Correlation Coefficient}} in similarity, and reaches an average of 0.77
%  on word pairs and 0.67 on MWE pairs by the Pearson Correlation Coefficient.
%
%  The pearson correlation coefficient is
%  improved by the range of [0.07, 0.41] \LP{The difference of PCC between our RCP approach with the best one of other competing methods is 0.056, 0.03, 0.105 respectively on three data sets while the PCC in RCP is 0.921, 0.725, 0.735 respectively on three data sets. The improvement percent is 0.065, 0.043 and 0.167.}compared to the state-of-the-art approaches
%  for the semantic similarity measurement between terms.
%  Meanwhile, our approach is very efficient and can be applied on computing
%  semantic similarity in a large scale.
\end{abstract}

% , and knolnumber
  % of conceptualization In order Meanwhile, in a massive corpus, a
  % substantial fraction of extractions appear infrequently. It is hence
  % a challenge for traditional information extraction techniques to
  % assess these large scale sparse extractions. Motivated by this
  % challenge, this paper shows how to assess the correctness of sparse
  % extractions by utilizing the semantic context-based assessment
  % approach. In our proposed method, we adopt three different semantic
  % contexts. Firstly, we use the conceptualization method to get a set
  % of representative concepts from the sentences as the
  % context. Secondly, we extract the attributes as the
  % context. Thirdly, we collects the isA concepts as the context. In
  % terms of these semantic contexts, we implement a similarity
  % evaluation to rank extractions by the likelihood that they are
  % correct. Lastly, we apply our approach into the Hearst pattern
  % database of Probase, which contains 2425558 concepts and 15805500
  % extractions extracted using Hearst patterns from 1.68 billion web
  % pages and two years' worth of Microsoft Bing's search
  % log.


% A category with the (minimum) three required fields
%\category{H.4}{Information Systems Applications}{Miscellaneous}
%A category including the fourth, optional field follows...
%\category{D.2.8}{Software Engineering}{Metrics}[complexity measures, performance measures]

%\terms{Theory}

% A category with the (minimum) three required fields
\category{H.3}{INFORMATION STORAGE AND RETRIEVAL}{Miscellaneous}
%A category including the fourth, optional field follows...
\category{I.2}{Computing Methodologies}{ARTIFICIAL INTELLIGENCE}[Knowledge Representation Formalisms and Methods]

%\terms{Algorithms,Measurement}

\keywords{Term Similarity; Multi-word Expression; Clustering; Semantic Network} % NOT required for Proceedings

%\keywords{ACM proceedings, \LaTeX, text tagging} % NOT required for Proceedings
\input{introductionNew.tex}
\input{knowledge}
\input{BaselineApproach}
%\input{Knowledge}
%\input{semanticSimilarityFormula}
\input{Refined}
\input{Experiments}
\input{RelatedWork}
\input{Conclusions}
\section{Acknowledgments}
This work is supported in part by National 863 Program of China under grant 2012AA011005, the National 973 Program of China under grant
2013CB329604, the Natural Science Foundation of China under grants (61100050, 61273292, 61229301, 61070131, 61273297), the Postdoctoral Science
Foundation of Hefei University of Technology under grant 2013HGBH0025, MOE New Faculty under grant 201100731- 20023, and the US National Science Foundation (NSF) under grant
CCF-0905337.
%\input{ThreeExamples}
%
% The following two commands are all you need in the
% initial runs of your .tex file to
% produce the bibliography for the citations in your paper.
\bibliographystyle{abbrv}
\bibliography{similarity}  % sigproc.bib is the name of the Bibliography in this case
% You must have a proper ".bib" file
%  and remember to run:
% latex bibtex latex latex
% to resolve all references
%
% ACM needs 'a single self-contained file'!
%
%APPENDICES are optional
%\balancecolumns
%\appendix
%Appendix A
%\balancecolumns
% That's all folks!
%\end{multicols}
\end{document}
