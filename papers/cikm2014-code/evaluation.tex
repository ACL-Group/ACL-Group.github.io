\section{Evaluation}
\label{sec:eval}
In this section, we first explain how we prepare the repositories dataset and test data.
set up a series of experiments to evaluate the performance of RMM
comapring with the baseline systems. All the experiments are performed on a 64bit workstation
with with 32GB memory and Intel(R) Core(TM) i7-3770 CPU @ 3.40GHz running ubuntu 12.04
system .
\subsection{Data Preparation}
We evaluate our model with three famous repositories from Github, Minix, Gcc and VLC, which are
all open source repositories with different parameters.

\begin{table}[th]
\centering
\begin{tabular}{|c|c|c|c|}
\hline
Data Set & Files & Commits & Vocabulary\\
\hline \hline
Minix& 7900 & 2900 & 5000 \\
Gcc& 10000 & 10000 & 10000 \\
VLC& 2000 & 10000 & 4000 \\
\hline
\end{tabular}
\caption{Data Sets}
\label{tab:data-par}
\end{table}

For these data sets, we select 300 files and label them with concepts from taxonomy as 
the test set.

Before topic models are applied to source code, several preprocessing steps are generally
taken in an effort to reduce noise and improve the resulting topics.
\begin{itemize}
\item Characters related to the syntax of the programming language (e.g., ``\&\&'') are
removed; programming language keywords (e.g.,``if'', ``while'') are removed.
\item Identifier names are split into multiple parts based on common naming conventions
(e.g., ``oneTwo'', ``one\_two'').
\item Common English-language stopwords (e.g., ``the'', ``it'') are removed.
\item Word lemmatization is applied to find the root of each word (e.g., ``saw'' becomes
``see'').
\item Header files and body files which share the same file name (e.g., ``clock.h'', ``clock.c'') are merged together.
\end{itemize}
The main idea behind these steps is to capture the semantics of the developers' intentions, 
which are thought to be encoded within the identifier names and comments in the
source code. The rest of the source code (i.e., special syntax, language keywords,
and stopwords) are just noise and will not be beneficial to the results of topic models.


\subsection{Code Topic Prediction}
We evaluate the effectiveness of ``RMM'' with ``Labeled-LDA''\cite{ramage-EtAl:2009:EMNLP} comparing with ``TF$+$hESA'', ``RMM$+$hESA'' and ``LDA$+$Labeled-LDA''. 

