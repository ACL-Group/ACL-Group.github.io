\section{Introduction}
\label{sec:intro}
Getting insight of the source code of one project is always a horrible job for the 
readers or even the programmer himself. Some large open source projects like Gcc 
and Linux have thousands of files, it is hard to get what are these codes about in a short time.
GitHub\cite{githuburl} is home to over 11.7 million repositories.
As the availability of open source software repositories
continues to grow, so does the need for tools that can automatically analyze 
these repositories on an increasingly larger
scale. The automated analysis of such repositories is important, 
for instance, to understand software structure, function, 
complexity, and evolution, as well as to identify relationships 
between humans and the software they produce.
Tools to mine source code for functional concepts and organization 
are also of interest to private industry, where they
can be applied to such problems as in-house code reuse and
refactoring.

Many useful tools are developed to help users explore the repositories. Traditional
IDE or text editer like {\it Emacs, gedit} or {\it Notepad}$++$ can show the 
organizing structure of the repositories, but can not help much in finding the 
logical relationships between different parts.
{\it CodeMap} is a repository exploring tool which shows one repository in form of 
world map. CodeMap wants to mining the relationships between code files with the
help of call graph and hierarchical structure of the repositories. However
it only provides a file name, which is not enough to capture the semantics of the 
developers' intentions. It is attrictive if we can automaticly give some semantic 
labels of these code files.

The main problem of this job is there is completely no training data that can
map source code files to a sensible computing taxonomy. {\it Github} just classifies
there codes into different programming languages which is not very useful for 
programmer to understand the repositories.
Some existing data on internet can proveide us some help, like {\it Stack overflow} \cite{sofurl}
which is a famous programming Q\&A website. Almost all of the posts in {\it Stack overflow}
are about programming problems, dissussing source code and even some code directly 
attached. Since what we want is to mine the semantic features of source code files,
it is reliable to used the data of {\it Stack overflow}.

Tagging of Stackoverflow are collabrated by all users who ask questions. 
This kind of label strategy will consume much labering to manage. We perfer 
a more constrained taxonomy, which can serve as a standard one. In this case, 
our job is to find out the significant features of all the elements of this 
taxonomy. In this paper, we extract a hierarchical tags graph from the 
{\it Stack overflow} tagging system.

As far as we know, there is no labeled code repositories data for training
a code taxonomy. Then how can we tackle such kind of problems for repositories?
Unsupervised learning like traditional LDA can explore topics of corpus, but 
it can not tell us what the topics exactly are. If we use other data to train
the taxonomy, the distributions behand them are not same according to the 
special style of code files. In this paper, we solve this problem by trying
to mine the latent natural language parts of code files and use text data from
programming website to train the taxonomy.

Traditional topic models such as PLSA\cite{hofmann1999probabilistic}, LDA
\cite{blei2003latent} mine topics of plain texts. Some researchers have 
already apply LDA to code topic mining \cite{linstead2007mining,tian2009using}.
However, the data contained in repositories are not ``plain'', a 
code file consists codes which may be decided by programming
languages and natural language comments which is writed by the programmers.
We try to design one probabilistic graphical model to mine knowledges from 
repositories which can take advantages of the structure information of them. 

Source code are developed by programmers. They used to 
denote variables and function names with ``meaningful'' words. And plenty of comments 
are telling readers what this code is about. In addition, the commit information created
during the process of development also provide some help to understand the code.
Consider the following examples.
%\myskip
\begin{example}
\label{ex-bear1}
Code on topic ``time''
\insertcode{"Scripts/ccode.c"}{A piece of ``clock.c'' from minix} 
\insertcode{"Scripts/ccode.h"}{A piece of ``clock.h'' from minix} 
\insertcode{"Scripts/commit.c"}{A commit touching ``clock.c''}
\end{example}
This is a piece of C code of ``clock.c'' file from the operating system ``minix'' and a check 
in message written by a developer on it. We can mine some useful knowledge from it. We can 
get a bag of words like ``include'',``kernel'',``realtime'',``clock'',``return'' from codes 
and another bag of words ``get'', ``return'', ``current'', ``wall'', ``time'',``ticks'',``boot'' 
from comment part. In addition, the check in message can provide ``change'', ``argument'', 
``timer'', ``library'',``function''. In these words, ``include'',``return'' are more likely 
determined by programming language. The word ``change'' appers probabily because the check 
in message itself.

In addition, in many languages there are header files which make declaritions 
of variables and methods in corresponding body files, it is obvious that the topic of
header files and the body files are similar.

Finally, we can easily find that the topic of check in messages are related with the 
files it touches. All of these structure information should be explored in a repository model.

In this paper, we propose a new probabilistic graphical model to explore the 
topic of repositories. This model does not regards code files of repository as plain texts, but a 
structural data source. Different parts of the repository like identifiers, comments
header files body files and commits are united together. This model also simulates the 
generating process of the repositories which are more close to the natural process than
traditional topic models. In addition, commits are also additional data that can improve
the performance of the model.

However, topic models can not provide us what the topic is actually is. What we obtain are words 
distributions. This is not straitforward enough. In this case, we built a computing hierarchical
taxonomy based on the {\it Stack overflow} tagging system and developed different methods to make it a 
hierarchical classification system.


This paper makes the following contributions.
\begin{itemize}
\item {\em The repository model explore the structural information.}
We propose a probabilistic graphical model to mining the source code 
repository(see \secref{sec:method}). The specific structural features of 
repositories are involved to mine the topics.


\item {\em We build a standard taxonomy for computing.}
We use the ACM taxonomy in the area of computing to categorize the source 
code files(see \secref{sec:map}). We apply different methods to build a 
hierarical classification system.


\item {\em This taxonomy system can imporve the proformace of repository
tagging.}We show comprehensive evaluation results that demonstrate the
effectiveness of this novel approach(see \secref{sec:eval}).
\end{itemize}

%\subsection{Paper Organization}
%The rest of the paper is structured as follows.
%\secref{sec:framework} presents the framework of our project;
%\secref{sec:implement} discusses some implementation details;
%\secref{sec:eval} demonstrates the experimental results;
%\secref{sec:related} introduces some related work while
%\secref{sec:conclude} concludes the paper.


