\section{Implementation Details}
\label{sec:impl-detail}

We show in detail the steps of model training, which includes candidate generation,
translation model pre-train, and parameter tuning.

\textbf{Candidate Generation}

In order to generate candidate entities for each Chinese mention, we first use several different translation tools including Google Translate ~\footnote{http://translate.google.cn}, Baidu Translate ~\footnote{http://fanyi.baidu.com} and Tencent Translate ~\footnote{http://fanyi.qq.com}. Besides, in order to correctly translate some Chinese traditional words such as ``春分'' which is a Chinese solar term， and can not be translated into ``Spring'', we add Chinese PinYin into our translation step.
After we get all English translations, we use several heuristics to find candidate English entities in Wikipedia for each Chinese mention.
We add all anchor entities whose anchor text exactly match the each translation with confidence $1.0$. Then we remove all the stop words of translations and anchor texts of Wikipedia and do a fuzzy match, which is to calculate the Jaccard similarity to fetch more candidate entities. Their confidence rely on this similarity score.




\noindent
\textbf{Translation Model Pre-Train}

In order to pre-train of the translation model,
we collect a bilingual lexicon of common words using
Bing Translate API~\footnote{http://www.bing.com/translator},
containing 91,346 translation pairs at word level.
Each pair has a confidence score ranging from 0 to 1.
We further select those pairs in which both the Chinese and English word perfectly
match the name of an article in Wikipedia.
Out of 23,863 pairs after filtering, we finally pick all 3655 translation pairs
as our pre-train dataset, with score no smaller than 0.5 for each pair.


\noindent
\textbf{Model Learning and Parameter Tuning}

We implement RankNet~\cite{burges2010ranknet} as the pairwise ranking algorithm.
We tune the following parameters in our joint model:
\begin{itemize}
\item The size of candidates per mention (denoted by $N_{cand}$)
in the range of \{1, 3, 5, 10, 20, 30, 40, 50\}, 
\item The number of negative entity tables (denoted by $N_{tab}$) in \{9, 19, 49, 99\},
\item The dimension of cell, context and overall feature ($d_{cell}$, $d_{cont}$ and $d_{out}$) in \{20, 50, 100, 200\}.
\item The learning rate $\eta$ in \{0.0002, 0.0005, 0.001\},
\item The L1- and L2- regularization $l_1, l_2$ in \{0.0001, 0.0002, 0.0005, 0.001\}.
\end{itemize}

All the parameters are tuned on the validation set, the detail evaluation metric
is discussed in \secref{sec:exp-e2e-results}.


