\section{Evaluation}
\label{sec:evaluation}
Through the above approach, we translate two popular English knowledge graphs: \con and \pro into \zhcon and \zhpro, respectively. In terms of the word embedding, we use the Chinese Wikipedia dump on Aug 1, 2018,  to train word embedding with Word2Vec, where the vocabulary size is 110,978 and the embedding dimension is 300.\footnote{\url{https://code.google.com/archive/p/word2vec/}}
In this section, we evaluate the coverage and accuracy of \zhcon and \zhpro, respectively. The baseline experiment we choose is the direct translation using the translator, and we will denote it as \textbf{DT} later. For example, in the baseline, we translate triple (``ball'', AtLocation, ``ballroom'') by feeding ``ball, ballroom'' into translator, and split the translation result ``球, 舞厅'' into (``球'', AtLocation, ``舞厅'') as the final translation result. Here, we do not provide the translator with the contextualized sentence such as ``the ball is at the ballroom.'', since there are no fixed patterns in the translated sentence, which makes it hard to extract the corresponding part, even for the translated results of one particular relation.\footnote{For example, although ``french chefs are capable of preparing food.'' and ``spider web is capable of catching morning dew.'' share the same structure in English, they will be translated into ``法国厨师有能力准备食物。'' and ``蜘蛛网能够吸引晨露。'' respectively, which requires more than one pattern to split the translation result.}

%\KZ{In addition to the end-to-end eval on the two translated KBs, you also
%need to do some ablation tests. For example, what if you don't do the revision?
%Is there any alternative ways to do revision? You need to show that your way of
%revision is better than straightforward methods.}

\subsection{\zhcon}
\zhcon is a mixed Chinese common sense knowledge graph, which comes from two sources, 
the original Chinese part of \con and the translation result of the English part of \con.

\textbf{Coverage.}
As shown in Table \ref{tab:zh_conceptnet_coverage}, the size of \zhcon is \textbf{4.76} times as large as the original Chinese part of \con, 
which is a substantial increase in quantity. The size of \zhpro is not as 4.91 times as we expected, since there exists overlap in the process of merging.
To our best knowledge, there are no other Chinese knowledge graphs dedicated to common sense, and \zhcon will be the first large one with about 2 million edges, which, we hope, could be a valuable asset for Chinese common sense research.
\begin{table}[ht]
\caption{Size of \zhcon.}
\label{tab:zh_conceptnet_coverage}
\centering
\begin{tabular}{ll}\hline 
\textbf{Dataset}&\textbf{Size}\\\hline
1. Original Chinese Part in \con &438,307(x1.00)\\  
2. Translated English part in \con &1,716,327(x3.91)\\
\zhcon (Merge 1 and 2)&\textbf{2,085,681(x4.76}) \\\hline
\end{tabular}
\end{table}

\textbf{Accuracy.}
To evaluate the quality of \zhcon, 
we randomly sample 500 samples from original Chinese part in \con, 
\text{DT} result of English part in \con, translation result of English part in \con based on our two-steps approach (we denote it as \textbf{OURS} later), and \zhcon (which merges the Chinese part in \con and translated English part in \con of \textbf{OURS}), respectively. 
We ask two annotators to evaluate these samples. 
As Table \ref{tab:conceptnet_accuracy} shows, there exists 1\% error in the original Chinese part of \con, which comes from crowdsourcing errors.
%Since approximately 86\% of the data in \con comes from collaborative datasets, such as Wiktionary, DBpedia, etc 
Compared with the direct translation (\text{DT}), the accuracy of the translation result based on \textbf{OURS} has a relative gain of \textbf{2.8\%}.
The accuracy of \zhcon has also been improved to \textbf{89.6\%} due to the high quality of the merged original Chinese part from \con.

\begin{table}[ht]
\caption{Accuracy of different approaches. The Kappa coefficients \cite{landis1977measurement} of two annotators suggest a substantial agreement.}
\label{tab:conceptnet_accuracy}
\centering
\begin{tabular}{ll}\hline
	Approach & Accuracy (Kappa) \\ \hline
	1. Original Chinese part in Conceptnet& 98.3\%(0.58) \\
	2. \textbf{DT} of English part                 & 84.5\%(0.85) \\
	3. \textbf{OURS} & 87.3\%(0.85) \\
	Zh-Conceptnet (Merge 1 and 3) & \textbf{89.6\%(0.79)} \\\hline
\end{tabular}
\end{table}

\textbf{Qualitative Results.}
Our approach can handle some intractable word sense disambiguations, such as ``date'', ``ball'', ``court'', ``capital'', ``fan'', etc, as shown in the blue part in Table \ref{tab:zh_conceptnet_case}.
Besides, our method can translate (``fan'', RelatedTo, ``sector'') into (``扇'', RelatedTo, ``扇形''), while the result of \textbf{DT} is (``粉丝'', RelatedTo, ``部门''). This shows that our approach can disambiguate ``fan''  and ``sector'' at the same time. As for the errors in \zhcon, according to our observations, most errors in \zhcon come from the triples with the relation of ``RelatedTo''. Since the relation of ``RelatedTo'' is relatively weak in English such as (``blunt'', RelatedTo, ``money''), it becomes even weaker after translation, and the triples with the relation of ``RelatedTo'' account for 48.16\% of all the triples in \con. The red part in Table \ref{tab:zh_conceptnet_case} shows more error cases. 


\begin{table}[!htbp]
\caption{Some examples triples in \zhcon. Correct translations are in {\color{blue} blue}, and incorrect ones are in {\color{red}red}.}
\label{tab:zh_conceptnet_case}
\resizebox{\linewidth}{!}{%
\begin{tabular}{lll}\hline
	\textbf{English}                 & \textbf{OURS}     & \textbf{DT}  \\\hline
	{\color{blue}(date, fruit)/IsA}                  & {\color{blue}枣, 水果}     & {\color{blue}时间, 水果}    \\ 
	{\color{blue}(ball, ballroom)/AtLocation}        & {\color{blue}舞会, 舞厅}    & {\color{blue}球, 舞厅}     \\ 
	{\color{blue}(can, shelf)/AtLocation}            & {\color{blue}罐头, 货架}    & {\color{blue}可以, 货架}    \\ 
	{\color{blue}(court, gymnasium)/AtLocation}       & {\color{blue}球场, 体育馆}   & {\color{blue}法院, 体育馆}   \\ 
	{\color{blue}(munition, arm)/MannerOf}            & {\color{blue}军火, 武装}    & {\color{blue}军火, 手臂}    \\ 
	{\color{blue}(capital, proper noun)/AtLocation} & {\color{blue}大写, 专有名词}  & {\color{blue}资本, 专有名词}  \\ 
	{\color{blue}(spinach, can)/RelatedTo}             & {\color{blue}菠菜, 罐头}    & {\color{blue}菠菜, 可以}    \\ 
	{\color{blue}(fan, blow)/RelatedTo}             & {\color{blue}扇子, 吹}    & {\color{blue}粉丝, 吹}    \\ 
	{\color{blue}(fan, peacock)/RelatedTo}             & {\color{blue}扇子, 孔雀}    & {\color{blue}粉丝, 孔雀}    \\ 
	{\color{blue}(fan, sector)/RelatedTo}             & {\color{blue}扇, 扇形}    & {\color{blue}粉丝, 部门}    \\ 
	{\color{blue}(collection, garage)/AtLocation}             & {\color{blue}珍藏, 车库}    & {\color{blue}集合, 车库}    \\ 
	{\color{blue}(brook, tolerate)/RelatedTo}             & {\color{blue}容忍, 姑息}    & {\color{blue}小溪, 容忍}    \\ 
	{\color{red} (blunt, money)/RelatedTo}             & {\color{red} 生硬, 钱}    & {\color{red} 生硬, 钱}    \\ 
	{\color{red} (fouta, thin)/RelatedTo}             & {\color{red}伏塔加, 瘦}    & {\color{red}富塔, 瘦}    \\ 
	{\color{red}(major ninth, interval)/RelatedTo}             & {\color{red}主要的第九, 间隙}    & {\color{red}主要的第九, 间隔}    \\ 
	{\color{red}(melo, music)/RelatedTo}             & {\color{red}甜瓜, 音乐}    & {\color{red}melo, 音乐}    \\ \hline
\end{tabular}}
\end{table}

%粉丝    /r/RelatedTo    打击
%fan     ['球迷', '迷', '风扇', '扇子', '扇', '粉丝']
%blow    ['打击', '吹', '刮']
%扇子    吹      0.29190982571468305
%(fan, blow)/RelatedTo             & 扇子, 吹    & 粉丝, 吹    \\ \hline
%
%粉丝    /r/RelatedTo    孔雀
%fan     ['球迷', '迷', '风扇', '扇子', '扇', '粉丝']
%peacock ['孔雀']
%扇子    孔雀    0.2387474142191117
%(fan, peacock)/RelatedTo             & 扇子, 孔雀    & 粉丝, 孔雀    \\ \hline
%
%粉丝    /r/RelatedTo    部门
%fan     ['球迷', '迷', '风扇', '扇子', '扇', '粉丝']
%sector  ['扇形', '部门']
%扇      扇形    0.2658884528019793
%(fan,sector)/RelatedTo             & 扇, 扇形    & 粉丝, 部门    \\ \hline
% 
%\begin{table}[th]
%\caption{Some examples triples in \zhcon}
%\label{tab:conceptnet_case}
%\center
%\begin{tabular}{|l|l|l|}\hline
%\textbf{Node1(Subject)} & \textbf{Relation} & \textbf{Node2(Object)} \\ \hline\hline
%	\begin{tabular}[c]{@{}l@{}}植物/plant\end{tabular} & /r/Desires & 水和太阳/water\_and\_sun \\ \hline
%	\begin{tabular}[c]{@{}l@{}}植物/plant\end{tabular} & /r/AtLocation & \begin{tabular}[c]{@{}l@{}}污垢/dirt,\\花盆/flower\_pot,\\花园/garden\end{tabular} \\ \hline
%	
%	\begin{tabular}[c]{@{}l@{}}植物/plant\end{tabular} & /r/Antonym & \begin{tabular}[c]{@{}l@{}}矿物/mineral,\\动物/animal\end{tabular}\\ \hline
%	
%	\begin{tabular}[c]{@{}l@{}}植物/plant\end{tabular} & /r/NotCapableOf & \begin{tabular}[c]{@{}l@{}}移动/move,\\跑/run,\\想想/think,\\走路/walk\end{tabular} \\ \hline
%	
%	\begin{tabular}[c]{@{}l@{}}工厂/plant\end{tabular} & /r/RelatedTo & \begin{tabular}[c]{@{}l@{}}设施/facility,\\制造业/manufacturing,\\起动器/starter\\机械/machinery\end{tabular} \\ \hline
%	%					工厂(factory)\\/plant & /r/IsA & \begin{tabular}[c]{@{}l@{}}包装厂/packinghouse,回收厂/recycling\_plant,\\ 炼油厂/refinery\end{tabular} \\ \hline
%	\begin{tabular}[c]{@{}l@{}}植物/plant\end{tabular} & /r/CapableOf & \begin{tabular}[c]{@{}l@{}}绽放/bloom,\\成长/grow,\\光合作用/photosynthesis\end{tabular}  \\\hline
%\end{tabular}
%\end{table}

\subsection{\zhpro}
We translate \pro into \zhpro based on our proposed approach. In this section, we compare \zhpro with two well-known Chinese taxonomic knowledge graphs CN-Probase \cite{Xu2017} and zhishi.me \cite{Niu2011} in terms of coverage and accuracy.

\textbf{Coverage.}
As shown in Table \ref{tab:zh_probase_coverage}, \zhpro has the same order of magnitude as CN-Probase and is \textbf{11.74} times larger than zhishi.me. 
We further evaluate the overlap between \zhpro and existing Chinese taxonomic knowledge graphs.
Since CN-Probase is not open-source, to calculate the ratio of overlap, we apply the method of sampling. First, we sample 500 ``IsA'' pairs from CN-Probase via the public API of CN-Probase and count the ratio of overlap with \zhpro, which is only \textbf{1\%}. Then, we sample 500 ``IsA'' pairs from \zhpro, and get the ratio of \textbf{6\%}. The intersection of \zhpro and zhishi.me is only \textbf{5,243} pairs.
The reasons why the overlap ratio between \zhpro and CN-Probase is small are as follows: First, as shown in Table \ref{tab:zh_probase_coverage}, CN-Probase has more instances and fewer concepts, like the shape of the Pyramid, while \zhpro has more concepts and fewer instances, like the shape of the inverted Pyramid. 
Second, most entities in \zhpro are translated from English, which only exist in English context, while entities in CN-Probase are extracted from the high-quality Chinese encyclopedia. The third reason is that many latest entities are collected in CN-Probase, while not in \zhpro, since the publish time of CN-Probase is later.
Due to the small overlap between \zhpro and existing Chinese taxonomic knowledge graphs, \zhpro can substantially enrich them. Also, due to the large concept space and broader topics, it will exhibit a stronger ability in capturing the implied semantics, as demonstrated in \cite{wang2010toward}.
Therefore, we can conclude that although the number of ``IsA" pairs in CN-Probase is 3 times larger than that in \zhpro, \zhpro can still greatly enrich existing Chinese taxonomic knowledge graphs.

%The ratio of pairs in CN-Probase, which are also in \zhpro, is \textbf{6\%}, while the ratio of ``IsA'' pairs in \zhpro, which are also in CN-Probase, is less than \textbf{1\%}. This is the sampling estimate via the public API interface of CN-Probase, since it is not open-source.
%The size of the concepts in \zhpro (2,094,825) is \textbf{8} times larger than that in CN-Probase (270,000) while the number of the instances of \zhpro (4,532,110) is much less than CN-Probase (17,000,000). The reason may be that the data sources of both CN-Probase and zhishi.me come from Baidu Baike, Hudong Baike and Chinese Wikipedia (three largest Chinese encyclopedia websites), which, more specifically, come from the well-formed information, such as abstract, infobox, category information, therefore, the instance space of these two knowledge graphs is extremely large while the concept space is relatively small. 
%For example, in CN-Probase, the top instances of concept ``人/person'' are always specific person names, such as ``曹操'', ``崔健'', ``李清云'', etc.
%In contrast, the data source of \pro is massive text corpora in online webpages, which is freer than the data source of CN-Probase, thus, its concept space is large.
%For example, the top instances of concept ``人/person'' in \zhpro are all sub-concepts, such as ``老人/old people'', ``朋友/friend'', ``医生/doctor'', etc.


%\KZ{The style and font size of all tables must be consistent. You can't use 
%resizebox to scale everything into one column so that the fontsizes are
%different.}
\begin{table}[ht]
\caption{Size of existing taxonomic knowledge graphs. (`-' means we cannot get it. ``con-ins'' means ``concept-instance''. ``con-subc'' means ``concept-subconcept''.)}
\label{tab:zh_probase_coverage}
\centering
\begin{tabular}{cccc}\hline
	\textbf{}&\textbf{\zhpro}&\textbf{CN-Probase}&\textbf{zhishi.me}\\ \hline
	concepts  &\textbf{2,094,825}&270,000&17,936\\
	instances  &4,532,110&17,000,000&511,667\\
	con-ins pairs &\textbf{7,054,382}&-&959,581\\
	con-subc pairs&\textbf{4,238,111}&-&2,003\\
	IsA pairs&11,292,493&33,000,000&961,587 \\ \hline
	\end{tabular}
\end{table}

\textbf{Accuracy.}	
To evaluate the quality of \zhpro, 
we randomly sample 500 samples from \pro, \textbf{DT} result of \pro, translation result based on \textbf{OURS}, respectively.
We ask two annotators to evaluate these samples. 
The results are shown in Table \ref{tab:probase_accuracy}. 
Compared with \textbf{DT}, the accuracy based on \textbf{OURS} has increased by \textbf{1.4\%} (from 85.2\% to 86.6\%).
It is less than the improvement (2.8\%) of translation result based on \textbf{OURS} in
\zhcon, because most nodes in \pro are less ambiguous multi-words.
In addition to the inherent error around 7\% (accuracy 93.0\%) in \pro, our translation approach only introduces an additional error of 6.4\% (accuracy 86.6\%), which will be analyzed in the next section. 
\begin{table}[ht]
\caption{The accuracy of existing Chinese taxonomic graphs. The Kappa coefficients of two annotators suggest the substantial agreement.  }
\label{tab:probase_accuracy}
\centering
\begin{tabular}{ll}\hline
	\textbf{Knowledge Graph} & \textbf{Accuracy(Kappa)} \\ \hline 
	\pro    & 93.0\%(0.75) \\ 
	\textbf{DT} of \pro    & 85.2\%(0.84) \\ 
	Zh-Probase & 86.6\%(0.88) \\ 
	CN-Probase     & 95.0\% \\ 
	zhishi.me     & 100\% \\ \hline
\end{tabular}
\end{table}

\textbf{Qualitative Results.}
Our approach can handle some intractable word sense disambiguations, such as ``bank'', ``bark'', ``scale'' etc, as shown in the blue part in Table \ref{tab:probase_case}. On the other hand, there also exist some errors introduced by our method. 
Typical error cases are shown in the red part in Table \ref{tab:probase_case}. According to our observation, most of the errors come from two sources. 
First, translating the entities directly leads to ambiguous Chinese results.
For example, (``go move shift'', IsA, ``song'') will be translated into (``去转移'', IsA, ``歌曲''), which is hard to understand in Chinese. However, translation of named entities is hard to be avoided because not all the first letter of named entities will be capitalized.
Second, the machine translator sometimes cannot return all the Chinese word senses of the word. For example, (``florist'', isA, ``outlet'') will be incorrectly translated into (``花商'', isA, ``出口'') because the translator does not return the Chinese word sense ``批发商店'', which is the correct Chinese word sense of ``outlet'' here.

\begin{table}[!htbp]
	\caption{Some ``IsA'' samples in \zhpro. Correct translations are in {\color{blue} blue}, and incorrect ones are in {\color{red}red}.}
	\label{tab:probase_case}
	\resizebox{\linewidth}{!}{%
		\begin{tabular}{lll}\hline
			\textbf{English}                            & \textbf{OURS}     & \textbf{DT} \\\hline
			{\color{blue} (bank, natural feature)}          & {\color{blue}岸边, 自然特征} & {\color{blue}银行, 自然特征} \\
			{\color{blue}(bank, man-made boundary)}        &  {\color{blue}岸边, 人造边界}  & {\color{blue}银行, 人造边界}  \\
			{\color{blue}(grand Arab capital, capital)}    & {\color{blue}阿拉伯首都, 首都} & {\color{blue}阿拉伯首都, 资本} \\
			{\color{blue}(spring, natural water)}          & {\color{blue}泉水, 天然水}   &  {\color{blue}春天, 天然水}   \\
			{\color{blue}(spring, surface water)}          & {\color{blue}泉水, 地表水}   &  {\color{blue}春天, 地表水}   \\
			{\color{blue}(bark, close range vocalization)}&{\color{blue}吠,近距离发声}&{\color{blue}树皮,近距离发声}\\
			{\color{blue}(bark, vocalization)}&{\color{blue}吠,发声}&{\color{blue}树皮,发声}\\
			{\color{blue}(scale, graphic learning material)}&{\color{blue}比例尺, 图形学习材料}&{\color{blue}规模, 图形学习材料}\\
			{\color{blue}(scale, voice exercise)}&{\color{blue}音阶, 语音练习}&{\color{blue}规模, 语音练习}\\
			{\color{blue}(scale, animal covering)}&{\color{blue}鳞, 动物覆盖}&{\color{blue}规模, 动物覆盖}\\
			{\color{blue}(scale, musicianship skill)}&{\color{blue}音阶, 音乐技巧}&{\color{blue}规模, 音乐技巧}\\
			{\color{blue}(ball, social event)}&{\color{blue}舞会, 社交活动}&{\color{blue}球, 社交活动}\\
			{\color{blue}(ball, physical activity)}&{\color{blue}舞会, 体力活动}&{\color{blue}球, 身体活动}\\
			{\color{blue}(ball, celebration)}&{\color{blue}舞会, 庆祝}&{\color{blue}球, 庆祝}\\
			{\color{blue}(fan, artifact)}&{\color{blue}扇子, 人工制品}&{\color{blue}粉丝, 人工制品}\\
			{\color{red}(florist, outlet)}&{\color{red}花商, 出口}&{\color{red}花店, 出口}\\
			{\color{red}(go move shift, song)}&{\color{red}去移动, 鸣声}&{\color{red}转移, 歌曲}\\
			{\color{red}(Banks of the Ohio, song)}&{\color{red}俄亥俄州的银行, 曲子}&{\color{red}俄亥俄州的银行, 歌}\\
			{\color{red}(chin check, song)}&{\color{red}下巴检查, 鸣声}&{\color{red}下巴检查, 歌}\\\hline
		\end{tabular}
	}
\end{table}

%\subsection{Discussion of First step of \textbf{OURS}}
%%probase 22 16
%%probase 26 12  4770716/11292493=0.422
%total error:
%probase 11\%,13\%    ave:12\%
%
%-inner error
%probase 3\%, 7\%    ave:5\%
%
%%%%%%%%conceptnet 200 43 11  241962/2085681=0.116
%
%%conceptnet 200 15  3
%%conceptnet 200 28 9  241962/2085681=0.116
%total error:
%conceptnet 7.5\%,14\%  ave:10.75\%
%-inner error
%conceptnet 6\%, 9.5\%  ave:7.75\%
%
%hj:
%conceptnet 2,3,4:19,3,8
%probase 2,3,4: 22,16,7
%xr:
%conceptnet 2,3,4:27,9,12
%probase 2,3,4: 22,8,9
%
%
%wsd:
%conceptnet  5.5\%,7.5\% ave: 6.5\%
%probase: 7.5\%,6.5\% ave:7\%


%\begin{table}[H]
%\caption{Some ``IsA'' samples in \zhpro}
%\label{tab:probase_case}
%\begin{tabular}{|l|l|l|}
%	\hline
%	\textbf{Instance} & \textbf{Subconcept} & \textbf{Concept} \\ \hline\hline
%	\begin{tabular}[c]{@{}l@{}}番茄(tomato)\\玉米(maize, corn)\\大豆(soy, soybean)\end{tabular} & 
%	\begin{tabular}[c]{@{}l@{}}植物\\(plant, flora)\end{tabular} &
%	\begin{tabular}[c]{@{}l@{}}有机体(organism)\\ 生产者(producer)\end{tabular} \\ \hline
%	
%	%		\begin{tabular}[c]{@{}l@{}}无水乙醇/(anhydrous ethyl alcohol)\\ 合成乙醇/(synthetic ethyl alcohol)\end{tabular} & 
%	%		\begin{tabular}[c]{@{}l@{}}乙醇\\(alcohol,ethanol)\end{tabular}&
%	%	    \begin{tabular}[c]{@{}l@{}}生物燃料/(biological fuel)\\ 有机溶剂/(organic solvent)\\ 化合物/(compound)\end{tabular} \\ \hline
%	
%	\begin{tabular}[c]{@{}l@{}}橡胶厂(rubber plant)\\
%		炼油厂(oil refinery)\\ 电厂(power plant)\end{tabular} & \begin{tabular}[c]{@{}l@{}}工厂\\(factory, mill)\end{tabular} & \begin{tabular}[c]{@{}l@{}}资产(asset)\\地方(spot,place)\end{tabular} \\ \hline
%	
%	\begin{tabular}[c]{@{}l@{}}狗(dog),猫(cat,feline)\\ 牛(cattle,cow,ox)\end{tabular} &
%	\begin{tabular}[c]{@{}l@{}} 动物\\(animal)\end{tabular} & \begin{tabular}[c]{@{}l@{}}类别(category)\\
%		主题(theme)\\ 
%		生物(creature)\end{tabular}\\ \hline
%\end{tabular}
%\end{table}

%
%近距离发声      IsA     树皮
%close range vocalization        ['近距离发声']
%bark    ['吠', '树皮']
%近距离发声      吠      0.22152851973712392
%近距离发声      树皮    0.07381855955982522
%(bark, close range vocalization)&吠,近距离发声&树皮,近距离发声\\\hline
%
%发声    IsA     树皮
%vocalization    ['发声']
%bark    ['吠', '树皮']
%发声    吠      0.20266486701662512
%发声    树皮    0.02289122701292446
%(bark, vocalization)&吠,发声&树皮,发声\\\hline
%
%图形学习材料    IsA     规模
%graphic learning material       ['图形学习资料', '图形学习材料']
%scale   ['音阶', '规模', '级别', '尺度', '鳞', '比例', '比例尺']
%图形学习材料    比例尺  0.268557394974322
%图形学习材料    尺度    0.21657940353240107
%(scale, graphic learning material)&比例尺, 图形学习材料&规模, 图形学习材料\\\hline
%
%语音练习        IsA     规模
%voice exercise  ['配音练习', '语音练习']
%scale   ['音阶', '规模', '级别', '尺度', '鳞', '比例', '比例尺']
%语音练习        音阶    0.31595054519851007
%(scale, voice exercise)&音阶, 语音练习&规模, 语音练习\\\hline
%
%动物覆盖        IsA     规模
%animal covering ['动物覆盖物', '动物覆盖']
%scale   ['音阶', '规模', '级别', '尺度', '鳞', '比例', '比例尺']
%动物覆盖        鳞      0.2980978974505864
%动物覆盖        尺度    0.2653591599617439
%(scale, animal covering)&鳞, 动物覆盖&规模, 动物覆盖\\\hline
%
%音乐技巧        IsA     规模
%musicianship skill      ['音乐才能', '音乐技巧']
%scale   ['音阶', '规模', '级别', '尺度', '鳞', '比例', '比例尺']
%音乐技巧        音阶    0.3543777738132791
%(scale, musicianship skill)&音阶, 音乐技巧&规模, 音乐技巧\\\hline
%
%社交活动        IsA     球
%social event    ['社交活动']
%ball    ['球', '舞会', '丸子']
%社交活动        舞会    0.5062901630643256
%(ball, social event)&舞会, 社交活动&球, 社交活动\\\hline
%
%身体活动        IsA     球
%physical activity       ['体力活动', '身体活动']
%ball    ['球', '舞会', '丸子']
%身体活动        舞会    0.30998053650136403
%体力活动        舞会    0.2693407790252701
%(ball, physical activity)&舞会, 体力活动&球, 身体活动\\\hline
%
%庆祝    IsA     球
%celebration     ['庆典', '典礼', '庆祝']
%ball    ['球', '舞会', '丸子']
%庆典    舞会    0.5391221765807583
%(ball, celebration)&舞会, 庆祝&球, 庆祝\\\hline
%
%每日文章        IsA     粉丝
%everyday article        ['日常用品', '每日文章']
%fan     ['扇子', '爱好者', '球迷', '风扇', '迷', '粉丝']
%日常用品        扇子    0.24773631914892047
%每日文章        爱好者  0.19835457168625464
%(fan, everyday article)&扇子, 日常用品&粉丝, 每日文章\\\hline
%
%人工制品        IsA     粉丝
%artefact        ['假象', '人工制品']
%fan     ['扇子', '爱好者', '球迷', '风扇', '迷', '粉丝']
%人工制品        扇子    0.09307627931322751
%(fan, artefact)&扇子, 人工制品&粉丝, 人工制品\\\hline
