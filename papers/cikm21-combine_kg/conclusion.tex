\section{Conclusion}
We investigated the efficacy of KG-enhanced models for low-resource audio tagging. We proposed a semi-automatic procedure to build temporal knowledge graph in multiple domains to enrich existing ontologies. We further proposed D-GCN to effectively combine knowledge of two distinct types. Results on AudioSet and SONYC showed that GCN-based model with the introduced temporal knowledge can significantly outperform baseline without prior knowledge especially in low-resource settings, and D-GCN model with combined knowledge can provide further improvement over models with single type of knowledge. 
