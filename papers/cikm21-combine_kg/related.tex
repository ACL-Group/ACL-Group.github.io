\section{Related Work}

Traditional audio tagging models are typically based on CNNs \citep{kong2019cross,kong2020panns,gong2021psla}, while the utilization of knowledge is still under-explored. Recently, some works tried to leverage GCNs to model the relationships between labels. \citep{shrivaslava2020mt} proposed to leverage the AudioSet ontology, while \citep{wang2020modeling} constructed co-occurrence graph with the statistics of training data. \citep{sun2020ontology} utilized both co-occurrence graph and the 2-level SONYC ontology. However, this approach requires the mutual prediction of fine/coarse labels, which restricts its application to ontologies with more levels, such as AudioSet. Our method can combine the strength of ontological and temporal knowledge with no need of data statistics, which may not be reliable in low-resource cases, and is generalizable to more domains.
