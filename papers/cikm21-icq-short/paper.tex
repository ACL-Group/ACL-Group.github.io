\documentclass[sigconf]{acmart}
%% NOTE that a single column version may be required for 
%% submission and peer review. This can be done by changing
%% the \doucmentclass[...]{acmart} in this template to 
%% \documentclass[manuscript,screen]{acmart}
%% 
%% To ensure 100% compatibility, please check the white list of
%% approved LaTeX packages to be used with the Master Article Template at
%% https://www.acm.org/publications/taps/whitelist-of-latex-packages 
%% before creating your document. The white list page provides 
%% information on how to submit additional LaTeX packages for 
%% review and adoption.
%% Fonts used in the template cannot be substituted; margin 
%% adjustments are not allowed.
%%
%%
%% \BibTeX command to typeset BibTeX logo in the docs
\usepackage{graphicx, caption, subcaption}
\usepackage{amsmath}
\usepackage{color}
\usepackage{url}
\usepackage{multirow}
\usepackage{booktabs}
\usepackage{bbm}
\usepackage{enumitem}
\usepackage[flushleft]{threeparttable}
\usepackage{makecell}
\usepackage{ulem}
\usepackage{float}
\restylefloat{table}
% \usepackage{boondox-cal}

\AtBeginDocument{%
  \providecommand\BibTeX{{%
    \normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
\setcopyright{acmcopyright}
\copyrightyear{2021}
\acmYear{2021}
\acmDOI{10.1145/1122445.1122456}

%% These commands are for a PROCEEDINGS abstract or paper.
\acmConference[CIKM '21]{ACM International Conference on Information and Knowledge Management}{November 1--5, 2021}{Virtual Event}
\acmBooktitle{ACM International Conference on Information and Knowledge Management, November 1--5, 2021, Virtual Event}
\acmPrice{15.00}
\acmISBN{978-1-4503-XXXX-X/18/06}
%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%\acmSubmissionID{168}

\newtheorem{example}{Example}
\newcommand{\secref}[1]{Section \ref{#1}}
\newcommand{\figref}[1]{Figure \ref{#1}}
\newcommand{\eqnref}[1]{Eq. (\ref{#1})}
\newcommand{\tabref}[1]{Table \ref{#1}}
\newcommand{\exref}[1]{Example \ref{#1}}
\newcommand{\KZ}[1]{\textcolor{blue}{Kenny: #1}}
\newcommand\BibTeX{B\textsc{ib}\TeX}
\newcommand{\sgn}{\text{sgn}}
\newcommand{\cut}[1]{}
\DeclareMathOperator*{\argmax}{argmax} % thin space, limits underneath in displays
\DeclareMathOperator*{\argmin}{argmin}

% \renewcommand{\cmidrulesep}{0mm} 
% \setlength{\aboverulesep}{0mm} 
% \setlength{\belowrulesep}{0mm} 
% \setlength{\abovetopsep}{0cm} 
% \setlength{\belowbottomsep}{0cm}
\newcommand{\tabincell}[2]{\begin{tabular}{@{}#1@{}}#2\end{tabular}}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

%{\footnotesize \textsuperscript{*}Note: Sub-titles are not captured in Xplore and
%should not be used}
%\thanks{Identify applicable funding agency here. If none, delete this.}

\begin{document}
\title{Do NLP Models Cheat with Statistical Cues in Datasets?}
%\maketitle
\begin{abstract}
%However, none of the work has been able to
%easily pinpoint what these cues are. 
%Inspired by black-box test in software engineering,
Previous work has claimed many NLP models may learned from 
that statistical cues, or correlation between simple linguistic features
and the  labels, in natural language understanding datasets, but they
provide little evidence.  
We propose two simple blackbox tests to evaluate whether a given model
actually exploit such cues computed from the training data using 4 different
popular statistical metrics. We found that LMI is the best model-independent
cueness measure, SNLI, MNLI, ROCStory and ARCT carry more cues than other
well known datasets, and fastText and ESIM are more susceptible to statistical
cues than BERT and RoBERTa.
\end{abstract}
%
% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
% Please copy and paste the code instead of the example below.
%
\begin{CCSXML}
<ccs2012>
<concept>
<concept_id>10010147.10010178.10010179</concept_id>
\begin{CCSXML}
<ccs2012>
<concept>
<concept_id>10010147.10010178.10010179</concept_id>
<concept_desc>Computing methodologies~Natural language processing</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10010147.10010257.10010293.10010294</concept_id>
<concept_desc>Computing methodologies~Neural networks</concept_desc>
<concept_significance>300</concept_significance>
</concept>
</ccs2012>
\end{CCSXML}

%\ccsdesc[500]{Information systems~Recommender systems}
%\ccsdesc[500]{Computing methodologies~Neural networks}

%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\keywords{spurious cues, natural language reasoning models}

\maketitle
\input{intro}
%\input{formulation}
\input{approach}
\input{experiment}
%\input{related}
\input{conclusion}

\bibliographystyle{ACM-Reference-format}
\bibliography{aaai21}
\end{document}
