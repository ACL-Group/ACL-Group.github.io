\section{Related Work}
Classifying relations between entities in certain sentences plays a significant part in natural language processing tasks, and thus has been a trendy research topic recently.
Feature-based methods~\cite{sem} and neural network techniques are most common. 
\cite{socher2011semi} design a Recurrent Neural Network (RNN) based method using constituency parse trees. \cite{ebrahimi2015chain} narrows down the attention to shortest dependency path (SDP) of given sentences. 
\cite{xu2015classifying} introduce a multi-channel SDP-based LSTM model to classify relations incorporating several different kinds of information of a sentence improved by~\cite{xu2016improved}, which performs the best on the SemEval-2010 task8 and is one of our baseline methods.


One of the most notable end task for relation classification and extraction from large text corpus is knowledge base construction.
Research on large-scale knowledge graphs has been paid much attention these years, in which the most notable endeavors are Freebase~\cite{bollacker2008freebase} and DBpedia~\cite{auer2007dbpedia}. 
Such projects along similar lines focusing on factual knowledge, and disregard the kind of commonsense knowledge considered in this paper. 
Methods for Open Information Extraction (Open IE) leverage verbal phrases and patterns derived from them~\cite{fader2011identifying,del2013clausie}. \cite{blanco2011commonsense} utilize WordNet
and ConceptNet to infer commonsense rules, e.g., edible objects
are likely to be found at a supermarket. 
However, their focus is still on factual knowledge and does not deliver a specific disambiguated commonsense relations, especially in our paper, the specific \lnear~relation.

ConceptNet~\cite{speer2012representing} is probably the largest repository
of commonsense assertions about the world.
Ongoing projects on extending ConceptNet have made use of crowd-sourcing~\cite{havasi2007conceptnet,speer2010using}
and pattern-based extraction from Web pages~\cite{tandon2011deriving}. \cite{von2006verbosity,herdaugdelen2012bootstrapping} present games-with-a-purpose to acquire commonsense
facts. Approaches for extracting noun properties from text include
pattern-based information extraction~\cite{almuhareb2004attribute} and corpus co-occurrence
analysis~\cite{baroni2010nouns}. However, this line of research stayed
at the level of a single generic \textsc{HasProperty} relation.

The most related work to ours is the extraction of
visual commonsense knowledge by \cite{yatskar2016stating}. 
This work learns the textual representation of seven types of fine-grained 
visual relations such as ``touches'', ``above'' and ``disconnected from'' by jointly modeling the relative position of the 80 kinds of objects in 300,000 images
and the textual caption for the image in MS-COCO dataset\cite{lin2014microsoft}. 
The authors also generalized their extracted knowledge using WordNet. 

Due to the fact that the commonsense knowledge in image captions is limited by its selected objects and not scalable for its expensive human labor, we propose a framework to use large text which is scalable and involves more real world description. 
Another important related work is from \cite{li2016commonsense}, which enriches several popular relation types in ConceptNet by deep neural networks.
However, \lnear~relation is not studied in this work, while this relation is extremely scarce in \textit{ConceptNet} and has its own distinctiveness. 
Apart from that, this work studies a different problem known as knowledge base completion which seeks to add more edges into a knowledge graph, with little information from
text corpora. 
