\section{Introduction} \label{sec:intro}

\blfootnote{
    %
    % for review submission
    %
    % \hspace{-0.65cm}  % space normally used by the marker
    % Place licence statement here for the camera-ready version. See
    % Section~\ref{licence} of the instructions for preparing a
    % manuscript.
    %
    % % final paper: en-uk version 
    %
    % \hspace{-0.65cm}  % space normally used by the marker
    % This work is licenced under a Creative Commons 
    % Attribution 4.0 International Licence.
    % Licence details:
    % \url{http://creativecommons.org/licenses/by/4.0/}
    % 
    % % final paper: en-us version 
    %
    \hspace{-0.65cm}  % space normally used by the marker
    Kenny Q. Zhu is the corresponding author. 
    This work is licensed under a Creative Commons 
    Attribution 4.0 International License.
    License details:
    \url{http://creativecommons.org/licenses/by/4.0/}
}


Chinese word segmentation (CWS) is a fundamental task for Chinese natural language processing (NLP). Most state-of-art methods are based on statistical supervised learning and neural networks. They all rely heavily on human-annotated data, which is a time-consuming and expensive work. Specially, for domain CWS, e.g., medical field , the annotation expense is even higher because only 
domain experts are qualified for the work. 

Moreover, CWS tools trained from open source datasets, 
e.g., SIGHAN2005\footnote{http://sighan.cs.uchicago.edu/bakeoff2005/}, 
face a significance performance drop when dealing with domain text. 
The ambiguity caused by domain terms and writing style makes it extremely 
difficult to train a universal CWS tool. As shown in Table \ref{table:1}, 
given a medical term “高铁血红蛋白血症” (methemoglobinemia), 
Chinese medical experts would annotate it as “高/铁/血红蛋白/血症”, 
which means anemia caused by hemoglobin with ``high iron'' (in Chinese, 
means iron with valence of 3), corresponding to the morphology of 
``Methemoglobinemia''. ``PKU'' stands for a model trained on PKU's 
People's Daily corpus, we can see that after segmentation, the word 
``铁血'' (jagged) is treated as one word, which is wrong semantically. 
Also, another popular Chinese CWS tool 
Jieba~\footnote{https://github.com/fxsjy/jieba}
mistakenly puts the characters ``高'' and ``铁'' together, which stands for the high-speed bullet train in China.

\begin{table}[th]
\centering
\begin{adjustbox}{width=7.7cm}
\begin{tabular}{|c|c|c|c|c|}
\hline
{\bf CWS tool} & \multicolumn{4}{c|}{\bf 高铁血红蛋白血症} \\
\hline
\multirow{2}{*}{PKU} & 高 & 铁血 & 红蛋白 & 血症 \\ & high & jagged & albumen & anemia\\
\hline
\multirow{2}{*}{Jieba} & 高铁 & \multicolumn{2}{c|}{血红蛋白}  & 血症 \\ & train & \multicolumn{2}{c|}{hemoglobin} & anemia\\
\hline
\multirow{2}{*}{Medical} & 高 & 铁 & 血红蛋白  & 血症 \\ & high & iron & hemoglobin & anemia\\
\hline
\end{tabular}
\end{adjustbox}
\caption{Medical CWS ambiguity with CWS tools. PKU stands for a model trained on PKU dataset.}
\label{table:1}
\end{table}

In summary, domain specific CWS task poses significant challenges because:
\begin{enumerate}
\item Tools built on open source annotated corpus works badly on 
domain specific CWS.
\item Annotated domain data is scarce due to high cost.
\item How to leverage open source annotated data despite their generality is
an open question.
\end{enumerate}

Recently, efforts have been made to exploit open source (high resource) data to improve the performance of domain specific (low resource) tasks and decrease the amount of domain annotated data ~\cite{DBLP:journals/corr/YangSC17,DBLP:journals/corr/PengD16a,DBLP:journals/corr/MouMYLXZJ16}.
% For example, \newcite{DBLP:journals/corr/PengD16a} proposed a multi-task architecture, treating shared layers as \textit{transferable} between different domains or tasks, considering domain-specific layers as \textit{un-transferable}. 
% However, domain-specific layers can also share domain-invariant knowledge which is \textit{transferable}. For instance, consider a multi-task training task for CWS and part-of-speech tagging, the task-specific layers can share some knowledge intuitively, because the boundaries of CWS and POS are often the same. 
In this paper, we further this line of work by developing a multi-task 
learning ~\cite{Caruana1997,DBLP:journals/corr/PengD16a} framework, 
named \textit{Adaptive Multi-Task Transfer Learning}. 
Inspired by the success of \textit{Domain Adaptation}~\cite{Saenko:2010:AVC:1888089.1888106,DBLP:journals/corr/TzengHZSD14,DBLP:journals/corr/Long015}, 
we propose to minimize distribution distance of hidden representation 
between the source and target domain, thus make the hidden 
representations \textit{adapt} to each other and obtain domain-invariant 
features. Finally, we annotated 3 medical datasets from different medical 
departments and medical forum, together with 3 open source 
datasets$^{\ref{fn:1}}$. 
The contribution of this paper can be summarized as follows:

\begin{itemize}
\item We propose a novel framework for Chinese word segmentation in the medical
domain.
\item To the best of our knowledge, we are the first to analyze the performance of transfer learning methods against the amount of disparity between 
target/source domains.
\item Our framework outperforms strong baselines especially when there is substantial \textit{disparity}. 
% \KZ{Heterogeneity is not the right word. 
% Disparity or inconsistency is. You should fix this everywhere.}
\item We open source 3 medical CWS datasets from different sources, which can be used for further study.
\end{itemize}
