review #1

1. We will release our code and medical FORUM data in the camera-ready. 
Due to privacy concerns, we cannot release EMR datasets.

2. We are not sure what reviewer #1 really means when they said "I still have some lingering doubts about how the model parameters were selected". If they wanted to know how the hyper-parameters are selected, we clearly describe it in Sec 5.5.

review #2

1. "This is a useful study, but its impact outside this particular task may be currently limited"

In this paper, due to space and also resource constraint, we only focus 
on transfering CWS models within the medical domain, which was sufficiently 
evaluated using data from several sub-domains, including Respiratory, 
Cardiology and Forum. We have reasons to speculate that the methodology 
developed here may be applied across other domains with similar resource
disparity issues. The techniques may also be applied to other sequence tagging
problems such as NER and POS tagging. However, these ideas will have to be
validated as future work.
 
2. We will release our code and medical FORUM data in the camera-ready. Due to privacy concerns, we cannot release EMR datasets.

3. "The authors argue that their models have a significant advantage when there is high disparity between the source and the target domain, which is supported by the fact that bold numbers only appear in the columns that involve high disparity. This should have been made clearer, as the last paragraph of subsection 5.2 and the last point of subsection 5.8 are confusing."

We will explicitly point out in the camera-ready that the claimed advantage of our models is supported by the evaluation results in the corresponding tables.

4. "In the discussion, the authors did not compare the effect of transferring from a general-domain dataset (which has the advantage of quantity) against that of transferring from a medical dataset (which is good at quality) either."

We will add some discussion to weigh-in the quantity vs. quality when it comes
to the impact on transfer learning. After comparing the tasks with same target domain, we can figure out that quality weights more than quantity. Taking Cardiology as an example, the size of source training set used in cross-medical (high quality) tasks is almost 1 percent of the source training set used in general-to-medical (high quantity) tasks, however, the former tasks even out-performs the latter. We'll discuss it in detail in the camera-ready.

5. The INIT approach works very well between domains with low disparity because: (a) well trained model in the source domain provides a good start point for training in the target domain, which is very similar to the source; (b) the final model is fine-tuned against the target domain only. Our method is disadvantaged in this scenario because: (a) our model parameters are randomly initialized and are independent between the two domains (except for the shared parameters), thus it cannot inherit so much information from the source domain as INIT does; (b) the final model is fine-tuned against both the source and the target domain at the same time; thus noise from the source domain may be introduced into the target domain. This is a research problem we want to tackle in future.

6. We will fix the caption error and spelling errors in the camera-ready.

review #3

1. Given the limited space and annotation cost concern, we only do experiments over medical text. However, we conjecture that our method also works under other scenarios.

2. Using CRF as the decoder is a recent common practice in CWS and sequence tagging problems. We list a few papers below for example. Anyway, the keypoint of this paper is the transfer learning method and not the base model to solve CWS.

Xinchi Chen, Zhan Shi, Xipeng Qiu, and Xuanjing Huang. 2017b. Adversarial multi-criteria learning for chinese word segmentation. ACL 2017.

Matthew E. Peters, Waleed Ammar, Chandra Bhagavatula, and Russell Power. 2017. Semi-supervised sequence tagging with bidirectional language models. ACL 2017.

An Thanh Nguyen, Byron C. Wallace, Junyi Jessy Li, Ani Nenkova, and Matthew Lease. 2017. Aggregating and predicting sequence labels from crowd annotations. ACL 2017.
