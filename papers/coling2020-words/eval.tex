\section{Experiments}
\label{sec:eval}

In this section, we will display the details of dataset and experiments for word difficulty classification and comparison.
%Moreover, 

We choose two tasks to show the effectiveness of the multi-faceted features. For the classification task, each word will be classified into a difficulty category directly. For the ranking task, the model will tell which word is more difficult in a word pair.
To investigate the performance of our methods on various languages, we conduct the experiments on English, German and Chinese.
%The reason we choose these three different languages is that 
% to observe the performance on various languages.
%The reason we choose these two different languages is that English and German are distant enough with quite different morphological and syntactic rules. 
%%For instance, nouns in German have genders while English don't.}
%There are also several experiments about text readability implemented in English and German such as Anderson's work~\shortcite{anderson1981analysing}.
%Both the word difficulty classification task and pairs ranking task are 
%The word difficulty classification and word-pair difficulty ranking tasks in English is implemented on two corpora denoted as E1 and E2, while the tasks on German is only implemented on one corpus denoted G1.

\subsection{Dataset}
\label{sec:data}
A dataset is made up of three parts: a reliable corpus ($Corpus$), a pronunciation dictionary ($Pdict$) and a standard leveled word list ($W$). $Corpus$ and $Pdict$ are the resource for extracting features of words which is stated in Section \ref{sec:approach}, $W$ is regarded as the ground truth for this task.
%Table \ref{tab:src} list the source of datasets and corpora used for three languages.
%For $Corpus$ selection, there are two for English, one for German and one for Chinese.
%For ground truth word list $W$, we choose CEFR for both English and German and HSK for Chinese.
%%It is worth emphasizing that we chose CEFR as the ground truth, which 
%CEFR is an authoritative standard of over 20-year work by Council of Europe~\cite{little2006common,little2011common}. 
%and covers multiple language standards in Europe, including English and German.
%We select the relevant part for our needs -- English and German respectively.

%\begin{table}[ht]
%	\begin{center}
%		\scriptsize
%		\begin{tabular}{l|l|l}
%			\toprule[1pt]
%			& \multicolumn{1}{c|}{\textbf{Resource Description}} & \multicolumn{1}{c}{\textbf{Resource}}                     \\ 
%			\midrule
%			\multirow{4}{*}{\textbf{English}} & Corpus Resource 1             & \tabincell{l}{New York Times (2005-2006)}                        \\ 
%			& Corpus Resource 2                       & Gutenberg Dataset                                          \\ 
%			& Pronunciation Dictionary               & CMU Pronunciation Dictionary                               \\ 
%			& \tabincell{l}{Leveled Ground Truth}         & \tabincell{l}{The CEFR for British English\footnote{https://www.englishprofile.org/wordlists/evp}}      \\ 
%			\midrule
%			\multirow{3}{*}{\textbf{German}}  & Corpus Resource                    & \tabincell{l}{European Parliament Proceedings Parallel Corpus for German} \\ 
%			& Pronunciation Dictionary               & German Pronunciation Dictionary                            \\ 
%			&  \tabincell{l}{Leveled Ground Truth}         & BerLiner Platz Levels  (Based on CEFR)                                    \\ 
%			\midrule
%			\multirow{3}{*}{\textbf{Chinese}}  & Corpus Resource                    & \tabincell{l}{Wikipedia} \\ 
%			& Pronunciation Dictionary               & xxx                            \\ 
%			&  \tabincell{l}{Leveled Ground Truth}         & HSK Levels                                    \\ 
%			\bottomrule[1pt]
%		\end{tabular}
%	\end{center}
%	\caption{\label{tab:src} Details of the resources and dataset.}
%\end{table}

%\begin{table}[th]
%	\begin{center}
%		\scriptsize
%		\begin{tabular}{c|c|c||c}
%			\toprule[1pt]
%			\textbf{} & \multicolumn{2}{c||}{\textbf{English}} & \textbf{German} \\ 
%			\midrule
%			& \tabincell{c}{New York Times (2005-2006)}       & \tabincell{c}{Gutenberg}   & \tabincell{c}{Parallel Corpus for De. (G1)} \\ 
%			\tabincell{c}{Words}   & 91,082,168          & 157,196,249   & 28,423,344               \\ 
%%			\tabincell{c}{Articles} & 177,057   & 3,037          & -               \\ \hline
%			Size        & 617.06MB  & 1.13GB         & 440 MB          \\ 
%			\bottomrule[1pt]
%		\end{tabular}
%	\end{center}
%	\caption{\label{tab:corpus} Number of words and data size of the corpora.}
%\end{table}

For English,  
we choose The New York Times Annotated Corpus~\cite{Evan2008newyork} and Gutenberg Dataset~\cite{lahiri:2014:SRW} as $Corpus$ to extract the features of words.
We select the New York Times articles from 2005 to 2006 and all the articles in Gutenberg Dataset.
% which contains 177,057 and 3,037 articles respectively.\JQ{ambiguity: you select these number of articles? or both contains totally these number of articles but u just use part of them? }
For $Pdict$ selection, we choose the CMU Pronunciation Dictionary (CMUdict) to extract the phoneme components of words~\cite{John2004CMU}.
%\footnote{CMUdict: \url{http://www.speech.cs.cmu.edu/cgi-bin/cmudict}}.
The CEFR for British English\footnote{The leveled words are listed in this website:\url{https://www.englishprofile.org/wordlists/evp}}
%, an international standard to describe language ability, 
is selected as the ground truth $W$ for word difficulty classification and word-pair difficulty ranking. 
%This reference covers multiple language standards in Europe, including English, French, German and etc.
%We select the relevant part for our needs -- English and German respectively.
%In the prediction of English words difficulty, the English branch of CEFR is selected. \JQ{delete}
The details of word levels collected from CEFR are 
shown in Table \ref{tab:CEFR}.


%The German word levels are collected from BerLiner Platz books, which is corresponding to the first three levels of CEFR.
%\JQ{why there is no B2, C1 and C2 in Table 6? How did u divide the train and test set?}\\

%    \begin{table}[th]
%	
%	\centering  
%	\subtable[The Description and Word Size of CEFR Level.]{  
%	\begin{tabular}{|c|l|c|}
%		\hline
%		\textbf{Level}&\textbf{Description}& \textbf{Words} \\
%		\hline
%		A1&Breakthrough or beginner&211\\
%		\hline
%		A2&Waystage or elementary&395\\
%		\hline
%		B1&Threshold or intermediate&718\\
%		\hline
%		B2&Vantage or upper intermediate &1215\\
%		\hline
%		C1&\tabincell{l}{Effective operational \\ proficiency or advanced} &778\\ 
%		\hline
%		C2&Mastery or proficiency&911\\
%		\hline
%	\end{tabular}
%	\label{tab:CEFR}
%	}  
%	\qquad  
%	\subtable[The Corresponding CEFR Level and Word Size of BerLiner Platz Level.]{          
%	\begin{tabular}{|c|c|c|}
%		\hline
%		\textbf{Level}&\textbf{CEFR Level}& \textbf{Words} \\
%		\hline
%		G1 & A1 & 830\\
%		\hline
%		G2 &A2&741\\
%		\hline
%		G3&B1&931\\
%		\hline
%	\end{tabular}
%	\label{tab:German}
%	}  
%\caption{Description for Two Leveled Ground truth}  
%\end{table}  

\begin{table}[ht]
	\begin{center}
		\scriptsize
		\setlength{\abovecaptionskip}{0pt}
		\setlength{\belowcaptionskip}{0pt}
		\begin{tabular}{clcc}
			\toprule[1pt]
			\textbf{CEFR Level}&\textbf{Description}& \textbf{Train} & \textbf{Test}\\
			\midrule
			A1&Breakthrough or beginner& 522&58\\
			A2&Waystage or elementary& 774& 92\\
			B1&Threshold or intermediate& 1242&142\\
			B2&Vantage or upper intermediate & 1539&179\\
			C1&\tabincell{l}{Effective operational proficiency or advanced} & 900& 101\\ 
			C2&Mastery or proficiency& 900&106\\
			\bottomrule[1pt]
		\end{tabular}
	\end{center}
\caption{\label{tab:CEFR} The description and the number of words of the CEFR for British English.}
\end{table}

For German, the German part of European Parliament Proceedings Parallel Corpus~\cite{koehn2005europarl} is used as $Corpus$ to extract word features.
A German pronunciation dictionary\footnote{\url{https://github.com/f-e-l-i-x/deuPD}} modeled after CMUdict 
%\JQ{what do u mean by "modeled after CMUdict"?} 
is chosen as $Pdict$.
The ground truth $W$ is the collection of BerLiner Platz\footnote{The leveled German words are extracted from the book BerLiner Platz.}, a three-level wordlist based on CEFR standard as shown in Table \ref{tab:German}.

\begin{table}[th]
\scriptsize
\setlength{\abovecaptionskip}{0pt}
\setlength{\belowcaptionskip}{0pt}
	\begin{center}
		\begin{tabular}{cccc}
			\toprule[1pt]
			\textbf{BerLiner Platz Level}&\textbf{CEFR Level}& \textbf{Train} & \textbf{Test}\\
			\midrule
			G1 & A1 & 747 & 83\\
			G2 &A2& 667 & 74\\
			G3&B1& 838 & 93\\
			\bottomrule[1pt]
		\end{tabular}
	\end{center}
	\caption{\label{tab:German} The corresponding CEFR level and the number of words for BerLiner Platz Level.}
\end{table}

For Chinese, we choose the latest version of Chinese Wikipedia dump as $Corpus$.
Mandarin Phonetic Symbols can be applied as $Pdict$ to extract the pronunciation of Chinese Characters.
Then, we select HSK\footnote{The leveled Chinese words are displayed on the HSK examination website: \url{http://www.chinesetest.cn/userfiles/file/HSK/HSK-2012.xls}} which is a six-level wordlist shown in Table \ref{tab:HSK} as the ground truth $W$.

\begin{table}[ht]
\scriptsize
\setlength{\abovecaptionskip}{0pt}
\setlength{\belowcaptionskip}{0pt}
	\begin{center}
		\begin{tabular}{cccc}
			\toprule[1pt]
			\textbf{HSK Level}&\textbf{CEFR Level}& \textbf{Train} & \textbf{Test}\\
			\midrule
			H1&A1&135 &15\\
			H2&A2& 135& 15\\
		    H3&B1& 270&30\\
			H4&B2& 540&60\\
			H5&C1& 1270& 130\\ 
			H6&C2& 2250&250\\
			\bottomrule[1pt]
		\end{tabular}
	\end{center}
\caption{\label{tab:HSK} The description and the number of words of the CEFR for British English.}
\end{table}

For classification task,  the label for each word has already annotated by CEFR and HSK and can be used directly.
For ranking task, we choose the pairs of words of any two different difficulty levels according to the CEFR or HSK standard levels to make up the ranking dataset.
Each pair will be considered in both positive and negative directions which is shown as Table \ref{tab:pairs}, where $w_1$ and $w_2$ are words from different levels.
\begin{table}[ht]
	\scriptsize
	\setlength{\abovecaptionskip}{0pt}
	\setlength{\belowcaptionskip}{0pt}
	\begin{center}
		\begin{tabular}{cccc}
			\toprule[1pt]
			& \textbf{Word pair} & \textbf{Description} & \textbf{Label} \\ 
			\midrule
			1 & ($w_1, w_2$) & $w_1$ is more difficulty than $w_2$. & 1 \\
			2 & ($w_2, w_1$) & $w_2$ is easier than $w_1$. & 0 \\ 
			\bottomrule[1pt]
		\end{tabular}
	\end{center}
	\caption{\label{tab:pairs} Word pairs constructed for difficulty ranking task.}
\end{table}
The training set and test set for both tasks are divided by a ratio of 9:1.

In this task, we focus on the classification and word-pair ranking for word difficulty and ignore the phrases in $W$.
For the 6.54\% words in CEFR with multi labels, we assign the lower levels for these words.
Because for L2 learners, if we have already learned a word as the simple one, then it will not be considered again when learning complex words.

%\textbf{Data Preprocessing.} To extract the features of words, we tokenize the original corpora with the help of Stanford CoreNLP~\cite{manning2014stanford}.
%We define our task as a single label classification or ranking problem based on the fact that only 6.54\% of phrases and words have multiple labels in CEFR dataset.
%Thus, phrases and words that belong to multiple classes are removed from the reference word lists. 
%The details listed in Table \ref{tab:CEFR} and \ref{tab:German} have been filtered.

%Other procedures for getting the features has been mentioned in Section \ref{sec:approach}.
%The derived features are concatenated into vectors as the input for classifiers, while the subtracted vectors are the input of the difficulty ranking model.

\subsection{Experiment Settings}
\label{sec:exper}
There are totally 10 features discussed in Section \ref{sec:approach},
we tokenize the $Corpus$ and extract most features by using Stanford CoreNLP~\cite{manning2014stanford}.
As for word embedding, we try different algorithms to generate embedding vectors,
such as Word2Vec with the dimension of 300 and the context size of 5 and the GloVe with dimension of 300 and the context size of 10.
%and do the parameter selection by grid-search for determining the dimension and context size of Word2Vec and GloVe.
% and finally choose the parameters with the best performance.
%For BERT, we acquire word embeddings not only by pre-trained $\text{BERT}_\text{BASE}$ and $\text{BERT}_\text{LARGE}$, but also by the $\text{BERT}_\text{BASE}$  model trained with our own corpora.
What's more, we pretrain the $\text{BERT}_\text{BASE}$ model on English and German $Corpus$ for 100000 epochs with the learning rate of 5e-5 to acquire the updated word embeddings.
For Chinese, there exists a pre-trained BERT based on Wikipedia, so we didn't train again.
%\SY{Due to the limit of space, the results of different parameters will be shown in the Appendix.}
%\textbf{Classification and Word-pair Difficulty Ranking.} 

Based on the extracted features, we implement both the classification model and word-pair difficulty ranking model to measure the word difficulty.
We choose the support vector machine (SVM) with a linear kernel and the penalty factor $C=0.1$ and a three-layer perceptron (MLP) with the hidden size of 512 and learning rate of 0.01.
For both tasks, accuracy on test set and the average accuracy on 10-fold cross validation sets are used as the metrics. All of the results on test set are the average of 10 runs.


