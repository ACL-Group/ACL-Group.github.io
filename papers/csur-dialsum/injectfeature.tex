\section{Injecting Pre-processed Features} 
\label{sec:feature}
%\JQ{The source dialogue input length is one factor that affects the choice and performance of abstractive models, authors can discuss it in the corpora and methods sections.}
To pursue better dialogue understanding and reasoning, different features either designed by experts back on linguistic knowledge or engineered with observations are proposed to simulate the human comprehension process.
Recognizing these features is not only independent dialogue analysis 
tasks but also critical enablers for downstream applications. 
A subset of these features has been proved helpful for dialogue summarization by extracting from $D$ explicitly and injecting it into the vanilla model.
We group different features into two sub-categories by their scopes:
\begin{itemize}
	\item \textbf{Intra-utterance features} are features within an utterance or for an individual utterance.
	\item \textbf{Inter-utterance features} are features connecting or distinguishing multiple utterances.
	%or even \KZ{do not understand: a reformulation of the whole dialogue.}
\end{itemize}



\subsection{Intra-Utterance Features}

We divide the intra-utterance features into three groups: word-level, 
phrase-level or utterance-level.
%Some features may belong to multiple groups, depending on 
%\KZ{rephrase: the specific definition of the different scenarios}. 
%More details are as follows.


\subsubsection{Word-level}
Word-level intra-utterance features include TF-IDF weights, Part-of-speech (POS) tags, and named entity tags.

The \textbf{TF-IDF weight} is a well-known statistical feature for each word, signifying its importance in the whole corpus. 
Term-frequency, i.e., TF,  for each word is the number of repetitions in a dialogue or an utterance divided by the total number of words. Inverse-document-frequency abbreviated as IDF refers to the logarithm of the total number of dialogues or utterances divided by the number of them containing the word.
Each dialogue or utterance can be represented in a TF-IDF weight vector with a dimension of the vocabulary size, where each element is the product of TF and IDF. 
In early work, \citet{murray2005extractive} used such utterance vectors as features and input them to classifiers to find important utterances.
This feature is still prevalent in constructing better prompts for the summary generation with GPT-3~\cite{brown2020language}. Given a testing dialogue, \citet{prodan2021prompt} uses the cosine similarities between such dialogue vectors to find the most similar training dialogues for prompt construction.
%Given a testing dialogue, \citet{prodan2021prompt} ranks candidate dialogues from the training set by calculating the cosine similarities between the target dialogue and each candidate. It is used to find the most similar ones for constructing better prompts for summary generation with GPT-3~\cite{brown2020language}.


\textbf{POS tags} and \textbf{named entity tags} are linguistic labels assigned for each word. POS tags represent grammatical properties, including nouns, verbs, adjectives, etc. Named entity tags belong to pre-defined categories such as person names, organizations, and locations. Both features are easily labeled by well-known NLP packages such as NLTK\footnote{\url{https://www.nltk.org/}} and Spacy\footnote{\url{https://spacy.io/}}. 
\citet{zhu2020end} trained two embedding matrices for both tags and concatenated them with word embeddings as part of the embedding layer for the model, i.e.
$x_i^t = [e_i^t;POS_i^t;ENT_i^t]$. 
$e_i^t$, $POS_i^t$, and $ENT_i^t$ are the word embedding, POS embedding, and named entity embedding for $x_i^t$, respectively. These features, which were also adopted by \citet{qi2021improving} in the same way, work for hierarchical models trained from scratch on this task and 
help with language understanding and entity recognition. 
However, the probing tests indicated that pre-trained 
language models have already captured both features well 
implicitly~\cite{tenney2018you,miaschi2020linguistic}, the two are no longer 
needed. The POS tags or dependency tags can also be assigned to summaries in the training set~\cite{OyaMCN14,singla2017spoken}, to generate summary templates for abstractive text summarization without neural models. 

\subsubsection{Phrase-level}
Phrase-level intra-utterance features have key phrases/words and negation scopes.
 
\textbf{Key phrases/words} emphasize salient 
n-grams in the original dialogue, which can help with the information scattering challenge and lead to more informative summaries. 
The definition of key phrases varies.
%There isn't an agreement on the definition of key phrases. %Speakers and named entities mentioned above can be regarded as two kinds of key phrases.
\citet{wu2021controllable} regarded the longest common sub-sequence (LCS) between each candidate phrase, extracted from $D$ first using a trained constituency parser, and $Y$ as key phrases. %They extract candidate phrases from $D$ first using a trained constituency parser. %~\cite{kitaev2018constituency} @inproceedings{kitaev2018constituency,
%title={Constituency Parsing with a Self-Attentive Encoder},
%author={Kitaev, Nikita and Klein, Dan},
%booktitle={Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
%pages={2676--2686},
%year={2018}
%}
%Then, LCS is found by comparing each candidate phrase with $Y$. 
The LCSs are concatenated into a sketch, 
which is prefixed to $Y$ as a weakly 
supervised signal for the summary generation. 
Similarly, \citet{zou2021topic} proposed that words that appear both 
in $D$ and $Y$ are salient or informative topic words, i.e., another kind of keywords. 
They used an extension of the Neural Topic Model (NTM)~\cite{miao2017discovering} to learn the word-saliency correspondences. 
Then, input utterances are converted to topic representations by the saliency-aware NTM and further incorporated into Transformer Decoder layers for a better extractor-abstractor two-stage summarizer.
%The hidden states trained in their saliency-aware NTM with different input utterances are converted to topic representations and incorporated into Transformer Decoder layers for a better extractor-abstractor two-stage summarizer.
Differently, \citet{feng2021language} regarded unpredictable words by DialoGPT as keywords since they assumed that highly informative words could not be predicted. %given the pre-trained knowledge and dialogue context. 
They appended all extracted keywords at the end of $X$ as inputs to the summarization model. 




The \textbf{Negation scope} is also a set of consecutive words that 
reflect denied contents in utterances. \citet{chen2020multi} pointed out that negations are challenging for dialogues. With that in mind, \citet{khalifa2021bag} trained a Roberta model on CD-SCO dataset~\cite{morante2012sem} for negation scope prediction. This model labels the beginning and end positions of sentences' negation scopes in $D$ with designated special tokens. Unfortunately, inputting such labeled $D$ to the summarization model hurts the performance according to their experiment results. Negations are still of great importance in some task-oriented scenarios for generating accurate facts, such as realizing the patient's confirmation or negation of a symptom in a medical care conversation. \citet{joshi2020dr} proposed using an additional binary vector to label each $x_i$ based on a set of manually-curated negative unigrams, using this vector to modify the cross-attention distribution. Besides, they also extended the vocabulary with a special token `[NO]' and 
learned when to generate it by formulating the probability distribution over extended vocabulary, similarly to~\citet{see2017get}. The results showed reductions in coherency despite capturing negations, achieving competitive performance on doctor evaluations


\subsubsection{Utterance-level}
Speakers or roles, redundancies, user intents, and dialogue acts are utterance-level intra-utterance features. 
Domain knowledge is another kind of intra-utterance feature. It lies across phrase-level to utterance-level depending on specific circumstances. 

\textbf{Speaker} or \textbf{role} is a naturally provided ``label'' for each dialogue utterance. 
Since the general default input to models is the concatenation of all of 
the utterances into a sequence of tokens, each speaker or role token $s_t$ 
is encoded just like any other content token $w_i^t$~\cite{chen2020multi,feng2021language}. Thus, the speaker or role 
information is likely ignored or misunderstood, especially by language models pre-trained 
on common crawled texts. 
For a better understanding of speaker information, \citet{lei2021hierarchical} introduced Speaker-Aware Self-Attention made up of Self-Self Attention and Self-Others Attention to the vanilla Transformer layer, which only considered whether utterances were from the same speaker and avoided using the exact names. This structured feature is also 
adopted in~\cite{lei2021finer}.
In addition, the number of speakers is used as a feature for 
finding similar dialogues in the training set by \citet{prodan2021prompt}.
In TDS as mentioned in Section~\ref{sec:scenarios}, the number of roles is always fixed in a specific scenario, although the speakers are various among dialogue sessions.
\cite{yang2022tanet} modified the input with template ``\{\textit{participant}\} of role \{\textit{role}\} said: \{\textit{utterance}\}''.
Other previous work mainly focuses on modeling roles, reflecting functional information bias in utterances. 
The cheapest way is to represent each role with a dense vector $r_t$ which is either obtained by randomly initialized trainable vectors~\cite{zhu2020end,duan2019legal,qi2021improving,gan2021inspectional,asi2022end} or a small trainable neural network~\cite{song2020summarizing}. This vector is further concatenated, summed up, or fused by non-linear layers with input embeddings $e_i^t$ or utterance-level representations $h_t^u$ in summarization models. 
There are also works that capture such features by different sets of model parameters for different roles~\cite{zou2021topic,zhang2020unsupervised,yuan2019scaffolds}, which require a higher GPU memory footprint. More complicated methods that regard speakers or roles as graph nodes beyond the utterance-level will be introduced in Section~\ref{sec:graphs}.


Since dialogue utterances are mixed with backchanneling or repetitive confirmations~\cite{sacks1978simplest}, \textbf{redundancy} is also a significant 
utterance-level feature where each utterance is either preserved or removed. 
\citet{murray2005extractive} and \citet{zechner2002automatic} regarded 
utterances similar to the previous ones as redundant by calculating 
the cosine similarity between two sentence vectors %which are in turn
computed using TF-IDF features. {Then, the remaining utterances can be regarded as a summary}.
Different from previous work calculating similarities between individual utterances,
\citet{feng2021language} brought the context into consideration which calculated similarities on the dialogue level.
Utterance representations $h_t^u$ are collected by inputting the whole dialogue into DialoGPT~\cite{zhang2020dialogpt} which is pretrained on 
dialogue corpus. 
Then, they assume that if adding an utterance $u_{t+1}$ to the 
previous history $\{u_1, ..., u_t\}$ doesn't result in a big difference 
between the context representation $h_t^u$ and $h_{t+1}^u$, 
$u_{t+1}$ will be regarded as a redundant utterance. 
Such features will be added as part of the dialogue input with special tokens. 
\citet{wu2021controllable} regarded non-factual utterances 
such as chit-chats and greetings as redundancies.
They used a sentence compression method with neural content selection to 
remove this less critical information as the first step for their summary 
sketch construction.

Another group of utterance-level features is matching each utterance with 
a label from a pre-defined multi-label set. \citet{wu2021controllable} defined 
a list of interrogative pronoun category to encode the \textbf{user intent}. 
Their definition is drawn upon the FIVE Ws principle and adapts to the 
dialogue scenario, including \textit{WHY}, \textit{WHAT}, \textit{WHERE}, 
\textit{WHEN}, \textit{CONFIRM} and \textit{ABSTAIN}. %\KZ{there's only
%4 Ws here.}
%~\footnote{According to \citet{wu2021controllable}, the definition of these intent categories are: (1) \textit{WHY} is asking for the reason of content in the previous turn. (2) \textit{WHAT} is requesting more detailed information. (3) \textit{WHERE} represents event locations. (4) \textit{WHEN} represents the time of events. (5) \textit{CONFIRM} is the rhetorical question of a certain case. (6) \textit{ABSTAIN} means the others.}.
Each utterance is labeled by a few heuristics and these user intents are combined with the keywords and redundancies mentioned above as a sketch prefixed to the summary output.
%at the beginning of the decoding process for encoder-decoder models. 
This definition is different from the so-called user intent in task-oriented dialogue systems, while the latter can be used for TDS and will be discussed in domain ontologies in Section~\ref{sec:graphs}.

A more widely-accepted label set is \textbf{dialogue act}, which is defined as the functional unit used by speakers to change the context~\cite{bunt1994context} and has been used for different goals~\cite{kumar2018dialogue, oraby2017may}. The whole dialogue act taxonomy, including dialogue assess, inform, offer, etc., is tailored for different scenarios. For example, only 15 kinds of dialogue are labeled in the meeting summarization corpus AMI~\cite{carletta2005ami} 
while the total number of categories is 42~\cite{stolcke2000dialogue}. \citet{goo2018abstractive} explicitly modeled the relationships between dialogue acts 
and the summary by training both the dialogue act labeling task and 
abstractive summarization task jointly. 
\citet{di2020da} further added the dialogue act information as a contextualized 
weight to $h_t^u$. These labels are required from human annotators. 

\textbf{Commonsense knowledge} generated by widely-used generative commonsense model PARA-COMET~\cite{gabriel2021paragraph} is considered in~\cite{kim2022mind}. PARA-COMET takes dialogue history with the target utterance or a summary sentence as input and outputs short phrases for each of the 5 relation types, which are strongly correlated with speakers' intentions and the hidden knowledge, such as ``XINTENT'' and ``XREACT''. The generated knowledge is concatenated with each utterance as input and is used as the additional generation target in a dual-decoder setting.

In addition, \textbf{domain knowledge} plays an important role in TDS for 
dialogue understanding, even with pre-trained language models. %pretrained on large common crawled data. 
\citet{koay2020meet} showed that the existence of 
terms affects summarization performance substantially. 
Such knowledge is considered as intra-utterance features in previous work.
\citet{joshi2020dr} leveraged a compendium of medical concepts for 
medical conversation summarization. They incorporated domain knowledge at 
the phrase level by simply encoding the presence of medical concepts, which 
are both in the source and the reference. The corresponding one-hot vectors 
affect the attention distribution by the weighted sum with contextualized 
hidden states $H$ for each word only during training, like the teacher forcing strategy.
\citet{gan2021inspectional} defined a number of domain aspects, and labeled text spans manually in $D$ and $S$. Auxiliary classification tasks of these aspects help generate more readable summaries covering important in-domain contents. 
Differently, work by~\citet{duan2019legal} incorporated their legal 
knowledge for each utterance. This is because their legal knowledge graph 
(LKG) depicts the legal judge requirements for different cases rather than a dictionary to look up, and each node represents a judicial factor 
requiring more semantic analysis beyond the word level. A series of graph 
knowledge mining approaches were adopted to seek relevant knowledge w.r.t. 
each utterance $u_t$, and the final legal knowledge embedding was added 
to the sentence embedding $h_t^u$ for further encoding.
 
%$12$ factual aspects and $14$ expectant aspects

\subsection{Inter-Utterance Features}\label{sec:interutt}

As dialogue utterances are highly dependent, information transitions among utterances are of great importance for dialogue context understanding. 
%Besides inputting the concatenation of all of the utterances into an encoder 
%or using a hierarchical model architecture with the utterance-level encoder, 
Multiple inter-utterance features show up for more efficient and 
effective dialogue summarization, which can be categorized into 
two sub-categories:
\begin{itemize}
	\item \textbf{Partitions} refer to extracting or segmenting the whole dialogue into relatively independent partitions. Information within each partition is more concentrated with fewer distractions for the summary generation. Meanwhile, these features reduce the requirements on GPU memory with shorter input lengths, which are especially preferred for long dialogue summarization.
	\item \textbf{Graphs} refer to extracting key information and relations from utterances to construct graphs, serving as a complement to the dialogue. These features are designed to help the summarization model understand the inherent dialogue structure.
\end{itemize}
%More details are as follows. 

\subsubsection{Partitions} 

There are two types of partitions.
One is to cut the dialogue into a sequence of $K$ consecutive segments $\{S_k|_{k=1}^K\}$ with or without overlaps, i.e., $|D|\leq|S_1| + ... + |S_K|$, where $|\cdot|$ counts the number of utterances. Representative features under this category are as follows.

%\KZ{I find the sectioning in section 3 is quite a mess. I don't know which is
%which subsection or paragraph now..}
\textbf{Topic transition} is an important feature for dialogues where speakers turn to focus on different topics. It has been studied as topic segmentation and classification~\cite{takanobu2018weakly}. Consecutive utterances that focus on the same topic constitute a topic segment, and the topic segment should meet three criteria\cite{arguello2006topic}, including being reproducible, not relying heavily on task-related knowledge,  and being grounded in discourse structure.
%Previous work defined topics at different levels of granularity. Some of them annotated such features when constructing datasets. For example, shallow hierarchical topic-subtopic structures are adopted by \citet{carletta2005ami} and \citet{janin2003icsi}. 
Some previous works annotate this feature when constructing datasets such as \citet{carletta2005ami} and \citet{janin2003icsi}. 
\citet{di2020da} took advantage of such labeled information during decoding.
Others collected such features by rules or algorithms.
\cite{asi2022end} adopted the text segmentation idea from~\cite{alemi2015text} and broke the long dialogue into semantically coherent segments by word embeddings.
\citet{liu2019topic} regarded different symptoms as different topics in medical dialogues and detected the boundaries by human-designed heuristics.
To alleviate human annotation burdens, unsupervised topic segmentation methods are adopted. \citet{chen2020multi} used the classic topic segmentation algorithm C99~\cite{choi2000advances} based on inter-utterance similarities, where utterance representations were encoded by Sentence-BERT~\cite{reimers2019sentence}. \citet{feng2021language} regarded sentences that are difficult to be generated based on the dialogue context to be the starting point of a new topic. Thus, sentences with the highest losses calculated based on DialoGPT~\cite{zhang2020dialogpt} are marked.
%These segmentation labels are either labeled by human annotators~\cite{li2019keep,zheng2020abstractive}, human-designed heuristics~\cite{liu2019topic}, unsupervised methods~\cite{chen2020multi} or pretrained models~\cite{feng2021language}. 
However, the window size and std coefficient for C99 algorithm~\cite{choi2000advances} in 
\citet{chen2020multi} and percentage of unpredictable utterances in \citet{feng2021language} are still hyper-parameters that need assigning by humans.
%, or by hyperparameter optimization techiniques which may be regarded as a future work in this area. 
%~\cite{liu2021empirical,wang2020economic}
%@article{liu2021empirical,
%	title={An Empirical Study on Hyperparameter Optimization for Fine-Tuning Pre-trained Language Models},
%	author={Liu, Xueqing and Wang, Chi},
%	journal={arXiv preprint arXiv:2106.09204},
%	year={2021}
%}
%@inproceedings{wang2020economic,
%	title={Economic hyperparameter optimization with blended search strategy},
%	author={Wang, Chi and Wu, Qingyun and Huang, Silu and Saied, Amin},
%	booktitle={International Conference on Learning Representations},
%	year={2020}
%}
Among these works, some models use topic transitions as prior knowledge and input to summarisation models. They either add special tokens to dialogue inputs~\cite{chen2020multi,feng2021language}, add interval segment embeddings, such as $\{t_a, t_a, t_b, t_b, t_b, t_a,...\}$ for each utterance~\cite{qi2021improving}, or guide the model on learning segment-level topic representations $h_k^s$ based on utterance representations $h_t^u$~\cite{zheng2020abstractive}.
Others adjust their RNN-based models to predict topic segmentation first and do summarization based on the predicted topic segments~\cite{liu2019topic,li2019keep}, either with or without using additional supervised topic labels for computing the segmentation loss during training. 

Multi-view~\cite{chen2020multi} describes \textbf{conversation stages}~\cite{althoff2016large} from a conversation progression perspective. They assumed that each dialogue contained $4$ hidden stages, which were interpreted as ``openings$\rightarrow$intentions$\rightarrow$discussions$\rightarrow$conclusions'', and annotated with an HMM conversation model. These four stages. In their approach, both the preceding topic view and such stage view are labeled on dialogues with a separating token ``|'', encoded with two encoders sharing parameters and guided by the Transformer decoder in BART with additional multi-view attention layers. 

There also exists a simple \textbf{sliding-window} based approach that regards window-sized consecutive utterances as a snippet and collects snippets with different stride sizes.
On the one hand, it can be used to deal with long dialogues. Sub-summaries are generated for each snippet and merged to get the final summary.
On the other hand, pairs of (snippet, sub-summary) are augmented data for training better summarization models.
Most works regarded the window size and the stride size as two constants~\cite{koay2021sliding,liu2021topic,zhang2021leveraging,zhang2021summ},
while \citet{liu2021dynamic} adopted a dynamic stride size which predicts the stride size by generating the last covered utterance at the end of $Y'$.
\citet{koay2021sliding} generated abstractive summaries for each snippet by news summarization models as a coarse stage for finding the salient information.
Other work carefully matched the sentences in $Y$ with snippets to get 
better training pairs.
%Then, the most similar utterances to the generated summary are regarded as the extractive summary, showing competitive results on extractive meeting summarization. 
By calculating Rouge scores between reference sentences and snippets, 
the top-scored snippet is paired with the corresponding sentence~\cite{liu2021topic, zhang2021summ}.
Alternatively, multiple top-scored snippets can be merged as the corresponding input to the sentence~\cite{zhang2021leveraging} for the sub-summary generation. 
However, the gap between training and testing is that we don't know the oracle snippets since there is no reference summary during testing.
Therefore, each snippet was also considered to be paired with the whole summary~\cite{zhang2021leveraging,zhang2021summ}, but it leads to hallucination problems.
These constructed pairs can also be used with an auxiliary training objective~\cite{liu2021topic}, or as pseudo datasets for hierarchical summarization~\footnote{Hierarchical summarization means we do summarization, again and again, using the previously generated summaries as input to get more concise output. These models can either share parameters~\cite{li2021hierarchical} or not~\cite{zhang2021leveraging,zhang2021summ} in each summarization loop.}.



%Instead of segmenting the whole dialogue, there are also approaches
The other is to \textbf{cluster utterances} or \textbf{extract utterances} into a single part or multiple parts $\{P_l|_{l=1}^{K'}\}$. In this way, outlier utterances or unextracted utterances will be discarded, i.e., $|D|>|P_1| + ... + |P_K'|$. Then, the abstractive summarization model is trained between the partitions and the reference summary. The whole process can be regarded as variants under the extractor-abstractor framework for document summarization~\cite{chen2018fast,liu2021keyword}. 

\citet{zou2021unsupervised} proposed to select topic utterances according to 
centrality and diversity\footnote{Centrality reflects the center of utterance clusters in the representation space. Diversity emphasizes diverse topics among selected utterances.} in an unsupervised manner. Each utterance with its surrounding utterances in a window size forms a topic segment.
\citet{zhong2021qmsum} extracted relevant spans given the query with the Locator model which is initialized by Pointer Network~\cite{vinyals2015pointer} or a hierarchical ranking-based model. 
Cluster2Sent by~\citet{krishna2021generating} extracted important utterances, clustered related utterances together and generated one summary sentence per cluster, resulting in semi-structured summaries suitable for clinical conversations. 
\citet{banerjee2015generating} and \citet{shang2018unsupervised} followed a similar procedure, including (segmentation, extraction,  summarization) and (clustering, summarization) respectively.
The oracle spans are required to be labeled for supervised training of extractors or classifiers for most approaches, except that \citet{shang2018unsupervised} used K-means for utterance clustering in an unsupervised manner.
Generally, the partitions are concatenated as the input to abstractive summarization models~\cite{zhong2021qmsum}, or the generated summary of each segment is concatenated or ranked to form the final $\hat{Y}$~\cite{zou2021unsupervised,banerjee2015generating}.

%Such segmentation, extraction or clustering features/operations are especially preferred by long dialogue summarization. 
%The extractive-abstractive process can also be used recursively to generate concise summaries for extreme long dialogues~\cite{li2021hierarchical}. 
%This is partially orthogonal to the taxonomy in this paper, and more approaches please refer to \citet{zhang2021exploratory} and \citet{manakul2021long}.
%@article{zhang2021exploratory,
%	title={An Exploratory Study on Long Dialogue Summarization: What Works and What's Next},
%	author={Zhang, Yusen and Ni, Ansong and Yu, Tao and Zhang, Rui and Zhu, Chenguang and Deb, Budhaditya and Celikyilmaz, Asli and Awadallah, Ahmed Hassan and Radev, Dragomir},
%	journal={arXiv preprint arXiv:2109.04609},
%	year={2021}
%}
%@article{manakul2021long,
%	title={Long-Span Dependencies in Transformer-based Summarization Systems},
%	author={Manakul, Potsawee and Gales, Mark JF},
%	journal={arXiv preprint arXiv:2105.03801},
%	year={2021}
%}


\subsubsection{Graphs} 
\label{sec:graphs}

The intuition for constructing graphs is attributed to the divergent structure between dialogues and documents mentioned in Section~\ref{sec:divergence}. To capture the semantics among complicated and flexible utterances, a number of works constructed different types of graphs based on different linguistic theories or observations and demonstrated improvements in dialogue summarization tasks empirically. We group these graphs into three categories according to the type of 
nodes in the graph, i.e., being either a word, a phrase or an utterance. 

\textit{Word-level graphs} focus on finding the central words buried in the whole dialogue. Some works~\cite{OyaMCN14,banerjee2015generating,shang2018unsupervised,park2022unsupervised} parsed utterances together with or without summary templates using the Standford or NLTK packages. Words in the same form and the same POS tag or synonyms, according to WordNet~\cite{MehdadCTN13} are regarded as a single node. Either the natural flow of text, parsed dependency relations or relations in WordNet are adopted to connect nodes, resulting in a directed \textbf{word graph}. It is used for unsupervised sentence compression by selecting paths covering nodes with high in-degree and out-degree without language models.

Complex interactions within dialogues always make it hard for humans and models to associate speakers with correct events. At the same time, different surface forms for the same event and frequent coreferences increase the difficulty for the model to generate faithful summaries. The purpose for \textit{phrase-level graphs} is mainly to emphasize relations between important phrases.
\citet{liu2021coreference} and \citet{liu2021controllable} transferred document coreference resolution models~\cite{joshi2020spanbert,lee2018higher} to dialogues,  applied data post-processing with human-designed rules and finally constructed \textbf{coreference graphs} for dialogues. The nodes are mainly person names and pronouns, and the edges connect the nodes belonging to the same mentioned cluster.
Based on the coreference results, \citet{chen2021structure} took advantage of information extraction system~\cite{angeli2015leveraging} and constructed an \textbf{action graph} with "WHO-DOING-WHAT" triples. ``WHO'' and ``WHAT'' constitute nodes, and the direction of edges representing ``DOING''  is from ``WHO'' to ``WHAT''.
\citet{zhao2021give} manually defined an undirected \textbf{semantic slot graph} based on NER and POS Tagging focusing on entities, verbs, and adjectives in texts, i.e., slot values. Edges in this graph represent the existence of dependency between slot values collected by a dependency parser tool.
More strictly defined ``domain-intent-slot-value'' tuples based on structured \textbf{domain ontologies} are marked in advance~\cite{yuan2019scaffolds,zhao2021todsum}. It is different from domain to domain, such as ``food, area'' slots 
for ``restaurant'' and ``leaveAt, arriveBy'' slot for ``taxi'' labeled in 
the MultiMOZ dataset~\cite{eric2019multiwoz}.
% \citet{yuan2019scaffolds} replaces slot values with slot names and uses delexicalizated dialogue-summary pairs to train the summarization model. The decoder can fill up the slots by copy mechanism based on the pointer network during generation. 
Ontologies in the medical domains containing clinical guidelines in 
``subject-predicate-object'' triples were introduced in~\citet{molennar2020healthcare}'s work. Triples are extracted from $D$ and matched with the ontology to construct a patient medical graph for report generation.
Moreover, external commonsense \textbf{knowledge graphs}, 
such as ConceptNet~\cite{speer2012representing}, have also been adopted to find the relations among speaker nodes, utterance nodes and knowledge nodes~\cite{feng2021incorporating}. The graph is undirected with ``speaker-by'' edges connecting speaker nodes and utterance nodes and ``know-by'' edges connecting utterance nodes and knowledge nodes.



\textit{Utterance-level graphs} considering the relationship between utterances have been explored mainly in four ways. 
One is \textbf{discourse graph} mainly based on the SDRT theory~\cite{asher2003logics} which models the relationship between elementary discourse units (EDUs) with 16 types of relations for dialogues. Both \citet{chen2021structure} and \citet{feng2020dialogue} adopted this theory and regarded each utterance as an EDU. They labeled the dialogue based on a discourse parsing model~\cite{shi2019deep} trained on a human-labeled multi-party dialogue dataset~\cite{asher2016discourse}. 
The former work used a directed discourse graph with utterances as nodes and discourse relations as edges.
Differently, the latter one transformed the directed discourse graph with the Levi graph transformation where both EDUs and relations are nodes in the graph with two types of edges, including default and reverse.  Self edges and global edges were also introduced to aggregate information in different levels of granularity.
%The standard SDRT theory contains 16 types of relations, including comment, clarification\_question, elaboration, acknowledgment, continuation, explanation, conditional, question-answer\_pair,
%alternation, q-elab, result, background, narration, correction, parallel and contrast.
\citet{ganesh2019restructuring} designed a set of discourse labels themselves and trained a simple CRF-based model for discourse labeling. Unfortunately, they haven't released the details about the discourse labels so far.
\textbf{Dependency graph} can be regarded as a simplification of discourse graph since it only focuses on the ``reply-to'' relation among utterances.
The tree structure of a conversation is a kind of it and is adopted in~\cite{yang2022tanet} by modifying the self-attention into thread-aware attention which considers the distance between two utterances, and also proposing a thread prediction task to predict the historical utterances in the same thread for some sampled utterances.
Another one is \textbf{argument graph}~\cite{stede2016parallel} for identifying argumentative units, including claims and premises and constructing a structured representation. \citet{fabbri2021convosumm} did argument extraction with pretrained models~\cite{chakrabarty2019ampersand} and connected all of the arguments into a tree structure for each conversation by relationship type classification~\cite{mirko2020towards}. Such a graph not only helps to reason between arguments but also eliminates unnecessary content in dialogues. Similarly, \textbf{entailment graph}~\cite{MehdadCTN13} is also used to identify important contents by entailment relations between utterances.
The fourth is \textbf{topic graph}. Usually, we regard the topic structure in dialogues as a linear structure as discussed above, but it can be hierarchical with subtopics~\cite{carletta2005ami, janin2003icsi} or other non-linear structures since the same topic may be discussed back and forth~\cite{kim2019dynamic}.
\citet{lei2021finer} used ConceptNet to find the related words in dialogue. These words indicate the connections among utterances under the same topic, capturing more flexible topic structures.


The graphs above have been used for dialogue summarization in three ways. One is to convert the original dialogue into a narrative format similar to documents by linearizing graphs and inputting to the basic summarization models~\cite{fabbri2021convosumm,ganesh2019restructuring} introduced in Section~\ref{sec:approach}.
Second is to bring graph neural layers, such as Graph Attention Network~\cite{velivckovic2018graph} and Graph Convolutional Networks~\cite{kipf2016semi}, for capturing the graph information. Such graph neural layer can be solely used as the encoder~\cite{feng2021incorporating}. It can also cooperate with the Transformer-based encoder-decoder models, either based on the hidden states from the encoder or injected as a part of the Transformer layer in encoder~\cite{liu2021coreference} or decoder~\cite{chen2021structure}.
The rest modify attention heads in the Transformer architecture with the constructed graphs from a model pruning perspective. \citet{liu2021coreference} replace the attention heads that represent the most coreference information with their coreference graph, while \citet{liu2023picking} replace the underused heads with similar coreference graphs.
% \citet{liu2021coreference} also pruned the Transformer heads based on their coreference graphs.




\subsection{Multi-modal Features}

Humans live and communicate in a multi-modal world. As a result, multi-modal dialogue summarization is naturally expected. Even for virtual dialogues from TV shows or movies, character actions and environments in videos are important sources for humans to generate meaningful summaries. However, due to the difficulties of collecting multi-modal data in real life and the limited multi-modal datasets, this area remains to be researched. Only 
\textbf{prosodic features} gained attention in early speech-related works, which contribute to automatic speech recognition (ASR). For example, 
\citet{murray2005extractive} collect the mean and standard deviation of the fundamental frequency, energy and duration features based on speech. The features are collected at the word level and then averaged over the utterance.
With the marvelous ASR models, most works later only focused on transcripts and ignored such multi-modal features.
Besides, \textbf{visual focus of 
attention} {(VFOA)} feature from the meeting summarization scenarios 
has been introduced to highlight the importance of utterances~\cite{li2019keep}. 
It represents the interactions among speakers reflected by the focusing target that each participant looks at in every timestamp. They assumed that the longer a speaker was paid attention to by others, his or her utterance would be more important. Such orientation feature was converted into a vector by their proposed VFOA detector framework and further concatenated to the utterance representations. %in the summarizer.

\subsection{Summary and Opinions}
%\JQ{unclear, need rewrite}
%  Summary how these features are used; advantage and disadatanges
\begin{figure}
	\centering
	\includegraphics[scale=0.7]{fig/approach-feature.pdf}
	\caption{A summary of all features.}
	\label{fig:app-feature}
\end{figure}
The features mentioned above are summarized in 
Figure~\ref{fig:app-feature}. They are mainly {injected into vanilla models} 
in three ways: 

\begin{itemize}
\item \textbf{Manipulating the input and output} by adding annotations or data reformulation. The former one adds additional tokens to the dialogue or summary to highlight the corresponding features, such as topic transition marks in the dialogue~\cite{chen2020multi} and key phrase prefixes of the summary~\cite{wu2021controllable}. This is suitable for features linearly buried in the texts. For the hierarchical or more complicated structures, researchers tend to reformulate the dialogue into different segments, especially for long dialogues~\cite{zhong2021qmsum,banerjee2015generating,shang2018unsupervised} or reordering utterances considering graph features. For example,  \citet{fabbri2021convosumm} linearized the argument graph following a depth-first approach to train a graph-to-text summarization model based on pre-trained sequence-to-sequence language models. Besides, \citet{zhao2021todsum} linearized the final dialogue states, i.e., slot-related labels, as a replacement of $D$ with a bi-encoder model.

%\textbf{Adding annotations or reformulating the dialogue} manipulates the input and output data.  The former one inputs additional tokens to the original dialogue or summary, such as key phrase prefix of the summary~\cite{wu2021controllable} and topic transition marks in the dialogue~\cite{chen2020multi}. These features are linear without considering the hierarchical or more complicated structures. The latter one reformulates dialogue utterances into different segments or orders as new inputs to the summarization model. For example, transforming the dialogue into several parts by clustering or extracting algorithms is commonly used for long dialogue summarization. Reordering utterances is also a simple way of utilizing graph features. Taking \citet{fabbri2021convosumm}'s work as an example, they linearized the argument graph following a depth-first approach to train a graph-to-text summarization model based on pre-trained sequence-to-sequence language models. Besides, \citet{zhao2021todsum} linearized the final dialogue states, i.e., slot-related labels, as a replacement of $D$ with a bi-encoder model.

\item \textbf{Modifying the model architecture or hidden states} for learning inductive bias on known features. Embedding layers are always modified for word-level or phrase-level features indicating the binary or multi-class classification properties, including the POS embeddings in~\cite{zhu2020end} and medical concept embedding in~\cite{joshi2020dr}. Modifications on self-attentions and cross-attentions are used to merge multiple features and are also preferable to graph features. For instance, \citet{chen2020multi} modified the cross-attention layer for balancing and fusing hidden states of two kinds of labeled input from double encoders. \citet{lei2021hierarchical} changed the self-attention layer in the encoder with two speaker-aware attentions to highlight the information flow within the same speaker or among speakers. Different graph neural layers~\cite{feng2021incorporating,liu2021coreference,chen2021structure} are also introduced for capturing graph features.
%More techniques for graph features, please refer to the last paragraph in Section~\ref{sec:interutt}.

\item \textbf{Adding additional training targets} means that features are regarded as a supervision output during training under multi-task learning and are ignored during inference. For example, \citet{goo2018abstractive}, \citet{li2019keep}, \citet{kim2022mind} used an additional decoder for dialogue act labeling, topic segmenting and commonsense knowledge generation, respectively.
\citet{yuan2019scaffolds} incorporated domain features by formulating domain classification as a multi-label binary classification problem for the whole $D$. All of them are using utterance-level features to help learn better encoder representations, which will lead to a high-quality summary in the end.

\end{itemize}
%\textbf{Taking features as a predicting target} means that features are regarded as a supervision output during training under multi-task learning, and are ignored during inference. 
%However, more fine-grained features such as word-level intra-utterance features tend to be not suitable as predictions together with the summary. 
%Such elementary linguistic features, such as POS tags, may harm the high-level semantic information for the ultimate summary generation.
%Besides, complicated graph features are not easy to implement with multi-task learning, as a result of the divergent of model architectures. Taking discourse graph as an example, discourse parsing models focus more on the development of utterances and benefits from the sequential model~\cite{shi2019deep} which predicts discourse relations for the incoming utterance without considering later utterances. Instead, dialogue summarization models need to make the content selection for the whole dialogue, where bi-directional encoder models are preferred.

The advantages and disadvantages of injecting pre-processed features are as follows:
\begin{itemize}
    \item[\Checkmark] Injecting pre-processed features as the mainstream research direction for dialogue summarization significantly improves the results compared with the basic summarization model. Features including negation scope, speaker/role, coreference graph, action graph and semantic slot graph pay more attention to generating consistent summaries, while most of the other features help to select valuable information for summarization.
    \item[\Checkmark] Such explicitly incorporated features are more interpretable to humans and can be manipulated for more controllable summaries. Different features can be selected and combined to promote the model performance in specific application scenarios.
%    \item[\Checkmark] Taking advantage of features collected by labelers trained on other dialogue understanding tasks and dataset connects dialogue analysis tasks with downstream application tasks, and it's a good way to take advantage of the essence of these tasks to alleviate the human labeling burden.
        \item[\Checkmark] Features collected by labelers on other dialogue understanding tasks capture the essence of these tasks and also establish connections with various aspects of dialogue analysis.  Therefore, leveraging such features is a good way to alleviate the human labeling burden.
	\item[\XSolidBrush] Features are not transferable in different scenarios and some features are not compatible with each other, thus feature engineering is shown to be important.
	\item[\XSolidBrush] Labelers trained with other datasets are always out-of-domain compared to the targeting dialogue summarization scenario. Hyper-parameters introduced in labeling algorithms with these labelers need try and error for the domain transfer. %Meanwhile, the accuracy of labeled features is still doubtful and can't be evaluated automatically.
	\item[\XSolidBrush] Error propagation exists in these dialogue summarization approaches. Incorrect features hinder the understanding of dialogues and lead to poor summaries. 
\end{itemize}
% a number of linguistic and intuitve features are proposed without enough comparisons

%These additional features especially the supervised ones do help existing basic summarization models on dialogue summarization tasks. 
%However, the accuracy of such labels are highly relied on the labeling tools which degrade on dialogue summarization data for domain discrepancy or need additional human efforts. This results in poor summaries caused by error propagations. 

{%Injecting pre-processed features} takes advantage of auxiliary dialogue features got by labeling tools that are unsupervised or trained on other datasets. 
%The definition of the same feature may varies in different works, but their motivation are consistent.
