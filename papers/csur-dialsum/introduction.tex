%\KZ{The English of this paper needs to be polished significantly. The current
%state is not up the standard of a top journal paper.}

\section{Introduction}

Abstractive text summarization aims at generating a concise summary output covering key points given the source input.
Prior studies mainly focus on narrative text inputs such as news stories 
, including CNN/DM~\cite{hermann2015teaching} and XSum~\cite{narayan2018don}, 
and other publications, including PubMed and 
arXiv~\cite{cohan2018discourse}, and have achieved remarkable success.  
As a natural way of communication, dialogues have attracted 
increasing attention in recent years. 
With the rapid growth of real-time messaging, consultation 
forums, and online meetings,
information explosion in the form of dialogues calls for more efficient 
ways of searching and digesting dialogues.
%Dialogue-related researches such as dialogue reading comprehension~\cite{sun2019dream}, response selection~\cite{xu2020learning} and dialogue information extraction~\cite{yu2020dialogue} achieve improvements on dialogue context modeling. 
%Information explosion in the dialogue format raise the requirements from human for efficient information digestion
%and the rapid growth of the above two areas paves the way for a recent revival of 
%interest in dialogue summarization. 
%Encoder-decoder neural models have 
%made remarkable progress on this task, tracing back from 
%non-pretrained models such as PGN~\cite{see2017get}, Fast-Abs~\cite{chen2018fast} and HRED~\cite{serban2016building}, to pretrained models including 
%BART~\cite{lewis2020bart} and Pegasus~\cite{zhang2020pegasus}. 



% task definition and motivation
Dialogue summarization targets summarizing salient information in a third party's view given utterances among two or 
more interlocutors. 
This task is not only helpful in providing a quick context to new participants of a conversation, 
but can also help people grasp the central ideas or search for key contents in the conversation, which promotes efficiency and
productivity. 
It is first proposed as meeting summarization by \citet{carletta2005ami} and \citet{janin2003icsi} and generally
covers a number of scenarios, such as daily chat~\cite{gliwa2019samsum,chen2021dialsumm}, 
medical consultation~\cite{joshi2020dr}, customer service~\cite{zou2021topic}, etc.
% challenges
Different from document summarization where inputs are narrative texts from a third party, inputs for dialogue summarization are uttered by multiple parties in the first person. %, as shown in 
%Figure \ref{fig:example}.
Dialogues are not only abundant with informal expressions and elliptical utterances~\cite{zhang2020filling,liu2020incomplete},
but also full of question answerings, and repeated confirmations to reach a consensus among speakers.
The inherent semantic flows are complicatedly reflected by vague topic boundaries~\cite{takanobu2018weakly} and
interleaved inter-utterance dependencies~\cite{afantenos2015discourse}. %discourse relations
%\footnote{A projective discourse structure is that the dependency relations are crossing with each other if we draw them on the same side~\cite{mcdonald2005non}. This is due to the untimely replies or interleaving sub-dialogues especially in a chat room.}.
In a word, the information in dialogues is sparse and less structured, and the utterances are highly content-dependent, raising the difficulty for dialogue summarization.

%Besides, the interlocutors may have discussions lasting several hours resulting in extremely long dialogues.
%Consequently, the information in dialogues is sparse and less structured, and more difficult to summarize.


Based on these characteristics, abstractive dialogue summarization generating fluent summaries is preferred by humans instead of the extractive one that extracts utterances.
The earliest efforts approached this by transforming dialogues into word graphs and selecting the suitable paths in the graph as summary sentences by complicated rules~\cite{banerjee2015generating,shang2018unsupervised}.
Template-based approaches~\cite{OyaMCN14,singla2017spoken} were also adopted, which collect templates from human-written summaries and generate abstractive summaries by selecting suitable words from the dialogue to fill in the blank. However, their generated summaries lack fluency and diversity thus are far from practical use.  
Later, neural encoder-decoder models showed up. They projected the input into dense semantic representations and summaries with novel words were generated by sampling from the vocabulary list step-by-step until a special token representing the end was emitted. Abstractive text summarization has achieved remarkable progress based on these models tracing back from 
non-pretrained ones such as PGN~\cite{see2017get}, Fast-Abs~\cite{chen2018fast} and HRED~\cite{serban2016building}, to pretrained ones including 
BART~\cite{lewis2020bart} and Pegasus~\cite{zhang2020pegasus}. 
At the same time, techniques for dialogue context modeling have also evolved significantly with neural models in dialogue-related researches, such as dialogue reading comprehension~\cite{sun2019dream}, response selection~\cite{xu2020learning} and dialogue information extraction~\cite{yu2020dialogue}.
The rapid growth of the two areas above paves the way for a recent revival of research in abstractive dialogue summarization. 



%It was first proposed as a meeting summarization task by \citet{carletta2005ami} and \citet{janin2003icsi} 
%for meetings recorded by a variety of devices including microphones, cameras, whiteboards, etc. 
%Due to the difficulty of data collection and the challenges with natural language generation, 
%research at that time focused on acoustic modeling for automatic speech recognition models 
%with low-level lexicon features, leaving dialogue modeling and summarization untouched. 
%\KZ{Rephrase: With the prosperous of real-time communication applications and online consultation 
%and working requirements caused by COVID-19}, a number of  datasets are collected, 
%spreading dialogue summarization to various scenarios, such as 
%daily conversations~\cite{gliwa2019samsum,chen2021dialsumm}, 
%e-mail threads~\cite{zhang2021emailsum}, customer-service dialogues~\cite{zou2021topic}, etc. 
%Each of them carries some unique characteristics.


% With a number of datasets been released these years, dialogue summarization is no more limited in the meeting scenario. Daily conversations, task-oriented dialogues, forum questiong-answerings, e-mail threads and so on are all important application scenarios, bringing characteristic problems to this task.


% current works from document summarization to dialogues
Dozens of papers have been published in the area of dialogue summarization in recent years. 
Notably, a number of technical papers have dug into various dialogue features and datasets under different scenarios. 
It is time to look at what has been achieved, find potential omissions and provide a basis for future work.
However, there is no comprehensive review of this field, except for Feng et al.'s recent survey~\cite{feng2021survey}. 
Different from their paper which focuses on datasets and benchmarks targetting only a few applications, 
our survey aims at providing a thorough account of abstractive dialogue summarization, containing taxonomies of task formulations with different scenarios, various techniques, and evaluations covering different metrics and $29$ datasets.
This survey not only serves as a review of existing work and points out future directions for research but also can be a useful look-up manual 
for engineers when solving problems. We also hope this survey could serve as a milestone for dialogue summarization approaches mainly before the emergence of large language models (LLM), such as LLaMa~\cite{touvron2023llama} and ChatGPT~\cite{openai2022}, and bring inspirations for developing new techniques with LLMs.

%techniques and 
%an in-depth analysis on correlations between techniques and application scenarios.

The remainder of this review is structured as follows. \secref{sec:task} is the problem formulation, providing a formal task definition, 
unique characteristics compared to document summarization and hierarchical classification of existing application scenarios.
\secref{sec:approach} to \secref{sec:useadddata} presents a comprehensive taxonomy of dialogue summarization approaches in which current dialogue 
summarization techniques are mainly based on tested document summarization models and can be divided into 
three directions, including (1) injecting pre-processed features~(\secref{sec:feature}), (2) designing self-supervised tasks~(\secref{sec:designselftasks}), and 
(3) using additional data~(\secref{sec:useadddata}).
A collection of proposed datasets and evaluation metrics are in \secref{sec:evaluation}.
Based on the highly related papers, 
%\KZ{Do you want to mention 75? What if 
%the number changes slightly in future. it's hard to keep track of this number.
%Anyway who cares about the exact number?}
we offer deep insights on correlations between techniques and scenarios in Section~\ref{sec:observations}. 
We further suggest several future directions, including more controlled and complicated 
scenarios, technical innovations and feature comparisons, open-source datasets in special domains, 
and benchmarks and methods for evaluation in \secref{sec:future}.
%automatic evaluation metrics targeting different error types

%Current research on dialogue summarization is largely based on 
%existing and tested document summarization models and 
%can be divided into three directions: injecting pre-processed dialogue-related 
%features, designing self-supervised auxiliary tasks and 
%pretraining model with other corpus.
%Most of the works focus on the first class to enhance the dialogue 
%understanding ability. 
%We first categorically organize all of the dialogue features that are utilized in existing works and explain how they have been utilized.
%%, and introduce several more high-level dialogue features that are ignored before.
%Then, we collect all of the published datasets and analyze correlations between application scenarios and dialogue features that have been proved to be effective. 
%%summarize what features have been proved to be effective under different scenarios.
%Next, we show the widely-accepted evaluation metrics for this task and point out that there is a lack of metrics specially designed for dialogue summarization.
%%analyzing whether these features are appropriate under different scenarios.
%Finally, we suggest several future directions, including more complicated 
%scenarios such as multi-modal dialogue summarization and 
%multi-session dialogue summarization, feature analysis and exploration, 
%and specially designed automatic evaluation metrics.

% our contributions
%In a word, the contributions of this paper are as follows:
%\KZ{These contributions are too weak now. Giving a taxonomy of dialogue features
%is not good enough because this is a paper about summarization, so
%this taxonomy should document the interplay of dialogue features and summarization
%techniques. You need to have insight and takeaways after reviewing so many papers
%and looking at so many different results from diff approaches. What is the real
%value of this survey to the audience?}
%\begin{itemize}

%	\item We throughly present a survey on dialogue summarization scenarios and approaches (Section \ref{sec:task}\&\ref{sec:approach}). 
	%It can help researchers find there positions in this area, and also guide industrial peers to quickly get a comprehensive understanding of current development and find suitable solutions in their applications 
	
%	\item As far as we know, we are the first to provide a taxonomy of dialogue features for downstream application, which is not only used for dialogue summarization, but also closely related to other dialogue understanding tasks (Section \ref{sec:approach}).
		
%	\item We present some valuable directions for further research on dialogue summarization (Section \ref{sec:future}).
%\end{itemize}
