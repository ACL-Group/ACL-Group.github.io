\subsection{Human Correction}
\label{sec:correction}
In this section, we describe the human correction process in our system. 
Based on a parsing tree returned to the user, 
our system will suggest that users should correct some of errors manually in order to improve the accuracy of the fuzzy parser. 

% \begin{enumerate}
% \item incremental learning model, features;
% \item How do we figure out which error should be corrected first;
% \item What will happen after an error been corrected and 
% why the process is incremental.
\subsubsection{Incremental Learning Model}
\label{sec:incremental}
Our correction model is incrementally changed according to the corrections that 
humans make. The design of the correction model adheres to some 
scoring policies. 

\paragraph{Initial Model}
% \KZ{Correct all the backquotes!}
Before the results been corrected by human, 
the initial model is generated using the candidate results of the OCR 
engine. 
%For example, for ``QRS'' in the example image, based on the OCR 
%engine, the most reliable result is ``ORS''. Other top candidates are 
%``QPS'', ``QRS'' and ``OPS''. So we can learn from them that ``OR'' can be 
%corrected as ``QP'', ``QR'' or ``OP''. These three candidates 
%will be added into the initial model. 
To calculate the probabilities of the correction candidates in the initial 
model, we count the number of occurrences of each correction. 
%In the example, the 
%probabilities for ``OR'' corrected as ``OR'', ``QP'', ``QR'' or ``OP'' are equal 
%since such corrections only happened once. 
% \[
% P(newStr|oriStr) = \frac{occurrence ~of~ ()}{\sum_{tar \in all} occurrence ~of~ C(oriStr)=tar}
% \]
\paragraph{Training From Human Correction}
After generating the parsing results using the initial model, we have 
made full use of the OCR engine. To correct the remaining errors, 
human input is needed. The incremental learning model is also suitable 
for learning from human correction. 
For example, if a human corrects the error result ``1o.o'' to ``10.0'', 
we can learn from it that for ``o''s in the OCR results, it's possible that 
they should be corrected as ``0''s. So the correction strategy 
for ``o'' is modified and ``0" is the new correct candidate. 
%The model for correction is used in the scoring policy in the 
%fuzzy parser. As shown in \secref{sec:score}, for each 
%description, our system will consider all the potential  
%results based on the correction strategies in the model.  If all potential results share the same
%probability, our system should choose one with the lowest error score based on the description.
%For example, if a human corrects the error result ``1o.o'' to ``10.0'', 
%we can learn from it that for ``o''s in the OCR results, it's possible that 
%they should be corrected as ``0''s. So the correction strategy 
%for ``o'' is modified and ``0" is the new correct candidate. 
%We also calculate the number of occurrences
%of different human correction for the probability calculation. 
%\paragraph{Application of the Model}
%The model for correction is used in the scoring policy in the 
%fuzzy parser. As shown in \secref{sec:score}, for each 
%description, our system will consider all the potential  
%results based on the correction strategies in the model.  If all potential results share the same
%probability, our system should choose one with the lowest error score based on the description.
%For the description ``QRS'' and the most confident results 
%of OCR ``ORS'', we will try all the strategies in the model 
%and consider both whether the corrected result satisfies the 
%description and whether the correction strategy is 
%feasible. In this example, since the four correction strategies 
%are the same probability to happen, we choose ``QR'' as the correction 
%result for ``OR'', 
%which has the lowest error score based on the description.  

\subsubsection{Manual Correction Policy}
In this section, we describe the policies for recommending 
errors to be manual corrected. When making use of human correction 
we find that some errors will have a greater impact on 
accuracy if they are corrected. The reason is some similar errors 
occur frequently. Which errors are recommended to a user 
for correction will affect the accuracy and the 
number of corrections that the user has to made. 
%\paragraph{Random}

The baseline for correction recommendation is random 
recommendation. Based on the parsing results, we can randomly 
recommend the errors we found for humans to correct.  
% \subsubsection*{Most Frequently Error Type}
%\paragraph{Most Frequent Error Description Elements}

Another policy is to recommend the description 
elements that contain the most frequent errors. For a set of images 
in similar formats and the corresponding ODL descriptions, 
we find out which elements in the description are more likely 
to be parsed with errors. For those elements, similar errors 
are more likely to happen since the descriptions for them are the 
same. In this way, our recommendations can be more 
accurate than a random recommendation. 

% \end{enumerate}
