Rebutals:

Thanks a lot for your reviews.

----------------------- REVIEW 1 ---------------------

1. As mentioned in Section 3.3, the match-LSTM layer is inspired by the work of Wang and Jiang(2016). Our model is novel in that it considers not only the two sentences but also the their history and distance, and the results show the effectiveness of this model architecture.

2. (1) In the 3rd paragraph of Section 4, we mentioned that 160,000 distinct dialogues were collected. The word embeddings are pretrained with Skip-gram model on all of the dialogues. We also add the unknown word token ([UNK]) as a zero vector to the pre-trained embeddings to handle the out-of-vocabulary words.

(2) In Q' and NQ', the history information c_i is simply concatenated with h_i individually as shown in Equation 3. The one-layer LSTM on top of that can better fuse history information at different state.

(3) Our evaluation shows that both the history and distance are useful features in this task. History is more useful for LQAs while distance is more useful for SQAs (please see Table 5). The way we adding the distance information is simple but effective. The experiment shows that the full model HDM is significantly better than the model HTY (which disabled the distance information) with p<0.1.

(4) We will correct this into: It's more likely to match the LQAs without losing the accuracy on SQAs.

3. All of the irrelevant sentences are removed during the data preprocessing step. All of the statistics we showed in the paper are calculated after preprocessing steps. Besides, these sentences are notices automatically generated by the forum platform and presented in the name of the doctors. They are irrelevant to the dialogues between the two speakers.


----------------------- REVIEW 2 ---------------------
The mutual attention design is motivated by characteristics in two-party dialogues. Multi-party dialogues are currently beyond the scope of this research.

----------------------- REVIEW 3 ---------------------
- (Section 4) Three undergraduate Chinese native speakers annotated the data with access to the Internet for searching in-domain knowledge. 

- Yes, only within the same dialogue. We aim to matching the QA relations within the noisy online dialogues as mentioned in Section 2.

- It is "irrelevant sentences". These sentences are notices automatically generated by the forum platform and presented in the name of the doctors. They are irrelevant to the dialogues between the two speakers, and they contain obvious features (up to 5 sentence patterns) and can be easily identified.

- Since the domain of the Chinese dataset and Ubuntu are not the same, it's hard to tell if the differences are due to the languages or the domains.

- Since there are no labels for question types in the dataset and the classification criterion for QA types is not clear, we randomly selected 100 Q-NQ pairs and classified the questions into two classes: Yes/No/Choice questions and other questions. The accuracy of our full model HDM is almost the same on these two types of questions: 78.21% vs. 78.66%. Intuitively, we think that the Yes/No/Choice question should be easier to predict, but factors like the informal expressions and disordered turns make things more complicated. We will add this bit of insight into the revised version.



