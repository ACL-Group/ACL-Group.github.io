Reviews:

----------------------- REVIEW 1 ---------------------
SUBMISSION: 248
TITLE: Matching Questions and Answers in Dialogues from Online Forums
AUTHORS: Qi Jia, Mengxue Zhang, Shengyao Zhang and Kenny Q. Zhu

----------- Relevance -----------
SCORE: 5 (excellent)
----------- Significance -----------
SCORE: 4 (good)
----------- Novelty -----------
SCORE: 3 (fair)
----------- Technical quality -----------
SCORE: 4 (good)
----------- Quality of the presentation -----------
SCORE: 4 (good)
----------- Overall evaluation -----------
SCORE: 1 (weak accept)
----- TEXT:
This paper proposes a novel method to match question-answer pairs in two-party dialogues. Compared with previous work, this paper considers the distance information and the turns located between a question-answer pair and put forward a new end-to-end model to solve this problem. Besides, the question matching in two-party dialogues is also a new question in this area. For evaluating this model, the authors build a corresponding dataset, and the results of their model on this dataset are remarkable.

Concerns:

1. Although this end-to-end model for this problem is new, the model itself is not particularly novel. First, using an end-to-end architecture for sentence matching has already been put forward. See “Modelling Interaction of Sentence Pair with Coupled-LSTMs”. Second, this model uses attention mechanism twice, the former is simpler, the latter is more complicated. The complicated one is quite similar to previous work. See “Gated Self-Matching Networks for Reading Comprehension and Question Answering” and “Learning Natural Language Inference with LSTM”. I don't see enough innovation points in those aspects.

2. Also there are a few questions about the details of the model.
(1) When computing the sentence-level embeddings, the model uses pre-trained word embeddings. Here, I think this description is sort of vague. How are those embeddings trained? What if encountering a word of which the embedding is not trained?

(2) In Sec. 3.3, I wonder why you use a one-layer LSTM to encode Q’ and NQ’ to Q’’ and NQ’’ respectively. Is it redundant to perform such a transformation?

(3) At the end of the model, distance information is considered. However, the distance information is just represented by a 10-dimensional one-hot vector and concatenated with corresponding vector p. I think this way of introducing distance information is a bit simple. And the experiment shows that when disabling the distance information at the prediction layer, the result decreases by only 1.5 percentage point.

(4) In Sec. 3.2, there are two considerations. The second one says “if there exists another Q which is closer to the NQ in both distance and semantics, the probability of matching the current Q-NQ pair should reduce”. This intuition has a negative effect on matching LQA indeed. That is to say, the model is more likely to match SQAs. But here, you say “it’s more likely to match the LQAs”, which is contradictory.

3. In the process of building dataset, you remove some irrelevant sentences. Have you considered this can artificially makes the result better? In fact, those “irrelevant” sentences are also NQs. And deleting these sentences can reduce the distance between lots of question-answer pairs. This means some LQAs can be “relative SQAs” which is relatively easier to be matched.


----------------------- REVIEW 2 ---------------------
SUBMISSION: 248
TITLE: Matching Questions and Answers in Dialogues from Online Forums
AUTHORS: Qi Jia, Mengxue Zhang, Shengyao Zhang and Kenny Q. Zhu

----------- Relevance -----------
SCORE: 3 (fair)
----------- Significance -----------
SCORE: 4 (good)
----------- Novelty -----------
SCORE: 4 (good)
----------- Technical quality -----------
SCORE: 5 (excellent)
----------- Quality of the presentation -----------
SCORE: 5 (excellent)
----------- Overall evaluation -----------
SCORE: 2 (accept)
----- TEXT:
The paper presents an attention-based approach for the task of matching questions to answers in two-party multi-turn dialogues with a strong focus in identifying long-distance question answer (QA) pairs in a conversation.
    The proposed approach uses sequence encoders in the form of LSTMs to encode not only vector representations for candidate query (Q) and potential answer (NQ) pairs, but also all contextual utterances between Q and NQ. While encoding Q and NQ, two attention layers (called mutual attention) are used to focus on the other party's context respectively. After a Match-LSTM processes the vector representations of Q and NQ word-by-word, a final classification layer incorporates both information from the Match-LSTM and the distance between Q and NQ. Finally, a greedy matching algorithm is used to assign each NQ to zero or one Q.

    Due to the lack of available multi-turn dialogue corpora that contain long-distance QA pairs from two parties, the proposed approach was evaluated on a new corpus which was created from a Chinese online medical forum and wich will be made publicy available. A comparative evaluation with baseline strategies and state-of-the art systems shows that the proposed approach (HDM) outperforms all of the other approaches with respect to F1 score. Moreover, additional experiments justify the validity of the proposed approach both in terms of architecture design, as well as in the incorporation of the distance feature.

    Finally, a comparative analysis on a subset of the Ubuntu Dialogue Corpus highlights the short-distance nature of this dataset and the effectiveness of the proposed approach which achieves competitive results.




    Overall, this is a well-written paper with a clear structure, which makes it very easy to read.
    The paper is self-contained and uses good examples and visualizations which help to clarify the workflow and architecture of the proposed model.

    The proposed approach is novel in the sense that it makes use of attention mechanisms, which have already been shown to be beneficial in other related QA tasks such as Answer Sentence Selection. By mutually attending the utterance history between a question Q and an answer A, the authors achieve significant improvement over the previous state-of-the-art system from (He et al., 2019).

    In the paper, there is a fair justification for the choice of creating a new custom dataset. I understand that current available corpora that do not contain multi-turn dialogues or long-range QA pairs are unsuited for the proposed task. However, I wonder if multi-party dialogue datasets such as the IRC dataset or the Reddit dataset could have been used to evaluate the model by considering candidate question-answer pairs where Q is a posed question from one party and NQ a candidate answer from the set of all other parties' utterances.

    Section 6 does a great job in justifying the choice of the proposed architecture by comparing different definitions of history, different ways of attending to the history and the choice of incorporating a distance feature into the final classification layer. I also enjoyed to see a comparison of the performances on the Ubuntu test dataset.

    I found the paper to be very self-explanatory, which left me with no open questions.


----------------------- REVIEW 3 ---------------------
SUBMISSION: 248
TITLE: Matching Questions and Answers in Dialogues from Online Forums
AUTHORS: Qi Jia, Mengxue Zhang, Shengyao Zhang and Kenny Q. Zhu

----------- Relevance -----------
SCORE: 4 (good)
----------- Significance -----------
SCORE: 4 (good)
----------- Novelty -----------
SCORE: 3 (fair)
----------- Technical quality -----------
SCORE: 4 (good)
----------- Quality of the presentation -----------
SCORE: 3 (fair)
----------- Overall evaluation -----------
SCORE: 1 (weak accept)
----- TEXT:
The paper "Matching Questions and Answers in Dialogues from Online Forums" proposes an attention-based neural network model to match the answer to a question in a multi-turn dialogue system (between two agents).

The topic of the paper is interesting, and potentially relevant to the ECAI conference. The proposed method seems sound to me, even if not particularly novel. The experimental setting is well defined, comparison with state of the art and ablation tests are carried out.

Additional questions and remarks:
- [Section 4] how many annotators annotated the data? (which background?)
- [Section 4] "A NQ from a party is paired with every earlier Q from the other party." -> only within the same dialogue?
- [Section 4] How were "irrelevant" questions been selected? How many of those, and which kind (beside the reported example)?
- Are the methods tested on Chinese only? (Ubuntu dataset contains English texts) -> can you see differences in the alignment that can be language-specific?
- did you analyze which categories of QA pairs are harder to align?


The paper requires proofreading. Typos, e.g.
[intro] a dialogues -> a dialogue
[intro] a major weaknesses -> a major weakness
...


------------------------------------------------------