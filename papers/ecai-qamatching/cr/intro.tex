\section{Introduction}
\label{sec:intro}
Question motivated dialogues are very common in daily life and 
they are rich sources for question-answer (QA) pairs. 
For example, in an online forum for health consultations, 
both the doctor and the patient tend to ask and answer questions to 
narrow down the information gap and reach the final diagnosis or 
recommendations. Matching QA pairs can help track the final answers from the doctor
to the original patient question and is valuable for the medical
domain.

QA matching is an important part of analyzing discourse structures 
for dialogue comprehension. Asher et. al~\cite{asher2016discourse} 
shows that in online dialogues where participants are prompted to 
communicate with others to achieve their goals, 24.1\% of the relations 
between elementary discourse units are QA pairs. 
Questions and answers are the main components of 
dialogue acts~\cite{stolcke2000dialogue}, providing key features for 
dialogue summarization and decision detection~\cite{fernandez2008modelling}. 
Besides, figuring out the QA relations between these utterances can 
provide question answering 
models~\cite{ji2014information,vinyals2015neural,cui2017superagent} with 
high-quality QA pairs and contribute to the exploration of proactive questioning \cite{yan2017building}.

\begin{figure}[t]
	\centering
	\includegraphics[scale=0.29]{pic_example.pdf}
	\caption{Questions and answers matching in dialogues from an online health forum. The identified pairs are painted in the same color and questions are underlined.}
	\label{fig:sample}
\end{figure}

However, many challenges exist. While it is relatively easy to distinguish
between questions and non-questions~\footnote{This can be done with a simple 
neural-based classifier with high accuracy.},
the non-questions may contain not only valid answers, but also chit-chats and
other informative statements. It is also a common phenomenon that a long and complete answer is broken up into several turns such as \{U5,U6,U8,U10\} in \figref{fig:sample}. Due to factors such as the network delay and different typing speed, the dialogue sequences are always mix-matched. Moreover,``personalized" orthography, ellipses, abbreviations, and missing punctuations are all difficulties for QA matching.



In this work, we focus on the task of matching questions and answers in two-party 
multi-turn dialogues. We found that the distance between the question and its answers 
is not only caused by the mix-matching and fragmentation mentioned above, 
but also by the very nature of the question. 
Some questions can be answered directly based on personal knowledge, 
such as U3, while others can not. For instance, when a patient asks questions 
such as ``what's wrong with me'' or ``what should I do'' just like U1, the doctor often has to ask follow-up questions \{U2,U3\} to seek additional information in order to give the final diagnosis or recommendation (U11). This often has to be done with several rounds of communication. 
We call this kind of QA pairs {\em incremental QA}. 
Such QA pairs often form the main idea of a dialogues or sub-dialogue, 
critical for dialogue comprehension. The answers are inherently far from the question (distance $\geq$ 3 \footnote{There is at least one follow-up question and one corresponding answer between the question and answer of an incremental QA pair. So the distance for such QA pairs is larger or equal to 3.}), aggravating the difficulty of matching such pairs. 

Roughly, we can categorize QA pairs according to the distance between them. 
When distance $\leq$ 3, we call them short-distance QA pairs (SQA); 
otherwise, long-distance QA pairs (LQA). 
It is obvious that matching LQAs is more difficult than SQAs. 
We assume that a two-party multi-turn dialogue contains two types of turns, 
questions (Q) and non-questions (NQ), 
which are labeled in advance~\footnote{We implemented a simple LSTM-based Q/NQ classifier
with accuracy equaling 96.10\% and F1-macro equaling 95.07\% on this dataset
which will be released to the research community.
Question detection is not the focus of this paper.}. 
Our task is to identify all answers from the set of NQs to a given Q. 

Previous methods~\cite{ding2008using,du2017discovering,jiang2018learning} on the task suffer from a major weaknesses: while classifying a pair of turns, they ignore the context of the turns in the dialogue. Meanwhile, their pre-defined features such as question words and answer words, are already implied by the Q and NQ labels in our definition and hence are not suitable for our task. He et al.~\cite{he2019learning} improves the above methods with a recurrent pointer network (RPN) model which takes the whole dialogue as an input. Their model was evaluated on a close-source customer service dialogue dataset. Although their model makes use of the context, they treat every utterance in the context equally with RNN-based networks which fails to capture the influences between turns especially with long distance. Besides, it encodes the distance information implicitly which downplays the effect of distance between the utterances. According to our experiments, none of the above approaches perform well on LQA pairs.


In this paper, we bring the dialogue context into the above simple models. 
For a given pair of Q and NQ to be matched, the context is defined as {\em history}, 
refering to the utterances between the Q and NQ. The critical part of our model 
is two simultaneous attention mechanisms that combine the history in a mutual way. 
Existing dialogue datasets, such as the Ubuntu dataset, do not contain
the QA matching labels. Moreover, they are either not two-party dialogues, or do not
contain long distance QA pairs. Therefore, we develop a new dataset based on
a Chinese online medical forum. We conducted experiments both on this dataset and the part of
labeled Ubuntu dataset~\footnote{The datasets and codes are available at: \url{https://github.com/JiaQiSJTU/QAmatching}}.  


Our main contributions are as follows:
\begin{itemize}

    \item We aggregate dialogue history and distance information into a new deep
neural QA matching model. We show that distance is an important feature when encoded explicitly, and that utterances between Q and A can be effectively captured by a mutual attention mechanism (\secref{sec:method}). 
    \item Since there is no open source dialogue datasets designed for
QA matching task, especially for LQAs, 
we construct a reasonably sized dataset and release it to the research community (\secref{sec:data}). 
    \item The experimental results show that our proposed method outperforms 
other strong baselines, especially on LQAs. 
The techniques developed here are generic and can
be applied to other types of online dialogues (\secref{sec:results}).

\end{itemize}


