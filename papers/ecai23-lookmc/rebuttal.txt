#Reviewer 1:
Q1:  I don't understand why adding or removing...
R1: Thank you for your thoughtful comments.

Indeed, we acknowledge the potential of back translation and have suitably referenced it as a baseline in our experiment.

On the subject of negation, our analysis uncovers a dominance of affirmations over negations in natural language, as illustrated in Table 3. As a result, the quantity of data available for augmentation via negation removal is limited.

While infusing additional negations might enrich our dataset, it could potentially distort the natural equilibrium between affirmative and negative expressions. When conducting data augmentation, preserving the original linguistic distribution is crucial to ensure the augmented data mirrors genuine linguistic phenomena accurately.

Your insightful feedback highlights the necessity for a more explicit exposition of our data augmentation choices, which we will address in the final manuscript.

Q2: Why you didn't use the back translation...
R2: We appreciate your thoughtful suggestion on incorporating back translation as a stress test. However, we foresee potential hurdles.

Specifically, unintentional semantic shifts may result in choices that diverge significantly from the original intent, leading to uncontrollable outcomes and potentially erroneous question generation. Thus, while back translation proves beneficial for training data augmentation, it may not be ideally suited for stress testing.

Once again, thank you for your insight and we'll consider all possibilities in our future endeavors.

Weakness: No resources, no reproducibility.
R3:I apologize for the initial lack of reproducibility resources. In response, all relevant data, code, and models are now available on GitHub. Should this paper be accepted, the link will be included in the manuscript.

Detailed feedback: Your experiments are about positive and negative examples.
R4: Thank you for directing us to the enlightening research by Enzo Veltri's team on data ambiguity. Their innovative approach, using deep learning for classifying ambiguity and generating training examples, holds potential value for our work.

Your emphasis on the link between short-circuiting and LLMs pre-training is significant, reminding us to check for overlap between pre-training and test data.We value your idea of using a unique dataset for evaluation. It's a strategic path for validating our model's robustness.

We're grateful for your constructive feedback and aim to include these insights in our future research. We eagerly anticipate further exploration of these topics.

Reviewer 2
Q1: The definition of the proposed...
R1: Thank you for your valuable feedback. You're correct that our "short-circuiting" concept is independent of the operator. However, as mentioned in our paper's introduction and approach sections, our method uses a proxy test, the efficacy of which varies with the operator used.

Our experiments in Section 3.2.1 aimed to identify the most effective operators for these proxy tests. Our findings indicated "AW" and "CO" to be particularly adept for this purpose, and consequently, we used them in Table 5 as short-circuiting indicators.

Q2: What is the model performance against...
R2: Please refer to the details in the Appendix.

Q3: What are the implementation details...
R3: The details are described in Section 2.1. 
We mentioned that the attention maps are visualized through an off-the-shelf tool proposed by Jesse Vig.

Weakness 1: The experiments for selecting...
R4: Thank you for your thoughtful comments.

a) We understand your concern about the limited sample size of 30 test cases. This was a necessary compromise given the scarce cases from certain operators. We believe this size strikes a balance between representativeness and practicality. Nonetheless, we recognize the advantages of a larger sample and will consider methods to expand it in future work.

b) The ensemble result was chosen as a comparative benchmark due to its diverse and comprehensive nature, thereby offering a robust estimate of short-circuiting. This decision was made under the assumption that a combination of multiple methods could better capture the essence of the issue.

c) As stated in the introduction, choice-only tests were not used because they might not effectively capture the complexity of the short-circuiting phenomena. 

Weakness 2: The paper does not consider...
R5: Thank you for your valuable input about the inclusion of stress test operations.

Indeed, we've accounted for such operations in our work, as indicated in the Introduction, Section 2.1, and Table 3. Our choice of operators was driven by their data augmentation capabilities. For further details on this decision, please see our response to #Reviewer1 Q1.

#Reviewer 3:
I sincerely appreciate your encouraging words and support for my work. Such affirmation motivates me greatly. I remain committed to pursuing excellence and diligence in my research.
