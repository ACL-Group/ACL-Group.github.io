\section{Experiment and Result}
\label{sec:experiment}
In this section we present the experiments, evaluate the procedure using different learning method and show the result we achieved for the current task.
\subsection{Data Set}
Our training data is extracted from 1/10 of the Bing \textquotedblleft Tier0\textquotedblright \ corpus. Snapshot is generated in February, 2013 and the total amount of webpages is about 1.6 billion whose size is nearly 10T. 
Before we do the filtering, we extract 68217404 pairs whose size is 8G. The number of unique words is 64436. Cover ratio of wordnet is 41.49\%(64436/155287).
We drop the pairs with stop words and pairs whose frequency is less than 10. After that, there are 9464879 pairs remaining with size being 1G. 31228 of them are unique words with cover ratio of wordnet being 20.11\%(31228/155287).

\subsection{Feature Extraction}
For each of the 31228 unique words, we first check the POS in the Google 2-gram. 
In our experiment, we only consider noun, verb, adjective and adverb. 
Thus, for any word, let's say word A, we record the probability of being each of the four POS.
If A is a noun, we directly classify it into 31 categories. A 31-bit feature is used to describe the 31 categories.
If A is not only a noun, suppose A is also a verb, we check the arch in Google 2-gram, finding other words(B, C, \ldots) which have the dependency relationship with A and also be a noun.


Take A-B as an example. B is classified into 31 categories, resulting in a 31-bit feature. We multiply the feature with the frequency of arch A-B, which is the semantic information B contributes to A.
We add up 31-bit feature from all other words when A is acting as a verb and normalize it.
At last, A get 4 31-bit semantic feature.


For the sibling structure feature, we record not only whether some certain pair exists in such structure but also the number of neighbours of the other word when one word is fixed.
For the other two structure features, we record the frequency as well.

\subsection{Training and Tesing Data}
We randomly extract 1000 pairs from our dataset. 
Three persons label the causality of those 1000 pairs. Any pair reckoned to be causal by more than two persons is decided to be causal.
We finally get 237(763) causal(non-causal) pairs.
Since, the non-causal pairs are in large scale, our supervised model tends to assign non-cause labels to almost all instances.
As a result, we employ equal number of causal and non-causal pairs for training.

Another 1000 pairs is extracted to be the testing data. We used the same method to decide the causality of the pair.

\subsection{Learning Algorithm}
We mainly use the RBM to do the classification and also calculate result of SVM and neural network.





