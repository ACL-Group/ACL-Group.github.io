Dear Yu Gong: 

I am sorry to inform you that the following submission 
was not selected by the program committee to appear at 
ACL-IJCNLP SystemDemo 2015: 

     Representating Verbs as Action Concepts 

The selection process was very competitive. Due to time 
and space limitations, we could only choose a small number 
of the submitted papers to appear on the program.  Nonetheless, 
I still hope you can attend the conference. 

I have enclosed the reviewer comments for your perusal. 

If you have any additional questions, please feel free 
to get in touch. 

Best Regards, 
Hsin-Hsi Chen and Katja Markert 
ACL-IJCNLP SystemDemo 2015 

============================================================================ 
ACL-IJCNLP SystemDemo 2015 Reviews for Submission #22 
============================================================================ 

Title: Representating Verbs as Action Concepts 

Authors: Yu Gong, Kaiqi Zhao, Kenny Zhu and Haixun Wang 
============================================================================ 
                           REVIEWER #1 
============================================================================ 


--------------------------------------------------------------------------- 
Reviewer's Scores 
--------------------------------------------------------------------------- 

                        APPROPRIATENESS: 5 
                                CLARITY: 3 
             ORIGINALITY/INNOVATIVENESS: 2 
                SOUNDNESS / CORRECTNESS: 2 
                  MEANINGFUL COMPARISON: 2 
                     IMPACT / USABILITY: 2 
                         RECOMMENDATION: 1 
                             CONFIDENCE: 4 


--------------------------------------------------------------------------- 
Comments 
--------------------------------------------------------------------------- 

This paper presents a system that maps verbs to what the authors call “action 
concepts”. Action concepts are defined as a set of arguments of the verbs 
mapped to more general concepts from an ontology. 

A deep problem with this paper is that the authors make a very substantial 
claim that they represent verbs as concepts. This is wrong for several reasons. 
(1) Concepts always underpin particular senses of words, rather than the words 
themselves. However, no word sense disambiguation is done, and instead all 
senses are lumped together in the representation. (2) The use of the term 
“action concept” is in itself misleading – the authors use this term to 
refer to arguments of the verbs instead of the semantics of the verbs 
themselves. In addition, merely mapping nouns co-occurring with the verbs to 
other (even if more general) nouns in an ontology doesn't mean you are 
representing any concepts. 

The authors further claim that other selectional preference induction methods 
lack the flexibility needed to model verbs as concepts, while their method 
provides this flexibility. This is not true either. The presented method is 
highly inflexible compared to other SP induction methods. Firstly, it relies on 
a manually created ontology, that makes it quite inflexible with respect to 
concept definitions and domain coverage, as well as the representation of 
different word senses.              Secondly, the authors manually preset k (the 
desired 
number of arguments) universally for all verbs. In reality, each verb has its 
own desired number of arguments, and the model needs to account for this 
somehow. 
Selectional preference induction methods based on clustering and LDA, in 
contrast, can automatically induce arguments classes for the verb in question, 
are able to model different senses (see work of O'Seaghdha 2010, Ritter at al. 
2010 and many 
others). They are thus more flexible than the presented approach. 

Generally speaking, I don't see what this system contributes that the SP 
systems don't. 

The paper also lacks experimental detail. For instance, what was the dataset 
used for evaluation? No information on this is given. How were the annotations 
mapped to the top [5,10,15] arguments? 

How were the arguments in Table 1 mapped to the respective FrameNet roles? 

Why use an ontology instead of clustering? The authors criticize hand-crafted 
lexical resources (such as FrameNet) for limited coverage. But any 
ontology-based approach would have the same problem. 

Why was this specific ontology chosen? What is its structure? No details are 
given. 

What is ReVerb? 

Overall, the comparison to related work contains a number of wrong claims and 
is misleading. 

Odd language sometimes, e.g. “massive English sentences”. 

============================================================================ 
                           REVIEWER #2 
============================================================================ 


--------------------------------------------------------------------------- 
Reviewer's Scores 
--------------------------------------------------------------------------- 

                        APPROPRIATENESS: 5 
                                CLARITY: 4 
             ORIGINALITY/INNOVATIVENESS: 3 
                SOUNDNESS / CORRECTNESS: 4 
                  MEANINGFUL COMPARISON: 3 
                     IMPACT / USABILITY: 3 
                         RECOMMENDATION: 2 
                             CONFIDENCE: 3 


--------------------------------------------------------------------------- 
Comments 
--------------------------------------------------------------------------- 

This paper proposes a graph-based approach to improve selectional preferences 
for verbs, where selectional preferences are represented as the 
concepts from an automatically created taxonomy called "Probase". I like the 
general idea of the approach. But I have some concerns: 

1) Taxonomy: why do you choose Probase instead of WordNet? The original 
baseline is based on WordNet, it would be a fair comparison if both approaches 
are based on WordNet. 

2) Evaluation: The evaluation part is not clear. First, what is "SRL" in  Table 
2? Second, how big the test dataset is? Where does it come from? Third, how do 
you calculate the precision of different approaches exactly? Fourth, in your 
approach, why small K (k=10) get better result than big k (k=15), while SP gets 
the similar result with different k? This is somehow not intuitive, with big K, 
your approach should be able to cover more diverse concepts. 

3) In general, I think that this approach needs more thorough evaluation.   

4) The description of resources in Section 1 is not quite right. 
"To that end, FrameNet(Baker et al., 1998), PropBank(Kingsbury and Palmer, 
2002), and VerbNet(Kipper et al., 2000)) are all examples of human-annotated 
lexicons of verbs including their meanings (called frames) and the different 
types of their arguments (called roles)." 
--------- First, FrameNet includes not only verbs, but also other forms of 
predicates, e.g., nouns. Second, different resources have different 
terminology, it's not appropriate to use FrameNet terms to generalize other 
resources. 

============================================================================ 
                           REVIEWER #3 
============================================================================ 


--------------------------------------------------------------------------- 
Reviewer's Scores 
--------------------------------------------------------------------------- 

                        APPROPRIATENESS: 4 
                                CLARITY: 5 
             ORIGINALITY/INNOVATIVENESS: 4 
                SOUNDNESS / CORRECTNESS: 4 
                  MEANINGFUL COMPARISON: 3 
                     IMPACT / USABILITY: 3 
                         RECOMMENDATION: 3 
                             CONFIDENCE: 4 


--------------------------------------------------------------------------- 
Comments 
--------------------------------------------------------------------------- 

This paper proposes a system to infer the action concepts for verbs. Action 
concepts of a verb are a set of noun concepts that are the feasible arguments 
of the verb. For example, the direct object of the verb “eat” may be the 
concepts “food”, “plant”, and “animal”.  Unlike the human-annotated 
resources such as FrameNet and PropBank, the method proposed in this paper 
offers a tunable set of human-readable and machine-computable concepts for the 
immediate subject and direct object of a verb. 
Given the argument instances of a verb, the proposed system will fetch top k 
concepts from the taxonomy according to likelihood of the corpus. The problem 
is modeled as a k-clique problem, and the author proposed a brand-and-bound 
algorithm to solve it. Some instances of the action concepts are illustrated, 
and the performance of the argument identification is compared with related 
work. 

This paper is well-written and well-structured, the problem is well-defined, 
and the proposed method looks promising. My major concern is about the 
evaluation. Why only the precision is reported? How about the recall and 
f-score of each method? In addition, the test set is very small that only 10 
verbs are evaluated. What are these 10 verbs? How these 10 verbs are selected? 
This paper will be more convincing if these details are supplied and discussed. 
My other concern is that the content of this paper is more suitable for the 
research track, but not so for the system demonstrations. 


-- 
ACL-IJCNLP SystemDemo 2015 - https://www.softconf.com/acl2015/SystemDemo
