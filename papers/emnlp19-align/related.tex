\section{Related Work}
\label{sec:related}

With several exceptions, the sentence similarity measure task is fulfilled in two general approaches: (a) sentence embeddings or word embeddings are first obtained and similarity score is calculated based on mathematical measure on vector distance, such as normalized Euclidean distance, cosine distance and earth mover's distance, or (b) similarity score is learned by semantic features or distributional statistics.

In explorations of word-level similarities, word vectors mostly relied on pretrained word vectors such as GloVe~\cite{pennington2014glove} and fasttext~\cite{joulin2017bag} pretrained word vectors. Then word-level similarity and multiple word alignment rules are applied to obtain sentence-level similarities. By directly obtaining sentence vectors, other studies focused more on the forms of distance measure for sentence vectors to better capture the real semantic distance~\cite{kajiwara2016building}.

Based on word embeddings, Zhu et al. constructed a parallel corpus for text simplification using cosine similarity between TF-IDF vectors of sentences~\cite{zhu2010monolingual}. Later studies considered more sentence semantic features including sentence ordering~\cite{coster2011learning} and word-level similarity~\cite{hwang2015aligning}. Kajiwara et al. used four word-level alignment methods for similarity measure, and constructed a monolingual parallel corpus for text simplification using similarity matrix and a given threshold~\cite{kajiwara2016building}. Hatzlvassiloglou et al. evaluated the incorporation of multiple linguistic features and the combinations of them in text similarity measure~\cite{hatzlvassiloglou1999detecting}.

In sentence alignment task, Zamani et al. modeled the sequential alignment process using integer programming, arguing that a weak similarity measure is compensated by an optimal sequential alignment algorithm~\cite{zamani2016sentence}. Hwang et al. compared a greedy alignment pattern with an ordered alignment algorithm by dynamic programming, and proved the practical priority of the former~\cite{hwang2015aligning}.


