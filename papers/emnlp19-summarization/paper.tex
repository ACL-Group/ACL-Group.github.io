% File emnlp2019.tex 
% 
%% Based on the style files for ACL 2019, which were
%% Based on the style files for EMNLP 2018, which were
%% Based on the style files for ACL 2018, which were
%% Based on the style files for ACL-2015, with some improvements
%%  taken from the NAACL-2016 style
%% Based on the style files for ACL-2014, which were, in turn,
%% based on ACL-2013, ACL-2012, ACL-2011, ACL-2010, ACL-IJCNLP-2009,
%% EACL-2009, IJCNLP-2008...
%% Based on the style files for EACL 2006 by 
%%e.agirre@ehu.es or Sergi.Balari@uab.es
%% and that of ACL 08 by Joakim Nivre and Noah Smith

\documentclass[11pt,a4paper]{article}
\usepackage[hyperref]{emnlp-ijcnlp-2019}
\usepackage{times}
\usepackage{latexsym}

\usepackage{url}

\usepackage{soul}
\usepackage{algorithm}
\usepackage{algorithmic}
\urlstyle{same}

\usepackage{helvet}
\usepackage{courier}
\usepackage{color}
\usepackage{amsmath,amsfonts,amssymb,amsthm,amsopn}
\usepackage{color}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{diagbox}
\usepackage{array}
\usepackage{multicol}
\usepackage{threeparttable}
\usepackage{epstopdf}
\usepackage{listings}
\usepackage{multirow}
\usepackage{subfigure}
\theoremstyle{definition}
\newtheorem{example}{Example}

\newcommand{\secref}[1]{Section \ref{#1}}
\newcommand{\figref}[1]{Figure \ref{#1}}
\newcommand{\eqnref}[1]{Eq. (\ref{#1})}
\newcommand{\tabref}[1]{Table \ref{#1}}
\newcommand{\exref}[1]{Example \ref{#1}}
\newcommand{\cut}[1]{}
\newcommand{\tabincell}[2]{\begin{tabular}{@{}#1@{}}#2\end{tabular}}

\newcommand{\KZ}[1]{\textcolor{blue}{Kenny: #1}}
\newcommand{\XS}[1]{\textcolor{red}{Xusheng: #1}}
\newcommand{\YZ}[1]{\textcolor{red}{Yizhu: #1}}
\newcommand{\KW}[1]{\textcolor{magenta}{Kiwi: #1}}

%\aclfinalcopy % Uncomment this line for the final submission

%\setlength\titlebox{5cm}
% You can expand the titlebox if you need extra space
% to show all the authors. Please do not make the titlebox
% smaller than 5cm (the original size); we will check this
% in the camera-ready version and ask you to change it back.

\newcommand\BibTeX{B{\sc ib}\TeX}
\newcommand\confname{EMNLP-IJCNLP 2019}
\newcommand\conforg{SIGDAT}

\title{Reducing Repetition in Convolutional Abstractive Summarization}

\author{First Author \\
  Affiliation / Address line 1 \\
  Affiliation / Address line 2 \\
  Affiliation / Address line 3 \\
  {\tt email@domain} \\\And
  Second Author \\
  Affiliation / Address line 1 \\
  Affiliation / Address line 2 \\
  Affiliation / Address line 3 \\
  {\tt email@domain} \\}

\date{}

\begin{document}
\maketitle

\begin{abstract}
Convolutional sequence to sequence (CNN seq2seq) models
have met great success in abstractive summarization. 
However, their outputs often contain repetitive word sequences and logical
inconsistencies, limiting the practicality of their application.
%It is important for CNN seq2seq model to get the ability to 
%generate summaries without repetition in abstractive summarization. 
In this paper, we propose to reduce the repetition in output summaries
by dynamically redistributing attention over the input sequence as
the output sentences are generated.
The results show that this approach 
generates high-quality summaries with minimal repetition, 
and outperforms the baselines 
%{\bf consistently} 
in terms of
ROUGE score, repeatedness, and readability.
%\KZ{If you say consistently, our R-2 score is not much better than
%TRI, so better to provide T-test results?}
\end{abstract}

\input{intro}
\input{approach}
\input{eval}
\input{related}
\input{conclude}


\bibliography{emnlp-ijcnlp-2019}
\bibliographystyle{acl_natbib}
\end{document}
