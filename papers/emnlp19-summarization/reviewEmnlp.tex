Review1:

What is this paper about, what contributions does it make, and what are the main strengths and weaknesses?
The paper proposes an approach to reduce the repetitions in CNN based sequence networks. The paper proposes a combination of attention filtering and sentence back tracking to address the repetition problem. The natural advantage of scalability of the CNN architecture (over RNNs) and the proposed improvement make them comparable to the pointer based RNN frameworks which are the baselines in this line of work.
Reasons to accept
The paper proposes an ad-hoc approach that provides sufficient control to the CNN frameworks and makes them close to the existing baseline in RNN-based summarization frameworks.
Reasons to reject

[1] The paper proposes the attention filtering and sentence re-ranking - but lack sufficient analysis on how they are helping achieve the stated objective. It would have helped to see a few candidate examples of successful satisfaction of objectives and examples where the proposed method fails - in comparison with the other baselines. 
[2] Backtracking was introduced mainly to remove repetition present in the source but it can work with essentially any kind of repetition in the summary right. Example in Table 6 is insufficient to justify that, without looking at the source document itself. 
[3] Looking at Table 4, SBD alone was able to get near-best performances (which is time consuming since the whole summary is backtracked), with slightly more gain in ATTF+SBD. Hence the value of ATTF is not clear - which is where [1] above can help. 
[4] From [3] unsure of whether the attention filtering works better than baselines (which is a major focus in the approach section compared to backtracking) - also the notations in that sections are a bit confusing making it less readable. 
[5] The human evaluations is perhaps needed to fully establish the proposed method is achieving the summary quality without repetitions.

Review2:

What is this paper about, what contributions does it make, and what are the main strengths and weaknesses?
Addressing the problem of repetition in abstractive summarization, this paper proposed a dynamic redistribution of attention over the source document and also further prevent the repetition by sentence backtracking at runtime.
Strengths:

1) Proposed a dynamic attention redistribution via attention filter mechanism. First, summaries and source documents are divided into segments and they compute the parts of interest (POIs) in the source document per segment in the summary. They minimize the attention scores of the words in these POIs that are already attended by the preceding segments in the summary.

2) Proposed a sentence-level backtracking during beam search, where they use ROUGE based score to identify the repetitions in the decoding instead of the tri-gram match-based approach used in the previous work.

3) Thorough analysis of repeatedness and readability scores on CNN/Daily Mail dataset for various models.

Weaknesses:

1) The main issue with this work is lack of fair comparison of their method. Table 4 presents reimplementation of various previous work approaches but they do not include all the components of those previous works, hence, none of them is state-of-the-art model. Line 579-585 says that they only compared with repetition reduction methods proposed previously, however, it is unclear whether these improvements with their new method can be achieved on top of a state-of-the-art (SotA) model. Also, the choice of CNN seq2seq model as baseline is not clear, given that we can also use Transformer-based models (fast training with SotA results). Will your methods show significant improvements on top of a Transformer model?

2) missing statistical significance test for the reported rouge scores in Table 4

3) In Table 4: SBD* model improved significantly w.r.t. its baseline, while ATTF+SBD* vs SBD* improvement is minor (are the scores statistically significant?), suggesting that ATTF is not powerful enough or SBD* brings more improvement than ATTF?

Typos, Grammar, Style, and Presentation Improvements
-- The notion of segment vs sentence is confusing in the model section. Try to make it more clear.

Review3:

What is this paper about, what contributions does it make, and what are the main strengths and weaknesses?
The paper proposes to redistribute the attention based on generated summary sentences, in order to leverage the problem of generating repeated sentences in the summary. The key idea is to use a segment attention vector that is obtained by summing up the attention over the segment span as a filter to prevent generating previously attended sentences.
Strength: The intuition of the proposed method makes sense and the improvement over the vanilla CNN encoder is significant.

Weakness:

The work seems incomplete to me. The baselines are weak and far from the performance of state-of-the-art baselines.
Although CNN is faster and you mention in your paper that it is supposed to generate better representation than RNNs, the reported result with your method ATTF+SBD* (R1: 37.69 R2:15.82 R-L: 26.47) underperforms pointer-generator network proposed by Abigail See et. al. (2016), which use pointer-generator + coverage (39.53 17.28 36.38) by more than 5 points in average. This is a very big discrepancy and the reported ROUGE-L of your models (including baselines) underperform other SOTA models by 10 points (http://nlpprogress.com/english/summarization.html). That seems really strange to me.

Reasons to accept
The proposed approach can potentially improve neural-based summarization model, but definitely need more experiments and stronger baselines to convince me.

Reasons to reject
The main experimental results seem strange to me in Table 4. I am fairly familiar with summarization models and almost all state-of-the-art baselines and models hover around 40 R-1, 18 R-2 and 36 R-L on average. The results on table 4 based on CNN-based encoders have 35 R-1, 15 R-2, and 26 R-L on average roughly. This is very strange to me. Why would these CNN based models have comparable ROUGE1 and ROUGE2, but perform so bad in R-L? This worth to investigate since many past papers argue that ROUGE-L is more important in accessing summary qualities.

The lead3 baseline on CNN/Daily mail (un-anonymized version) is 40.34 17.70 36.57. Even your best model is far from the lead and many state-of-the-art extractive and abstractive models are outperforming lead3 significantly. This really brings down the value of your proposed methods. I am not against your proposed method and I think it is possible that the proposed sentence level attention would help to reduce repeats in the generation. But more experiments need to be done, especially incorporate it with SOTA baselines (even RNNs as intra-attention and coverage are all used on RNNs), so you would have model performances that are not far from lead3 or better than lead3.
