Response#1
Thanks for your reviews.

Linguistic explanations: The reasons for feature selection are mentioned in Sec 1 and 2.1. POS tag and dependency reflect the syntactic features of a word. Word embeddings reflect the syntactic and semantic features, including the word similarity, synonym and topical information.

English and German are distant enough with quite different morphological and syntactic rules. For instance, nouns in German have genders while English don't. More comparisons are mentioned in Optilingo's offical website (https://www.optilingo.com/blog/german/10-differences-between-english-german/).

Multi-class problem: We define our task as a single label classification problem based on the fact that only 6.54% of phrases and words have multiple labels.

Choices of classifiers: We tried different classifiers as mentioned in line 338, such as MLP, SVM and Logistic Regression. Due to the space limitation, we only showed the best results of SVM (Linear Kernel performances best) and MLP in the paper.

The derived features are concatenated into a vector as the input for classifiers.

The features in Hiebert's work has been considered: the polysemy can be represented by the POS feature. Besides, we also have a new feature, the dependency feature. More explanations will be added in the revised version.
*****************************************************

Response#2
Thanks for your comments.

The choice of Embeddings

	* Our work pays more attention to exploring the effectiveness of multi-faceted features for word difficulty instead of comparison among different models of word embeddings.

	* Although we didn't use dependency-based word embeddings, we have considered the dependency information in the "Universal dependency vector" feature which captures the modifier and dependency relation direction of a word.

The parameters of embeddings

	* We tried different parameters for the embeddings. But in this paper we only showed the parameters with the best results. As an example, the following table shows the parameter selection (row:context-size; column:dimension) on the combined corpora of Gutenberg and New York Times (E1+E2).

|   | 100    | 150    | 200    | 250    |

| 2 | 39.47% | 39.77% | 39.80% | 39.68% |

| 3 | 41.09% | 40.77% | 38.89% | 40.85% |

| 4 | 40.34% | *41.18% | 39.49% | 39.81% |

| 5 | 39.16% | 39.26% | 40.11% | 39.90% |

*****************************************************

Response#3
Thanks for your comments.

The difficulty indicator is essential for a L2 learner especially a beginner. Our method aims at showing the effective features to represent the word difficulty and the technique can be applied to different languages or even the same language for different population. For example, there are various standards for learning English, such as CLB (Canadian Language Benchmarks) and PETS (Public English Test System).
The CEFR used in our paper is for European second language learners.

POS tag: As mentioned in line 291, we didn't discard the word with different POS tags. The feature vector for POS is an indicative vector instead of an one-hot vector.

Distance-based score: The correlation coefficient between our models and gold-standard labels is shown in Table 11 which can be regarded as distance-based score.

Morphological features

	* It was a mistake to put length into morphological feature, which will be fixed.

	* Line 196 will be rephrased as "Most languages have morphological features whose sounds and spellings of words are corresponding to the morpheme units."

	* N-gram implemented on character level captures the stems of words, and it can represent the inflections such as prefixes, suffixes and infixes. LM probability is defined as the product of probabilities of morpheme units in a word as shown in line 228.

We use the bag of phonemes instead of syllable counts.

P-value

    * 596: calculated by two frequency distribution. 

    * 631: calculated by the results of ten runs between our proposed models and the best baseline model (T-test).
