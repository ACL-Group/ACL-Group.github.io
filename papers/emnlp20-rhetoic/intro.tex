\section{Introduction}
\label{intro}

In a consultational dialogue between an expert $E$ and a client $C$, $C$ may 
fail to identify its complex information needs in a single consultation. 
So $E$ might ask a clarification question to figure out what $C$ is trying to do. That is, $E$ can assess the credibility of $C$'s previous statements and decide if a clarification question is needed. 
In this process, the main reason for clarifying the question is that $E$ 
can only respond to one of the questions or answers, 
so choosing which response is particularly important for improving 
the performance of the dialogue. \tabref{tab:example1} shows an 
example of such a consultation conversation selected from a health forum. 
We can see that in the first and second round of conversation, 
$E$ does not answer $C$'s statement, but instead ask 
two clarification questions. 
We would like to build a human-computer dialogue system in which
the computer (which acts as the expert) can respond the same way as $E$
in such situation as \tabref{tab:example1}. 
Such response typically involves two steps:
i) determine if a clarification question needs to be asked; and ii)
generate that question.

\begin{CJK}{UTF8}{gbsn}
\begin{table}[th]
\small
\begin{tabular}[t]{p{0.5cm}p{6.5cm}}
\toprule
$C$1:&\makecell[l]{到了秋天我的皮肤就痒,过敏应该吃什么药呢？\\(My skin is itchy in autumn. What kind of medicine\\ should I take for my allergy?)}\\
\hline
$E$1:&\makecell[l]{你好,每年都是这样吗？\\(\textbf{Hello, is it like this every year?})}\\
\hline
$C$2:&\makecell[l]{是的,在秋天就这样了。\\(Yes, in the fall.)}\\
\hline
$E$2:&\makecell[l]{有没有检查过过敏源呢？\\(\textbf{Have you ever had an allergy check?})}\\
\hline
$C$3:&\makecell[l]{没有。\\(No.)}\\
\hline
$E$3:&\makecell[l]{这是季节性过敏,你最好是查一下。\\(This is a seasonal allergy. You'd better have it\\ checked.)}\\
\bottomrule
\end{tabular}
\caption{A consultation conversation between an expert $E$ and a client $C$.}
\label{tab:example1}
\end{table}
\end{CJK}

We study clarification question generation based on clarification questions in person-to-person conversations, for example between doctors and patients. First, we crawl more than 100,000 doctor-patient Q$\&$A in the medical field as a dataset, and then propose a benchmark approach to attack this problem, 
consisting of the following three steps: (i) question classification; (ii) clarification trigger detection; (iii) clarification question generation. The purpose of question classification is to classify the clarification questions and answers that the expert $E$ says in the conversation. This is to construct the dataset that we use for clarification trigger detection and clarification question generation. 
Good conversations are forward-looking \citep{DBLP:journals/jsemantics/AllwoodNA92}. We use different methods to judge whether the $E$ needs to ask a clarification question at this point in the question trigger detection section, which takes into account the conversation above. The purpose of clarification question generation is to pick the appropriate method to generate a clarification question when the $E$ needs to ask.

The contributions of this paper are three-folds:
\begin{itemize}
    \item We collect a large-scale Chinese free-style dialogue dataset in the field of medical consultation and label a test set for the research of clarification question generation.
    \item We propose a baseline approach to determine when a clarification question should be asked and further generate that question automatically.
    \item Our automatic evaluation, manual evaluation and preliminary analysis show that the quality of the generated clarification question is best when taking the length of the current dialogue context into consideration. 
\end{itemize}
