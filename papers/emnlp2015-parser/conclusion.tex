\section{Conclusion}
We developed a novel sequence-based dependency parsing
framework. It shows promising results despite of an unoptimized
implementation.
The key idea is that a good parsing sequence can be predetermined
and can contribute to good parsing accuracy and substantial
speedup. Although only a few simple approaches are attempted here
to train the sequence predictor, the framework allows the integration
of better and more advanced models,
which may lead to results closer to the upper bound (93.59\%).
%We have to emphasis that the key idea of this paper is to
%propose the sequence-based framework, instead of just combining graph-based and
%transition-based methods.
\cut{We currently predict sequence by Malt action classifier,
which offers a best result among our preliminary attempts. }

Even though the current Malt-like sequence predictor 
produces better results among our preliminary attempts, 
the parsing accuracy is limited by the
rather localized or even incorrect sequence order produced by Malt.
%which is the main cause of not reaching the upper bound(93.59\%).
More importantly, we discovered that the parsing accuracy is very
sensitive to the quality of parsing sequence. Future work
can be focused on developing better sequence predictors that
outperform Malt action classifier.

Graph-based methods spend most of the time extracting features.
Some work attempted to save time by displaying arc
filter~\cite{bergsma2010fast,rush2012vine}. We can incorporate some of these
techniques to speed up the parsing. Furthermore, Beam search works well in a
left-to-right head attaching. We can also adapt beam search to
our framework so as to relax its strictly greedy nature.
\cut{
Furthermore, we use two sets of features for sequence predictor and
head mapper right now. A unified set of features between these two components
are worth exploring.
}
%Besides, better sequence predicting method and unified feature
%representation of two components are worth exploring.
%
%Though we currently get a not bad result,
%the sequence predictor still needs more exploration.
%According to our experiment, slightly changes
%on the sequence can lead to a fatal decline on accuracy. Ensuring the match degree of training sequence and testing
%sequence demands a high quality of sequence predictor.
%
%Further, the features in our current implementation are not expanded and well tuned yet  and we are free to define high order features to make use of parsing history. Our framework is flexible to merge other technics to enhance the performance. Introducing beam could make up for our greedy decoder and improve our accuracy. Vine pruning\cite{rush2012vine} could speed up parsing process. Besides, better sequence predicting method and unified feature representation of two components are worth exploring.
