\subsection{Bilingual Lexicon Induction for Internet Slang terms}
\label{sec:bleis}
%In this section, we evaluate our model on the second task, which aims to find the most similar English words in terms of meaning and sentiment of a given Chinese slang term, or vice versa.  
In this section, we first introduce the ground truth and baseline methods for comparison. Then, we analyze the experimental results quantitatively and qualitatively.

\subsubsection{Ground Truth}
We use an online Chinese Internet slang glossary\footnote{{\url{https://www.chinasmack.com/glossary}}} consisting of  200 popular slang terms with English explanations. For English , we resort to a slang word list from OnlineSlangDictionary\footnote{{\url{http://onlineslangdictionary.com/word-list/}}} with explanations and then downsample the list to 200 terms.
%To evaluate the performance of our model, 
%we propose to build the ground truth based on above-mentioned explanations from the glossary and slang dictionary. 
%Since the subtle and latent semantics of slang are too difficult to translate without losing any information, exact translation are always missing. 
For each Chinese slang term, the target English terms are hand picked 
from the English explanation. For each English slang term, the target
Chinese terms are the word-to-word translation from the words hand picked
from the English explanation.
Different methods should produce a list of translation terms 
as similar as possible to the ground truth target terms.
%and then computing the average similarity between the source term and the target terms is a better approach to evaluate a bilingual slang lexicon induction system.
For example, we construct the ground truth target terms for 
the Chinese slang term ``二百五'' by manually labeling words related 
to its meaning in its explanation:
\begin{description}
	\item[二百五] A \textbf{\textit{foolish}} person who is lacking in sense but still \textbf{\textit{stubborn}}, \textbf{\textit{rude}}, and \textbf{\textit{impetuous}}.
\end{description}


%what are the good word translation that best preserve and convey the meaning, sentiment tendency and usage context ot the original slang. 
%However most of the slangs possess most subtle senses that are related to native culture background, general characteristic and language style of netizens in different language worlds. 
%Thus it is really difficult, if not impossible, to find a exact word in another language that carries the exact same meaning with the original slang. 
%Because of this, our ground truth does not pursue exact Internet slang translation from one language to another's corresponding slang, since most likely such slang does not exist yet. 
%Our aim for the task is using IV (in-vocabulary) normal related words in target language to describe and translate the OOV (out-of-vocabulary) slang words in another language, which is more viable and feasible, and easier for people in different culture/language to understand not just literal meaning but the deeper buried and more subtle sense and context it conveys.
%
%Following this goal, we could build our ground truth based on filtered glossary. For Chinese slangs, we tokenize and lemmatize the definition sentences in English and manually remove the stop words that does not contribute to the meaning of a specific slang, left with a list of English words that have either same meaning or high relatedness to the Chinese slang.
%The same process is applied to English slang glossary as well, with the only difference is that due to the lack of direct Chinese definitions, we have to use Google Translate to translate the definition sentences to Chinese and human annotators tokenize, filter and paraphrase the definitions into Chinese word lists, resulting in the ground truth of slangs in the same format as the Chinese ones.
%Note that we do not manually add word translations by ourselves, we only delete irrelevant words for later evaluation, thus lowering the human error, cross-cultural and bilingual requirement to the minimum.

\subsubsection{Baseline and Our Methods}

We propose two types of baseline methods regarding Internet slang translation. 
The first type is based on well-known online translators, namely Google (Gg), 
Bing (Bi) and Baidu (Bd).
%With our test set's slang as input, we retrieve the output of translation. 
An additional baseline specific to Chinese slang is from CC-CEDICT\footnote{{\url{https://cc-cedict.org/wiki/}}} (CC), an online public-domain Chinese-English dictionary, which is well updated with popular slang terms. 
Considering situations that many slang terms have literal meaning, it is unfair to retrieve target terms from online translators by simply inputing slang terms without slang contexts. 
Thus, we use example slang sentences  from some websites 
(mainly from Urban Dictionary\footnote{{\url{http://www.urbandictionary.com/}}} ) 
as input, so that translators have a chance of knowing the slang meaning 
instead of literal meaning. \footnote{However, we noticed
that the online translators seem to ignore the slang contexts and still produce
literal translations.}
The following example shows how we obtain the target translation terms 
for the slang word ``fruitcake'' (an insane person) from Google Translator.

\noindent
\underline{Input Sentence:}
{\textit{Oh man, you don't want to date that girl. She's always drunk and yelling. She is a total \underline{fruitcake}.}}\footnote{{\url{http://www.englishbaby.com/lessons/4349/slang/fruitcake}}}\\ 
\underline{Google Translation:}
{\small哦, 男人, 你不想约会那个女孩。她总是喝醉了, 大喊大叫。她是一个\underline{水果蛋糕}。}

Since all possible target terms must come from the bilingual lexicon, 
we can score each of them and consider the top five as the target 
terms. Given a source term to be translated, two such scoring-based 
baseline methods are as follows.
Linear Transform (LT) method scores the candidate target terms by 
computing cosine similarities in the transformed vector space. 
A more sophisticated baseline (BL) leverages the bilingual lexicon: 
for each candidate target term $w$, we first obtain its translations 
$T_w$ back into the source language and then calculate the average word similarities between the source term and $T_w$  as the score of $w$. 
%Now over 20,000 words in the other language of the bilingual lexicon have their corresponding similarity score to the given slang. 
%A word may have multiple possible translation words in the other language. In this case, we choose to take average over all of them in terms of similarity score.
%We then rank the words by their scores and take top 5 words to form a word set, while other online translation baselines directly produce a word set for later comparison with the ground truth word set. 

\textbf{{Our SocVec-based method}} Our method (SV) simply calculates the cosine similarities between the source term and each candidate target term within \textit{\socvec} space as scores.

\subsubsection{Experimental Results}
\begin{table*}[th!]
	\small
	\centering
	\caption{Slang Translation Examples}
	\begin{tabular}{|L{1.2cm}|L{4.7cm}|L{1.7cm}|L{1.7cm}|L{1.7cm}|L{2.8cm}|}
		\hline
		\textbf{Slang} & \textbf{Explanation} & \textbf{Google}& \textbf{Bing}& \textbf{Baidu} & \textbf{Ours} \\ \hline \hline
		浮云 &something as ephemeral and unimportant as ``passing clouds''& clouds& nothing& floating clouds & nothingness, illusion \\ \hline
		水军 &``water army'', people paid to slandering competitors on the Internet to help shape public opinion& Water army& Navy& Navy & propaganda, complicit, fraudulent\\ \hline
		%		城管 & ``City administrators'', who enforce city regulations, with poor reputation as being corrupt and violent, best known for physically bullying illegal street peddlers & urban management& urban management& urban management & terrorist, rioting, threaten\\ \hline \hline
		floozy & a woman with a reputation for promiscuity & N/A&劣根性 (depravity)&荡妇(slut)&骚货(slut),妖精(promiscuous)\\ \hline
		fruitcake& a crazy person, someone who is completely insane & 水果蛋糕 \quad(fruit cake)&水果蛋糕 \qquad(fruit cake)&水果蛋糕 \quad(fruit cake)& 怪诞(bizarre),令人厌烦(annoying)\\ \hline
		%		nonce &  A person convicted (or simply guilty) of sexual crimes, especially pedophilia. Or a common British insult regardless of the tendencies of the person &随机数 (random numbers)&杜撰 (fabricate)&杜撰 (fabricate) & 伤风败俗(immoral),十恶不赦(extremely evil),畜类(beast),令人发指(heinous)\\ \hline
	\end{tabular}
	\label{tab:bleis_3}
\end{table*}
To quantitatively evaluate our methods, we need to measure similarities between the produced target term set and the ground truth word set. 
Exact-matching Jaccard similarity is too strict to capture valuable relatedness between two word sets.
We argue that average cosine similarity (ACS) between two sets of word vectors is a better metric to evaluate the similarity between two word sets. The following equation illustrates such computation, where $A$ and $B$ are the two word sets, $\mathbf{A_i}$ and $\mathbf{B_j}$ denotes the word vector of the $i^{th}$ word in $A$ and $j^{th}$ word in $B$ respectively. 
\begin{align*}
ACS (A,B)=
{\frac{1}{|A||B|}}{\sum_{i=1}^{|A|}{\sum_{j=1}^{|B|}} \frac{\mathbf{A_i }\cdot \mathbf{B_j}}{\|\mathbf{A_i }\|\|\mathbf{B_j }\|}}
\end{align*}

\begin{table}[H] 
	\small
	\centering
	\begin{subtable}[h]{\columnwidth}
		\centering
		\begin{tabular}{|c|c|c|c|c|c|c|}
			\hline
			Gg&  Bi& Bd & CC & LT  & BL  & SV \\ \hline
			18.24 &  16.38&  17.11 & 17.38 & 9.14&  20.92& \textbf{23.01}\\ \hline  
		\end{tabular}
		\subcaption{Chinese Slang to English}
	\end{subtable}
	\vfill \hfill
	\begin{subtable}[h]{\columnwidth}
		\centering
		\begin{tabular}{|c|c|c|c|c|c|}
			\hline
			Gg&  Bi& Bd &  LT  & BL  & SV \\ \hline
			6.40 &  15.96 &  15.44 &  7.32 &  11.43& \textbf{17.31} \\ \hline  
		\end{tabular}
		\subcaption{English Slang to Chinese}
	\end{subtable}
	\caption{ACS Sum Results of Slang Translation}
	\label{tab:bleis_acs}
\end{table}
Experiment results of Chinese and English slang translation in terms of the sum of \textit{ACS} are shown in~\tabref{tab:bleis_acs}.
The performance of online translators for slang typically depends on human-set rules and supervised learning on well-annotated parallel corpora, which are rare and costly, especially for social media where slang emerges the most. This could be a possible reason why they do not perform well. 
Linear transformation model is trained on translation pairs with high confidence in the bilingual lexicon, which contains little information about the OOV slang terms and social context on them, which is why LT method performs badly.
\textit{BL} method is competitive because its similarity computations 
are within monolingual semantic spaces and it uses a bilingual lexicon 
to transform, while it loses the information from the related words 
which are not in the bilingual lexicon.
%Experiment results of Chinese and English slang translation in terms of the sum of \textit{ACS} over the translations of 200 slang terms are shown in~\tabref{tab:bleis_acs}.
%The performance of online translators for slang terms typically depends on human-set rules and supervised learning on well-annotated parallel corpora, which are rare and costly, especially for social media where Internet slang emerges the most. 
%This could be a possible reason why they do not perform well. 
%~Linear transformation model is trained on translation pairs with high confidence in the bilingual lexicon, which contains little information about the OOV slang terms and social context on them, which is the reason why  LT method performs badly.
%\textit{BL} method is competitive for its similarity computations are within monolingual word vector spaces and uses a bilingual lexicon to transform, while it loses the information from the related words which are not in the lexicon translation pairs.
Our method (SV) outperforms baselines by directly using the distances in 
our proposed bilingual embeddings~\textit{SocVec}, which proves 
that ~\textit{SocVec} can capture the cross-cultural similarities between terms.
%utilizes comparable English and Chinese social media corpora and 
%encodes the context and usage of a given slang term by computing its similarities with words in the socio-linguistic vocabulary of the source language. Therefore, 
%our model keeps the cross-cultural socio-linguistic features, which is a most important reason why we outperform baselines.
%the best among all the baseline methods. 
%Then, we are able to find the most similar counterparts in the target language by computing the similarity in \textit{SocVec} space through \textit{BSL}. 
%Therefore, our performance is better than the others.    

To qualitatively evaluate our model, in~\tabref{tab:bleis_3}, 
we present several examples of our translations for Chinese and English slang 
terms as well as their explanations from glossaries.
Our results are highly correlated with these explanations and 
capture their core semantics, whereas most online translators just offer 
literal translatation of such slang terms, even with the ample
slang contexts.
% They often offer just literal meanings as translation even with the specific slang context using the example sentences from Urban Dictionary.
\begin{table}[th]
	\small
	\centering
	\caption{{Slang-to-Slang Translation Examples}}
	\begin{tabular}{|C{1.92cm}|L{2.5cm}|L{2.0cm}|}
		\hline
		\textbf{Chinese Slang} & \textbf{English Slang} & \textbf{Explanation} \\ \hline
		萌 & adorbz, adorb, adorbs, tweeny, attractiveee & cute, adorable \\ \hline
		二百五 & shithead, stupidit, douchbag & A foolish person\\ \hline
		鸭梨 & antsy, stressy, fidgety, grouchy, badmood & stress, pressure, burden \\ \hline
	\end{tabular}
	\label{tab:bleis_4}
\end{table}
Additionally, we take a step forward to directly translate between 
English slang terms and Chinese slang terms by simply filtering out 
common words in the original target term lists. Examples are shown 
in~\tabref{tab:bleis_4}. 
