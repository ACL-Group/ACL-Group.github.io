#R1
1. "uncertain about the necessity of the prominent aspect extraction problem"
While it is true that the human knowledge is useful in characterizing a product type, such manual approach does not scale well for general-purpose e-commerce platforms, such as Amazon and eBay, which feature too many product types, not to mention that new product and service types are emerging every day. Moreover, the key aspects of a product type may change over time. As shown in the paper, people care more about the screen size and signal intensity of a cell phone
in the past, while today they focus on battery life and processing speed.
Besides, when people talk about the bands nowadays, they usually refer to the smart bands which obviously have a different set of key aspects with the traditional ones.
The proposed approach can be applied to the emerging and cross-domain products as well as captures the changes of aspects over time.

2. "it is not clear whether other baselines implicitly address this point"
The topic modeling based baselines cannot control the granularity of the topics. For example, as shown in Table 5, `song` and `music` are treated as distinct key aspects of mp3 using LDA, while they are actually subtopics of the prominent aspect `sound`. For the neural based model, ABAE, which tends to minimize the semantic overlaps between different aspect clusters due to its clustering manner. However, ABAE focuses on extracting the fine-grained aspects and the top ranked aspect of each cluster is not qualified as a prominent aspect, as shown in Table 5.

#R2
1. "The quantitative evaluation (Sec. 3.3.1) is complex"
We do not use examples to further illustrate the quantitative evaluation due to the space limitation. We will add more examples to improve this in the revised version.

2. "presentation improvements"
We will definitely fix the typos and modify our representation accordingly.

#R3
1. "A more fair comparison might have been the extraction of 2K or 3K topics and then hand-picking the topics that correspond to aspects"
Yes, we agree that introducing the human effort may improve the accuracy
of the generated prominent aspects. However in this work, we only focus on the 
methods of automatically extracting the prominent aspects from user reviews.

2. "Would've liked to see a comparison of AutoPhrase with ExtRA"
AutoPhrase prefers the coherent phrases. For example, the top phrases extracted by AutoPhrase using reviews of laptop are `ogg vorbis`, `hip hop` and `steve jobs` which cannot be used as aspects. In Sec 2.2, we extract a multitude of phrases under the <N, N_{-1}> scheme, then we use AutoPhrase to filter out the incoherent phrases so as to obtain a set of high-quality phrases.

3. "Would like to see if the results are statistically significantly different, comparing AmodExt and ExtRA."
AmodExt is from the first stage of ExtRA which doesn't get the benefit of the 
aspect taxonomy. As shown in Table 5, AmodExt cannot help but extracting 
the semantically-overlapping aspects, such as `location` and `place` for hotel and `picture` and `photo` for cameras. 

4. "Is the evaluation suggested in Liu et al 2017 not applicable here?"
Since it is difficult to acquire exact K true prominent aspects for a given product type, we cannot directly use the evaluation method in Liu et al 2017.
Instead, we ask multiple annotators to provide K aspects each and keep all those labels, then apply the proposed quantitative evaluation on them.

5. "suggestion: Determinental point processes"
We will consider this in the future work.

