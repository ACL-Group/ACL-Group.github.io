\section{Introduction}
\label{sec:intro}
Causal reasoning, the core challenge in artificial intelligence, which aims to understand the causal dependency between events, is receiving more and more attention \cite{Pearl2009}.
In the reasoning process, causal knowledge plays a critical role in people's daily behavior and decision-making \cite{waldmann2013causal}.
It is of great interest in many domains, including finance \cite{Dunietz2017}, where understanding causality can provide significant opportunities for economic benefits. 
For example, consider the following,
\begin{enumerate}
	\item If a large disaster happens in a country and this country is rich in certain metal, the price of this metal will rise. \label{intro:natural-language-rule-1}
	\item If the price of some kind of metal rises, the price of the products based on this metal will also go up. \label{intro:natural-language-rule-2}
\end{enumerate}
Above causal knowledge expressed in the form of natural language is easy for us to understand and has great practical value in real life through simple reasoning. For example, if there's an earthquake in Chile and we know above rule \ref{intro:natural-language-rule-1}, it is easy to infer the price of copper will rise. Further, we can infer the price of the household appliances, such as air conditioners and refrigerators, will also rise via above rule \ref{intro:natural-language-rule-2}.

However, it is a daunting task for humans, especially traders, to learn many of these rules and use them for real-time reasoning in the real world.  
We hope machines can learn these rules automatically and reason quickly with them to help us get rid of the heavy burden of rule learning and real-time massive information processing. 
In order to achieve this goal, we face two challenges: how to represent causal knowledge in a machine-actionable way and how to automatically acquire a large amount of this type of causal knowledge. We explain these two aspects separately.
	
\subsection{Causal Knowledge Representation and Reasoning}
To get some inspirations on how to represent causal knowledge, we first review some previous causal knowledge representation schemes. Now, there are two general directions [for/of addressing] causal knowledge representation. 
One direction is \textbf{\textit{Neural or numeric}} form. Such neural form scheme can represent both causal knowledge and non-causal knowledge by a unified graph-embedding method \cite{Li2016a,Bordes}. However, it has problems of interpretability and reusability, which means that new data requires complete training from scratch.
The other direction is the \textbf{\textit{symbolic}} form, which also includes two directions. One is the specific description of causal knowledge. In this way, both the cause and the effect of the causal knowledge are specific events or actions, expressed by terms, short text or complete sentence, such as CausalNet \cite{Luo2016a}, ConceptNet \cite{Speer2016}, BECauSE 2.0 \cite{Dunietz2017}. However, this kind of knowledge is usually less expressive, since it only focuses on a specific causal event pair instead of a class of causal event pair. [For example, we can use general causal pair (watching\_entertaining\_video, /r/Causes, fall\_asleep), which is more expressive, to represent specific causal event pairs in ConceptNet, such as (watching\_movie, /r/Causes, fall\_asleep) and (watching\_television, /r/Causes, fall\_asleep).] The other direction is towards the general description of causal knowledge. In this manner, both the cause and the effect of the causal knowledge are abstract events, expressed by structures, such as frame in FrameNet \cite{BakerCollinFandFillmoreCharlesJandLowe1997} or a pair of abstract words \cite{Zhao2017}.
For example, in FrameNet, the `Causative\_of' relation exists between frame `Killing' and frame `Death'. 'Killer' and 'Victim' are two elements of frame `Killing', and `Protagonist' is one of the elements of `Death'. However, there is no explicit information expressing `Victim' and `Protagonist' refer to the same one. Therefore, these structures are usually unfriendly for machines to do precise reasoning.

As stated above, previous causal knowledge representation schemes encounter problems, such as uninterpretability, insufficient expression ability and unfriendly reasoning.
Therefore, we propose a novel and powerful representation scheme with logical form, which takes structured events as the basic key components and can reason with uncertainty. 
Here, we use the following logic rule (1), equivalent to above natural language rule \ref{intro:natural-language-rule-1}, as an example to illustrate how this idea evolved. 

上涨\_1/rise\_1(Z,价格/price,`',`'):-遭受\_1/suffer\_1(`',X,Y,袭击/attack),isA(X,国家/country),isA(Y,自然灾害/disaster),isA(Z,金属/metal),atLocation(Z,X) conf:0.842 \ \ (1)

\textit{First,} we try to use tuple structure to represent the events in the cause part and effect part of the causality well. A simple and effective symbolic event representation is a structured form \textit{Predicate(Subject, Object)} as used in \cite{Ding} and \cite{Ding2016}, also known as SPO. To capture richer event information, we extend the SPO form to \textit{Predicate(Modifier of Subj, Subj, Modifier of Obj, Obj)}. 
We call this event pair a rule instance, see (2) (following the convention of Prolog, we put the cause part in the head position).

上涨\_1/rise\_1(铜/copper,价格/price,`',`'):-遭受\_1/suffer\_1(`',智利/Chile,地震/earthquake,袭击/attack)\ \ (2)

\textit{Second,} using such a specific rule instance (2) to represent causal knowledge is less expressive and lacks the ability to infer the unseen since it is likely that some causal event pairs that we can recognize in this world are not written in a
corpus, no matter its size \cite{ha2015gener}. Instead, we use the generalized rule (3).

上涨\_1/rise\_1(Z,价格/price,`',`'):-遭受\_1/suffer\_1(`',X,Y,袭击/attack),isA(X,国家/country),isA(Y,自然灾害/disaster),isA(Z,金属/metal)\ \ (3)

\textit{Third,} reasoning using rule (3) may result in some errors. For example, we can get one inferred result: 上涨\_1/rise\_1(铁/steel,价格/price,`',`'):- 遭受\_1/suffer\_1(`',智利/Chile,地震/earthquake,袭击/attack). This is unreasonable because Chile is a large copper producer rather than a large steel producer. Therefore, we add some constraint relations, such as atLocation(Z,X), to exclude unreasonable inference.

\textit{Last,} after previous step, we assign a confidence value to enable it to reason with uncertainty. Finally, we get rule (1).

\textbf{\textit{To sum up}}, this kind of rule is more expressive and friendly for machines to reason.
%Moreover, it can be easily extended to the complex conjunction of multi-cause events by adding multiple cause events to the header of the rule. 
To the best of our knowledge, this is the first work about studying uncertain causal reasoning with the logical rule based on abstract event. 

\subsection{Causal Knowledge Acquisition}
\label{intro:Causal_Knowledge_Mining}
After developing a machine-actionable causal knowledge representation scheme with the logic rule, we need to tackle the second challenge about how to automatically obtain a large number of rules.  
WWW (World Wide Web) is a very large treasure trove of knowledge, but most of the content is unstructured and noisy text, which challenges us to learn rules.
Rule learning has been studied extensively in Inductive Logic Programming (ILP) \cite{Quinlan1990,Muggleton1997}. However, the rule instances extracted from Web text are noisy and incomplete. That negative examples are mostly absent cannot make the closed-world assumption typically made by ILP systems. This paper presents a new ILP system, which adopts a bottom-up approach with two stages:	

\textbf{1) From unstructured text to structured rule instances} Online text is massive but noisy. We first derive the sentences with causal relation through the designed patterns. Then, we use event extraction technology to extract the structured rule instances, such as above (2).
	
\textbf{2) From specific rule instances to general rules} With a large number of rule instances, we generalize them into rules, such as above (1), while balancing generality and specificity:
	
\textbf{Generality} We try to represent given rule instances semantically with as few general rules as possible under the help of Probase \cite{Wu2012a}. For example, generalize two rule instances fall\_1(corn,price, `',`'):-rise\_1(corn, yield,`',`'), fall\_1(soybean,price, `',`'):-rise\_1(soybean, yield,`',`') into the rule fall\_1(X,price,`',`') :- rise\_1(X, yield,`',`'),isA(X,food).


\textbf{Specificity} Overgeneralized  rules may lead to errors. For example,
generalizing above two rule instances into the rule fall\_1(X,price,`',`'):-rise\_1(X,yield,`',`'),isA(X,thing) is unreasonable. Because when the machine instantiates thing into air, the inferred events ``the yield or price of air rises" do not make sense.

Generalizing rule instances to rules can be seen as a semantic compression procedure, which accords with the MDL principle \cite{rissanen1978mdl}. In our case, hypotheses (H) accords with rules and data (D) accords with rule instances. Thus, we propose a rule induction algorithm, which takes MDL as the evaluation criterion and regards this rule induction procedure as an optimization problem, see detail in \ref{sec:approach}. This procedure is similar to \cite{Cui2016} and \cite{Zhu}. Finally, each learned rule will be automatically assigned a confidence value by considering some heuristics.
	
\textbf{Contributions}
In this paper, we present a full stack solution for causal knowledge representation, acquisition, and reasoning. More precisely, our contributions are as follows:
First, we design a novel and powerful causal knowledge representation scheme based on the logic rule with the ability of uncertain reasoning.
Second, we propose a rule learning framework for obtaining rules from large unstructured text and experiments show that the rules learned are reasonable and effective. 
Specifically, we learned 42037 rules and human's evaluation shows the top 10000 rules of the highest confidence reach 50.5\%(good), 39.5\%(fair), 10.0\%(bad). Last, we release the rules, the \zhpro and \zhcon and provide an interactive demo to show the reasoning process.
%and the application of futures price triggering. \TD{second and last repeat?}
	
The remainder of this paper is organized as follows. Our proposed rule learning and reasoning approach are presented in Section \ref{sec:approach}. Section \ref{sec:experiment} reports the experimental observations followed by a brief review of related works in Section \ref{sec:related}. Section \ref{sec:conclusion} concludes the paper.

%	\section{Problem Definition}
%	\label{sec:problem}
%	
%	In this section, we will formally state the focal problem to be solved.
%	\begin{equation}
%	\begin{split}
%	&p_e('', X_1, no_e, o_e):-p_c(X_0, s_c, no_c, o_c)\\
%	&isA(X_0, c_1),isA(X_1, c_3)\\
%	&relation(X0,X1) 
%	\end{split}
%	\label{equ:rule_notation}
%	\end{equation}
	%The list of major symbols and notations in this paper is summarized in the following table.
	
	%\begin{table}[htbp]
	%	\caption{Table of notations }
	%	\begin{center}
	%		\begin{tabular}{|c|l|}
	%			\hline
	%			\textbf{Notation}&\textbf{Definition}\\
	%			\hline
	%			rule instance & structured causality proposition pair\\
	%			\hline
	%			$E_{c_i}$ & the instances of $i-th$ concept \\
	%			\hline
	%			\multirow{2}{*}{rule}
	%			& generalized rule instance with concept constraints \\
	%			&and relation constraints \\
	%			\hline
	%		\end{tabular}
	%		\label{tab1}
	%	\end{center}
%	\end{table}	
	
	%our goal:
	%	We try to make reasoning interpretable via symbol not neural network. 
	% 
%	\textbf{Problem Statement.} Mining the causality knowledge in the form of first-order logic rule \ref{equ:rule_notation} from large online free text.