\section{Related Work}
\label{sec:related}
%We will review the related work from three perspectives: causal knowledge
%representation and reasoning, knowledge discovery, and some other related works.
\paragraph{Knowledge Representation and Reasoning}
Most of symbol-based work took specific event as key component, which fails to discover high-level abstract causality rules. For example, in ConceptNet \cite{Speer2016}, (`smoking', `/r/Causes',`cancer') fails to predict rare events like 'cough', thus limiting the flexibility. So does CausalNet \cite{Luo2016a}, which represents the event with a word.
Besides, FrameNet\cite{BakerCollinFandFillmoreCharlesJandLowe1997} is unfriendly to reason as analysed in Section \ref{sec:intro}. The same problem is with ATOMIC \cite{sap2018atomic} and  BECauSE 2.0 \cite{Dunietz2017} since their data is semi-structured or unstructured. \cite{Radinsky2012} uses clusters of causal event pairs to represent general causal knowledge, however, the general knowledge expressed in each cluster is implicit due to the blurred boundaries of each cluster.  Meanwhile, some works explored neural-based method, such as \cite{Bordes} and \cite{Li2016a}, which embeds knowledge graph into dense vectors. Neural-based method is effective for many downstream Natural Language Processing (NLP) works \cite{Wang2017}. However, it has problems of interpretability and reusability. Most importantly, all the previous work has no ability to express the uncertainty, which is necessary for machine to simulate the reasoning process.
\paragraph{Rule Acquisition} 
Different ways of knowledge representation adopt different knowledge acquisition methods.
Here, we mainly review how to acquire knowledge of logic rule. 
%The Inductive Logic Programming(ILP)\cite{Quinlan1990,Bergadano1996,Muggleton1997} makes strong assumptions, such as high-quality training data, closed-world assumption, and so on, which are inappropriate to handle the extracted data from Web text.%
This has been studied extensively in Inductive Logic Programming (ILP) (Quinlan, 1990; Muggleton, 1996). However, the strong assumptions made by ILP, such as high-quality training data, closed-world assumption are not met in the task of rule extraction from Web text.
For example, SHERLOCK system \cite{Schoenmackers2010} learns the first-order horn clauses in a top-down manner, which first identifies the classes(concepts in our rules) and relations(predicates in our events), enumerates all their combinations, and keeps good ones as final rules. 
However, due to a large number of predicates and concepts in web text, as well as the complexity of the rule structure, their combination will be explosive in our case. Therefore, this method is not applicable for open-domain knowledge acquisition. Instead, we propose a bottom-up framework based on MDL to learn rules.

%\subsection{Misc}
%\paragraph{Event-based Graph Construction}
%Event Extraction task has beed a long-standing problem in information Extraction which typically include two subtasks, event detecting and classification. In this paper, we mainly detect the events with a open form, which means we have no predefined event type constrains. many researchers use the parser to do event detection subtasks, for example, \cite{Huang2017} use the AMR parsing\cite{Wang2015e} or Semantic Role Labeling (SRL) to extract the event candidate, \cite{Ding2016} use the Open IE\cite{Fader2011} and dependency parsing to extract the structured events.

%Event-based Graph construction   
%\cite{Saleh2018} learns the narrative event chains from raw newswire text. Further
%\cite{Glavas2015} formally proposes the concept of event graphs where events are structured and concrete. Later, a hierarchical event network using event abstract duples (verbs and nouns) as nodes and causality to represent edges is proposed in \cite{Zhao2017}. \cite{Li} constructs the Narrative Event Evolutionary Graph and the graph neural network is used to predict the subsequent events. Our rules can also be seen as an abstract event graph, but it is a logical form that is easy to reason.

%\paragraph{Financial Market Price Prediction} There are many works on financial market price forecasting using text information, mainly on stock prices. \cite{Ding} attempts to use structured event information to predict stock prices. 
%Furthermore, \cite{Ding2016} enriches event representation with the knowledge base to improve prediction accuracy.

%deductive database \\
\section{Conclusion and Outlook}
\label{sec:conclusion}

In this paper, we design a novel and powerful causal knowledge representation scheme based on the logic rule with the ability of uncertain reasoning and we propose a rule learning framework for obtaining rules from large unstructured text. The experiments show that the rules learned are reasonable and effective.
In the future, we would like to improve the main components in the rule learning framework, such as rule instance extraction, external knowledge bases, and rule induction. Besides, we will also explore other downstream applications based on this reasoning system, such as consumption intent prediction, stock price prediction, and reasoning-based information retrieval.




