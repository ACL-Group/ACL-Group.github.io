\subsection{Human Evaluation}
Except the automatic evaluation in Section \ref{sec:res}, human evaluation is also important to show the performance of our methods.
%Since our system finishes answer extraction and question generation at the same time, and considering the relevance of aspect keywords, we will perform human evaluation from these three angles.
Since our system consists of answer extraction and question generation, 
and considering the relevance to aspect keywords,
we can evaluate the QA pairs from 4 metrics which are rated on a 1-5 scale.
\begin{itemize}
\item \textbf{Relevance ($S_R$)}: The relevance between one QA pair and corresponding aspect keyword.
\item \textbf{Meaningful ($S_A$)}: The quality of an extracted answer, it need to determine that whether the answer is meaningful and complete.
\item \textbf{Grammaticality ($S_Q$)}: The grammatical correctness and fluency of the generated question.
\item \textbf{Answerable ($S_{QA}$)}: According to the original context, whether the generated question can be answered by the current answer.
\end{itemize}
%\begin{itemize}
%\item \textbf{Score with Aspect.} This is used to evaluate the relevance between QA pairs and the aspect keyword. 
%%If relevant, it will be set as 1 otherwise it is 0. 
%\begin{itemize}
%\item Relevant: 1, 
%\item Irrelevant: 0.
%\end{itemize}
%\item \textbf{Score of Answer.} A complete and meaningful answer is expected to be extract. Therefore the scale to evaluate the answers is divided into three levels:
%\begin{itemize}
%\item Complete and meaningful: 2, 
%\item Incomplete but little meaningful: 1, 
%\item None: 0.
%\end{itemize}
%\item \textbf{Score of Question.} A good question is regarded to have high fluency and be well matched to the input paragraph and the answer. The scale is divided into four levels:
%\begin{itemize}
%\item Fluent and well matched with the answer: 3, 
%\item Non-native but matched with the answer: 2, 
%\item Disfluent but matched with the answer: 1, 
%\item None: 0.
%\end{itemize}
%\end{itemize}

There are 3 annotators and each is presented with a total of \SY{144} QA pairs which are extracted from \SY{5} contexts for all the models shown in Table \ref{tab:res}.
After annotating, we use the following formula to calculate the total score of each QA pair:
\begin{equation*}
\small
S_{\text{Human}} = S_R \times (S_A + S_Q + S_{QA}).
\end{equation*}
Due to the definition of this task is to generate aspect related QA pairs, $S_R$ will be scaled to [0, 1] and regarded as a factor in above formula.
%To allocate the same weight for these three angles, we scaled each score to 1.0 and the calculated the total score for each QA pair.
%Table \ref{tab:humaneval} records the results for human evaluation.

%\begin{table*}[th]
%\scriptsize
%\centering
%\begin{tabular}{ccccc}
%\toprule[1.5pt]
%\textbf{} & \textbf{Score with Aspect} & \textbf{Score of Answer} & \textbf{Score of Question} & \textbf{Total} \\
%\midrule
%\textbf{BERT+BiLSTM-CRF+Seq2seq}&0.64  &  0.53  &  0.26  &  1.43  \\
%\textbf{BERT+BiLSTM-CRF+}$\text{\textbf{Seq2seq}}_{\text{\textbf{Aspect}}}$& 0.66  &  0.53  &  0.31  &  1.50  \\
%\textbf{BERT+Ptr+Seq2seq}& 0.84  &  0.81  &  0.49  &  2.13 \\
%\textbf{BERT+Ptr+}$\text{\textbf{Seq2seq}}_{\text{\textbf{Aspect}}}$& 0.84  &  0.81  &  0.49  &  2.13  \\
%\textbf{BERT+Ptr+UNILM}& 0.85  &  0.81  &  0.67  &  2.33  \\
%\textbf{BERT+Ptr+}$\text{\textbf{UNILM}}_{\text{\textbf{Aspect}}}$& 0.85  &  0.81  &  0.70  &  2.35  \\
%\midrule
%\textbf{Ptr+UNILM+Filtering}& 0.44  &  0.83  &  0.40  &  1.67\\
%\midrule
%\textbf{BERT+Ptr+UNILM+Filtering}&\textbf{0.95}  & \textbf{0.88} &  \textbf{0.76} &  \textbf{2.59}  \\
%\textbf{BERT+Ptr+}$\text{\textbf{UNILM}}_{\text{\textbf{Aspect}}}$\textbf{+Filtering}& 0.90  &  0.75  &  0.67  &  2.32  \\
%\midrule
% \textbf{Full Marks} & 1.00 & 1.00 & 1.00 & 3.00 \\
%\bottomrule[1.5pt]
%\end{tabular}
%\caption{\label{tab:humaneval} Scores for human evaluation. The numbers shown here is the average score for each QA pair labeled by each annotator. 
%%Noted that the full marks for each QA pair is 6. 
%}
%\end{table*}

\SY{It is observed that the results by human evaluation follow the similar trends with automatic evaluation.
xxx}
%Complete and meaningful answers are easy to inquire about, so the answers extracted by pointer network have more meaningful questions, which is reflected in the 3rd and 4th columns from the 1st to 4th rows. 
%Similarly, a better question generation model can produce better questions which is reflected in the 4th column from the 3rd to 6th rows. 

%Our framework has two drawbacks.
%One is that the aspect keywords don't play a significant role in question generation.
%The other is that the filtering model is not strong enough, it often removes the relevant QA pairs but keeps the irrelevant ones, and that is the reason we need to integrate aspect in all steps to strengthen its influence.


\subsection{Case Analysis}
\label{sec:analysis}
%Observing the results illustrated in Table \ref{tab:res}, the F1 score between generated samples and ground truth doesn't perform very well. 
%are a little far from the ground truth, which reflects there are amount totally different QA pairs produced by our framework.
In this section, we will show several cases of our generated QA pairs to analyze the results.
%Since the pipeline framework \textbf{BERT+Ptr+}$\text{\textbf{UNILM}}_{\text{\textbf{Aspect}}}$ has relatively high F1 scores, we choose this method to extract QA pairs.
Since the method ``Ck-QG$_\text{Aspect}$-$\text{R}_\text{a}$'' has the highest F1 scores in Table \ref{tab:res}, we choose this method to extract QA pairs and analyze its results.
%Since the methods using Chunking to extract answers have better performance, 
%we will analysis the QA pairs extracted by ``Ck-QG-$\text{R}_\text{a}$-Filter'' and ``Ck-QG$_\text{Aspect}$-$\text{R}_\text{a}$'' in Table \ref{tab:ex_qa}.
%Table \ref{tab:ex_qa} and \ref{tab:ex_qa2} randomly lists several generated QA pairs.
%Table 
%They are obtained from the Wikipedia page ``Normans''~\footnote{Normans: https://en.wikipedia.org/wiki/Normans} with the aspect keyword ``architecture'' and ``music'' respectively.
%Table \ref{ex_qa} shows the results of the above two methods.
%Then, we can analyze the results from several angles:
\begin{table}[th]
\scriptsize
\centering
\begin{tabular}{lll}
\toprule[1.5pt]
\textbf{$Aspect$}      & \multicolumn{2}{l}{architecture}                              \\
\midrule
\textbf{$Context$}               & \multicolumn{2}{l}{\begin{tabular}[c]{m{5cm}}Norman architecture typically stands out as a new stage in the architectural history of the regions they subdued. They spread a unique \textbf{Romanesque} idiom to England and Italy, and the encastellation of these regions with keeps in their north French style fundamentally altered the military landscape. Their style was characterised by \textbf{rounded} arches, particularly over windows and doorways, and massive proportions.\end{tabular}} \\\\
Ground Truth              & \multicolumn{2}{l}{\begin{tabular}[c]{m{5cm}}
$Q_1$:xxx\\
$A_1$:xxx\\\\
$Q_2$:xxx\\
$A_2$:xxx\\\\
$Q_3$:xxx\\
$A_3$:xxx\\
\end{tabular}}\\
                     \midrule
%\textbf{$P_2$}               & \multicolumn{2}{l}{\begin{tabular}[c]{m{4cm}}In England, the period of Norman architecture immediately succeeds that of the \textbf{Anglo-Saxon} and precedes the \textbf{Early Gothic}. In southern Italy, the Normans incorporated elements of Islamic, Lombard, and Byzantine building techniques into their own, initiating a unique style known as Norman-Arab architecture within the Kingdom of \textbf{Sicily}.\end{tabular}} \\\\
\multirow{6}{*}{Ck-QG-$\text{R}_\text{a}$-Filter} & \begin{tabular}[c]{m{4cm}}
$Q_4$: What period follows the Anglo-Saxon in England?\\ 
$A_4$: Norman architecture
\end{tabular} & $\checkmark$ \\ \\
& \begin{tabular}[c]{m{4cm}}
                     $Q_5$: What style of architecture did the Normans create in southern Italy?\\ 
                     $A_5$: Norman-Arab architecture
                     \end{tabular} &  $\checkmark$\\
\bottomrule[1.5pt]
\end{tabular}
\caption{\label{tab:ex_qa} Examples of generated QA pairs by the Filtering Method and Aspect-based Method.
\textbf{Bold} strings in Context represent the ground truth answers.
The marks behind each QA pair shows the relevance between it with the aspect, where ``$\checkmark$'' means they are relevant and ``$\times$'' means they are irrelevant.}
\end{table}

%\begin{table}[th]
%\scriptsize
%\centering
%\begin{tabular}{lll}
%\toprule[1.5pt]
%\textbf{$Aspect$}      & \multicolumn{2}{l}{architecture}                              \\
%\midrule
%\textbf{$P_1$}               & \multicolumn{2}{l}{\begin{tabular}[c]{m{5cm}}Norman architecture typically stands out as a new stage in the architectural history of the regions they subdued. They spread a unique \textbf{Romanesque} idiom to England and Italy, and the encastellation of these regions with keeps in their north French style fundamentally altered the military landscape. Their style was characterised by \textbf{rounded} arches, particularly over windows and doorways, and massive proportions.\end{tabular}} \\\\
%\multirow{11}{*}{\textbf{$QA$}} 
%                     & \begin{tabular}[c]{m{4cm}}$Q_1$: Norman architecture spread a unique Romanesque idiom to what two countries?\\ 
%                     $A_1$: England and Italy\end{tabular} & $\checkmark$ \\ \\
%                     & \begin{tabular}[c]{m{4cm}}$Q_2$: What type of arches were Norman architecture characterized by?\\
%                     $A_2$: rounded arches                     \end{tabular} & $\checkmark$ \\ \\
%                     & \begin{tabular}[c]{m{4cm}}$Q_3$: What style of architecture stands out as a new stage in the architectural history of the regions they subdued?\\
%                     $A_3$: Norman architecture\end{tabular} & $\checkmark$ \\
%                     \midrule
%\textbf{$P_2$}               & \multicolumn{2}{l}{\begin{tabular}[c]{m{4cm}}In England, the period of Norman architecture immediately succeeds that of the \textbf{Anglo-Saxon} and precedes the \textbf{Early Gothic}. In southern Italy, the Normans incorporated elements of Islamic, Lombard, and Byzantine building techniques into their own, initiating a unique style known as Norman-Arab architecture within the Kingdom of \textbf{Sicily}.\end{tabular}} \\\\
%\multirow{6}{*}{\textbf{$QA$}} & \begin{tabular}[c]{m{4cm}}
%$Q_4$: What period follows the Anglo-Saxon in England?\\ 
%$A_4$: Norman architecture
%\end{tabular} & $\checkmark$ \\ \\
%& \begin{tabular}[c]{m{4cm}}
%                     $Q_5$: What style of architecture did the Normans create in southern Italy?\\ 
%                     $A_5$: Norman-Arab architecture
%                     \end{tabular} &  $\checkmark$\\
%\bottomrule[1.5pt]
%\end{tabular}
%\caption{\label{tab:ex_qa} Examples of generated QA pairs from $P_1$ and $P_2$ which are both relevant to the aspect keyword ``architecture''. 
%\textbf{Bold} strings in paragraphs represent the ground truth answers.
%The marks behind each QA pair shows the relevance between this with the aspect, where ``$\checkmark$'' means they are relevant and ``$\times$'' means they are irrelevant.}
%\end{table}
%
%\begin{table}[th]
%\scriptsize
%\centering
%\begin{tabular}{lll}
%\toprule[1.5pt]
%\textbf{$Aspect$}      & \multicolumn{2}{l}{music}                              \\
%\midrule
%\textbf{$P_3$}               & \multicolumn{2}{l}{\begin{tabular}[c]{m{5cm}}At Saint Evroul, a tradition of \textbf{singing} had developed and the choir achieved fame in Normandy. Under the Norman abbot Robert de Grantmesnil, several monks of Saint-Evroul fled to southern Italy, where they were patronised by Robert Guiscard and established a Latin monastery at Sant'Eufemia. There they continued the tradition of singing.\end{tabular}} \\\\
%\multirow{11}{*}{\textbf{$QA$}} 
%                     & \begin{tabular}[c]{m{4cm}}$Q_6$: In what region did the choir achieve fame?\\ 
%                     $A_6$: Normandy\end{tabular} & $\checkmark$ \\ \\
%                     & \begin{tabular}[c]{m{4cm}}$Q_7$: Where did the monks of Saint-Evroul establish a Latin monastery?\\
%                     $A_7$: Sant'Eufemia\end{tabular} & $\times$ \\ \\
%                     & \begin{tabular}[c]{m{4cm}}$Q_8$: Who patronised the monks of Saint-Evroul?\\
%                     $A_8$: Robert Guiscard\end{tabular} & $\times$ \\
%                     \midrule
%\textbf{$P_4$}               & \multicolumn{2}{l}{\begin{tabular}[c]{m{5cm}}Normandy was the site of several important developments in the history of classical music in the \textbf{11th} century. Fécamp Abbey and Saint-Evroul Abbey were centres of musical production and education. At Fécamp, under two Italian abbots, William of Volpiano and John of Ravenna, the system of denoting notes by letters was developed and taught. It is still the most common form of pitch representation in English- and German-speaking countries today. Also at Fécamp, the staff, around which neumes were oriented, was first developed and taught in the 11th century. Under the German abbot Isembard, La Trinité-du-Mont became a centre of musical composition.\end{tabular}} \\\\
%\multirow{6}{*}{\textbf{$QA$}} & \begin{tabular}[c]{m{4cm}}
%$Q_9$: Where was Saint-Evroul Abbey located?\\ 
%$A_9$: Normandy
%\end{tabular} & $\times$ \\ \\
%& \begin{tabular}[c]{m{4cm}}
%                     $Q_{10}$: In what century was the system of denoting notes by letters developed?\\ 
%                     $A_{10}$: 11th
%                     \end{tabular} &  $\checkmark$\\\\
%& \begin{tabular}[c]{m{4cm}}
%                     $Q_{11}$: Who developed the system of denoting notes by letters?\\ 
%                     $A_{11}$: William of Volpiano and John of Ravenna
% \end{tabular} &  $\checkmark$\\\\
% & \begin{tabular}[c]{m{4cm}}
%                      $Q_{12}$: What was a centre of musical composition under the German abbot Isembard?\\ 
%                      $A_{12}$: La Trinité-du-Mont
%                      \end{tabular} &  $\checkmark$\\
%\bottomrule[1.5pt]
%\end{tabular}
%\caption{\label{tab:ex_qa2} Examples of generated QA pairs from $P_3$ and $P_4$ which are both relevant to the aspect keyword ``music''.}
%\end{table}
%Our automatic evaluation metric covers several criteria, 
%We use the cases in Table \ref{tab:ex_qa} to explain the performance of these criteria as follows:
%The reason for low accuracy is explained as follows:
%The as following:

Observing the quality of generated QA pairs, \SY{relevance analysis}.
Among this cases, questions \SY{Qs} are flawless, question \SY{Qs} is good and \SY{Qs} is a non-native question.
\SY{compare with GT}.
This observation shows the question generation module has a good performance.
 
Considering the coincidence with ground truth,
In the \SY{nums of A} extracted answers, 
\SY{hit the gt?}
%only two answers ($\{A_2, A_{10}\}$) hit the ground truth and the average F1 of these four paragraphs is 8.72\%.
Since the answers are firstly extracted from the input context, F1 score of answer extraction plays a critical role in the whole process.
Combined with Table \ref{tab:res} and the above analysis, 
we find that some generated QA pairs are outside the ground truth, but they are still meaningful and relevant to the aspect keywords,
which indicates the effectiveness of our model.

%\paragraph{Relevance with Aspect} 
%%The QA scores are calculated in aspect keywords. 
%%Although all of these four paragraphs are highly relevant to the corresponding aspect keywords, not all the extracted QA pairs are necessarily relevant. Among these cases, the QA pairs $\{QA_1, QA_2, QA_3, QA_4, QA_5, QA_6, QA_{10}, QA_{11}\}$ are eligible but $\{QA_7, QA_8, QA_9\}$ are talking about totally different things.
%In our task, It is crucial to generate QA pairs related to aspect keywords.
%Among these cases, \SY{relevance analysis}
%%the QA pairs $\{QA_1, QA_2, QA_3\}$ are eligible but $\{QA_7, QA_8, QA_9\}$ are talking about totally different things.
%
%\paragraph{Fluency of Question} 
%Questions are generated based on paragraphs, corresponding answers and  aspect keywords.
%It is observed that questions $\{Q_2, Q_4, Q_5, Q_6, Q_7, Q_8, Q_9, Q_{10}, Q_{11}, Q_{12}\}$ are flawless, question $\{Q_3\}$ is good and $\{Q_1\}$ is a non-native question.
%This observation shows the question generation module has a good performance.

%\subsubsection{Coincidence with Ground Truth}
%Table \ref{tab:allres} shows the results where generated QA pairs are compared with the ground truth.
%Since the answers are firstly extracted from the input document, F1 score of answer extraction plays a critical role in the whole process.
%In the 12 answers extracted from $\{P_1, P_2, P_3, P_4\}$, only two answers ($\{A_2, A_{10}\}$) hit the ground truth and the average F1 of these four paragraphs is 8.72\%.

%After the above analysis, we found that even if there are lots of QA pairs that are meaningful and relevant to the aspect keywords, they cannot match the ground truth well in terms of quantification, which is the main reason for the poor numbers in Table \ref{tab:allres}.
%The good news is that we can produce a lot of effective QA pairs by our framework.
%Combined with Table \ref{tab:res} and the above analysis, 
%we find that some generated QA pairs are outside the ground truth, but they are still meaningful and relevant to the aspect keywords,
%which indicates the effectiveness of our model.

