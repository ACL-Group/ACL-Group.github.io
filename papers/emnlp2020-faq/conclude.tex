\section{Conclusion}
\label{sec:conclusion}
In this paper, we raised a new task that is to generate QA pairs given documents and an aspect and propose an evaluation metric for the task. We provide a training set and a manually annotated test set with over 1000 test samples for the task. Further, we give two baselines for the task, which are a three-step pipeline framework and a filtering framework. We demonstrate that aspect can guide the generated QA pairs, which allows us to add manual guidance to QA pairs generation. However, the framework we proposed is still naive and has a lot of room for improvement, for example, how to solve the task in a single joint model instead of the combination of a series of models is one of our future works.