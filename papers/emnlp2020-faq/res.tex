\section{Results and Analysis}
\label{sec:res}

In this section, we will compare the results from the Filter Method and the Aspect-based Method to demonstrate the improvement from the later method. 
In this section, we will first give the 
Then we are going to give the evaluation results from human begins to investigate the effectiveness of the  automatic evaluation.
Finally, we discuss our results qualitatively by case analysis.

%In this section, we will first give our experimental setup for different models. 
%Then we compare the results from the Filter Method and the Aspect-based Method to demonstrate the improvement from the aspect-based models. 
%In Section~\ref{sec:strong} we discuss the result of each module to select the best combination for the Aspect-based Method.
%After that we are going to give the evaluation results from human and compare with the automatic evaluation.
%Finally, we discuss our results qualitatively and quantitatively.

%In this section, we will first discuss the result of each module in the two-step QA generation framework.
%In this section, we will compare the results from the Filter Method and the Aspect-based Method to demonstrate the improvement from the later method. 
%Then we are going to give the evaluation results from human begins to investigate the effectiveness of the  automatic evaluation.
%Finally, we discuss our results qualitatively by case analysis.
% In this section, we will first discuss the result of each module to select the best combination for the pipeline method and the filtering method.
% We then discuss the results of pipeline methods and filtering methods qualitatively and quantitatively.

%\subsection{Experimental Setup}
%We use BERT tokenizer to do the tokenization for BiLSTM-CRF and UNILM, and use Stanford CoreNLP~\cite{manning-EtAl:2014:P14-5} to do the tokenization in other models.
%% The BERT retrieval model is fine tuned with the learning rate of 3e-6 and 3 epochs.
%For LSTM-CRF model, we use BiLSTM with hidden state size of 128.
%The Adam optimizer is adapted with the learning rate of 1e-2 and the model is trained for 300 epochs.
%For pointer network, we follow the parameters set as Subramanian et al's~\shortcite{subramanian2017neural}.
%The Seq2seq model for question generation follows the parameters set as Zhao et al~\shortcite{zhao2018paragraph}. We add additional 1-layer LSTM encoder and self-gated layer to encode aspect. The hidden size of LSTM and self-gated layer is the same as the hidden size which is used for encoding paragraph.
%The UNILM model for question generation is fine tuned with the learning rate of 5e-5 and 8 epochs with half-precision training.

%\subsection{Results of Individual Module from Two-step Framework}
%For a two-step framework, we have separately introduced the methods of each module in Section \ref{sec:two-step}.
%%The comparison of results for each module is listed in Table \ref{tab:answer} and xx.
%
%\paragraph{Answer Extraction}
%The comparison of results for answer extraction is listed in Table \ref{tab:answer}.
%\SY{analysis}
%
%\begin{table}[ht]
%\scriptsize
%\centering
%\begin{tabular}{cccc}
%\toprule[1.5pt]
%\textbf{}  & \textbf{Precision} & \textbf{Recall} & \textbf{F1}\\ 
%\midrule
%\textbf{Ptr} & 29.52 & 32.04  & 30.73 \\ 
%\textbf{Ck} &  &  & \\
%\bottomrule[1.5pt]
%\end{tabular}
%\caption{\label{tab:answer} The results of answer extraction module.}
%\end{table}
%
%\paragraph{Question Generation}

\subsection{Results}
We proposed two methods to generate the aspect related QA pairs which has been mentioned in Section \ref{sec:method}.
Table \ref{tab:res} shows the results of two-step generation framework without the information of aspect keywords, the Filter Method and the Aspect-based Method.

%\paragraph{Results for Individuel Comparison}
%Answer extraction and question generation are two modules involved in two-step framework, 
%they are separately trained and then concatenated to generate QA pairs.
%%Table xxx indicates the results of different methods in these two modules.
%
%For answer extraction, the F1 of Pointer Network and Chunking are 30.73\% and 31.11\% respectively.

\paragraph{Ranking Strategy Comparison}
Due to the characteristics of different models which is mentioned in Section \ref{sec:ranking}, 
we choose different ranking strategies when obtaining the list of QA pairs.
Observing the 2nd to 4th rows of Table \ref{tab:res}, 
the model ranked according to the probability of the answer is better than those of other strategies,
which is because that the generation of a good question depends on a good answer.
Therefore, we only consider $\text{R}_\text{a}$ strategy for the methods using Chunking in latter comparisons.

In addition, there are two methods for answer extraction module: Pointer Network (Ptr) and Chunking (Ck).
The F1 of Pointer Network and Chunking are 30.73\% and 31.11\% respectively for individual evaluation.
Thus, the methods with Chunking model outperform those with Pointer Network in the end-to-end evaluation, but the gap between them are not large.

\paragraph{Two Methods Comparison}
After adding the filter to two-step generation framework, 
both of Ptr-QG-$\text{R}_\text{q}$-Filter and Ck-QG-$\text{R}_\text{q}$-Filter have better results than the methods without filters.
This shows that the filter with an accuracy of \SY{Acc. of filter} can effectively remove some of the irrelevant QA pairs to improve the performance.

Considering to encode the information of aspect into question generation directly, we obtain the better results against the Filtering Method.
Given the same context and answer, it indicates that the aspect keywords can prompt the model to generate more appropriate questions.

%\begin{table*}[ht]
%\scriptsize
%\centering
%\begin{tabular}{cccccccc}
%\toprule[1.5pt]
% & \multicolumn{2}{c}{\textbf{F1-BLEU4}} & \multicolumn{2}{c}{\textbf{F1-METEOR}} & \multicolumn{2}{c}{\textbf{F1-ROUGE}} &\textbf{Human Eval}\\ 
% & \textbf{P@K} & \textbf{MRR} &  \textbf{P@K} & \textbf{MRR} &  \textbf{P@K} & \textbf{MRR} & $\textbf{S}_{\text{\textbf{Human}}}$ \\ 
% \midrule
%Ptr-QG-$\text{R}_\text{q}$ &2.80 &  5.58 &  9.62 &  20.36 & 14.61 & 29.97\\
%Ck-QG-$\text{R}_\text{q}$ & 2.29 &  5.29 &  8.61 &  16.50 & 13.01 & 22.20\\
%Ck-QG-$\text{R}_\text{a}$& 2.99 &  7.26 &  11.16 & 22.77 & 16.04 & 30.63\\
%Ck-QG-$\text{R}_\text{qa}$ &2.06 &  5.36 &  8.70 &  17.46 & 13.15 & 23.29 \\
%\midrule
%Ptr-QG-$\text{R}_\text{q}$-Filter& 4.97 &  6.91 &  14.04 & 24.16 & 19.08 & 33.07 \\
%Ck-QG-$\text{R}_\text{a}$-Filter& 3.27 &  6.49 &  11.88 & 23.21 & 16.42 & 31.18 \\
%\midrule
%Ptr-QG$_\text{Aspect}$-$\text{R}_\text{q}$& 9.30 &  17.44 & 16.63 & 32.19 & 20.10 & 40.04 \\
%Ck-QG$_\text{Aspect}$-$\text{R}_\text{a}$& 10.72 & 27.88 & 18.73 & 41.71 & 22.73 & 47.45 \\
%\midrule
%Ptr-QG$_\text{Aspect}$-$\text{R}_\text{q}$-Filter& 12.99 & 19.74 & 22.31 & 37.27 & 25.93 & 45.46 \\
%Ck-QG$_\text{Aspect}$-$\text{R}_\text{a}$-Filter& 12.42 & 22.72 & 21.64 & 38.72 & 24.98 & 45.65 \\
%\bottomrule[1.5pt]
%\end{tabular}
%\caption{\label{tab:res} The results for QA pairs generation. Ptr }
%\end{table*}
\begin{table*}[ht]
\scriptsize
\centering
\begin{tabular}{ccccccccccc}
\toprule[1.5pt]
 & \multicolumn{3}{c}{\textbf{F1-BLEU4}} & \multicolumn{3}{c}{\textbf{F1-METEOR}} & \multicolumn{3}{c}{\textbf{F1-ROUGE}} &\textbf{Human Eval}\\ 
 & \textbf{P@K} & \textbf{R@K} &\textbf{F1@K} & \textbf{P@K} & \textbf{R@K} &\textbf{F1@K}& \textbf{P@K} & \textbf{R@K} &\textbf{F1@K} & $\textbf{S}_{\text{\textbf{Human}}}$ \\ 
 \midrule
Ptr-QG&2.80 &  2.19 &  2.46 &  9.62 &  8.63 &  9.10 &  14.61 & 13.14 & 13.84 \\
%Ck-QG-$\text{R}_\text{q}$ & 2.29 &  2.11 &  2.19 &  8.61 &  8.49 &  8.55 &  13.01 & 12.55 & 12.77 \\
%Ck-QG-$\text{R}_\text{qa}$ &2.06 &  1.96 &  2.01 &  8.70 &  8.71 &  8.71 &  13.15 & 12.87 & 13.01  \\
Ck-QG& 2.99 &  2.87 &  2.93 &  11.16 & 11.17 & 11.16 & 16.04 & 15.91 & 15.98 \\
\midrule
Ptr-QG-Filter& 3.43 &  2.57 &  2.94 &  10.66 & 9.17 &  9.86 &  15.22 & 13.02 & 14.04  \\
Ck-QG-Filter& 3.10 &  2.94 &  3.02 &  11.50 & 11.35 & 11.43 & 16.28 & 15.94 & 16.11  \\
\midrule
Ptr-QG$_\text{Aspect}$ & 9.30 &  7.54 &  8.32 &  16.63 & 14.47 & 15.48 & 20.10 & 17.86 & 18.92  \\
Ck-QG$_\text{Aspect}$ & 10.72 & 10.26 & 10.48 & 18.73 & 18.42 & 18.58 & 22.73 & 22.40 & 22.56  \\
\midrule
Ptr-QG$_\text{Aspect}$-Filter& 9.55  &  7.28  &  8.26  &  17.45  & 14.33 &  15.73 &  20.85 &  17.46 &  19.00  \\
Ck-QG$_\text{Aspect}$-Filter& 11.29  & 10.74 &  11.01 &  19.79  & 19.33 &  19.56 &  23.48 &  22.87 &  23.17  \\
\bottomrule[1.5pt]
\end{tabular}
\caption{\label{tab:res} The results for QA pairs generation.
Ptr and Ck are the methods for answer extraction. 
QG represents UNILM which is a question generation method.
The models with subscript ``$\text{Aspect}$" represents the information of aspect keywords is encoded.
$\text{R}_\text{a}$, $\text{R}_\text{q}$ and $\text{R}_\text{qa}$ represent the strategies of ranking by the scores of answer, question and their product respectively.
``Filter'' means the Filtering Method.
}
\end{table*}


%\subsection{Comparison between Two Methods}
%In this section we will analysis the results from our two methods. 
%As shown in table xxxxx \ZL{need a table here}, the Aspect-based Method outperforms the Filter Method in a large margin not only in precision, but also in recall. It is easy to understand the improvement in precision since we add aspect in all steps to filter out some wrong QA pairs. The improvement in recall indicates that "aspect" can also help the Answer Extractor and Question Generator to find more correct results. In human evaluation, we asked the annotators to mark whether the result is related to the aspect, it is clearly showed that the Aspect-based Method is more relevant.
%
%\subsection{Results of Module from the Aspect-based Method}
%\label{sec:strong}
%The Aspect-based Method is designed as the QA pairs generation frameworks which take the state-of-the-art of different areas into consideration.
%% We have separately introduced the methods of each module in Section \ref{sec:method}.
%The comparison of the results for each module is listed in Table \ref{tab:answer}, \ref{tab:QG}.
%
%% \subsubsection{Paragraph Retrieval}
%% From Table~\ref{tab:retrieval}, TF-IDF and BM25 have similar performance.
%% Compared to human performance, they have lower F1 scores but higher MRR scores, which represents the traditional retrieval methods are still good at ranking.
%% BERT is much better than the former two traditional methods and outperforms the human baseline. 
%% Here we just use the base model of BERT due to the limit of the GPU resource. 
%
%% %All retrieval methods are better than the human baseline, which represents machines are better at large-scale information retrieval.
%
%% \begin{table}[ht]
%% \scriptsize
%% \centering
%% \begin{tabular}{ccc}
%% \toprule[1.5pt]
%% \textbf{} & \textbf{F1@K} & \textbf{MRR@K} \\ 
%% \midrule
%% \textbf{TF-IDF} & 54.94 & 57.22 \\ 
%% \textbf{BM25} & 55.86 & 58.45 \\ 
%% $\text{\textbf{BERT}}_{\text{\textbf{base}}}$ & \textbf{76.50} & \textbf{73.48} \\ 
%% \midrule
%% \textbf{Human Baseline} & 63.83 & 46.87\\
%% \bottomrule[1.5pt]
%% \end{tabular}
%% \caption{\label{tab:retrieval} The results of paragraph retrieval module.}
%% \end{table}
%
%
%\subsubsection{Answer Extraction}
%
%From Table~\ref{tab:answer}, the NER model has a high recall and low precision. Because the largest proportion of the answers in our dataset are entities. We keep all ner results of the NER model, so the precision is low. BiLSTM-CRF gets the maximum recall but also performance bad on precision. We think the reason is in the training part we only use the sentences with answers. This may make the model predict answer tags for every sentence. The pointer network gets the highest F1 score. But the recall is the lowest. Because it's a generative model and it's difficult for it to generate the same answer in the ground truth.
%
%None of the three methods has higher precision than human but they outperforms on recall. 
%Human can easily hit the interesting phrases in paragraphs but hard to cover all of the ground truth.
%This also shows that it is difficult for us to find suitable features for extracting answers but there is still large room for precision improvement.
%
%%\begin{table}[th]
%%\begin{tabular}{|c|c|c|c|c|c|c|}
%%\hline
%%\textbf{} & \textbf{BLEU-1} & \textbf{BLEU-2} & \textbf{BLEU-3} & \textbf{BLEU-4} & \textbf{METEOR} & \textbf{ROUGE-L} \\ \hline
%%\textbf{Seq2seq} & 43.93 & 28.24 & 20.17 & 14.92 & 19.97 & 43.84 \\ \hline
%%\textbf{UNILM} & 49.50 & 34.58 & 26.30 & 20.65 & 24.37 & 49.36 \\ \hline
%%\textbf{Seq2Seq+Aspect} & 45.32 & 29.09 & 20.77 & 15.27 & 20.40 & 43.58 \\ \hline
%%\textbf{UNILM+Aspect} & 51.42 & 36.57 & 28.12 & 22.27 & 25.63 & 50.85 \\ \hline
%%\end{tabular}
%%\caption{\label{tab:QG} The results of question generation module.}
%%\end{table}
%
%\subsubsection{Question Generation}
%
%From Table~\ref{tab:QG}, we find seq2seq with aspect and UNILM with aspect both have better performance than the original model, which means the aspect can help the question generation model to generate questions closer to the targets.
%UNILM is a very strong model whose performance is much better than seq2seq and similar to human's.
%\begin{table}[ht]
%\scriptsize
%\centering
%\begin{tabular}{cccc}
%\toprule[1.5pt]
%\textbf{} & \textbf{BLEU-4} & \textbf{METEOR} & \textbf{ROUGE-L} \\ 
%\midrule
%\textbf{Seq2seq} & 14.92 & 19.97 & 43.84 \\ 
%$\text{\textbf{Seq2seq}}_{\text{\textbf{Aspect}}}$ & 15.27 & 20.40 & 43.58 \\ 
%\midrule
%\textbf{UNILM} & 20.65 & 24.37 & 49.36 \\ 
%$\text{\textbf{UNILM}}_{\text{\textbf{Aspect}}}$ & \textbf{22.27} & \textbf{25.63} & \textbf{50.85} \\ 
%\midrule
%\textbf{Human Baseline} & 20.22 & 26.44 & 47.72\\
%\bottomrule[1.5pt]
%\end{tabular}
%\caption{\label{tab:QG} The results of question generation module. \textbf{Seq2Seq} is the seq2seq model with gated self-attention and copy mechanism. $\text{\textbf{Seq2seq}}_{\text{\textbf{Aspect}}}$ is the seq2seq model with aspect. $\text{\textbf{UNILM}}_{\text{\textbf{Aspect}}}$ is the UNILM model with aspect.}
%\end{table}
%
%\subsubsection{Results of End-to-end QA Pairs Generation}
%\label{sec:end2end}
%In this paper, pipeline and filtering methods are chosen for end-to-end QA pairs generation task.
%%We will discuss the results qualitatively and quantitatively here.
%In Table \ref{tab:allres}, we display the results of these two methods.
%% Since BERT is much better than the other two methods, we just use BERT in retrieval step. 
%In filtering experiment, we only use UNILM as the generation model for the same reason.
%%Due to the limit of space, we 
%%The discussion is as follows.
%
%
%\begin{table*}[ht]
%\scriptsize
%\centering
%\begin{tabular}{cccccccccc}
%\toprule[1.5pt]
% & \multicolumn{3}{c}{\textbf{J-BLEU4}} & \multicolumn{3}{c}{\textbf{J-METEOR}} & \multicolumn{3}{c}{\textbf{J-ROUGE}} \\ 
% & \textbf{Precision} & \textbf{Recall} & \textbf{F1} & \textbf{Precision} & \textbf{Recall} & \textbf{F1} & \textbf{Precision} & \textbf{Recall} & \textbf{F1} \\ 
% \midrule
% \textbf{BERT+BiLSTM-CRF+Seq2seq} &  0.15  &  0.62  &  0.24  &  1.58  &  5.50  &  2.46  &  2.02  &  6.96  &  3.13 \\
% \textbf{BERT+BiLSTM-CRF+}$\text{\textbf{Seq2seq}}_{\text{\textbf{Aspect}}}$ & 0.19  &  0.71  &  0.31  &  1.62  &  5.62  &  2.51  &  2.04  &  6.98  &  3.16 \\
%\textbf{BERT+Ptr+Seq2seq} & 0.65  &  0.50  &  0.57  &  3.94  &  4.15  &  4.04  &  4.59  &  4.72  &  4.66  \\ 
%\textbf{BERT+Ptr+}$\text{\textbf{Seq2seq}}_{\text{\textbf{Aspect}}}$  & 0.52  &  0.45  &  0.48  &  3.84  &  4.06  &  3.95  &  4.55  &  4.79  &  4.67   \\ 
%\textbf{BERT+Ptr+UNILM} & 1.38  &  1.37  &  1.37  &  4.79  &  4.89  &  4.84  &  6.67  &  7.04  &  6.85 
%  \\ 
%\textbf{BERT+Ptr+}$\text{\textbf{UNILM}}_{\text{\textbf{Aspect}}}$ & 1.49  &  \textbf{1.41}  &  1.45  &  5.02  &  5.17  &  \textbf{5.10}  &  7.06  &  7.51  &  \textbf{7.28}  \\ 
%\midrule
%\textbf{Ptr+UNILM+Filtering} & 0.72   &  1.26  &  0.92   & 2.78 &  \textbf{5.23}  & 3.63  & 3.71 &   \textbf{7.79} &  5.02  \\ \midrule
%%\textbf{Ptr+}$\text{\textbf{UNILM}}_{\text{\textbf{Aspect}}}$\textbf{+Filtering}& 1.10 & 1.62  &  1.31   & 2.77  &  \textbf{5.39} &  3.66 &  3.93  &  7.87   & 5.25  \\ \hline
%\textbf{BERT+Ptr+UNILM+Filtering} & 2.06 & 1.12 & 1.45 & 6.36 &  3.76  & 4.73  & 8.32 & 5.19  & 6.39  \\ 
%\textbf{BERT+Ptr+}$\text{\textbf{UNILM}}_{\text{\textbf{Aspect}}}$\textbf{+Filtering} & \textbf{2.23}  &  1.12  &  \textbf{1.49}  &  \textbf{6.73}  &  3.79  &  4.85  &  \textbf{8.74}  &  5.28  &  6.58   \\ 
%\bottomrule[1.5pt]
%\end{tabular}
%\caption{\label{tab:allres} The result of pipeline framework in first four columns and filtering framework in last four columns.}
%\end{table*}
%
%\paragraph{Different Combination of the Models}
%The results in the first four rows show that BiLSTM-CRF performs worse than the pointer network in the pipeline method, which also follows the results of answer extraction. 
%%Therefore, we just use pointer network in the UNILM pipelines and from the results, we can see the combination of BERT, pointer network and UNILM with the aspect is the best. Each of them also has the best performance in individual module evaluation.
%Therefore, we just use pointer network in the UNILM pipelines.
%Among all the pipeline results, the combination of \textbf{BERT+Ptr+}$\text{\textbf{UNILM}}_{\text{\textbf{Aspect}}}$ which has the best performance in individual module evaluations is undoubtedly the best.
%
%\paragraph{Using the Aspect-based Method without the Filter}
%Since the aspect has been integrated into the models of Answer Extraction and Question Generation, we also try to remove the Filtering step in the Aspect-based Method to avoid multiple-filtering. \ZL{need a table here to show the result with filter and without filter}
%However, results in table xxxx shows the Filter can improve the performance of our system.  
%

% \paragraph{Using Filtering with Retrieval}
% If we use filtering at the end of the pipeline method, the precision is better but the recall is lower. 
% Because the filter can remove the QA pairs which is irrelevant to the aspect. 
% However, the filter also removes some relevant pairs which leads to a lower recall.
% %Overall, the filtering method can get better performance on F1 score and precision but worse performance on recall.

% \paragraph{Using Filtering without Retrieval}
% %If we don't use retrieval in the first step, the final performance is the worst in precision.
% %Without retrieval the pipeline model will generate QA pairs for each paragraph, so the recall is lower than filtering with retrieval.
% Without retrieval the pipeline model will generate QA pairs for each paragraph.
% The filter here is not strong enough to remove all the irrelevant QA pairs, so the final performance of this method is the worst in precision.
% Instead, its recalls have been greatly improved for the same reason.
% In most metrics, this method has the best performance on recall.

%\begin{table*}[th]
%\small
%\centering
%\begin{tabular}{cccccccccc}
%\hline
% & \multicolumn{3}{c}{\textbf{J-BLEU}} & \multicolumn{3}{c}{\textbf{J-METEOR}} & \multicolumn{3}{c}{\textbf{J-ROUGE}} \\ 
% & \textbf{F1} & \textbf{Precison} & \textbf{Recall} & \textbf{F1} & \textbf{Precision} & \textbf{Recall} & \textbf{F1} & \textbf{Precision} & \textbf{Recall} \\ \hline\hline
%\textbf{BERT+Ptr+Seq2seq} & 0.83 & 0.90 & 0.76 &  &  &  & 6.85 & 6.91 & 6.79 \\ 
%\textbf{BERT+Ptr+}$\text{\textbf{Seq2seq}}_{\text{\textbf{Aspect}}}$  & 0.79 & 0.83 & 0.75 &  &  &  & 6.91 & 6.96 & 6.85 \\ 
%\textbf{BERT+Ptr+UNILM} & 2.23 & 2.22 & 2.23 &  &  &  & 9.80 & 9.67 & 9.93 \\ 
%\textbf{BERT+Ptr+}$\text{\textbf{UNILM}}_{\text{\textbf{Aspect}}}$ & 2.30 & 2.35 & 2.25 &  &  &  & \textbf{10.00} & 9.92 & \textbf{10.08} \\ \hline
%\textbf{Ptr+UNILM+Filtering} & 0.92 & 0.72 & 1.26 &  &  &  & 5.02 & 3.71 & 7.79 \\ 
%\textbf{Ptr+}$\text{\textbf{UNILM}}_{\text{\textbf{Aspect}}}$\textbf{+Filtering}& 1.31 & 1.10 & 1.62 &  &  &  & 5.25 & 3.93 & 7.87 \\ \hline
%\textbf{BERT+Ptr+UNILM+Filtering} & 2.18 & 2.77 & 1.80 &  &  &  & 9.31 & 11.45 & 7.85 \\ 
%\textbf{BERT+Ptr+}$\text{\textbf{UNILM}}_{\text{\textbf{Aspect}}}$\textbf{+Filtering} & 2.32 & 3.14 & 1.84 &  &  &  & 9.39 & \textbf{11.99} & 7.71 \\ \hline
%\end{tabular}
%\end{table*}

