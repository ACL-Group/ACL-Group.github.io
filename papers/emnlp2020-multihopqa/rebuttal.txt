Reviewer 1:
Thanks for you comments.
- The semantic graph presented in HDE paper exibits a heterogenous structure,
    while our proposed RF graph invloves concepts that reside in the same
    level to discover latent reasoning paths that are both coherent and
    human-like. In a sense, the complexity of RF is on par with HDE since the
    core computation of our proposed model is still matrix operation.  In HDE,
    the internal representations for each node are updated using GCN in a
    parallel fasion. To the best of our knowledge, there is no trivial or
    intuitive way to interpret. More importantly, the interpretability of our
    proposed model enable it to justify its prediction when it makes a correct
    prediction and let us know how and where did it get wrong when it makes a wrong prediction. 
- By fine-grained, we mean that the granularity of reasoning path in each hop is able to match what we human would perform or at least not cause potential ambiguity. 
In our work we tackle this challenge by modeling reasoning state within the same concept or cross different concepts based on our proposed RF graph with elaborately designed six type of edges. Specifically,  we embed fine-grained triples with the form (subject, predicative relation, object) using the 5-th type of edge (Section 3.1) into learnable latent space and decode it back to human-readable symbolic form during inference phase. We will provide more detailed illustration in the revised version.

Reviewer 2:
Thanks a lot for your valuable review, we try our best to address your concern here.
- In each hop l, "coarse" refers to the pair-wise connectivity matrix C_c^l. It is "coarse" in the sense that C_c^l is used to represent the connectivity between any pair of nodes (0 indicates non-connective, value greater than 0 indicates the relative weight). "fine" refers to, 
after the relation message passing step in section 3.3.1, the pair-wise connectivity matrix C_f^l. The output matrix of relational message passing step is masked by the "coarse" C_c^l to inject topological structure and ensure the reasoning path is valid.
- There is indeed no path supervision provided in the dataset. Our path loss is defined in a way that paths (multiple possible paths to the same mention and multiple mentions that refer to the same concept) lead to the corrent answer is encouraged to have higher weight.
- source node is any span recognized as one of the four types of nodes in one document, and target node is the span recognized as one of the four types of nodes that appears earliest in a different document. This type of edge is introduced to redirect reasoning path from "source" document to "target" document when source document doesn't suffice to 
derive the answer.

Reviewer 3:
Thank you for your precious review.
- The key difference between Wikihop and HotpotQA is that the "multi-hop" property is mostly reflected in the question for HotpotQA, while it is reflected purely in the documents for Wikihop. 
Our method can be potentially applied to HotpotQA using the same graph construction procedure and the answer span can be predicted in a classification manner instead of  span extraction. 
For Yes/No question in HotpotQA, the most straightforward way is to introduce a global "virtual" node whose final representation will be used for Yes/No prediction. For support sentence prediction, the representations of extracted nodes belonging to the same sentence can be utilized. The decoded symbolic reasoning path can further provide a more fine-grained interpretation than supporting sentences. In conclusion, it is promising to apply our method to HotpotQA with slight modification.

General response:
-We sincerely thank all the comments of three reviewers, hope our response will address as much your uncertainty and questions as possible.
