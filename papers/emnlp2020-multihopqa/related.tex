\section{Related Work}
The approach presented in this paper is closely related to existing work on multi-hop machine reading comprehension over multiple documents~\cite{Zhong2019, Cao2019,BAG,Chen2019}. Current models tailored for solving multi-hop reasoning can be roughly categorized into three types: attention-based, graph-based and evidence path-based. Our proposed
model presents an effective combination of the later two streams of models by harnessing the strong modeling capacity of GNN~\cite{DBLP:journals/corr/KipfW16} on a semantic-rich relational graph and human-interetable model prediction as a natural outcome of how we inject relation prior and iteratively induce the complete reasoning path. One connection between our model and attention-based ones is reflected in the bi-attention and self-attention based context encoding scheme~\cite{Zhong2019} that we utilize to initialize the node representation.
One notable difference between our RF graph and the graph adopted in previous methods is that: the RF graph is elaborately designed to mimic human reading process by considering the information flow within and across objects. 
Other related work include:

\textbf{Multi-hop RC.} To facilitate machine reading comprehension beyond simple pattern matching within a local context, several datasets requiring multi-hop reasoning have been proposed, for example bAbI~\cite{weston2015towards}, MultiRC~\cite{khashabi-etal-2018-looking} and OpenBookQA~\cite{DBLP:journals/corr/abs-1809-02789}. However, these datasets requires mulit-hop inference over multiple sentences within the same document, while the scope of RC task we try to solve in this paper is lifted to multi-document level.

\textbf{Graph Neural Networks for NLP.} There has been a rapidly growing interest of employing GNN to a variety of NLP tasks, including sentiment analysis~\cite{Huang2019, Zhang2019} and relation classification~\cite{Guo2019, Zhu2019}. The improved task performance as compared to using conventional sequential encoding scheme such as RNN demonstrate the effectiveness of GNN when tackling tasks where salient graph-structured information is needed.