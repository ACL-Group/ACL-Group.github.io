Review #1
What is this paper about, what contributions does it make, and what are the main strengths and weaknesses?
This paper proposes an interpretable graph-based multi-hop model for multi-document QA tasks. The key technical improvement seems to come from the multi-task graph learning.
Strength:

It shows that using multiple graphs helps to improve the model's accuracy. They also provide a certain level of interpretability.

Extensive experiments with detailed analysis, e.g. ablation study.

It comes with source code for reproducing their results.

Weakness:

In Table 1, the performance is very close to HDE. The proposed new method is much more complicated.

In my opinion, HDE is also interpretable in the sense that we can read some internal reasoning paths through the graph.

The definition of "fine-grained" interpretation is a big vague to me. It might be better to provide more analysis on it — perhaps in the Appendix.

Reasons to accept
It shows that using multiple graphs helps to improve the model's accuracy. They also provide a certain level of interpretability.

Extensive experiments with detailed analysis, e.g. ablation study.

It comes with source code for reproducing their results.

Reasons to reject
In Table 1, the performance is very close to HDE. The proposed new method is much more complicated.

In my opinion, HDE is also interpretable in the sense that we can read some internal reasoning paths through the graph.

The definition of "fine-grained" interpretation is a big vague to me. It might be better to provide more analysis on it — perhaps in the Appendix.

Reproducibility:	5
Overall Recommendation:	3.5
Missing References
Cognitive Graph for Multi-Hop Reading Comprehension at Scale


Review #2
What is this paper about, what contributions does it make, and what are the main strengths and weaknesses?
This paper proposes a more explainable multihop QA system, which achieves strong performance on WikiHop.
Strengths:

The proposed method considers more types of node and edges in the graph. This could probably provide more human-readable reasoning paths.
Weaknesses:

The paper writing is not clear and I find it difficult to differentiate the proposed method from existing work that also use graph networks.
There is a nontrivial performance gap between the proposed method and the top entries on the public leaderboard. Some of these entries (with papers) appeared more than 3 months before the submission deadline.
The only obvious contribution seems to be the finger-grained graph. The model is complicated and lacks clear intuition or motivations.
Only a single dataset is considered, and the proposed method seems too specific for this particular dataset.
Reasons to reject
The main contributions of the paper are vague to me, especially for the first two contributions in the intro section. For the third one, the authors need to explain why the path induction is more efficient than previous method and why the existing work is "brute-force". The Section 3.3.2, which describes the path induction, is hard to read.

The proposed approach is a modification of the existing approaches that use the entity graph constructed by NLP tools. Most of the modules are from existing work.

Reproducibility:	4
Overall Recommendation:	2
Questions for the Author(s)
Why is it "coarse-to-fine" and why the graph learning named "collaborative learning"?

There's no path supervision for Wikihop, how do you define the path loss?

What is a "source" node and "target" node in line 281-283?


Review #3
What is this paper about, what contributions does it make, and what are the main strengths and weaknesses?
This paper mainly proposes a fine-grained reading comprehension model for answering multi-hop questions on WikiHop dataset. The paper mainly proposes a reasoning flow method, which is a graph-based mut-hop model to abstract information from unstructured data. The paper breaks down the reasoning into a graph with six types of relation connecting the four types of nodes. The empirical results conducted on the dataset shows slight achievement over the previous method.
Strength: this paper is well motivated, the empirical results and analysis are also complete. The related work study is also comprehensive including all the existing methodology on tackling the problem proposed in the dataset. Weakness: the approach is somewhat overfitted to the given dataset. When reading the title of this paper, the first thing coming to my mind is a more general setting where you have questions and a bunch of documents to reason over like HotpotQA setting. But the approach of this paper is tied to the annotation and entity alignment information provided by the specific WikiHop dataset. And the question is also quite synthetic, not a real human language question. This WikiHop dataset is indeed a very good benchmark, but I'm eager to see whether this approach can generalize to other datasets without these annotations on human-language question.

Reasons to accept
Overall, this paper is well written and motivated. The paper addresses the weakness of current system which lacks the ability to perform logical reasoning during reading comprehension.
Figure4 shows a quite convincing example to demonstrate the effectiveness of their proposed semantic graph.
Reasons to reject
The approach is quite restricted to the given dataset. Only results on WikiHop is reported, which is less convincing.
The empirical boost over the existing models is not quite inspiring. It's hard to tell whether it's significant or not.
Reproducibility:	4
Overall Recommendation:	3.5
Questions for the Author(s)
Could you explain how your method can be applied to HotpotQA dataset? Or do you actually have some results on that?
Typos, Grammar, Style, and Presentation Improvements
Mostly fine, just a few typos. Line 380, which (is) defined as.
