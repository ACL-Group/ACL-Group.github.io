Reviewer 1:
Thank you for the precious comments and suggestions.

"PAD token"
For extractive summarization models, PAD is a special token in vocabulary of training dataset, which makes the length of inputs in one batch the same. In this paper, the PAD is used to align the <SEP> of pseudo summary and predicted summary in the same position and preserved in the set loss (Line 383~387). 

"Abstractor":
In our model, we train extractor and abstractor separately first. Then, we use RL to make the extractor-abstractor model an end-to-end trainable model, which can finetune the pretrained extractor and abstractor (Line 409~413).
In order to train the abstractor, an input of the abstractor is a multi-sentence set of pseudo summary and the output is its corresponding multi-sentence set of reference summary.
The extractor first extracts salient sentences from source document, and these salient sentences are separated into multiple sets by <SEP> token. Then each set should be rewritten as generated sentence set, such as the Set 1 and Set 2 of generated summary shown in Section 3.3.3. The abstractor can work on these sets in parallel at one time. Finally, we can get the final summary by concatenation of the generated sentence sets.
The abstractor cannot produce <SEP> token because the sets should be separated by extractor. The human judges evaluate all the sets of generated summary together.

"Section 2.4"
"t" can be regarded as the extractive time step and l can be regarded as the abstractive time step.
During RL, we can obtain a predicted sentence q_t^l by the extractor at the training step t, which belongs to the l-th set for the abstractor (Line 414~419).
The RL reward consists of the extractive reward (the sentence-level reward between t-th sentence in pseudo summary and predicted sentence q_t^l at each timestep t) and the abstractive reward (set-level reward at the end of l-th set and summary-level reward at the end of generated summary) (Line 427~449).
P-hat is the padded pseudo summary, which correspond to predicted summary Q (Line 420).
B_l in Eq.10 represents the concatenation of the sentence sets from the first sentence set (b_0) to the l-th sentence set (b_l) in B=(b_0,...,b_l,...,b_m) (Line 422).

"confusingly written & typos"
We will carefully revise the order of information presentation, gramma errors and typos in the final version. We will add the reason behind merging reference summary sentence sets into Section 2.1 and explain the difference between autoAlign and ROUGE in Section 3.3.1.

Reviewer 2:
Thank you very much for your reviews.

"plug-in SOTA systems together"
The SOTA systems (HIBERT and BART) are pretrained models and only used to enhance the language modeling ability. We improve the extractor-abstractor summarization models from three aspects: training dataset, extractor and the combination of extractor and abstractor.
1. The improvement on our model depends on the novel set-level keywords-based matching heuristic which creates new training datasets for extractor and abstractor. This new heuristic extracts the pseudo summaries as the output of extractor and input of abstractor during training, which improves the quality of training data and enhance the alignments between inputs and outputs of abstractor (as shown in Table 4). 
2. We propose a new keywords encoder (KE) and combinational loss (cl) which are added into extractor. As shown in Table 5, the models with KE_cl are the best, which means that the keywords encoder is effective for both non-pretrained model (Base-) and SOTA pretrained model (Pre-).
3. We use RL with new rewards to bridge encoder and decoder, which makes extractor-abstractor framework an end-to-end trainable model. As shown in Table 7, the models with our proposed RL achieve better ROUGE scores, which shows that we successfully design the RL model for our new training dataset and proposed keywords-based extractor-abstractor model. 
(KZ: you need to explicitly point out that in which experiments, you did the ablation tests to show that it is our innovations that make the difference, not just plain plugin of sota models.)

"Human evaluation":
We will select more samples from CNN/Daily Mail dataset for human evaluation and show more reliable results in the future.

Reviewer 3:
Thanks a lot for the precious comments and suggestions.

"Analyze keywords":
The keywords denote the salient information of the text. So we propose a keywords encoder and its corresponding keywords loss to guide the decoder to select more accurate sentences (Section 2.2).
The experiment to evaluate keywords encoder is in Section 3.3.2 (Line 561~564). 
As shown in Table 5 and 9, the models with keywords encoder (KE) have higher ROUGE scores (increased by about 1.0) and keywords coverage (KC) scores (increased by about 0.5). 
(KZ: if space permitts, say a bit more why keywords works.)


"Analyze the RL":
The proposed RL makes the extractor-abstractor framework an end-to-end trainable model. 
The analysis of RL rewards is in Section 3.3.2 (Line 617~664). 
As shown in Table 7 and 8, the models with proposed RL rewards obtain higher ROUGE scores, indicating that our proposed rewards are more suitable for our proposed approach with set-level matching heuristic and achieve better result than the traditional extractor-abstractor framework.
As for the proposed RL rewards in Section 2.4, we have tried different combinations of rewards during the model designing process. Due to space limitation, we only show the best rewards combination in this paper.

General:
Thank you all for the precious comments and suggestions.
