Review #1
What is this paper about, what contributions does it make, and what are the main strengths and weaknesses?
The paper proposes a set-based method for constructing intermediate target extractive summaries for extract-then-abstract summarization. It addresses a limitation of prior approaches to this problem, which are unable to handle document-summary pairs where summary sentences do not map one-to-one to document sentences.
Strengths:

The proposed set-based representation of the intermediate target summary partitions the reference summary based on which reference sentences are best aligned to which document sentences, allowing for a better selection of intermediate target sentences, as well as decreasing the time and memory cost of the abstractor due to shorter input-output pairs.

The best-performing proposed system outperforms the existing state of the art on the CNN/DM and DUC 2002 datasets.

Weaknesses:

The paper is confusingly written, especially Section 2.4 (see questions below). The order in which information is presented is slightly off; the reason behind merging reference summary sentence sets (which is done in Section 2.1) is not made clear until RL is discussed (Section 2.4). The explanation of the autoAlign metric in Section 3.2.1 is very terse and sounds no different than an ordinary ROUGE evaluation; it is not until Section 3.3.1 that the difference between the two evaluations is explained.

Partitioning the pseudo and reference summaries into sets of sentences is the main contribution of this paper. However, it is not clear how this is used to generate the final abstractive summary (see questions below). Is the contribution simply the improved intermediate target that serves as input to the abstractor, or is the partition used by the abstractor in some way as well?

Reasons to accept
The set-based representation of the intermediate extractive target is novel and improves the overall performance of the extract-then-abstract approach. Using the proposed representation with the pre-trained BART generator achieves new state-of-the-art performance on CNN/DM and DUC 2002.
Reasons to reject
The paper would benefit a great deal from another round of revisions. As described above, it was difficult to follow due to changing notation and portions of the approach that are not explained until a page or two later. As it is, the reader has to work hard to figure out what is going on, and several questions are left unanswered (see below). There are also numerous grammatical issues that make the paper an unpleasant read in its current state.
Reproducibility:	4
Overall Recommendation:	3
Questions for the Author(s)
In the set loss, how is p(PAD) obtained? The PAD token is never mentioned earlier and does not seem like it would be present in any training targets.
Section 2.4 is confusingly written.

What is t counting? Abstractive time steps makes the most sense in an RL setup, but t is also used to count the sentences q predicted by the extractor.

What is P-hat? The text references the set loss, which has a Y (the reference pseudo sumary) and a Y' (both the predicted pseudo summary and the padded pseudo summary). Does P-hat correspond to Q'?

What is B_l in equation 10?

How is the abstractor trained? With the pseudo summary and reference summary partitioned into sets of sentences, does the abstractor work on one set at a time? Or all concatenated together? The generated summary is shown in Section 3.3.3 as being separated into Set 1 and Set 2. Does the abstractor also produce a SEP token between the abstracts corresponding to different sets? Do the human judges evaluate each set separately or all together?

Typos, Grammar, Style, and Presentation Improvements
Many missing determiners and pluralization/agreement errors throughout.
Missing word in Algorithm 1, "... the number of overlapping words _ two sequence." Also example of missing plural.

Typos:

Figure 1, "architacture"

Section 2.4, variable "z"

Table 4, "differet"


Review #2
What is this paper about, what contributions does it make, and what are the main strengths and weaknesses?
In this paper, the author purposed that adding Keywords information could help the summarization system keep good consistency and catch the major points of the original document. The combined CNN(token level) + RNN (sentence level) and a pre-trained HIBERT as the encoder, and apply a pointer decoder for their extractive system. For the abstractive part, they directly use BART as the abstractor. Then applying reinforcement learning on top of the ext and abs system by fixing the parameters of the abstractive model.
Strengths:

good performance on CNN/DM
weakness:

Marginal improvement on the model, just plug-in a lot of State-of-the-art systems together.
The human evaluation is not enough, only 50 / 11k < 0.5% instance and 2 annotator could have a very high variance.
Reasons to reject
Marginal improvement on the model, just plug-in a lot of State-of-the-art systems together. I couldn't see any break through or exciting idea from the paper.
Reproducibility:	5
Overall Recommendation:	2.5

Review #3
What is this paper about, what contributions does it make, and what are the main strengths and weaknesses?
This paper improves the existing extractive-abstractive summarization framework with a novel set-level matching heuristics to extract pseudo summary, which can improve the alignments between documents and summaries during abstractive generation process. The paper also describes a RL method to connect the keyword-based summary extractor and BART-based abstractor. Experimental results show that the proposed method obtains significant better performance than baselines.
strengths: (1) The proposed method augments the traditional extractor-abstractor framework with a keyword-based set extractor, which can improve the alignments between documents and summaries. The results also show that the new method significantly improves the summarization performance. (2) Extensive experiments have shown the effectiveness and efficiency of the proposed framework. The proposed model are faster and more memory-efficient than existed models. (3) The proposed model has better generalization than previous SOTA model BART, and obtains better performance on new dataset.

weaknesses: (1) As the paper emphasis keyword in many places, including the title, the functionality of keywords in the proposed framework have not been sufficiently analyzed and compared. (2) The effectiveness of the proposed RL reward has not been sufficiently analyzed.

Reasons to accept
(1) The proposed method augments the traditional extractor-abstractor framework with a keyword-based set extractor, which can improve the alignments between documents and summaries. The results also show that the new method significantly improve the summarization performance. (2) Extensive experiments have shown the effectiveness and efficiency of the proposed framework. The proposed model are faster and more memory-efficient than existed models. (3) The proposed model has better generalization than previous SOTA model BART, and obtains better performance on new dataset.
Reasons to reject
(1) As the paper emphasis keyword in many places, including the title, the functionality of keywords in the proposed framework have not been sufficiently analyzed and compared. (2) The effectiveness of the proposed RL reward has not been sufficiently analyzed.
Reproducibility:	4
Overall Recommendation:	3.5

