\section{Preliminary Definition}
\label{sec:formulation}
%\textcolor{red}{Hongru: these are concrete examples, which i think should be given after the problem
%formulation} 
We define an instance $x$ of a natural language reasoning (NLR) task 
dataset $X$ as
\begin{equation}
    x = (p, h, l) \in X, \label{eq:nli}
\end{equation}
\noindent
where $p$ is the context against which to do the reasoning ($p$ corresponds 
to ``premise'' in~\exref{exp:snli});
$h$ is the hypothesis given the context $p$; 
$l \in \mathcal{L}$ is the label that 
depicts the type of relation between $p$ and $h$. 
The size of the relation set $\mathcal{L}$ varies with tasks. 
%We argue that 
%most of the discriminative NLR tasks can be formulated into this general form. 
%which will bring us much convenience to evaluate the cues of a dataset. 
%For example, an NLI question consists of a \textit{premise}, a \textit{hypothesis} 
%and a \textit{label} on the relation between premise and hypothesis. 
%The formulation of this task will be $p =$ \textit{premise}, $q =$ \textit{hypothesis} and $l =$ \textit{label}. 
%$|\mathcal{L}| = 3$ for three different relations: 
%\textit{entailment}, \textit{contradiction} and \textit{neutral}. 
%We will talk about how to transform into this form in \secref{sec:dynamic}. 
%The ROCStory~\cite{mostafazadeh2016corpus} dataset
%such as in~\exref{exp:roc}, 
%consists of a \textbf{context} and two possible story \textbf{endings}. 

%We will formulate this task by setting $p = $ \textit{context}, $h = $ \textit{ending1/ending2}. In this case, $|\mathcal{L}| = 2$. because $l$ is ``true'' or ``false'' indicating whether 
%the ending is a plausible ending of the story.


%\subsection{Transformation of MCQs with dynamic choices}
%\label{sec:dynamic}
%So far the multiple-choice questions we targeted such as NLI problems
%are actually classification problems with fixed set of choices. 
There is another type of natural language reasoning tasks which 
are also in the form of multiple-choice questions, 
but their choices are a fixed set of labels, as shown below. 
\begin{example}\label{exp:roc}
A story in ROCStory dataset, with ground truth bolded~\cite{mostafazadeh2016corpus}.
\begin{description}
\item{Context:} Rick grew up in a troubled household. 
He never found good support in family, and turned to gangs.           
It was n't long before Rick got shot in a robbery.             
The incident caused him to turn a new leaf.
\item{Ending 1:} He joined a gang. 
\item{Ending 2:}  \textbf{He is happy now.}
\end{description}
\end{example}

We can transform the this case into two separate 
problem instances, still
in the same form as in \eqnref{eq:nli}, 
$u_1=(context, ending1, false)$ and $u_2=(context, ending2, true)$, where $L = {true, false}$.
%For better take advantage of the bias score to choose the right choice. We also use two linear model: SGDClassifier and 
%logistic regression. The inputs of the models for instance $e_n$ is the concatenation of bias scores for each label which %can express as :  $input(e_n) = [ f_{\mathcal{F}}^{(w_{n_1}^{l_1})},..., f_{\mathcal{F}}^{(w_{n_d}^{l_1})},..., f_{\mathcal{F}}^{(w_{n_1}^{l_v})},..., f_{\mathcal{F}}^{(w_{n_d}^{l_v})}]$. The corresponding target is the correct label $l_{gold}\in{L}$.

 

