\section{Conclusion}

We investigate a speculation that 
models can short circuit the premises on multiple-choice natural 
language reasoning questions. Our experiments verify the existence 
of short circuit behavior in three fine-tuned strong models.
We also find that crossover is better than choice-only and 
human annotation as proxy test to detect short circuit for models. 
In addition, we try different data augmentation methods and 
recommend two operators, crossover and mutation, 
to make models more robust.
