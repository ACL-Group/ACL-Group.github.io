\section{Discussion and Future Work}
\label{sec:discussion}
Our study has taken important initial steps in model 
evaluation and exploration by providing a lightweight yet 
effective method to reveal statistical biases and cues in NLU datasets. 
However, further exploration is needed to 
obtain a comprehensive understanding of model behavior.

First, as prompt impact varies across tasks and domains, 
future research will entail extensive prompt 
exploration and testing for specific applications.

Second, expanding our focus beyond the MNLI dataset's ``no''
feature to other features and tasks will help 
generalize our findings and deepen our 
understanding of prompt design and bias mitigation.

Third, the ``CoT'' strategy's effectiveness and generalizability 
in different settings and language models 
remain open questions, which we will address in future work.

By tackling these challenges, we aim to develop 
more reliable, robust, and unbiased AI systems 
through comprehensive model evaluation and bias mitigation research.

