\section{Experiments}
\label{sec:experiment}

%\begin{table*}[th!]
%	\centering
%	\scriptsize
%	\begin{tabular}{l|llcc}
%		\toprule
%		\textbf{Dataset} &\textbf{Premise}  & \textbf{Choices} & \textbf{Training size} & \textbf{Test size}\\
%		\midrule
%		\multirow{4}{*}{ROC} & Sarah was home alone. &\multirow{2}{*}{Sarah then happily watched the show.     %\checksymbol}&\multirow{4}{*}{1871}&\multirow{4}{*}{1871}\\
%						&She wanted to stay busy. & 	\multirow{2}{*}{Sarah could not find anything to watch. \crosssymbol } \\
%						&She turned on the TV. \\
%						&She found a reality show to watch.\\
%		\midrule
%		\multirow{3}{*}{ARCT} &\textbf{Reason}: Milk isn’t a gateway drug even though &\textbf{Warrant 1}: Milk is similar to marijuana. \checksymbol&\multirow{3}{*}{1210}&\multirow{3}{*}{444}\\
%		&most people drink it as children. &\textbf{Warrant 2}: Milk is not marijuana.\crosssymbol \\
%		&\textbf{Claim}: Marijuana is not a gateway drug. \\
%		\midrule
%		\multirow{4}{*}{RECLOR} &\textbf{Context}:In a business...to financial prosperity. &A: ignores the fact that in... the family 's prosperity.\checksymbol&\multirow{4}{*}{4638}&\multirow{4}{*}{500}\\
%		&\textbf{Question}:The reasoning in the argument&B: presumes, without... the family's prosperity.\crosssymbol&\\
%		& is flawed because the argument&C: ignores the fact... even if they pay high wages.\crosssymbol\\
%		&&D: presumes, without providing...can succeed.\crosssymbol\\
		
		
%		\bottomrule
%	\end{tabular}
%	\caption{Examples for three datasets. The right choice is labeled with \checksymbol, the wrong choice is labeled with  \crosssymbol .}
%	\label{table:dataset}
%\end{table*}

\begin{table*}[th!]
	\centering
	\scriptsize
	\begin{tabular}{l|lccc}
		\toprule
		\textbf{Dataset} &\textbf{Premise}  & \textbf{Choices} & \textbf{Training size} & \textbf{Test size}\\
		\midrule
		\makecell[c]{COPA} &  \makecell[l]{I pushed the door.} &\makecell[l]{The door opened.     \checksymbol 
		\\The door locked. \crosssymbol }&\makecell[c]{500}&\makecell[c]{500}\\
		\midrule
		\makecell[c]{ROC} &  \makecell[l]{Sarah was home alone.\\She wanted to stay busy.\\She turned on the TV.\\She found a reality show to watch.} &\makecell[l]{Sarah then happily watched the show.     \checksymbol 
		\\Sarah could not find anything to watch. \crosssymbol }&\makecell[c]{1871}&\makecell[c]{1871}\\
		\midrule
		\makecell[c]{ARCT} &\makecell[l]{\textbf{Reason}: Milk isn’t a gateway drug even though \\ most people drink it as children. \\\textbf{Claim}: Marijuana is not a gateway drug.}&\makecell[l]{\textbf{Warrant 1}: Milk is similar to marijuana. \checksymbol \\
		\textbf{Warrant 2}: Milk is not marijuana.\crosssymbol}&\makecell[c]{1210}&\makecell[c]{444}\\
		\midrule
		\makecell[c]{RECLOR} &\makecell[l]{\textbf{Context}:In a business...to financial prosperity. \\
		\textbf{Question}:The reasoning in the argument\\  is flawed because the argument}&\makecell[l]{A: ignores the fact that in... the family 's prosperity.\checksymbol
		\\B: presumes, without... the family's prosperity.\crosssymbol
		\\C: ignores the fact... even if they pay high wages.\crosssymbol
		\\D: presumes, without providing...can succeed.\crosssymbol}&\makecell[c]{4638}&\makecell[c]{500}\\
		
		
		\bottomrule
	\end{tabular}
	\caption{Examples for all 4 datasets considered in this paper.}
	\label{table:dataset}
\end{table*}

%1. Re-evaluate the extent to which the model is exploiting short circuit after augmentation. Test it on the same sampled examples to see the improvement of percentage of cases where model look at context.

To verify the effectiveness of \textit{crossover} and 
\textit{mutation}, We evaluate it on four popular reasoning tasks 
which consist of multiple-choice natural language understanding (NLU) questions. 
Three transformer-based models, BERT, XLNet, and RoBERTa are employed as the
testbed for our experiments. 
In this section, we first show the experimental setup. 
%Second, we compare several operators for testing short circuit problem and apply the best one to multiple models on diverse NL reasoning tasks.
Second, we evaluate models with different augmentation methods on original test data and 
stress tests. 
Third, we explore the reason for the fragility of raw models and 
the strengths of enhanced models with augmented data by choice-only test. 
%without data augmentation 
%and of different modelswith choice-only test and 
Finally, we use a case study to further explain the reason for model improvement.

\subsection{Experimental Setup} 
\label{sec:setup}
In this section, we will show our setup for datasets, models and test operators.
\subsubsection{Datasets}
We experiment on 4 datasets from four different tasks:
%\KZ{I think you need to say what is the context and what are the
%choices for these four datasets.}

\textbf{ROC} is a story ending prediction dataset. 
The task is to identify the correct ending of a four-sentence 
story premise from two alternative choices. 

\textbf{COPA} is a causal reasoning dataset, an example is previously shown
in~\secref{sec:intro}. Given a premise, 
COPA requires choosing the more plausible, causally related choice. 
%There are 500 instances in 
%training data and 500 instances for testing.

\textbf{ARCT} is an argument reasoning comprehension dataset. 
There may exist an alternative warrant choice 
in which the reason is connected to the claim.

\textbf{RECLOR} is a reading comprehension dataset that requires logical reasoning.

Examples and statistics of these datasets are shown in~\tabref{table:dataset}. 

\subsubsection{Models}
We mainly investigate three popular classifiers based on pre-trained language models. 
There are several available versions of pre-trained models differing in the number of layers and parameters. We choose to use the base version of each model. We train and test all the models on a server: a GeForce GTX 1080 Ti GPU with 11G RAM and Intel(R) Xeon(R) CPU E5-2630 with 128G of RAM.

\textbf{BERT} (BT) is a popular attention model, which applies the bidirectional training of Transformer. 
%The basic one has 12-layer transformer, blocks, 768 hidden-size, and 12 self attention, 
%heads, totally 110M parameters and fine-tune for 3 epochs to predict the relation based on context and 
%choices.

\textbf{XLNet} (XL) is trained with Permutation Language Modeling and without NSP.

\textbf{RoBERTa} (RB) is an improved pre-training procedure of BERT.

Besides the original models (marked as w/o), we also train these three
models with four competing data augmentation methods: 
back-translation~\cite{back2019} (B),  crossover (C), mutation (M)
and crossover + mutation (C+M). 
We start by implementing and comparing with back-translation method as our baseline which is 
popularly used in NLU tasks. While there exists promising data augmentation methods~\cite{qu2020coda,chen-etal-2021-hiddencut} that are based on dynamic perturbation of hidden states, back-translation is by far the most
effective data augmentation method that operates on the input level.
% \KZ{Explain that why back-translation is the best
%baseline for data-only augmentation, and give some cites.}
%Other complicate data augmentation methods are hard to transform to all multiple-choice datasets. 
%\KZ{Do we need another stronger data aug baseline than backtranslation?
%since we are focusing on data aug now.} 
The expanded data volume for each augmentation method is consistent with the original data volume.
The expanded data volume is equal to the original data volume and 
the size of new train dataset has doubled.

\subsubsection{Stress Test Cases}
Following previous research~\cite{checklist2020acl}, 
we will test the effectiveness of different data augmentation
methods by looking at the robustness of models against
different stress tests.
We create these stress test cases using the operators
introduced in \tabref{table:proxyop}.
Different operations generate different number of cases 
as shown in \tabref{tab:cases}. 
The standard test data accuracy and stress test accuracy are utilized for all 
data augmentation methods to ensure a fair comparison and thorough evaluation for 
both effectiveness and robustness. 



%To evaluate the
%ability of testing for short-circuiting, we will
%use a subset of these test cases whose original MCQs are correctly answered by models in the next section.
%negation-add(Neg+),  negation-remove(Neg-), 
%NER, pronoun-replacement(PR), pronoun-instantiation(PI), 
%crossover(CO), adverbial(Adv), mutation(MT), Voice and synonym(Syn). 

\begin{table}[th]
\centering
\scriptsize
\begin{tabular}{c|rrrr}
\toprule
\textbf{Stress} & \textbf{ROC} & \textbf{COPA} & \textbf{ARCT} & \textbf{RECLOR} \\ \midrule
Neg+  &	1,797&492&	297&375	\\ \hline
Neg-  &	94&	2&	152&	119\\ \hline
NER  &	362&	0&	5&0	\\ \hline
PR  &	1,073&	328&71&72	\\ \hline
PI  &	     861&	219&	56&	91\\  \hline
Voice  &	1,014&246	&174	&263	\\  \midrule
Adv  &	1,850&496	&444	&500	\\ \hline
%CO  &	1,871&500	&444	&500	\\ \hline
Syn&	653&	 25&	303&289	\\ \midrule
%MT  &	1,871&500	&444	&500	\\ \hline

Total & 11,446  &  2,808 & 2,390 & 2,709 \\ \bottomrule
\end{tabular}
\caption{Number of stress test cases \protect\footnotemark generated
by different operators for the four datasets.}
\label{tab:cases}
\end{table}

\footnotetext{The number denotes the number of questions 
which can be transfered to a new stress test case with a certain operation.}
%we divide the stress test into two parts, the above part of~\tabref{table:tripleclassification} 
%are test types without syntax and  semantic errors, the following are test cases with errors.  
%compare different we re-evaluate the 
%exploiting short give the results
%on cue discovery as well as model probing along with some analysis. The whole framework has been implemented into
%an online demo at 
%review.


\iffalse
%\subsection{Testing for Short Circuit}
%\label{sec:short_circuit}
%In this section, we will select proper testing operators for short circuit testing and 
%we use these operators to detect the extent of model short circuit.

\subsubsection{Selecting Short Circuit Testing Methods}
\label{sec:select-sc}
%\KZ{Here we evaluate different black-box tests available to
%detect short-circuits in 3 different models. The ground truth
%is the attention map results generated by roy's code.}
%In~\secref{sec:proxy}, we have discussed the possibility that both white-box attention-based method and black-box choice operators 
%in some of the equivalent classes can evaluate short circuits. 
We now evaluate which proxy test operators are better suited for short circuit evaluation.
%For further exploring which operator is better for short circuit evaluation, 
%we sampled 100 random ROC questions that models had already done right for human annotation labeling. 
%Human annotators were asked to determine whether the model considered both premise and choice at the same time 
%with a visual attention map tool. 
%Different with AW,  human annotators are capable of reasoning, 
%and they do not consider relationships that have nothing to do with the answer, 
%such as punctuation and stop words between premise and choices. 
%As described in \secref{sec:proxy}, 
Each test operator generates new test cases by making directional changes to
the test cases that the model answers correctly. 
The model is considered not short-circuiting on a case according 
to a test operator if it still gets the right answer after the operation. 
%Assuming that human attention annotation, attention weight thresholding (AW), 
%and each choice operator are all plausible proxy tests, 

Including human attention annotation and choice-only test, we compare 8 different 
proxy tests in \tabref{tab:agree}. 
%In AW, the hyper parameter $t_1$ and $t_2$ are tuned to 0.14 and 0.13 separately 
We randomly sample 30 MCQs from the test set of ROC that are correctly answered 
by three models respectively. 
For each proxy test, we constructed a binary proxy vector 
of 30-dimensional one-hot vector~(proxy vector) for each model, where each dimension refers to 
a test case passing that proxy test (1) or not (0). If a model doesn't pass the proxy test 
on a certain test case, it means that model short-circuits on that specific MCQ. 
If a test case is not applicable to a proxy test, we generate 0 or 1 randomly.
%Each proxy test will produce a 30-dimensional one-hot vector~(proxy vector) for each model, where 1/0 indicates if the 
%model short-circuited on that specific MCQ or not. 
%\footnote{For MCQ where a certain proxy test is not applicable, we 
%randomly label it as 1 or 0.}. 
For each model, we then compute another vector as the ensemble of all proxy tests by 
majority voting on each of the 30 dimensions. We use the Euclidean distance between the 
proxy vector and the ensemble vector (i.e., center) because the test 
closest to the center will be the most 
representative and applicable to most test cases.  
%The smaller euclidean distance between the individual proxy vector of each test type 
%and the ensemble vector indicates higher reliability. 
We can find that the results of CO are generally closer to the ensembled results. 
Thus, we use CO as the proxy test for short circuit evaluation in the rest of
this section. 

\begin{table}[th]
	\scriptsize
	\centering
	\begin{tabular}{c|cccc}\hline
		\toprule  
		\textbf{Test types} &BERT  & XLNet & RoBERTa  &Ave\\ 
		\midrule
		{Neg+}      &  4.24   	&   3.46  &	\textbf{2.65}	&3.45\\
		\midrule
		{Neg-}&   4.0 	&       3.61  &	3.87	&3.83\\
		\midrule
		{NER}    &   4.0 	&  3.46      &	4.24	&3.9\\
		\midrule
		{PR}&    4.0 	&    3.32   &	4.0	&3.77\\
		\midrule
		{PI}&   3.32 	&    4.0    &	3.16	&3.49\\
		\midrule
		{CO}  &      \textbf{2.0}   	&  \textbf{ 2.0} &	2.83	&\textbf{2.28}\\
		\midrule
		%{AW}   &  \textbf{2.45}	&3.46&	\textbf{2.45}	&\textbf{2.79} \\
		%\midrule
		{Choice-only}   &  4.12  	&3.87  &	3.87	&3.95\\
		\midrule
		{Human}   & 2.24	&   3.0&	3.0	&2.75\\
		\bottomrule
		\hline
	\end{tabular}
	\caption{\label{tab:agree} 
		Euclidean distances between proxy vector and 
		the ensemble vector on short circuit test (the smaller
		the better). 
		Ave is the average score across all models.
		Top test type for each model are highlighted.}
\end{table}

It is noted that, we choose not to use a higher-dimensional vector
here because a) we are not computing accuracy or
pass rate, so statistical significance
is not an issue, and b) in a 30-dimensional space,
we can already sufficiently distinguish these short
circuit tests in \tabref{tab:agree}. Adding more test cases
or more dimensions will not change that distinction.

In our experiment, we do not use human labeling results on the attention map 
as gold indicators.  Because the attention map on each model is not a direct 
expression of the final decision for multiple-choice questions, 
but the expression of the premise and choices which is an indirect information for reasoning.

\fi


%%\begin{table}[th]
%%\scriptsize
%%\centering
%%\begin{tabular}{c|cccc}\hline
%%\toprule  
%%\textbf{Test types} &BERT  & XLNet & RoBERTa  &Ave\\ 
%% \midrule
%%{Neg+}      &     30.06	 &46.67&	19.55	&32.09\\
%%\midrule
%%{Neg-}&    47.22	&63.33&	64.52	&58.36\\
%%\midrule
%%{NER}    &    49.94	&46.67	&51.61	&49.41\\
%%\midrule
%%{PR}&      30.99	&43.33	&38.71&	37.68\\
%%\midrule
%%{PI}&    34.07	&40&	35.48	&36.52 \\
%%\midrule
%%{CO}            &     21.98	&23.33	&25.81	&\textbf{23.71}\\
%%\midrule
%%{AW}   &     22.28	&40&	19.35&	\textbf{27.21}\\
%%\midrule
%%{choice-only}   &     22.28	&40&	19.35&	\textbf{27.21}\\
%%\midrule
%%{Human}   &75.98	&20	&29.03	&41.67\\
%%\bottomrule
%%\hline
%%\end{tabular}
%%\caption{\label{tab:agree} Euclidean distance between test type vector and the ensemble vector on short circuit test. Ave is 
%%the average score across all models.}
%%\end{table}
%
%

%Each operator in~\table{tab:agree} are possible to show whether the model has short circuit problem to a certain extent, In order to choose a more appropriate method, we adopt the following strategies: find the focus of these methods, that is, vote on a topic. If most methods think that the model cheats on this topic, then this topic will be considered cheating. According to the various methods and the Euclidean distance of the selected answer, choose the method that is more suitable for short-circuit test

%\begin{table}[th]
%\scriptsize
%\centering
%\begin{tabular}{c|ccc}\hline
%\toprule  
%\textbf{Test types} &BERT (\%) & XLNet (\%) & RoBERTa (\%)  \\ 
% \midrule
%{Neg+}      &     36.67      &      47.83   & 52  \\
%\midrule
%{Neg-}&     50     &   60 & 40  \\
%\midrule
%{NER}    &     66.67       &    42.85          &   35.71\\
%\midrule
%{PR}&      47.61       &    44.44      &  26.31  \\
%\midrule
%{PI}&     50           &   50    & 35.71  \\
%\midrule
%{CO}            &     83.33        & \textbf{ 70}       &    70.97\\
%\midrule
%{AW}   &      \textbf{99.6}     & 66.67 &   \textbf{77.42} \\
%\bottomrule
%\hline
%\end{tabular}
%\caption{\label{tab:agree} The agreement on short circuit 
%detection between human annotation and each proxy test.}
%\end{table}
%
%\subsubsection{Testing Short Circuit Problems}
%\label{sec:fix-sc}
%%We test short circuits by observing AW and CO scores, 
%%i.e., higher AW/CO scores indicate a lower chance for short-circuiting. We fine-tune the multiple choice classifiers of BERT, XLNet and RoBERTa on 4 datasets. 
%Each number in ``Short Circuit Tests'' columns of
%\tabref{tab:results} denotes
%the percentage of test cases that pass 
%the proxy short circuit test. 
%The higher the percentage, the lower the possibility of short circuit problem.
%Each group of models (e.g., BT*) are tested
%on the subset of the original test set (1871 cases for ROC)
%that vanilla model answers correctly.
%For example, the test set for BT* on ROC contains 
%1871*86.58\% = 1620 questions.
%
%In~\tabref{tab:results}, we fine-tune the multiple-choice classifiers of BERT, XLNet and RoBERTa on 4 datasets 
%with their original training data. 
%We can find that all models trained on original data (in gray color) without 
%data augmentation generally suffer from lower short-circuit passing rates. 
%%We can find that the original models (the gray part in ``Short circuit Test'' column) without 
%%data augmentation are most likely to have short-circuits because the CO score are quite low. 
%%lower CO scores indicate a higher chance for short-circuiting. 
%Unsurprisingly, all models tend to short-circuit on COPA, 
%as it has been shown to contain easy-to-exploit 
%single-token cues by prior work~\citep{kavumba-etal-2019-choosing}. 
%RECLOR is a relatively hard task for models to solve as model 
%accuracies on the original test set are generally 
%lower than other tasks. 
%Nevertheless, the fairly low short circuit test passing rates indicate that these models are still largely making use of superficial cues in the datasets. 
%%Thus we can conclude that short circuit is a serious and common problem which is harmful for 
%%model robustness on different tasks.
%
%We further evaluate the augmented models (with white background in 
%``Short Circuit Tests'' columns) 
%using the short circuit test. According to \tabref{tab:results}, 
%models augmented by crossover always gets the highest short circuit test
%score. It indicates that model learns to reason jointly over both premise and choice. 
%Back-translation doesn't help ameliorate short circuit much, 
%possibly because cues being exploited are still kept after back-translation process. 
%Mutation turns out to be not as effective as crossover for alleviating short circuit. 
%This is likely due to mutation introducing incorrect syntax to the wrong choice, 
%which makes it easier to be eliminated by models.
%
%

%\KZ{Remove the parts about overall robustness} 


%\begin{table}[th!]
%	\centering
%	\scriptsize
%	\begin{tabular}{ll|cc|cc}
%		\toprule
%		\textbf{Dataset} &\textbf{Model}  & \textbf{AW} & \textbf{CO\_sc} & \textbf{Original}&\textbf{Stress}\\
%		\midrule
%		\multirow{3}{*}{ROC} & BT &98.76&90.80&86.58&81.93\\
%		&XL& 28.08&83.28&90.81&79.22\\
%		&RB&77.41&88.76&92.73&82.33\\
%		\cmidrule{2-6}
%		\multirow{3}{*}{COPA} & BT &89.68&68.71&62.00&57.40 \\
%		&XL& 93.16&60.26&61.40&57.71\\
%		&RB&80.89&78.01&76.40&74.85\\ \cmidrule{2-6}
%		
%		\multirow{3}{*}{ARCT} & BT & 9.65&78.52&63.96&58.08\\
%		&XL& 85.67&59.10&75.45&61.72\\
%		&RB&  99.14&60.29&78.83&66.16\\ \cmidrule{2-6}
%			
%		\multirow{3}{*}{RECLOR} & BT &    82.46&50.88&45.6&33.91\\
%		&XL&  79.64&62.86&56.0&39.77\\
%		&RB&85.88&70.2&51.0&36.76\\
%		\bottomrule
%	\end{tabular}
%	\caption{Evaluation models with short circuit test and robustness 
%	test on 4 different datasets. $CO_sc$ denotes we use crossover operator for short circuit evaluation}
%	\label{tab:original}
%\end{table}


%\KZ{Compare crossover, mutation, backtranslation's abilities to
%fix the short-circuit problems. Use roy's code to evaluate
%the new models after augmentation to show that short-circuit problems
%drops the most under crossover.}
\subsubsection{Generating Augmented Data}
We first apply the proposed two operators \textit{crossover}~(C) and \textit{mutation}~(M) as well as their combination \textit{crossover}+\textit{mutation}~(C+M) to generate additional training data. For each MCQ in the original training set, we follow the description in \secref{sec:aug} to generate one additional MCQ using C, M, or C+M. 

For back-translation, we also generate one additional MCQ for each MCQ in the original training set by conducting a round-trip English-to-French and French-to-English translation over each wrong choice. The translation model we utilized is the mBART model based on HuggingFace~\cite{wolf-etal-2020-transformers} library. The quantity of augmented data generated by each method is the same as the original training data of each dataset, hence allowing a controlled comparison.

\subsection{Evaluation}
%\KZ{It's a little strange to have this as a section. More like part
%of implementation details?}
%To improve the diversity of augmented examples, 
%we explore back-translation and our \textit{crossover} and \textit{mutation} strategies.
In this subsection, we explore models with different data augmentation methods, 
back-translation, \textit{crossover} and \textit{mutation}, from overview and detail perspectives. 
Overview means we analyze the results from the original test accuracy result and overall stress test accuracy 
result. Detailed perspective means we will show the stress test accuracy results separately with different operators.

%\KZ{No such thing as micro result}
\begin{table*}[th]
	\scriptsize
	\centering
		\begin{tabular}{l|cc|cc|cc|cc|cc}\toprule
			\multirow{2}{*}{\textbf{Model}} & \multicolumn{2}{c|}{\bf ROC} & \multicolumn{2}{c|}{\bf COPA} & \multicolumn{2}{c|}{\bf ARCT} & \multicolumn{2}{c|}{\bf RELOR}& \multicolumn{2}{c}{\bf Average of 4 Datasets} \\ \cline{2-11}
			& \textbf{Original} &\textbf{Stress}&\textbf{Original} &\textbf{Stress}&\textbf{Original} &\textbf{Stress}&\textbf{Original} &\textbf{Stress} & \textbf{Original} &\textbf{Stress} \\ \hline
			%\rowcolor{gray}
			BT(w/o)&86.58&80.53&62.00&55.53&63.96&57.19&45.60&33.24 &64.53 &56.62\\
			BT+B&86.75&82.50&68.60&68.03&68.47&55.39&48.60&35.02&68.11&60.24\\
			BT+C&87.07&83.20&72.80&78.84&68.92&63.78&47.00&47.63&\textbf{68.95}&68.04\\
			BT+M&86.48&86.06&70.40&76.32&67.79&63.45&46.80&42.77&67.87&66.34\\
			BT+C+M&86.75&85.67&72.40&77.27&67.57&67.38&43.60&47.92&67.58&\textbf{69.56}\\
			\midrule
			
			%\rowcolor{Gray}
			XL(w/o)&90.81&78.69&61.40&53.93&75.45&60.59&56.00&37.70&70.92&57.73\\
			XL+B&90.43&82.01&63.20&63.44&79.05&63.25&57.0&42.66&\textbf{72.42}&62.84\\
			XL+C&89.47&86.01&67.80&74.22&74.55&65.58&54.40&50.59&71.56&69.10\\
			XL+M&90.17&88.44&62.20&69.75&74.10&71.17&53.60&49.96&70.02&69.83\\
			XL+C+M&90.22&90.76&67.20&81.64&77.03&73.37&54.2&51.11&72.16&\textbf{74.22}\\
			\midrule
			%\rowcolor{Gray}
			RB(w/o)&92.73&81.23&76.40&74.56&78.83&65.84&51.00&31.82&74.59&68.16\\
			RB+B&92.46&76.70&77.00&79.31&81.31&65.91&51.00&34.97&\textbf{75.44}&64.22\\
			RB+C&91.18&88.59&79.00&82.52&77.93&65.31&50.40&51.00&74.63&71.86\\
			RB+M&92.62&88.47&72.60&82.85&77.03&74.90&52.00&51.02&73.56&74.31\\
			RB+C+M&91.88&90.76&74.00&86.73&75.00&73.17&48.40&50.04&72.32&\textbf{75.16}\\
			\bottomrule
		\end{tabular}
	\caption{\label{tab:results} Overview test
		on 4 models with or without(w/o) data augmentation.
		All numbers are percentages (\%). 
		+B = augmented with back-translation,
		+C = augmented with crossover, +M = augmented with mutation.}
	%Robustness Test includes: Neg+=negation-add, Neg-=negation-remove, NER, 
	%PR=pronoun-replacement, PI=Pronoun-instantiation, Adv=adverbial, MT=mutation, Voice, Syn=synonym.}
\end{table*}

\subsubsection{Overview results}
\label{sec:overview}

%\KZ{Pls check the caption of all the tables and figures. Many of them
%are not right.}
Our overall comparison experiments results are shown in ~\tabref{tab:results}.
The numbers in the ``Original'' columns denote the percentage of cases in the original test set that is correctly predicted by the models. 
For example, ROC has 1871 test cases~(\tabref{table:dataset}).
The scores in the ``Stress'' columns are the percentage of
stress test cases correctly predicted by the models.

%\KZ{Compared with w/o and +B, we do well with stress tests. That's no
%problem. But with original, things are not that clear. We (including
%+C and +M and +CM) are better than w/o in 8/12 cases, better than +B
%in 7/12 cases. So the success is not overwhelming. Maybe we need to
%compute the average F1 over all the datasets for each model, or
%even the average of all the cases to make us look better?
%We need to discuss how to present it to make it look good.}
In~\tabref{tab:results}, we can find that vanilla BERT, XLNet, and RoBERTa models on different 
datasets are mostly not robust on stress test.
Compared with testing on original test data, 
the accuracy rate has dropped by 12.12\% for XLNet model trained with ROC. 
Similarly, all three models perform much 
worse than before on COPA (7.47\%), RECLOR (18.3\%) and ARCT (14.86\%) datasets. 
It indicates that the original models are fragile and can be easily confused by 
small perturbations. Furthermore, there are two possible sources for model fragility, 
model structure and spurious features in training data. 
Since the model is black-box and hard to interpret, 
we explore the source from the data. 
If the model can get better performance on stress test with a 
data augmentation method, it suggests that the source for model fragility
is from data rather than model structure. 
Meanwhile, it indicates that this data augmentation 
method is effective for enhancing model robustness.
%\textit{Crossover} and \textit{mutation} can 
%reduce data bias in some extent. It is shown in ...

We can also find that model performances with these data augmentation 
methods and the vanilla transformer-based models 
have achieved similar performance ($\pm$2.2) mostly from the average original test column, 
demonstrating that leveraging diverse changes to choices won't harm the effectiveness of models 
in most cases. Consistent with other people's research~\cite{chen-etal-2021-hiddencut}, 
back-translation can help to improve the accuracy of the model on the original tests slightly. 

Besides, among all the augmentation
strategies, we observe that 
back-translation only takes slightly improvement (no more than 5\%)
on stress test for all models in 4 tasks.
Moreover, great gains can be obtained by integrating 
\textit{crossover} (+C), \textit{mutation} (+M) and their combination (+C+M) from 
the aggregate results in the ``Stress'' columns. 
Especially, the augmented models with combination (+C+M) method surpass original 
models greatly. The stress test result for XLNet on COPA has 27.71\% improvement. 
The performance gap between the original test and stress test becomes smallar.
\textit{Crossover} and \textit{mutation} also 
perform consistently
better than back-translation. 
It indicates that these two methods 
are effective for improving the robustness and generalization of the models. 
They can further complement each other.

\label{sec:robust}
%\KZ{Show that the models all vulnerable to different kinds of
%stress tests. And then how our data augmentation methods can
%improve the robustness of these models on 4 diff datasets.}


%\subsubsection{Model Weakness}
%From previous work,  we have recognized the weakness of  
%models and the possible causes. 
%and are not robustness on stress test. 
%We fine-tune the multiple choice classifiers of on 4 datasets. 
%Robustness test in~\tabref{tab:results} includes original test and stress 
%test generated by all possible operators in \tabref{tab:cases}. 
%which is consistent with the CO score (is also much lower than 100\%). 
%From these experiments, we can conclude that the instability of the model is a common problem, 
%and one of the most likely reasons is short circuit. 
%Mostly the AW and CO are consistent with each other, but 
%sometimes they are different on some baselines, like.... In fact, AW is white-box testing while CO is black-box testing. 
%Their behaviors are not intended to be the same.
%In practice, these two testing methods can complement 
%each other.
%Due to limited space, we average the accuracies of different stress tests into a single number 
%in the last column of \tabref{tab:results}. Please refer to the Appendix for complete results.


\subsubsection{Detailed Results}

\begin{figure*}[th]
\centering
\begin{subfigure}[b]{0.24\textwidth}
\centering
\includegraphics[width=\columnwidth]{data/roc_bert.pdf}
\caption{BT (ROC)}
\label{fig:roc_bert}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.24\textwidth}
\centering
\includegraphics[width=\columnwidth]{data/copa_bert.pdf}
\caption{BT (COPA)}
\label{fig:copa_bert}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.24\textwidth}
\centering
\includegraphics[width=\columnwidth]{data/arct_bert.pdf}
\caption{BT (ARCT)}
\label{fig:arct_bert}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.24\textwidth}
\centering
\includegraphics[width=\columnwidth]{data/reclor_bert.pdf}
\caption{BT (RECLOR)}
\label{fig:reclor_bert}
\end{subfigure}
\hfill
\newpage
\begin{subfigure}[b]{0.24\textwidth}
\centering
\includegraphics[width=\columnwidth]{data/roc_xlnet.pdf}
\caption{XL (ROC)}
\label{fig:roc_xlnet}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.24\textwidth}
\centering
\includegraphics[width=\columnwidth]{data/copa_xlnet.pdf}
\caption{XL (COPA)}
\label{fig:copa_xlnet}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.24\textwidth}
\centering
\includegraphics[width=\columnwidth]{data/arct_xlnet.pdf}
\caption{XL (ARCT)}
\label{fig:arct_xlnet}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.24\textwidth}
\centering
\includegraphics[width=\columnwidth]{data/reclor_xlnet.pdf}
\caption{XL (RECLOR))}
\label{fig:reclor_xlnet}
\end{subfigure}
\newpage
\begin{subfigure}[b]{0.24\textwidth}
\centering
\includegraphics[width=\columnwidth]{data/roc_roberta.pdf}
\caption{RB (ROC)}
\label{fig:roc_roberta}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.24\textwidth}
\centering
\includegraphics[width=\columnwidth]{data/copa_roberta.pdf}
\caption{RB (COPA)}
\label{fig:copa_roberta}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.24\textwidth}
\centering
\includegraphics[width=\columnwidth]{data/arct_roberta.pdf}
\caption{RB (ARCT)}
\label{fig:arct_roberta}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.24\textwidth}
\centering
\includegraphics[width=\columnwidth]{data/reclor_roberta.pdf}
\caption{RB (RECLOR)}
\label{fig:arct_roberta}
\end{subfigure}
\caption{Detailed stress test with different aspects on 4 different tasks. The x-axis in the figures indicates different stress test aspects and the y-axis indicates model accuracy in percentage.}
%\KZ{Caption is wrong! most graphs are fine. 
%But ReCLOR (RB) is a bit strange. 
%Why is BT line exactly the same as the BT+C? And why is BT+B so bad?}}
\label{fig:detail_stress}
\end{figure*}

We have described the performance of models with different 
augmentation methods in the aggregated stress test above. 
Moreover, we explore models with detailed stress tests. 
%We show the detailed results in~\figref{fig:detail_stress} 
Concretely, different aspects of stress test data are 
utilized for testing. 
%We apply the proposed two operators \textit{crossover} and \textit{mutation} to BERT, XLNet and RoBERTa 
%models and compare it with back-translation.
%and test on various stress test cases with different aspects. 
The corresponding results are presented in~\figref{fig:detail_stress}. 
We observe that the vanilla model with purple and back-translation with green exhibit 
worse across different aspects than other lines (especially the vanilla model). 
The models trained with data augmented by \textit{crossover} and \textit{mutation} (the red line) 
are mostly more robust than others.
It is consistent with our overview results in~\tabref{tab:results}. 
Please refer to the Appendix for complete numbers of results. 

Furthermore, in~\figref{fig:detail_stress}, we can also find that the 
accuracy performance points for ``Syn'' and ``Adv'' are concentrated 
but scattered on other operator aspects. 
As described in \secref{sec:aug},
all stress tests  (except ``Syn'' and ``Adv) can evaluate whether a model considers 
the premise by using similar choices. 
Thus it indicates that our data augmentation 
method improves the model robustness by encouraging models to pay attention 
to the relation between premise and choices.  
To further explore model ability on avoiding short circuits, 
we also use ``choice-only'' tests
and white-box attention map observation in the next sections.

%\KZ{The weakness can be on the same table as the improvements
%to save space.}
%\KZ{Check the following analysis to make sure it's consistent with the tables.}

%Compared with 
%base models without data augmentation, we find that 
%all four data augmentation methods moderately improve
%the models when tested on the original test set. 
%In ROC, accuracy of BERT and RoBERTa trained with crossover augmented data 
%exceeds base models and ranks top. Crossover method also works on COPA. 
%Even though back-translation obtains higher score mostly on ARCT and RECLOR,
%crossover, mutation and crossover+mutation barely fall below the base model. 
%
%Augmentation fares much better in the ``Stress'' columns, though
%different methods show varying degree of success.
%Compared with the model without data augmentation, 
%the performance of models with crossover 
%has always been greatly improved (i.e., by 21.44\% for BERT on COPA).
%It indicates that reducing the short circuits 
%is a good way to improve the robustness of a model.
%The performance of new models with crossover has 
%great improvement for all models on different dataset 
%compared with the model without data augmentation, like 21.44% for BERT on COPA. 
%Mutation alone can also help with robustness on stress test better than crossover.
%This result suggests that mutation is a good method 
%for enhancing the robustness of models. 
%Though, mutation may be not a 
%good method to decrease the short circuits (\secref{sec:fix-sc}). 
%Overall, crossover+mutation 
%can mostly get the best performance on the stress test except for 
%training on RECLOR with RoBERTa. 
%to This result indicates that this kind of data can prevent models from being confused 
%by simple perturbations thus improving the robustness of models. 
%Besides, we can also find that back-translation doesn't improve the models' robustness much.
%Crossover alone can also help with robustness on stress test but 
%no better than mutation and crossover+mutation.  

%some of Table 5's AW scores being 
%some of Table 5's AW scores being 
%lower than AW for model w/o augmentation (e.g., 45.13 in (b)), 
%then the reason is AW is only a proxy test
%that catches majority of short circuit cases in our opinion, 
%but it's not perfect, as we pointed out in A2 of R1. 
%If you are referring to some accuracies in the Original columns 
%being lower than models w/o augmentation in Table 5 (e.g., 72.6 in (b)), 
%the reason is some models w/o augmentation might have 
%"cheated" to get high accuracy. Augmenting (C or M) corrects the
%biases in these models and may reduce the accuracy on the original test set.
%Nevertheless, all models after augmentation do better on the stress tests.

%have least short circuits based on BERT and XLNet. 
%Crossover+mutation based on RoBERTa takes less short circuits than others. 
%In the CO and AW columns, the result are consistent on ROC. 

%\subsection{White-box Attention Weights~(AW)}
%\KZ{Here we first talk about human testing by visualizastion,
%then talk about how to automatic it thru code.}

%show human annotation results of bert, roberta, xlnet.
%For exploiting whether attention-based models are suffered from short circuits, 
%we propose to 
%use the AW method which we have described in~\secref{}.
%It is noted that t\_1 is greater than t\_2. 
%Here t\_1 and t\_2 are tuned to 0.14 and 0.13 separately.

\subsection{Choice-only Test}

%In this section, we use choice-only test for different models on four tasks. 
%We have shown the effectiveness of \textit{crossover} and \textit{mutation} on in robustness test. 
%$The detailed stress test can somewhat confirm the reason for model improvement with data augmentation 
%strategies. Moreover, this test is used to further explore 
%whether our strategies can encourage models pay more attention to premise.
In choice-only test, we only feed choices for a model without premise which is replaced 
by an empty string. In this way, 
models have to make selection without the premise, not to mention the relationship 
between premise and choices. 
%what we can know whether a model can 
%solve cases easily without awaring premise by test accuracy. 
We expect the model selection results to be consistent with random selection
Because if a model can easily get the ``right'' result which 
is labeled for the relationship between premise and choices in choice-only test, 
it may indicate this model have the 
opportunity to cheat in evaluation procedure and become fragile. 
Another possibility that is also not ruled out is that even if the model 
can tell the result with only choices, it still chooses to look at the premise context. 
Although high scores do not necessarily correspond to models not looking forward, 
low scores necessarily mean that models cannot conclude that solely relying on choices. 

In~\figref{fig:choice-only}, we can find that the choice-only model accuracy rate has dropped 
with \textit{crossover} and \textit{mutation} augmentation methods (red line is the lowest among all). 
Some rates are similar to random selection, like BT+C on ROC (51.2\%) 
and RB+C+M on ARCT (54.8\%), which indicates that models are less 
likely to cheat anymore. 
In other words, models are more likely to consider premise. 
The results on the choice-only tests provide another perspective for us
to confirm that models augmented with crossover and mutation can reduce
short circuits and thus model fragility.

%\begin{table}[th]
%\centering
%\scriptsize
%\begin{tabular}{c|rrrr}
%\toprule
%\textbf{Model} & \textbf{ROC} & \textbf{COPA} & \textbf{ARCT} & \textbf{RECLOR} \\ \midrule
%%BT  &98.76 &89.68&\textbf{99.65}&82.46 	\\ \hline
%%BT+B  &99.26 &96.79	&99.34	&86.01	\\ \hline
%%BT+C  &\textbf{99.69} &\textbf{98.35}&98.37	&80	\\ \hline
%%BT+M  &99.26 & 95.17 &98.67 &82.48	\\ \hline
%%BT+C+M  &98.82 &96.96	&98.00 &\textbf{96.79}	\\ \midrule
%%XL  &28.08 &93.16 & 85.67 & 79.64	\\ \hline
%%XL+B  &19.27	&91.46 &95.73 & 81.40	\\ \hline
%%XL+C  &\textbf{64.58}	&45.13	&55.59	&\textbf{87.87}	\\ \hline
%%XL+M  &62.77	&96.85 & \textbf{95.74}& 72.76	\\ \hline
%%XL+C+M  &60.25 & \textbf{98.51}&86.26 &	48.71\\ \midrule
%%RB  &77.41 & 80.89 & 99.14& 85.88	\\ \hline
%%RB+B  &	58.15 &\textbf{96.36}	& 97.78& 15.69	\\ \hline
%%RB+C  &	82.71& 89.62&79.19&	89.68\\ \hline
%%RB+M  &71.73& 62.26& \textbf{100.00}&\textbf{100.00}	\\ \hline
%%RB+C+M  &\textbf{93.31} &61.89	&71.47 & 89.26\\ 
%%
%BT (w/o)&54.62&51.4&61.94&42.8 \\ \hline
%BT+B&58.26&50.8&64.41&39.2  \\ \hline
%BT+C&51.2&48.2&55.63&30.8  \\ \hline
%BT+M&51.79&48.8&55.18&38   \\ \hline
%BT+C+M&43.56&49.4&52.03&33.8  \\ \midrule
%XL (w/o)&71.14&57&65.99&42.2 \\ \hline
%XL+B&73.17&60&66.89&41.4  \\ \hline
%XL+C&65.63&55&55.86&34.2  \\ \hline
%XL+M&71.94&57.8&66.22&42  \\ \hline
%XL+C+M&66.22&58.4&62.84&35  \\ \midrule
%RB (w/o)&73.97&59.4&67.79&30.2 \\ \hline
%RB+B&74.77&61.4&69.37&42.2  \\ \hline
%RB+C&73.06&58.4&68.47&34.6  \\ \hline
%RB+M&70.34&56&61.49&40      \\ \hline
%RB+C+M&71.3&54.8&67.79&32.2  \\ 
%\bottomrule
%\end{tabular}
%\caption{Choice-only test for transformer-based models on 4 datasets. All numbers are percentages (\%)}
%%\KZ{I assume this is the ending-only test? But isn't smaller the better
%%for ending-only tests?}}
%\label{tab:only-test}
%\end{table}
%
\begin{figure}[th]
 	\centering
 	\includegraphics[width=0.9\columnwidth]{data/choice-only.pdf}
 	\caption{The choice-only results of different data augmentation 
methods with 3 models on 4 tasks.}
 	\label{fig:choice-only}
\end{figure}

\subsection{Case Study}
\label{sec:case}
To glean more insight on how our data augmentation methods help 
enhance model robustness on natural language reasoning, 
we perform case study by analyzing the change of attention patterns.

We present an example from COPA to describe the decision made on 
attention map. The story example is shown in~\tabref{table:dataset}.
In this example, the word ``pushed'' in the premise has great relevance with 
the word ``opened'' in the right choice from human knowledge. 
The relationship between these two words is the key to answer this question. 
We explore different models with the augmentation method with attention map to visualize 
whether these two words have a relation or not.
The attention map is visualized through an off-the-shelf tool~\cite{vig-2019-multiscale}.
\begin{figure}[th!]
\centering
\begin{subfigure}[b]{0.20\textwidth}
\centering

\framebox{\includegraphics[width=\columnwidth]{figure/case_original.eps}}
\caption{RB(w/o)}
\label{fig:case_original}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.20\textwidth}
\centering
\framebox{\includegraphics[width=\columnwidth]{figure/case_b.eps}}
\caption{RB+B}
\label{fig:case_b}
\end{subfigure}
\hfill
\newpage
\begin{subfigure}[b]{0.20\textwidth}
\centering
\framebox{\includegraphics[width=\columnwidth]{figure/case_c.eps}}
\caption{RB+C}
\label{fig:case_c}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.20\textwidth}
\centering
\framebox{\includegraphics[width=\columnwidth]{figure/case_cm.eps}}
\caption{RB+C+M}
\label{fig:case_cm}
\end{subfigure}
\caption{Attention map on a COPA example for models.}
%\KZ{Caption is wrong! most graphs are fine. 
%But ReCLOR (RB) is a bit strange. 
%Why is BT line exactly the same as the BT+C? And why is BT+B so bad?}}
\label{fig:case}
\end{figure}


In \figref{fig:case}, 
%illustration. There is no positive attention value in front of the 
%fourth sentence, so we intercept it from where it is worth. 
RoBERTa trained on the original training set fails to pick up the 
relation between ``pushed'' and ``opened''. 
%right choice likely due to there being virtually no attention 
%connection between words in the choice and words in the premise. 
After training with \textit{crossover} data augmentation, 
the model learns to build contextual reasoning  
by attending to relevant concept in the premise. 
%i.e., ``show'' in this example. The rationale behind 
%such a change of attention pattern is that, 
%in a MCQ created by crossover operation, 
%the model needs to combine information 
%in the premise to effectively 
%distinguish the true ``right'' choice from the wrong one, 
%which is also a right choice in another MCQ. 
Similar trends also exist for the combination of \textit{crossover} 
and \textit{mutation} operation in~\figref{fig:case_cm}. 
These observations empirically demonstrate the effectiveness of our methods 
to encouraging the model to pay attention to premise in terms of improving model robustness.  
However, back-translation in \figref{fig:case_b} seems not to improve model by enhance the 
relation between premise and choices.

%\begin{figure}[th]
%\centering
%{\setlength{\fboxsep}{0pt}
%5\framebox{%
%\includegraphics[width=0.47\columnwidth]{figure/o_un.eps}
%}
%\hfill
%\framebox{%
%\includegraphics[width=0.47\columnwidth]{figure/cross_un.eps}
%}
%}
%\caption{Attention maps showing that RoBERTa short-circuits on a ROC
%question (left) and no longer short-circuits after data augmentation (right). \KZ{I suggest we show a few more cases here to be more convincing. Show the before and after. Before there's no attention to the
%premise, after there is.}}
%\label{fig:case_study}
%\end{figure}
