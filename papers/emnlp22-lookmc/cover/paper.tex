\def\year{2022}\relax
%File: formatting-instructions-latex-2022.tex
%release 2022.1
\documentclass[letterpaper]{article} % DO NOT CHANGE THIS
\usepackage{aaai22}  % DO NOT CHANGE THIS
\usepackage{times}  % DO NOT CHANGE THIS
\usepackage{helvet}  % DO NOT CHANGE THIS
\usepackage{courier}  % DO NOT CHANGE THIS
\usepackage[hyphens]{url}  % DO NOT CHANGE THIS
\usepackage{graphicx} % DO NOT CHANGE THIS
\urlstyle{rm} % DO NOT CHANGE THIS
\def\UrlFont{\rm}  % DO NOT CHANGE THIS
\usepackage{natbib}  % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
\usepackage{caption} % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
\DeclareCaptionStyle{ruled}{labelfont=normalfont,labelsep=colon,strut=off} % DO NOT CHANGE THIS
\frenchspacing  % DO NOT CHANGE THIS
\setlength{\pdfpagewidth}{8.5in}  % DO NOT CHANGE THIS
\setlength{\pdfpageheight}{11in}  % DO NOT CHANGE THIS
%\usepackage{algorithm}
%\usepackage{algorithmic}

\usepackage{newfloat}
\usepackage{listings}
\lstset{%
	basicstyle={\footnotesize\ttfamily},% footnotesize acceptable for monospace
	numbers=left,numberstyle=\footnotesize,xleftmargin=2em,% show line numbers, remove this entire line if you don't want the numbers.
	aboveskip=0pt,belowskip=0pt,
    showstringspaces=false,tabsize=2,breaklines=true}
%\floatstyle{ruled}
%\newfloat{listing}{tb}{lst}{}
%\floatname{listing}{Listing}
%\pdfinfo{
%/Title (AAAI Press Formatting Instructions for Authors Using LaTeX -- A Guide)
%/Author (AAAI Press Staff, Pater Patel Schneider, Sunil Issar, J. Scott Penberthy, George Ferguson, Hans Guesgen, Francisco Cruz, Marc Pujol-Gonzalez)
%/TemplateVersion (2022.1)
%}

% This is not strictly necessary, and may be commented out,
% but it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}
\usepackage{natbib}
\usepackage{caption}
\usepackage{helvet}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{tikz}
\usepackage{graphicx}
\usepackage{multirow}
%\usepackage[usenames,dvipsnames]{color}
%\usepackage{color, colortbl}
%\usepackage{subfigure}
\usepackage{url}
\usepackage{bm}
\usepackage{booktabs}
\usepackage{verbatim}
\usepackage[noend]{algpseudocode}


\usepackage{algorithmicx,algorithm}
\usepackage{bbding}
\usepackage{subcaption} 
\setcounter{secnumdepth}{2} %May be changed to 1 or 2 if section numbers are desired.

\newtheorem{example}{Example}
\newcommand{\secref}[1]{Section \ref{#1}}
\newcommand{\figref}[1]{Figure \ref{#1}}
\newcommand{\eqnref}[1]{Eq. (\ref{#1})}
\newcommand{\tabref}[1]{Table \ref{#1}}
\newcommand{\exref}[1]{Example \ref{#1}}
\newcommand{\KZ}[1]{\textcolor{blue}{Kenny: #1}}
\newcommand{\Roy}[1]{\textcolor{red}{Roy: #1}}
\newcommand{\crosssymbol}{{ \XSolidBrush} }
%{{\color{red} \XSolidBrush} }
\newcommand{\checksymbol}{{\Checkmark} }
%{{\color{green} \Checkmark} }
\newcommand{\cut}[1]{}

\usepackage{makecell}
%\usepackage[table]{xcolor}
%\aclfinalcopy % Uncomment this line for the final submission
%\def\aclpaperid{138} %  Enter the acl Paper ID here

%\setlength\titlebox{5cm}
% You can expand the titlebox if you need extra space
% to show all the authors. Please do not make the titlebox
% smaller than 5cm (the original size); we will check this
% in the camera-ready version and ask you to change it back.

\newcommand\BibTeX{B\textsc{ib}\TeX}
\definecolor{Gray}{gray}{0.9}

\title{Genetically Inspired Data Augmentation for 
Multiple-Choice Natural Language Reasoning}

\begin{document}

\maketitle

\begin{abstract}
For multiple-choice natural language reasoning problems, 
we investigate recent speculation that some neural models 
can make a correct choice without referring to the context of 
the choices in the questions which may make the model fragile. 
To encourage models to learn more from the logical connections between 
premises and choices, we propose biologically inspired operations 
that can effectively be used to augment training data to teach the existing
models to be more robust in their tasks. This method can augment
any type of multiple choice reasoning dataset, and be applied to
any supervised learning models. Results show that augmented models
become more robust against both difficult cases and original
test data, beating back-translation, which is a recent strong baseline.
\end{abstract}

\input{intro}
\input{method}
\input{experiments}
\input{related}
\input{conclude}
\bibliography{aaai22}
%\bibliographystyle{acl_natbib}
\end{document}
