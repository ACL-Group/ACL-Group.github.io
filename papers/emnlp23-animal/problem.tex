\section{Problem}
\label{sec:problem}
% To understand lexical semantics of dogs with the help of YouTube videos, 
% we seek to address the following technical problems.
Our goal is to understand the lexical semantics of dogs, 
we seek to address the following technical problems: 
\begin{enumerate}
	\item Given a sequence of dog vocal sounds from a Youtube video, 
	segment it into a sequence of distinct ``words'', similar to what we 
	do to human languages. 
	\item Given a word and its position in the video, extract the context, i.e.,
	the location and activity of the dog at that point.
\end{enumerate}

To answer these questions, in Section \ref{sec:divide} we propose the method for word segmentation, and in Section \ref{sec:infer_context} the method for context extraction.

% To answer this question, we begin by curating a dataset of Shiba Inu videos sourced from YouTube. Our objective is to construct a dataset comprising triplets, each consisting of a segment word of a dog sound audio clip, accompanied by its corresponding location and activity (as depicted in Figure 2). Initially, we focus on extracting the ``words" emitted by the dogs. To ensure the high quality of the audio clips, we segment the dog audio clips into minimal units and eliminate any unwanted noise. Following this, we employ classification techniques to categorize these short units into predefined word types. We define dog surrounding context as a combination of the dog's location and activity. Determining them in YouTube dog videos poses a significant challenge because of the unique video shooting perspective and shooting ways including shaking and scene transition. To overcome this, we establish a robust pipeline that leverages timestamps from the
% ``word'' audio clips with notable accuracy. Then we can analyze the 
% triplets across different contextual scenarios.

