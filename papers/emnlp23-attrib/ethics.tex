\section*{Ethics Statement}
The proposed method is utilized for the control of gender style. As we've noticed and discussed in Sec. \ref{sec:results}, the model may resort to gender stereotypes for generating responses in that gender. The potential reason is that the dataset used to train the classifier already contains gender-biased labels, and such biases are exploited by the classifier, and passed to the generation model through the automatic annotated labels. To avoid such effects, we may carefully clean the dataset for such biased labels \cite{gehman2020realtoxicityprompts}, or mine such biased tokens and penalize them during weighted decoding. We may also apply RLHF to further mitigate the biases \citep{ouyang2022training}.
% \KZ{Maybe RLHF can be used also? Just mention and give a cite?}

Though the proposed method is mainly intended for improving the interestingness of the chatbot, and endowing the model with abilities like emotional support, such method may also be applied for vicious application. For example, they may introduce toxicity as an attribute and encourage the model to generate more toxic responses. Therefore, the application range of such techniques should be carefully restricted. 

We adhere to the license of the used datasets.
