\section{Details of Experimental Setup}
\label{sec:d}

\paragraph{Datasets.} The Chinese AI and Law Challenge 2018 (CAIL2018) is widely utilized in the Legal Judgment Prediction (LJP) task \cite{DBLP:journals/corr/abs-1807-02478}\footnote{All cases come from China Judgment Online. All personal information has already been hidden.}. As Figure~\ref{fig:sta} demonstrate, some of crimes have limited training data. Besides, the sentencing results of most criminal cases are too concentrated in a smll range to be trained.

Therefore, in this paper, we specifically focus on three crimes: \textit{fraud}, \textit{intentional injury}, and \textit{arson}. These three crimes are defined by Articles 193, 234, and 114 of the Criminal Acts of China, respectively. More important, these three crimes are also representative in Chinese criminal law, reflecting the comprehensive protection of personal safety, public safety and economic order. 

To evaluate the predictive capabilities of models across varying training case sizes, we randomly selected cases as the training sets, with sizes ranging from 10 to 1,000 cases. To reduce randomness, we performed five times of random selection. Table~\ref{tab:test} details the statistical outcomes for the test sets of these crimes.

\begin{table}
    \centering
    % \scriptsize
    \small
    \caption{Statistical test cases for the Crime of fraud, intentional injury, and Arson. 
    %where '\#Cases' represents the number of cases. 
    According to these legal provisions, we divide these cases into three categories: 0 to 3 years, 3 to 10 years, and more than 10 years.}
    \begin{tabular}{p{0.2\columnwidth}cccc}
    \toprule
      Crime & \#Cases & 0 to 3 & 3 to 10&More than 10\\
      \hline
    Fraud & 6004 & 3265 & 2186 & 553\\
    Intentional Injury & 8148 & 5110 & 2632 & 406\\
    % Robbery & 777 & 0 & 689 & 88\\
    Arson & 510 & 121 & 369 & 20\\
    \bottomrule
    \end{tabular}
    \label{tab:test}
\end{table}

\paragraph{Evaluation metrics.}
Most previous studies regard PTP as a classification problem and employ cross-entropy as the distance function $d(\cdot,\cdot)$ for comparing between the reference and predicted values~\cite{feng-etal-2022-legal,ML-LJP}. 
However, this formulation overlooks the ordinal nature of penalty terms, treating two misclassifications as identical even when one is much closer to the ground truth value. Motivated by this, we regard PTP as a regression problem and use Root Mean Square Error (RMSE)~\cite{chai2014root} as the distance function. 

% As a regression problem, we employ a prevalent regression metric, Root Mean Square Error (RMSE)~\cite{chai2014root}.
Furthermore, to assess the degree of alignment between the prediction results and human judges' decisions, we introduce the Pearson correlation coefficient~\cite{cohen2009pearson}. 

Additionally, considering the variable severity classes associated with each crime, it's imperative that predictions not only approximate the numerical decision closely but also align with the correct severity category. Table~\ref{tab:test} illustrates that the distribution of cases across the three defined classes is imbalanced. Hence, we employ the Macro F1 score to evaluate the model's performance, which accounts for the imbalance by treating each class equally in the calculation. Furthermore, given that the third category in Table~\ref{tab:test}, ``More than 10'', includes three levels of sentencingâ€”fixed-term imprisonment, life imprisonment, and the death penalty, we adjust our classification schema to a total of five classes to satisfy the severity classes.