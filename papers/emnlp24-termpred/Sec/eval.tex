\section{Experiments}
% We assess the effectiveness of our methods by exploring the following research questions:

% \textbf{RQ1.} Do the proposed methods offer any advantages over previous works?

% \textbf{RQ2.} How is the quality of auto-constructed Law-Graph?

% \textbf{RQ3.} Is the new design essential when we have Large Language Models? 

\subsection{Experimental Setup} \label{es}
\paragraph{Datasets.} In this paper, we choose three representative crimes: \textit{fraud}, \textit{intentional injury}, and \textit{arson}, in the well-known Chinese AI and Law Challenge 2018 (CAIL2018) dataset~\cite{DBLP:journals/corr/abs-1807-02478}\footnote{All cases come from China Judgment Online. All personal information has already been hidden.}. To evaluate the predictive capabilities of models across varying training case sizes, we randomly selected cases as the training sets, with sizes ranging from 10 to 1,000 cases. More details about the datasets can be found in Appendix~\ref{sec:d}.

% These three crimes are defined by Articles 193, 234, and 114 of the Criminal Acts of China, respectively.  To reduce randomness, we performed five times of random selection. Table~\ref{tab:test} details the statistical outcomes for the test sets of these crimes.

% \begin{table}
%     \centering
%     \scriptsize
%     \caption{Statistical test cases for the Crime of fraud, intentional injury, and Arson. 
%     %where '\#Cases' represents the number of cases. 
%     According to these legal provisions, we divide these cases into three categories: 0 to 3 years, 3 to 10 years, and more than 10 years.}
%     \begin{tabular}{ccccc}
%     \toprule
%       Crime & \#Cases & 0 to 3 & 3 to 10&More than 10\\
%       \hline \vspace{-2mm} \\
%     Fraud & 6004 & 3265 & 2186 & 553\\
%     Intentional Injury & 8148 & 5110 & 2632 & 406\\
%     % Robbery & 777 & 0 & 689 & 88\\
%     Arson & 510 & 121 & 369 & 20\\
%     \bottomrule
%     \end{tabular}
%     \label{tab:test}
% \end{table}

\vspace{-0.5em}
\paragraph{Baselines.}
We compare with the following baseline models: (1) Language models: Both BERT~\cite{devlin-etal-2019-bert} and Electra~\cite{DBLP:conf/iclr/ClarkLLM20} are language models that can be applied to this task. We also evaluate a fine-tuned BERT, BERT-FT, on the CAIL2018 dataset. We utilize about a million sentences to fine-tune BERT. (2) Models learning from previous cases: R-former~\cite{Rformer} introduce the relation learning to improve the prediction results. (3) Models equipped with legal knowledge: NeurJudge~\cite{neurjudge} and ML-LJP~\cite{ML-LJP} are two representative and the state-of-the-art models which considers legal rules information.

To ensure a fair comparison, we standardized the loss functions of these models to Mean Squared Error (MSE)~\cite{chicco2021coefficient}, aligning them with our methodology. All other settings were maintained as described in original publications.

\vspace{-0.5em}
\paragraph{Evaluation metrics.}
In this paper, we regard PTP as a regression problem and use Root Mean Square Error (RMSE)~\cite{chai2014root} as the distance function. Furthermore, to assess the degree of alignment between the prediction results and human judges' decisions, we introduce the Pearson correlation coefficient~\cite{cohen2009pearson}. Additionally, considering the variable severity classes associated with each crime, it's imperative that predictions not only approximate the numerical decision closely but also align with the correct severity category. Hence, we also apply the Macro F1 to evaluate this. More details about the metrics can be found in Appendix~\ref{sec:d}.

% Most previous studies regard PTP as a classification problem and employ cross-entropy as the distance function $d(\cdot,\cdot)$ for comparing between the reference and predicted values~\cite{feng-etal-2022-legal,ML-LJP}. 
% However, this formulation overlooks the ordinal nature of penalty terms, treating two misclassifications as identical even when one is much closer to the ground truth value. Motivated by this, we regard PTP as a regression problem and use Root Mean Square Error (RMSE)~\cite{chai2014root} as the distance function. 

% % As a regression problem, we employ a prevalent regression metric, Root Mean Square Error (RMSE)~\cite{chai2014root}.
% Furthermore, to assess the degree of alignment between the prediction results and human judges' decisions, we introduce the Pearson correlation coefficient~\cite{cohen2009pearson}. 

% Additionally, considering the variable severity classes associated with each crime, it's imperative that predictions not only approximate the numerical decision closely but also align with the correct severity category. Table~\ref{tab:test} illustrates that the distribution of cases across the three defined classes is imbalanced. Hence, we employ the Macro F1 score to evaluate the model's performance, which accounts for the imbalance by treating each class equally in the calculation. Furthermore, given that the third category in Table~\ref{tab:test}, ``More than 10'', includes three levels of sentencingâ€”fixed-term imprisonment, life imprisonment, and the death penalty, we adjust our classification schema to a total of five classes to satisfy the severity classes.

\vspace{-0.5em}
\paragraph{Hyper-parameter Setting.}

For the proposed statute knowledge enhanced method, all learnable parameters are initialized by a standard normal distribution, and hidden vector dimensions $d$ with the same settings as previous work~\cite{neurjudge}. We utilize Adam optimizer with the learning rate $1\times 10^{-3}$. To reduce randomness, we take the average results from 5 times of experiments. 
We perform training and evaluation on a workstation with an Nvidia RTX 4090 GPU with 24 GB memory. 



% \begin{figure*}
% \vspace{-1em}

%     \centering
%     \subfigure[Fraud: MAE]{\label{fig:fraud-mae}
% \includegraphics[width=0.22\linewidth]{latex/figs/fraud-mae.png}}
% % \vfill
% \hspace{0.001\linewidth}
% \subfigure[Fraud: RMSE]{\label{fig:fraud-rmse}
% \includegraphics[width=0.22\linewidth]{latex/figs/fraud-rmse.png}}
% \hspace{0.001\linewidth}
% \subfigure[Fraud: Macro F1]{\label{fig:fraud-f1}
% \includegraphics[width=0.22\linewidth]{latex/figs/fraud-F1.png}}
% \hspace{0.001\linewidth}
% \subfigure[Fraud: Pearson]{\label{fig:fraud-p}
% \includegraphics[width=0.22\linewidth]{latex/figs/fraud-pearson.png}}
% \vspace{-1em}

% \subfigure[II: MAE]{\label{fig:injure-mae}
% \includegraphics[width=0.22\linewidth]{latex/figs/injure-mae.png}}
% % \vfill
% \hspace{0.001\linewidth}
% \subfigure[II: RMSE]{\label{fig:injure-rmse}
% \includegraphics[width=0.22\linewidth]{latex/figs/injure-rmse.png}}
% \hspace{0.001\linewidth}
% \subfigure[II: Macro F1]{\label{fig:injure-f1}
% \includegraphics[width=0.22\linewidth]{latex/figs/injure-F1.png}}
% \hspace{0.001\linewidth}
% \subfigure[II: Pearson]{\label{fig:injure-p}
% \includegraphics[width=0.22\linewidth]{latex/figs/injure-pearson.png}}
%     \vspace{-1em}

% \subfigure[Robbery: MAE]{\label{fig:robbery-mae}
% \includegraphics[width=0.22\linewidth]{latex/figs/robbery-mae.png}}
% % \vfill
% \hspace{0.001\linewidth}
% \subfigure[Robbery: RMSE]{\label{fig:robbery-rmse}
% \includegraphics[width=0.22\linewidth]{latex/figs/robbery-rmse.png}}
% \hspace{0.001\linewidth}
% \subfigure[Robbery: Macro F1]{\label{fig:robbery-f1}
% \includegraphics[width=0.22\linewidth]{latex/figs/robbery-F1.png}}
% \hspace{0.001\linewidth}
% \subfigure[Robbery: Pearson]{\label{fig:robbery-p}
% \includegraphics[width=0.22\linewidth]{latex/figs/robbery-pearson.png}}
%         \vspace{-1em}

% \subfigure[Arson: MAE]{\label{fig:arson-mae}
% \includegraphics[width=0.22\linewidth]{latex/figs/arson-mae.png}}
% % \vfill
% \hspace{0.001\linewidth}
% \subfigure[Arson: RMSE]{\label{fig:arson-rmse}
% \includegraphics[width=0.22\linewidth]{latex/figs/arson-rmse.png}}
% \hspace{0.001\linewidth}
% \subfigure[Arson: Macro F1]{\label{fig:arson-f1}
% \includegraphics[width=0.22\linewidth]{latex/figs/arson-F1.png}}
% \hspace{0.001\linewidth}
% \subfigure[Arson: Pearson]{\label{fig:arson-p}
% \includegraphics[width=0.22\linewidth]{latex/figs/arson-pearson.png}}
%     \vspace{-1em}

% \caption{Results on Four Different Laws. II denotes the intentional injury.
% \KZ{Fonts too small. Fonts in figs and tables must be at least 2/3 of the main text size.}}
% \label{fig:over}
% \vspace{-2em}
% \end{figure*}
% \KZ{Be careful, you can't show a figure or table on a page before the first mention of this figure or table.}
\begin{figure*}[th]
\vspace{-2em}
    \centering
% \vfill
\subfigure[Fraud: RMSE]{\label{fig:fraud-rmse}
\includegraphics[width=0.3\linewidth]{figs/fraud-rmse.png}}
\hspace{0.001\linewidth}
\subfigure[Fraud: Macro F1]{\label{fig:fraud-f1}
\includegraphics[width=0.3\linewidth]{figs/fraud-F1.png}}
\hspace{0.001\linewidth}
\subfigure[Fraud: Pearson]{\label{fig:fraud-p}
\includegraphics[width=0.3\linewidth]{figs/fraud-pearson.png}}
\vspace{-1em}

\vfill
\hspace{0.001\linewidth}
\subfigure[Intentional Injury: RMSE]{\label{fig:injure-rmse}
\includegraphics[width=0.3\linewidth]{figs/injure-rmse.png}}
\hspace{0.001\linewidth}
\subfigure[Intentional Injury: Macro F1]{\label{fig:injure-f1}
\includegraphics[width=0.3\linewidth]{figs/injure-F1.png}}
\hspace{0.001\linewidth}
\subfigure[Intentional Injury: Pearson]{\label{fig:injure-p}
\includegraphics[width=0.3\linewidth]{figs/injure-pearson.png}}
    \vspace{-1em}
% \vfill
% \hspace{0.001\linewidth}
% \subfigure[Robbery: RMSE]{\label{fig:robbery-rmse}
% \includegraphics[width=0.3\linewidth]{figs/robbery-rmse.png}}
% \hspace{0.001\linewidth}
% \subfigure[Robbery: Macro F1]{\label{fig:robbery-f1}
% \includegraphics[width=0.3\linewidth]{figs/robbery-F1.png}}
% \hspace{0.001\linewidth}
% \subfigure[Robbery: Pearson]{\label{fig:robbery-p}
% \includegraphics[width=0.3\linewidth]{figs/robbery-pearson.png}}
%         \vspace{-1em}

\vfill
\hspace{0.001\linewidth}
\subfigure[Arson: RMSE]{\label{fig:arson-rmse}
\includegraphics[width=0.3\linewidth]{figs/arson-rmse.png}}
\hspace{0.001\linewidth}
\subfigure[Arson: Macro F1]{\label{fig:arson-f1}
\includegraphics[width=0.3\linewidth]{figs/arson-F1.png}}
\hspace{0.001\linewidth}
\subfigure[Arson: Pearson]{\label{fig:arson-p}
\includegraphics[width=0.3\linewidth]{figs/arson-pearson.png}}
    \vspace{-1em}
\caption{Results on Three Different Crimes.}
\label{fig:over}
\vspace{-1.5em}
\end{figure*}

\subsection{Comparisons among PTP Methods}

\figref{fig:over} presents a comparison between previous representative methods and our proposed methods. 

Compared to conventional methods, methods incorporating statute information significantly outperform their counterparts. This superiority is primarily attributed to conventional methods lacking the legal knowledge for accurate decision-making. Previous studies have similar findings.
%This observation aligns with findings reported in previous studies.

Compared to methods emphasising case relations, the proposed method surpasses the R-former method in accuracy. Although R-former achieves a few good results in the RMSE metric, these advantages are minimal due to the narrow range of predicted penalty times across all cases. Pearson correlation results further corroborate this lack of relevance to the actual labels. The limitation may stem from these method dependencies on historical cases, which are restricted in this problem.

Compared to methods leveraging statute information, the proposed SKE method outperforms the state-of-the-art ML-LJP method. This enhanced performance is credited to our application of the Law-Graph through transforming plain text legal information into a structured format, thereby facilitating easier comprehension by the models.

We evaluate the impact of training sample size. Initially, with fewer than 200 training cases, the proposed SKE method also demonstrates a weak correlation with human judgments. Then, the correlation strengthens as the training sample size increases to between 200 and 400 cases. Beyond 400 cases, the method strongly correlates with human judgments, which significantly outperforms other methods. These results suggest that our proposed SKE model is effective in scenarios with infrequent crimes or limited case examples.


\begin{figure*}[th]
% \vspace{-1em}
    \centering
% \vfill
\hspace{0.001\linewidth}
\subfigure[Fraud: RMSE]{\label{fig:fraud-gpt-rmse}
\includegraphics[width=0.3\linewidth]{figs/fraud-GPT-rmse.png}}
\hspace{0.001\linewidth}
\subfigure[Fraud: Macro F1]{\label{fig:fraud-gpt-f1}
\includegraphics[width=0.3\linewidth]{figs/fraud-GPT-F1.png}}
\hspace{0.001\linewidth}
\subfigure[Fraud: Pearson]{\label{fig:fraud-gpt-p}
\includegraphics[width=0.3\linewidth]{figs/fraud-GPT-pearson.png}}
\vspace{-1em}
\vfill
\hspace{0.001\linewidth}
\subfigure[Intentional Injury: RMSE]{\label{fig:injure-gpt-rmse}
\includegraphics[width=0.3\linewidth]{figs/injure-GPT-rmse.png}}
\hspace{0.001\linewidth}
\subfigure[Intentional Injury: Macro F1]{\label{fig:injure-gpt-f1}
\includegraphics[width=0.3\linewidth]{figs/injure-GPT-f1.png}}
\hspace{0.001\linewidth}
\subfigure[Intentional Injury: Pearson]{\label{fig:injure-gpt-p}
\includegraphics[width=0.3\linewidth]{figs/injure-GPT-pearson.png}}
    \vspace{-1em}
\caption{Comparison with LLMs. }
\label{fig:gpt}
\vspace{-1em}
\end{figure*}

\vspace{-0.5em}
\subsection{Comparison with Large Language Models}
With the development of Large Language Models (LLMs) that demonstrate good performance across various tasks~\cite{NEURIPS2020_1457c0d6,Katz2023GPT4PT, sun2023short}, it becomes imperative to assess the need for specialized task models in the PTP problem. We compare our proposed SKE method against two benchmark LLMs, GPT-3.5 and GPT-4~\cite{NEURIPS2022_b1efde53,DBLP:journals/corr/abs-2303-08774}, by conducting evaluations using fraud and intentional injury cases. Due to the usage limitation of GPT, we selected a subset of 200 cases for each type of crime to serve as test instances, ensuring that these LLMs were provided with the same training samples for references utilized for the SKE method. The outcomes of these evaluations are detailed in Figure~\ref{fig:gpt}.

Our SKE method generally surpasses the performance of the GPT models, showing particularly significant advantages over GPT-3.5. Although GPT-4 is a little bit better in a few points, its deployment is constrained by the requirement for billions of parameters and extensive training periods. In contrast, the SKE method requires only approximately 2000MB of memory and less than a day's training for each type of crime, presenting a more cost-effective solution. More importantly, the legal domain demands stringent data privacy measures that may not be readily achievable with GPT models. Our method offers the advantage of local processing, ensuring enhanced protection of personal privacy, which is crucial for legal applications.

% \begin{figure}
%     \centering
%     \includegraphics[width=0.8\linewidth]{latex/figs/eva.png}
%     \caption{Evaluation of constructed Law-Graphs.}
%     \label{fig:eva}
%     \Kaiqi{I think we don't need to use a figure. This figure can't make any comparison. Consider providing the numbers in the text.}
% \vspace{-1em}
% \end{figure}

\vspace{-0.5em}
\subsection{Generalization Analysis}
The proposed method consists of two steps: (1) converting the plain statutory provision text into a \lawgraph{}; and (2) using SKE to encode the \lawgraph{} and case facts to predict prison terms. Since the proposed SKE is a neural network, the second step faces no significant challenges in applying to a wide range of crimes. Section~\ref{con} describes the construction process based on Legal Norm theory and statutory pattern analysis. Legal Norm theory divides statutory provisions into three parts, a method supported by legal research and widely applied in criminal law~\cite{Greco2023BringingOI,wang-etal-2022-d2gclf}. The Chinese statutory provisions are written following the creation \textit{Legislative Technical Specification}. This means that pattern analysis is applicable to many provisions that follow the same rule. Based on this approach, the \lawgraph{} construction process is general and can be applied to Chinese criminal statutory provisions. To further validate this, we successfully constructed 220 \lawgraph{s} using the proposed method~\footnote{The \lawgraph{s} dataset will be released after paper acceptance. During the review process, we uploaded it as supplementary material.} and discussed the quality in Section~\ref{qa}. Overall, the proposed method can be applied to other crimes.

%~\footnote{The rule is from \textit{Legislative Technical Specification (Trial) (I)}, which can be found at \url{http://zgfxqk.chinalaw.org.cn/portal/article/index/id/3045.html}.}

\vspace{-1em}
\subsection{Quality Analysis of \lawgraph{s}} \label{qa}
\vspace{-0.5em}
The Law Graph quality directly influences the performance of the SKE method, underscoring the importance of evaluating its quality. To undertake this assessment, we randomly select 50 crimes from Chinese Criminal Law as a basis for comparison between the \lawgraph{} generated by our method (detailed in Section~\ref{con}) and those constructed by human experts. The human experts utilize the same definition of graphs. We simplify this comparison by framing it as a multi-label classification problem~\cite{6471714}, focusing on both the vertices and edges that comprise the Law Graph. The evaluation employs F1 scores and Hamming Loss as metrics to quantify the performance and accuracy of the constructed Law Graphs.

After experiments, we obtain 97.48\% F1 scores and 0.04 Hamming Loss for node comparison with labels; and 95.08\% F1 scores and 0.09 Hamming Loss for edge comparisons. The high F1 scores and low Hamming Loss values. Additionally, we conducted an error analysis to identify the sources of inaccuracies. These errors have two reasons: the misinterpretation of parallel words and the failure to accurately differentiate between leading elements and subsequent steps in statutory provisions.

\vspace{-1em}
\subsection{Interpretability Analysis}
\vspace{-0.5em}

% Most research on prison term prediction, including the proposed approach, is based on neural networks, which makes it challenging to understand why a predicted decision has been made. To explain and enhance the reliability of the proposed models, we propose utilizing the \lawgraph{} and LLMs to explain the reasoning behind the decision. Based on the \lawgraph{} definition and construction, we can align the predicted terms with one of the sanction subgraphs and the corresponding disposition subgraphs. Then, the LLM can be used to find detailed facts aligned with the disposition and the reasons for the decision by following the disposition subgraphs.  More details, such as the LLM used in this paper and prompt design, can be found in Appendix~\ref{sec:c}. We evaluated the accuracy of the reason analysis on 50 cases per crime, and the analysis process achieved an accuracy of 96\% for \textit{fraud}, 94\% for \textit{intentional injury}, and 92\% for \textit{arson} crimes. The results shows that this process effectively provides reasons for the decision.
Most PTP research proposes neural network models, which makes it challenging to understand why a predicted decision has been made. To explain and enhance the reliability of the proposed models, we propose utilizing \lawgraph{} and LLMs to explain the reasoning behind the decision. Based on the \lawgraph{} definition, we can align the predicted terms with one of the sanction subgraphs and the corresponding disposition subgraphs. The disposition subgraphs provide the initial decision reasons for the case by indicating the severity level. Then, the LLM can be used to find detailed reasons in the facts aligned with the term. More details, such as the LLM used in this paper and prompt design, can be found in Appendix~\ref{sec:c}. We conducted experiments based on 50 cases per crime with the accuracy metric to evaluate the correctness of the proposed method in explaining the predicted results. The results show that the proposed analysis process achieved accuracies of 96\% for \textit{fraud}, 94\% for \textit{intentional injury}, and 92\% for \textit{arson} crimes. These results demonstrate that the proposed interpretability analysis method is effective.
