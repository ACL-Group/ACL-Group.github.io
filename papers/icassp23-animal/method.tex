\section{Methodology}
\label{sec:method}
To verify our assumptions that dogs from different human language environments bark differently and the barking difference is related to their host's language, we conduct classification-based experiments and use the Shapley value to interpret prominent acoustic features. Once classifications between barks from different language environments have distinguished accuracy, it is equivalent to say that those barks are different. To eliminate the confounding factors of context, the classification is done on barks pairs with similar contexts.

\subsection{Classwise Classification}
%We first attempt to classify dog barks of different host language environment settings. %The dataset is EJShibaVoice created by us. 
Note that in EJShibaVoice, we have 9,200 pairs index of barks with similar contexts. These pairs are respectively divided into four classes: En-En, Ja-Ja, En-Ja, Ja-En. We conduct a four-class classification experiment to validate whether the dog barking differences can be distinguished. Acoustic features including spectral features (filterbank, PLP, MFCC) and handcrafted feature-sets (eGeMAPS, GeMAPS, ComparE, and ComParE) are used. These features contain different levels of acoustic characteristics. Our classification models include xgboost, KNN, Logistic Regression, and Random Forest. All experiments are conducted with 5-fold cross-validation. 

\subsection{Prominent Factors Analysis}


To ascertain the influence of the host language on dog barks, we analyze prominent factors that distinguish Japanese and English dogs' sounds. Shapley value is commonly adopted to explain feature importance for a given machine learning model, which can help determine the prominent features influencing dog barking. %Python implements that in SHAP. 
% The Shapley value computation is illustrated below:
% % \MYW{Rewrite the previous sentence. Introduce it as: Shapley value is commonly adopted to explain feature importance for a given machine learning model, which can help us determine the prominent features influencing dog barking. }

% Suppose sample $x_i$, the $j-th$ dimension of its feature is $x_{ij}$, the prediction target value is $y_i$, the average target value is $\overline{y}$. Then SHAP is defined below, in which $f(x_{ij})$ is the SHAP value of $x_{ij}$:
% \begin{align}
% y_i = \overline{y} + f(x_{i1}) + f(x_{i2}) + ... + f(x_{ik})
% \label{eq:shap}
% \end{align}

GeMAPs\cite{eyben2015geneva} is a widely-utilized acoustic feature set containing, consisting of statistical computation on acoustic features, which are low-level descriptors that exhibit high interpretability.
%low-level acoustic descriptors is taken for better interpretation. It is 62-dimension
For its universality and explainability, it is selected as the input features to compute Shapley values and determine our prominent influencing acoustic features.

% GeMAPs is designed to easy to explain, thus we choose it as the source of our prominent factors. \MYW{Weird sentence too. First say what is GeMAPS, what is the original purpose when proposed, and add refs, for instance: it consists of statsitical computation on acoustic features, which are low-level descriptors that exhibit high interpretability}
% GeMAPs is 62-dimension with comprehensive meaning for each dimension. It's based on 18 low-level descriptors containing frequency related parameters, energy/amplitude related parameters and spectral(balance) parameters. All these dimensions are processed such as standardization.\MYW{what do you mean such as standadization? didn't understand the purpose of this sentence}
To compare the relationships between a dog barking and the host language, we also included features extracted from human speech (English and Japanese corpus). The speech sources include 8,000 clips from CommonVoice~\cite{ardila2019common}, which is a publicly available multilingual speech dataset contributed by volunteers around the world, and hosts' speech from EJShibaVoice. Speech from EJShibaVoice has direct relation with barks, so that we can conduct Pearson value analysis between them, while CommonVoice is purer and more common to help us find universal feature of human speech. Similar procedures are conducted on human language and the prominent factors are later compared with those inferred from dog barking~(\secref{sec:prominentfactor}).  
% \MYW{epxlain why we still need commonvoice, since we already have host speech}

%On the other hand, we conduct SHAP analysis on the extracted audio, which are more related to barks of dogs. To extract the speech from the same videos as the clips of barks, we apply PANNs as well in order to cut up and filter those speech clips. Here we have also done experiment in the same way as above, apart from that the speech clips are also pairwise using the same method as barks pairwise. 

%Afterwards, we analyze the relationship between the barks of dogs and the voice of humans on these final prominent factors and find similarities between them. 
%The voice of human comes from two sources: open public human voice corpus Common Voice
