\section{Related Work}
\label{sec:related}
The top-$k$ list extraction problem, presented in this work,
belongs to the general area of web structured data extraction,
where many techniques have been developed and improved recently.
In general, these techniques can be categorized as follows:
(a) heuristic methods \cite{googlesets,webtables08};
(b) automatic extraction rule discovery \cite{ChangL01:IEPAD};
(c) similarity-based extraction \cite{LiuGZ03:MDR,MiaoTHSM09:TagPathClustering}; and
(d) visual model and features \cite{GatterbauerBHKP2007:Towards, FumarolaWBMH11:List}.

Google Sets \cite{googlesets} and WebTables \cite{webtables08}
extract web lists or tables based
on very specific list-related tags, such as {\tt <UL>},
{\tt<OL>}, {\tt<DL>}, and {\tt<TABLE>}.
IEPAD \cite{ChangL01:IEPAD}
identifies repetitive substrings as list patterns
in an encoded document/web page.
MDR \cite{LiuGZ03:MDR} is proposed to extract data records of the same type
based on the similarity between DOM trees, which is measured by edit distance.
Miao et al. \cite{MiaoTHSM09:TagPathClustering} introduce the visual signal
which is a vector describing tag path occurrence patterns.
Based on a similarity measure between visual signals, they perform clustering of tag
paths and rebuild the structure of data in the form of sets of tag paths.
Ventex \cite{GatterbauerBHKP2007:Towards} uses CSS2 visual box
model \cite{CCS2Box} instead of DOM trees to represent web pages,
and extract web tables based on several rules and heuristics.
HyLiEn \cite{FumarolaWBMH11:List} is a hybrid list extraction approach
as it not only utilizes the visual alignment of list items
but also takes advantage of structural feature (DOM tree).
And it claims a remarkable improvement compared with Ventex\cite{GatterbauerBHKP2007:Towards}.

In general,  category (c) and (d) are more practical,
as the (a) and (b) are not very robust against evolving or complicated web pages.
(d) often has better accuracy since web pages are rendered for visual presentations,
thus the visual models should be more expressive
and intuitive in representing a list or table.
Nevertheless, (c) is often more efficient in time as it does not need to render the page.

Although our system is inspired by some of approaches above
(e.g, we improve tag path clustering by Miao et al. \cite{MiaoTHSM09:TagPathClustering}
and use it in list extraction), it has several major differences:
%most of them cannot effectively address the top-$k$ extraction problem
%for several reasons:
\begin{itemize}
  \item \emph{Different goals}:
  The goal of previous approaches is to indiscriminatingly extract all lists
  or tables from a web page, while ours is to extract one specific list from a special
  kind of page while purging all other lists.
  \item \emph{The use of number $k$}:
  Our method takes advantage of the top-$k$ list size $k$,
  which is inferred from title. This is important to filter most of noise lists.
  \item \emph{Understanding semantics}:
  We understand each top-$k$ list as a list of instances with attributes
  with respect to the concept in the title.
  This is critical not only for identifying the correct list, but also for
  the future application of the extracted results.
  \item \emph{Time Efficiency}:
  On average, our system can process a page in about 0.1 second,
  which is significantly faster than the previous approaches 
  (Miao\cite{MiaoTHSM09:TagPathClustering}: $\approx 0.3s$;
  HyLiEn\cite{FumarolaWBMH11:List}: $4.2s$).
  This is key to scaling up the system to process billions of pages.
\end{itemize}

We first introduced the concept of ``top-$k$'' list
in a demo paper \cite{ZZX2012KDD}.
In that demo, we proposed the top-$k$ list extraction problem
and designed a prototype system.
We presented this prototype as a web GUI
on the project website \cite{list-extractor}.

One of the potential use of the extracted top-$k$ lists
is to act as background knowledge for a Q/A system\cite{cao2012approaches} to answer
top-$k$ related queries. To prepare for such knowledge, we need techniques
to aggregate a number of similar or related lists into a more comprehensive
one, which is in the space of top-k query processing.
One of the most well-known algorithms there is
TA (threshold algorithm) \cite{fagin2001optimal,guntzer2000optimizing}.
TA utilizes aggregation functions
to combine the scores of objects in different
lists and computes the top-$k$ objects based on the combined score.
Later, Chakrabarti et al. \cite{chakrabarti2006ranking} introduced the
OF (object finder) query,
which ranks top-$k$ objects in a search query
exploring the relationship between TOs (Target Objects, e.g., authors, products)
and SOs (Search Objects, e.g., papers, reviewers).
%OF differs from TA in that each TO can be related to multiple SOs,
%thus an additional aggregation of multiple scores within
%each list is needed.
Bansal et al.\cite{bansal2008ad} utilize a similar framework but
elevate terms at a higher level by taking advantage of a taxonomy,
in order to compute accurate rankings.
Angel et al.\cite{angel2009ranking} considered
the EPF (entity package finder) problem which is concerned with
associations, relations between different type of TOs.
Some of these techniques can serve as the basis for comprehensive integration of
top-$k$ lists.
%The output is a ranked list of a package which is a tuple of different type of objects.

%Unfortunately none of the above approaches can be applied directly to our problem,
%because in the approaches above, SOs (documents or reviews) are treated equally,
%whereas in our problem, lists from different sources (web pages) should be
%weighed differently.
%For example, lists from more popular web sites should be given more weight as
%their content are more trustable.
%In addition, lists that are exactly the same should be count only once
%as they may be reshipments from one source.

