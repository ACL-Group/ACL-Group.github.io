Thanks for the valuable comments. Below are our responses.
R1:
Our definition of “rumor” is modeled after Yang 2012, Jin 2013, Takahashi
2012, etc. However, it can be revised to “misinformation” or “false
statement” if necessary (See Wikipedia Rumor entry). 

Our framework doesn’t require the entire propagation tree to be seen,
although some visible structure of the propagation is helpful. The propagation
trees we experimented on are not necessarily complete. Many messages
are still spreading. Romero and Cheng worked on predicting the wide spread but
not the truthfulness of the information.

We compared our work with Castillo’s, which does include some useful simple
graph features like PROPAGATION_MAX_LEVEL.

R2: 
Although rumors are rare compared with all posts, they are very harmful and
raise a significant problem.

If skewed data is used as test set, the classifier which always labels
“false” will have unreasonably high accuracy. Near half-half data sets have
been used extensively in most previous work (Castillo 2011, Jin 2013, Yang
2012, Qazvinian 2011).

Calculation of doubt score and approval score is similar to that of average
sentiment score except we only consider the doubt words and approval words from
the respective lexicons.

R3:
We use Sina Weibo API to obtain an original message and all its reposts. 
Yang in Table 3 basically represents “(a) only old features”. Figure 8 (β=
1) and Table 3 (“Graph”) represent “(c) only graph feature”. We
didn’t include “(b) old features + graph feature” because we want to show
the impact of each individual new features and such an ablation style is also
used in recent work of Yang 2012.

For definition of “rumor”, please refer to R1. 

We have considered the source features (IS_VERIFIED, NUM OF FOLLOWERS, etc.) as
well as the text features (SENTIMENT, TOPIC TYPE, etc.). Previously,
information network has been largely applied to rumor source detection,
which is different from our problem.

We will tone down the wordings in the revised version.
