\section{Related Work}
\label{sec:related}
Previous work on false rumor detection for microblogging service (either
on Twitter or Weibo) has largely modeled the problem as a
binary classification problem. Hence the primary focus has been feature
selection. In the following, we will first discuss the definition of rumor.
Then, we will discuss features ever used in false rumor detection
in the literature.
After that, we will compare various classification methods and discuss
some graph kernels. We conclude this section with rumor source detection,
which is a related problem.

\subsection{Definition of Rumor}
Although there is no commonly accepted definition of rumor,
in many dictionaries \cite{website:OxfordDic} and previous literatures
\cite{difonzo2007rumor}, an important character of rumor is uncertainty.
In the previous work on false rumor detection for microblogging service,
there are different definitions of rumor and false rumor.
Some previous work \cite{qazvinian2011rumor} defines rumor according
to social psychology, where a rumor is defined as a statement
whose truth-value is unverifiable or deliberately false.
In their research, they use the word ``false rumor,''
``misinformation'' or ``disinformation'' to distinctively refer to 
rumors that turn out to be false eventually
\cite{castillo2011information,okazaki2013extracting}.
In our work, we follow a similar definition.

However, some other research \cite{yang2012automatic,mendoza2010twitter}
does not make a distinction between ``rumor'', ``false rumor'',
and ``misinformation,'' and use these terms interchangeably to mean false
statements. Some literatures \cite{takahashi2012rumor,jin2013epidemiological}
use the word ``rumor'' as the opposite term of ``news'' where they
consider ``news'' to be always true while ``rumor'' always false.
Most of these researchers come from Asia where ``rumor'' is generally carries
a negative connotation. Such cultural differences may be the reason why
there is no universally agreed upon definition for this term.

\subsection{Features for False Rumor Detection}
We divide existing features for false rumor detection into 4 types.

{\bf Linguistic Features}
pertain to the microblog message text \cite{qazvinian2011rumor}.
They range from simple features such as message length, punctuations,
letter case, whether URLs or hashtags are included
\cite{ratkiewicz2010detecting},
types of emoticons used and POS tags \cite{hassan2010s} to more
advanced semantic features such as sentiment scores
\cite{castillo2011information,qazvinian2011rumor} and
opinion words \cite{KwonCJCW13}.
Previous research \cite{yang2012automatic,KwonCJCW13}
shows that not all these features are effective for false rumor detection.
The most significant features among them are emoticons, opinion words and
sentiment scores (positive or negative).
In this paper, we used all the effective features,
plus a topic model feature and a search engine feature
(see \secref{sec:feature}).
%The topic model feature returns the topic distribution by LDA from
%the messages, while the search engine feature keeps the count of number of
%results returned by Google when searching for the message plus the keyword
%``rumor''.
These new semantic features were not previously attempted and they
turn out to be very useful.

{\bf User Features} describe the characteristics of an individual user.
These include the time and location of the account registration, gender
and age of the user, username and avatar \cite{MorrisCRHS12},
whether this is a verified account, number of friends,
number of followers, the description and the personal home page of the user,
number of messages post in the past, etc. \cite{castillo2011information}
These features are associated with the
original message to be classified in this paper. Furthermore, we
utilize a more refined user type than verification status.

{\bf Structural Features} pertain to either the message propagation
tree or the user friendship network. All existing work
\cite{castillo2011information,qazvinian2011rumor,mendoza2010twitter}
focuses on the numeric summary of such graph structures,
e.g., the total number of
nodes (i.e., messages or users) in the graph, maximum or average depth of
the graph, the degree of the root and the maximum or average degree of the
graph. Most of the work treats each node (either message or user)
equally and hence only derives such generic statistics.
Recently, some researchers \cite{jin2013epidemiological,bao2013new}
adapted the epidemiological
models to false rumor detection, and group users into population compartments
such as susceptible (S), infected (I) and skeptic (Z), etc. Users transit
from one compartment to another as they choose to or not to
repost a topical message. Structural features under these models are
slightly more refined as the they keep the counts for each compartment
separately. Our approach adopts some of these features but we advocate that
the actual graph structure of the message propagation is more explicit thus
important than the summary statistics. But since the graph can be very big,
we distinguish the messages posted by opinion leaders or normal users and
propose a way to simplify the graph so it can be used efficiently
in a graph kernel.

{\bf Temporal Features} look at the time stamps of the messages and compare them
with the time of the original post or the time when the author
was first registered \cite{castillo2011information}.
More advanced models use these times to detect sudden
spikes in the volume of responses or periodicity of such spikes
\cite{KwonCJCW13}.
Researchers also use time to calculate rates of
population change among the compartments in epidemiological models
\cite{jin2013epidemiological,KwonCJCW13}.
We use the time between a repost and the original message as a damping
factor to indicate the strength of the sentiments in the response.
Thus responses which are posted long after the original message have little
effect on false rumor identification.


In addition to the above 4 types, there are also miscellaneous features like
type of software client used to post a message, location from which a message
is posted, etc.

\subsection{Classification Methods}
Most of existing research uses common supervised learning approaches such as
decision tree, random forest, Bayes networks and support vector machine (SVM).
Castillo et al. \cite{castillo2011information}
reported that different methods produce comparable results
but decision tree is the best for 608 topics
(equivalent to our original messages), with a classification
accuracy of 89\% under 3-fold cross validation. More recently,
Kwon et al. \cite{KwonCJCW13}
considered random forest to outperform other methods with 11 features on
102 topics each with at least 60 tweets. Although they reported 90\% accuracy
under 2-fold cross validation, their data set is relatively small.
Our paper proposes a hybrid SVM classifier which combines
a random walk graph kernel with normal RBF kernel using 23 features including
8 new features. Our experiments show that its performance is superior against
the state-of-the-art methods and features used by Castillo et al. and
Yang et al.

Okazaki et al.\cite{okazaki2013extracting} instead used unsupervised
approach for extracting false information after the 2011 Japan
earthquake and tsunami.
They designed a set of linguistic patterns for correction or refutation
statements, extracted the text passages that match the correction patterns
and clustered them into different topics. At last, they selected a
representative passage for each topic as the rumor.

Besides that, research that adapts epidemiological models
\cite{jin2013epidemiological,bao2013new}
to false rumor detection
generally define ordinary differential equations (ODEs) on the rate
of user population changes and fit non-linear functions to the data.
By observation of the function curves of different population compartment,
they then manually design a classification function to tell false rumors from
others.

\subsection{Graph Kernels}
Traditional SVM classifiers are based on the data that can be
represented as simple, flat vectors. However, it is not always reasonable
as many objects in the real world are structured by
nature\cite{gartner2003survey}.
For this reason, people have developed ways to incorporate complex structures
such as trees and graphs as the kernels of SVM.
In this paper, as proposed in \secref{sec:random},
although the propagation pattern of a message is tree-structured,
we use graph kernel to calculate the similarity of two propagation trees.

One kind of kernel that can be used in graph is convolution kernel
\cite{haussler1999convolution}. Convolution kernel assumes that one
object can be decomposed into different parts and the similarity of
two objects can be computed by combining the similarity of parts from
two objects. Convolution kernel provides a generic way to construct
kernel for discrete structured data and can be used in many different
problems. One application of convolution kernel on tree structures is
subset tree (SST) kernel\cite{collins2002new}. SST decomposes syntax
tree into different subset trees and the similarity of two trees can be
computed by the similarity of their subset trees. Although convolution
kernel is very general, it remains a difficult problem to find a
reasonable method to decompose an object into different parts.

Graph kernel can be defined on all paths or shortest paths
\cite{borgwardt2005shortest}. The all-path kernel is defined as the sum
over all kernels on all pairs of paths from two graphs. However,
computing the all-path kernel is time-consuming because
finding all paths in a graph is NP-hard.
Conversely, computing shortest path in a graph can be solved in
polynomial time using classic algorithms such as Dijkstra
\cite{dijkstra1959note} and Floyed-Warshall
\cite{floyd1962algorithm,warshall1962theorem}.
Given a pair of graphs, we can first compute the shortest-path
graph for both graphs. Then we compute pair-wise kernels from all
pairs of edge walks of length 1, each coming from one of the short-path graphs.
The shortest-path graph kernel of the pair of graphs
is defined as the sum of all these pair-wise kernels.
The shortest-path graph kernel
is positive definite and can be computed efficiently ($O(n^4)$).
However, it is inappropriate for computing the similarity of
propagation trees in our problem
because the shortest-path graph kernel only consider the
shortest path of one graph, which loses information in the propagation tree.

Random walk graph kernel was first proposed by G{\"a}rtner
\cite{gartner2003graph}. The idea of random walk graph kernel is, given a
pair of graphs, to first perform random walks on both simultaneously,
then to count the number of matching walk paths.
This procedure is equivalent to
doing random walks on the direct product of two graphs
\cite{vishwanathan2010graph}. Random walk graph kernel is applicable to
graphs with labeled nodes and edges and have considered the whole graph
when computing similarity, which is appropriate for propagation trees.
However, the original random walk graph kernel can not deal with
continuously labeled graphs \cite{neuhaus2006random}. For this reason,
an extension of the original random walk kernel has been proposed
\cite{borgwardt2005protein}. The idea is to calculate the similarity
rather than equality between two walks.
The extended random walk graph kernel can then be applied to our problem.

\subsection{Rumor Source Detection}
Some previous work \cite{shah2011rumors,seo2012identifying}
focuses on rumor propagation through social network. They try to use
graph theory to detect rumors and find the source of rumors.
A social network is modeled as a directed graph where each vertex
represents an individual person and each edge represents information
flow between two individuals. Some of the nodes are designated as
``monitor nodes'' where data that they receive may be observed.
Given that messages are sent from some of the nodes and get propagated
through the network, rumors can be detected and their sources can be
recognized by observing the data received at the monitor nodes.



%\subsection{Linguistic patterns}
%Reponses to a message often carry user's approval or refutation
%of the original message. As such, sentiment analysis and opinion mining
%are viable tools in rumor detection \cite{okazaki2013extracting,KwonCJCW13}.
%\KZ{cite a few more papers in this category?}
%Okazaki et al. focus on how to
%extract false information after the 2011 East Japan Earthquake and
%Tsunami Disater \cite{okazaki2013extracting}. They assume that misinformation
%would be identified or refuted by others and thus design a set of
%linguistic patterns for error correction or refutation statements.
%Then the text passages that match to the correction patterns were extracted
%and clustered into different topics. At last, they select a representative
%passage for each topic as one rumor. Their work mainly focus on expressions
%and assume the misinformation will be corrected or refuted,
%which is not always the case. Our work is related in the sense
%that the sentiment of approval and refutation are calculated for the
%graph kernel. However, we also consider the pattern of propagation
%and other features in addition.
%
%\subsection{Epidemiological model}
%Because the propagation of rumor is analogous to the spread of an epidemy,
%several researchers have adapted epidemiological model to rumor detection.
%Jin et al. use an epidemiological model, specifically, compartmental
%population model, to characterize information cascades
%in twitter resulting from both news and rumors \cite{jin2013epidemiological}.
%They discovered SEIZ, where the
%the letters stands for susceptible (S), exposed (E), infected (I) and
%skeptic (Z), works better at modeling the diffusion of news and rumors.
%%They define a parameter $R_{SI}$ to classify rumor and news.
%Bao et al. \cite{bao2013new} propose a similar SPNR model to capture
%rumor spreading in Sina Weibo.
%In both works, differential equations are used to model
%the rates of change in different population compartments. And the parameters
%in the model are obtained by fitting non-linear functions to the observed data.
%Then by observation authors propose a function on these parameters
%to classify rumors from news and other content. The drawbacks of these models
%are i) accurate sizes the population compartments are hard to obtain and
%can only be estimated; and ii) final classification metric is chosen
%empirically and not automatically.
%Our work is related since we make use of the
%propagation pattern as well.
%But instead of the theory of epidemiology, we use a graph kernel to
%calculate the similarity of two propagation trees in a machine learning
%approach.
%
%\subsection{Classification by Machine learning}
%In this area, various types of features have been explored
%on different corpuses for identifying rumors.
%Qazvinian et al. propose three categories of features: content-based,
%network-based and microblog-specific memes \cite{qazvinian2011rumor}.
%They build Bayes classifiers as high level features and learn a
%linear function that maximizes the log-likelihood for these classifiers
%to identify rumors as well as user endorsements of a rumor.
%For content-based features, they follow \cite{hassan2010s} and
%present features with 2 different patterns: lexical patterns and
%part-of-speech patterns. For network-based features,
%they focus on whether the users have a history of posting or
%re-tweeting rumors. For microblog-specific mems,
%they follow \cite{ratkiewicz2010detecting} and extracted the hashtags
%and URLs.
%
%Mendoza et al. analysed the propagation of confirmed truths and
%false rumors related with earthquake on Twitter during the 2010 earthquake
%in Chile\cite{mendoza2010twitter}. They find rumors tend to be questioned
%more than news by the Twitter community as they propagate.
%
%Castillo et al. explore four types of features to estimate information
%credibility\cite{castillo2011information}: message-based features,
%user-based features, topic-based features and propagation-based features.
%They tried a lot of learning schemes including SVM, decision trees,
%decision rules and Bayes networks on these features and the best turns out
%to be J48 decision tree. Besides, they analyze the decision tree and
%list the most valuable features for this work.
%In China, Yang et al. study the automatic detection of rumor on
%Sina Weibo \cite{yang2012automatic}. They consider features that have
%been proposed by \cite{qazvinian2011rumor} as well as two new features:
%the location of event and the client program. They build an SVM classifier
%using these features on the data set of Sina Weibo.
%
%Our work is similar to these works in that our primary vehicle
%is an SVM classifier. Some of those features mentioned above
%are also included in our classifier.
%However, this paper presents several more powerful features including
%the random walk graph kernel which have not been attempted before.
%
%


