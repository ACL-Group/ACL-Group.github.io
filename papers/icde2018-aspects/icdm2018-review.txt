--========  Review Reports  ========--

The review report from reviewer #1:

*1: Is the paper relevant to ICDM?
  [_] No
  [X] Yes
  
*2: How innovative is the paper?
  [_] 6 (Very innovative)
  [X] 3 (Innovative)
  [_] -2 (Marginally)
  [_] -4 (Not very much)
  [_] -6 (Not at all)
  
*3: How would you rate the technical quality of the paper?
  [_] 6 (Very high)
  [X] 3 (High)
  [_] -2 (Marginal)
  [_] -4 (Low)
  [_] -6 (Very low)
  
*4: How is the presentation?
  [_] 6 (Excellent)
  [X] 3 (Good)
  [_] -2 (Marginal)
  [_] -4 (Below average)
  [_] -6 (Poor)
  
*5: Is the paper of interest to ICDM users and practitioners?
  [X] 3 (Yes)
  [_] 2 (May be)
  [_] 1 (No)
  [_] 0 (Not applicable)
  
*6: What is your confidence in your review of this paper?
  [_] 2 (High)
  [X] 1 (Medium)
  [_] 0 (Low)
  
*7: Overall recommendation
  [_] 6: must accept (in top 25% of ICDM accepted papers)
  [X] 3: should accept (in top 80% of ICDM accepted papers)
  [_] -2: marginal (in bottom 20% of ICDM accepted papers)
  [_] -4: should reject (below acceptance bar)
  [_] -6: must reject (unacceptable: too weak, incomplete, or wrong)
  
*8: Summary of the paper's main contribution and impact
  This paper provides a framework for extracting review aspects automatically from online customer reviews

*9: Justification of your recommendation
  The paper provides good background for significance of the problem; the approach is an engineering one using existing components but is well motivated. The empirical evaluation is very reasonable.

*10: Three strong points of this paper (please number each point)
  1. Solution to well motivated problem
2. code/data and example website are provided
3. Evaluation is extensive and well structured

*11: Three weak points of this paper (please number each point)
  1. An issue is whether an engineered solution using available components is innovative enough.
2. lots of parameters are needed making fair evaluation difficult
3. the problem solved "automation of aspect extraction" is just a small incremental step relative to existing methods

*12: Is this submission among the best 10% of submissions that you reviewed for ICDM'17?
  [X] No
  [_] Yes
  
*13: Would you be able to replicate the results based on the information given in the paper?
  [_] No
  [X] Yes
  
*14: Are the data and implementations publicly available for possible replication?
  [_] No
  [X] Yes
  
*15: If the paper is accepted, which format would you suggest?
  [X] Regular Paper
  [_] Short Paper
  
*16: Detailed comments for the authors
  

Table V: should the last column be "average number of words" not "no. of works"?

some minor typos:
"obtain the final pured aspect clusters" should be 
"obtain the final pure aspect clusters"?

"Note that we don't concern about the number" should be
"Note that we don't concern ourselves about the number"


========================================================
The review report from reviewer #2:

*1: Is the paper relevant to ICDM?
  [_] No
  [X] Yes
  
*2: How innovative is the paper?
  [_] 6 (Very innovative)
  [_] 3 (Innovative)
  [X] -2 (Marginally)
  [_] -4 (Not very much)
  [_] -6 (Not at all)
  
*3: How would you rate the technical quality of the paper?
  [_] 6 (Very high)
  [_] 3 (High)
  [X] -2 (Marginal)
  [_] -4 (Low)
  [_] -6 (Very low)
  
*4: How is the presentation?
  [_] 6 (Excellent)
  [_] 3 (Good)
  [X] -2 (Marginal)
  [_] -4 (Below average)
  [_] -6 (Poor)
  
*5: Is the paper of interest to ICDM users and practitioners?
  [_] 3 (Yes)
  [X] 2 (May be)
  [_] 1 (No)
  [_] 0 (Not applicable)
  
*6: What is your confidence in your review of this paper?
  [_] 2 (High)
  [_] 1 (Medium)
  [X] 0 (Low)
  
*7: Overall recommendation
  [_] 6: must accept (in top 25% of ICDM accepted papers)
  [_] 3: should accept (in top 80% of ICDM accepted papers)
  [X] -2: marginal (in bottom 20% of ICDM accepted papers)
  [_] -4: should reject (below acceptance bar)
  [_] -6: must reject (unacceptable: too weak, incomplete, or wrong)
  
*8: Summary of the paper's main contribution and impact
  In this paper, the authors propose an automatic and unsupervised framework, ExtRA, for extracting the best aspect terms from massive amount of textual user reviews. ExtRA first performs topic modeling on sentence clusters to generate potential aspect topics, and clusters the potential topics to obtain the final pured aspect clusters. ExtRA designs two ranking metrics respectively for pruning aspect clusters and ranking candidate aspect terms, in which it represents aspect clusters with vectors (AspVec) in a shared space with aspect terms. Finally, ExtRA can then extract aspect words and phrases by simply computing the similarities between each AspVec and all the candidate aspect terms. Experimental results on reviews gathered from various e-commerce websites showed that compared with LDA and other topic modeling methods, ExtRA can achieve better accuracy.

*9: Justification of your recommendation
  Advantage:
1.        The experiment is extensive. The paper has three main experiments. They analyze methods for obtaining sentence vectors and compare ExtRA with a number of baselines including the state-of-the-art approaches in the end-to-end aspect extraction task. At last, they also present an end-to-end demo system based on ExtRA.
2.        The vector representation of each aspect cluster is reasonable and meaningful. It takes both the segment and the duplicate of words into consideration. Besides, vector representation can also help to find the most adjacent words.
Disadvantage:
1.        When ExtRA searches Q-Nearest words and phrases for each aspect cluster, it uses all words and phrases that selected from corpus. Maybe, after sentence and topic cluster, each cluster can have a words and phrases candidate set. It will use less time to select aspect words and phrases from candidate set. Besides, ExtRA only selects the nearest words and phrases to the cluster, it don’t considers the distance to other clusters.
2.        To find the aspect cluster, ExtRA first cluster the sentence and then use topic model for each cluster. Finally, it clusters these topics to form aspect clusters. What’s the difference between it and use topic model directly. The significance to cluster the sentence first isn’t explained, it seems complicated and redundant.
3.        Some symbol expressions for ExtRA are not consistent or lack of explanation. For example, the significance score of word w in aspect cluster fi(w) and ui(w) . The weight of word w in each topic vt(w).
4.        The dataset is not convincing. The data they use in experiment is gathered from various e-commerce websites, and annotate ground truth aspect words by themself. They don’t use the published dataset.

*10: Three strong points of this paper (please number each point)
  1.        The experiment is extensive. The paper has three main experiments. They analyze methods for obtaining sentence vectors and compare ExtRA with a number of baselines including the state-of-the-art approaches in the end-to-end aspect extraction task. At last, they also present an end-to-end demo system based on ExtRA.
2.        The vector representation of each aspect cluster is reasonable and meaningful. It takes both the segment and the duplicate of words into consideration. Besides, vector representation can also help to find the most adjacent words.

*11: Three weak points of this paper (please number each point)
  1.        When ExtRA searches Q-Nearest words and phrases for each aspect cluster, it uses all words and phrases that selected from corpus. Maybe, after sentence and topic cluster, each cluster can have a words and phrases candidate set. It will use less time to select aspect words and phrases from candidate set. Besides, ExtRA only selects the nearest words and phrases to the cluster, it don’t considers the distance to other clusters.
2.        To find the aspect cluster, ExtRA first cluster the sentence and then use topic model for each cluster. Finally, it clusters these topics to form aspect clusters. What’s the difference between it and use topic model directly. The significance to cluster the sentence first isn’t explained, it seems complicated and redundant.
3.        Some symbol expressions for ExtRA are not consistent or lack of explanation. For example, the significance score of word w in aspect cluster fi(w) and ui(w) . The weight of word w in each topic vt(w).
4.        The dataset is not convincing. The data they use in experiment is gathered from various e-commerce websites, and annotate ground truth aspect words by themself. They don’t use the published dataset.

*12: Is this submission among the best 10% of submissions that you reviewed for ICDM'17?
  [X] No
  [_] Yes
  
*13: Would you be able to replicate the results based on the information given in the paper?
  [X] No
  [_] Yes
  
*14: Are the data and implementations publicly available for possible replication?
  [X] No
  [_] Yes
  
*15: If the paper is accepted, which format would you suggest?
  [X] Regular Paper
  [_] Short Paper
  
*16: Detailed comments for the authors
  In this paper, the authors propose an automatic and unsupervised framework, ExtRA, for extracting the best aspect terms from massive amount of textual user reviews. ExtRA first performs topic modeling on sentence clusters to generate potential aspect topics, and clusters the potential topics to obtain the final pured aspect clusters. ExtRA designs two ranking metrics respectively for pruning aspect clusters and ranking candidate aspect terms, in which it represents aspect clusters with vectors (AspVec) in a shared space with aspect terms. Finally, ExtRA can then extract aspect words and phrases by simply computing the similarities between each AspVec and all the candidate aspect terms. Experimental results on reviews gathered from various e-commerce websites showed that compared with LDA and other topic modeling methods, ExtRA can achieve better accuracy.

Advantage:
1.        The experiment is extensive. The paper has three main experiments. They analysis methods for obtaining sentence vectors and compare ExtRA with a number of baselines including the state-of-the-art approaches in the end-to-end aspect extraction task. At last, they also present an end-to-end demo system based on ExtRA.
2.        The vector representation of each aspect cluster is reasonable and meaningful. It takes both the segment and the duplicate of words into consideration. Besides, vector representation can also help to find the most adjacent words.
Disadvantage:
1.        When ExtRA searches Q-Nearest words and phrases for each aspect cluster, it uses all words and phrases that selected from corpus. Maybe, after sentence and topic cluster, each cluster can have a words and phrases candidate set. It will use less time to select aspect words and phrases from candidate set. Besides, ExtRA only selects the nearest words and phrases to the cluster, it don’t considers the distance to other clusters.
2.        To find the aspect cluster, ExtRA first cluster the sentence and then use topic model for each cluster. Finally, it clusters these topics to form aspect clusters. What’s the difference between it and use topic model directly. The significance to cluster the sentence first isn’t explained, it seems complicated and redundant.
3.        Some symbol expressions for ExtRA are not consistent or lack of explanation. For example, the significance score of word w in aspect cluster fi(w) and ui(w) . The weight of word w in each topic vt(w).
4.        The dataset is not convincing. The data they use in experiment is gathered from various e-commerce websites, and annotate ground truth aspect words by themself. They don’t use the published dataset.


========================================================
The review report from reviewer #3:

*1: Is the paper relevant to ICDM?
  [_] No
  [X] Yes
  
*2: How innovative is the paper?
  [_] 6 (Very innovative)
  [_] 3 (Innovative)
  [_] -2 (Marginally)
  [X] -4 (Not very much)
  [_] -6 (Not at all)
  
*3: How would you rate the technical quality of the paper?
  [_] 6 (Very high)
  [_] 3 (High)
  [_] -2 (Marginal)
  [X] -4 (Low)
  [_] -6 (Very low)
  
*4: How is the presentation?
  [_] 6 (Excellent)
  [_] 3 (Good)
  [_] -2 (Marginal)
  [X] -4 (Below average)
  [_] -6 (Poor)
  
*5: Is the paper of interest to ICDM users and practitioners?
  [_] 3 (Yes)
  [X] 2 (May be)
  [_] 1 (No)
  [_] 0 (Not applicable)
  
*6: What is your confidence in your review of this paper?
  [X] 2 (High)
  [_] 1 (Medium)
  [_] 0 (Low)
  
*7: Overall recommendation
  [_] 6: must accept (in top 25% of ICDM accepted papers)
  [_] 3: should accept (in top 80% of ICDM accepted papers)
  [_] -2: marginal (in bottom 20% of ICDM accepted papers)
  [X] -4: should reject (below acceptance bar)
  [_] -6: must reject (unacceptable: too weak, incomplete, or wrong)
  
*8: Summary of the paper's main contribution and impact
  This paper attempts to extract different aspects for reviews via text analysis.

*9: Justification of your recommendation
  Although it addresses an interesting problem, it has overlooked recent progress along this direction and the methodology lacks innovation.

*10: Three strong points of this paper (please number each point)
  S1: The paper is addressing an interesting and important problem.

*11: Three weak points of this paper (please number each point)
  W1: This problem is not well defined. Fig. 1 is a misleading motiving example, as the later part has not addressed the rating issue, and the output does not contain any aspect rating.
W2: This paper has ignored very important related work; some examples are given in detailed comments
W3: The proposed methodology is ad-hoc and lacks innovation.

*12: Is this submission among the best 10% of submissions that you reviewed for ICDM'17?
  [X] No
  [_] Yes
  
*13: Would you be able to replicate the results based on the information given in the paper?
  [X] No
  [_] Yes
  
*14: Are the data and implementations publicly available for possible replication?
  [_] No
  [X] Yes
  
*15: If the paper is accepted, which format would you suggest?
  [_] Regular Paper
  [X] Short Paper
  
*16: Detailed comments for the authors
  D1: Some important related work is missing:
-Derek Wu and Hongning Wang. ReviewMiner: An Aspect-based Review Analytics System. The 40th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR 2017)
-Hongning Wang, Yue Lu and ChengXiang Zhai. Latent Aspect Rating Analysis without Aspect Keyword Supervision. The 17th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD'2011), P618-626, 2011.

D2: It is difficult to understand why and how topic model is performed after sentences are already clustered in Stage 1.

D3: The datasets used are extremely small, especially for the vocabulary size.

========================================================
