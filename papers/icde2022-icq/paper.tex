\documentclass[conference]{IEEEtran}
\usepackage[numbers]{natbib}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
%\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{enumitem}
\usepackage{xcolor}
\usepackage{bm}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

\usepackage{times}
\usepackage{soul}
\usepackage{url}
\usepackage{microtype}
\usepackage[hidelinks]{hyperref}
\usepackage[utf8]{inputenc}
\usepackage{caption}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{courier}
\usepackage{color}
\usepackage{amsmath,amsfonts,amssymb,amsthm,amsopn}
\usepackage{epsfig}
\usepackage{booktabs}
\usepackage{array}
\usepackage{multicol}
\usepackage{threeparttable}
\usepackage{epstopdf}
\usepackage{listings}
\usepackage{multirow}
\usepackage{xcolor}
\usepackage{subcaption}

\usepackage{tabularx}
\newcommand{\ft}[1]{\textsc{#1}}
\newtheorem{example}{Example}
\newcommand{\secref}[1]{Section \ref{#1}}
\newcommand{\figref}[1]{Figure \ref{#1}}
\newcommand{\eqnref}[1]{Eq. (\ref{#1})}
\newcommand{\tabref}[1]{Table \ref{#1}}
\newcommand{\exref}[1]{Example \ref{#1}}
\newcommand{\cut}[1]{}
\newcommand{\LL}{\mathcal{L}}
%\newcommand{\citealp}[1]{\citeauthor{#1}~\shortcite{#1}}
\newcommand{\KZ}[1]{\textcolor{blue}{Kenny: #1}}
%\newcommand\BibTeX{B\textsc{ib}\TeX}
\newcommand{\sgn}{\text{sgn}}


\begin{document}

%\title{Conference Paper Title*\\
\title{ICQ: Detecting and Explaining Statistical Biases in Natural Language Reasoning}
%{\footnotesize \textsuperscript{*}Note: Sub-titles are not captured in Xplore and
%should not be used}
%\thanks{Identify applicable funding agency here. If none, delete this.}
%}
\iffalse
\author{\IEEEauthorblockN{1\textsuperscript{st} Given Name Surname}
\IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
\textit{name of organization (of Aff.)}\\
City, Country \\
email address or ORCID}
\and
\IEEEauthorblockN{2\textsuperscript{nd} Given Name Surname}
\IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
\textit{name of organization (of Aff.)}\\
City, Country \\
email address or ORCID}
\and
\IEEEauthorblockN{3\textsuperscript{rd} Given Name Surname}
\IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
\textit{name of organization (of Aff.)}\\
City, Country \\
email address or ORCID}
\and
\IEEEauthorblockN{4\textsuperscript{th} Given Name Surname}
\IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
\textit{name of organization (of Aff.)}\\
City, Country \\
email address or ORCID}
\and
\IEEEauthorblockN{5\textsuperscript{th} Given Name Surname}
\IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
\textit{name of organization (of Aff.)}\\
City, Country \\
email address or ORCID}
\and
\IEEEauthorblockN{6\textsuperscript{th} Given Name Surname}
\IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
\textit{name of organization (of Aff.)}\\
City, Country \\
email address or ORCID}
}
\fi
\maketitle

\begin{abstract}
Recent work has suggested that many natural language 
reasoning datasets contain spurious statistical cues that
may be learned and exploited by NLP models trained on such
data.  
%However, none of the work has been able to
%easily pinpoint what these cues are. 
%Inspired by black-box test in software engineering,
However, no existing work was able to pinpoint what these cues 
really are or provide evidence of a model ``cheating'' on 
a particular cue.
%To discover the potential weakness in the models, some human-designed 
%stress tests have been proposed but they are expensive to create 
%and do not generalize to arbitrary models. 
In this paper, we propose a framework called ICQ (I-See-Cue), 
which automatically identifies spurious linguistic features from 
any multiple-choice NLR dataset, creates stress cases with the
spurious features neutralized, and finally does blackbox testing
on a model to see if it is biased by these spurious features 
and further explain why it does so. Our provide comprehensive
case studies on 4 popular NLR tasks and 3 pretrained language
models adapted to these tasks. 
\end{abstract}
\input{intro}
\input{preliminary}
\input{approach}
\input{experiment}
\input{related}
\input{conclusion}
\bibliographystyle{IEEEtran}                 
\bibliography{AAAI21} 
\begin{IEEEkeywords}
component, formatting, style, styling, insert
\end{IEEEkeywords}

\end{document}
