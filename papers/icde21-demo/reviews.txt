Paper ID1105
Paper TitleICQ: Visualizing Statistical Biases in Discriminative Text Inference Tasks and Models
Track NameDemo

Reviewer #1
Questions
1. Relevant for ICDE
Yes
2. Originality of the Demo
Interesting But Not Too Novel
3. Overall Rating
Weak Accept
4. Strong Points (please number S1, S2, ...)
S1: The paper can mostly be understood even without in-depth knowledge and the different figures illustrate the idea of the framework well.
S2: The presented framework may lead to improvements in the robustness in the area of NLI and may also help improving the selection of test and training data.
S3: The set of linguistic features, that the framework uses for analysis, is chosen well. It mostly contains features that are relevant and can be extended.
S4: The framework provides data-sets and prediction models as well as the possibility to use one's own data-set or model. Furthermore, the user is allowes to select the set of features he wants to use. This enables the user to evaluate different sets of features independently.
5. Weak Points (please number W1, W2, ...)
W1: The use case should have been described in more detail so that the reader can decide more easily whether or not the framework could be a solution for his problem.
W2: Some features (especially NER) should have been described in more detail. Here, it is not clear what is measured and why.
6. Detailed Comments
The idea of the presented framework is promising and a first step to the improvement of natural language inference. However, it is just a first step and further development and evaluation of different features will be needed in the long term.

Further remarks:
- You wonder weather the feature even influences the model because even huge overlaps do not necessarily indicate a relation. If the text is prefiltered before measuring the overlap (e.g. by removing words like 'the', 'is' or 'a'), a high overlap should be more robust and could therefore be an indicator. Wouldn't that be a more typical real world application of the Overlap feature?
- The paper would benefit from careful proof-reading and grammar checks.
- For the sake of readability, the figures should be placed at the beginning of the page and not within the text. (Especially Fig. 2 which also would benefit from a detailed caption)
Reviewer #2
Questions
1. Relevant for ICDE
Yes
2. Originality of the Demo
Substantially New Idea
3. Overall Rating
Weak Reject
4. Strong Points (please number S1, S2, ...)
S1: This paper opens up an interesting set of discussions about how to introspect better about the datasets we have, as we blindly shove them into ML models.

S2: This paper provides an implementation to introspect over NLP data used. A nice example, in an important sub-area.

S3: 12 datasets and 3 models. They have covered all of the biggest approaches.

5. Weak Points (please number W1, W2, ...)
The paper sells the wrong thing. I'm not actually convinced that the filtering is good, and creates a better model. Perhaps the "biases" found arn't necessarily biases, but actual differences. Over-population of data is bad if it does not reflect the real world, or is an artifact of collection. But if it's actually a reflection of reality (and not a narrow view of it, then it's ok. So what you really have here is a "flag" of possible areas where bias might exist. Or, you have a way to profile datasets so that ML users can be more aware of the data they are feeding into the system. This isn't the same. It depends on what you want out of your system whether you remove them or not!
6. Detailed Comments
The demo itself is a bit uninspiring. No one wants to watch code run. How are you going to get your viewer involved. How will they "feel" the problems you are talking about?

Figure 3 is the wrong type of chart. The datasets are not connected, so the lines across them shouldn't be either. Try a stacked bar chart.

Figures 4 and 5 could be both compressed... and need more explanation in the caption so they can be better understood more quickly.
Reviewer #3
Questions
1. Relevant for ICDE
No
2. Originality of the Demo
Interesting But Not Too Novel
3. Overall Rating
Reject
4. Strong Points (please number S1, S2, ...)
I did not detect any
5. Weak Points (please number W1, W2, ...)
Poorly written paper; it does not properly convey the problem, it does not properly characterize the crucial notions

It is not clear what kind of bias the authors are talking about. They are not properly characterized. Nor the consequences of those bias.

In the end, not clear what's going on inside the system

The data aspects and data-related tasks are not clear
6. Detailed Comments
See 5

