Thanks for your constructive and careful comments. Here are the replies to the opportunities for improvement.

To reviewer #2:

Response to O1: the significance tests.
R1: We conduct t significance test between the best score and the second-best score for the main results, the improvement is strongly significant as p<0.001. We conduct t significance test between the results of the whole model and the ablation model, the decline is statistically significant as p<0.01. We will add the significance tests in the paper.

Response to O2: the choice of attention.
R2: We choose the attention mechanism in our paper because: (1) The idea of regarding the attention score as the weight of each piece of news and computing the weighted-sum as the final representation of the current session is consistent with the item-based recommendation, where we use the clicked articles to model the user under the anonymous user login scenario. Many other session-based recommendation approaches like STAMP, SGNNHN also adopt this kind of mechanism. (2) This kind of weighted-sum method is quite simple, so it's convenient for us to plug in our positive implicit feedback module and user representation module using the start time of the session. It's also making our component easy to plug into other GNN network.
Why we don't use multi-head attention: Actually one of our baselines SASRec is using multi-head attention mechanism as we described in the paper, however, the advantage of multi-head attention is not obvious (comparing SASRec with STAMP), mainly because the limited number of click articles within a session (since anonymous news reading sessions are short by nature)
will make it hard to capture the relations between articles.

Response to O3: the code.
R3: Sorry for the unavailable anonymous link, we didn't realize that changing the name of git branch would make the link stop updating, now the link is recovered. 


To reviewer #3:

Response to O1: all characteristics have been mentioned.
R1: We admit there are discussions about the active time, exposed but not clicked items signals before, however, as we discussed in our related work, their work is not suitable for anonymous users. The Trivago 2019 dataset is for the e-commerce domain while for our work, we care about news recommendation under the session-based scenario, where the news articles are published incrementally over time. Exploiting the temporal information with explainable physical meaning is also a part of our contribution. This paper is the first time to introduce all these signals in session-based news recommendation.

Response to O2: notions not in line with literature.
R2: It's true that clicks are usually considered implicit feedback, but in most of the previous work, “clicks” usually indicate a “like” or a positive vote from the user. We insist that this is not true because the user could click an article after being fooled by the title, which does not mean that this user likes this article. Also, many other negative sampling strategies didn't consider the publish time of articles. The way we consider these signals is more implicit than all the previous work.


To reviewer #4

Response to O1: the attention mechanism.
R1: Our work aims to bring attention to the news recommendation for anonymous users by leveraging different kinds of implicit feedback, and the attention mechanism is not the key part of our paper, which is just one of the approaches to fuse our implicit feedback. From the experiments, we can find an explainable physical meaning of the neutral feedback, also, we achieve a better overall trade-off between the precision and diversity and cold-start problem, which is very practical for real-world application.

Response to O2: the overall performance gain.
R1: Actually the improvements are quite significant for recommendation precision (HR and NDCG) even on Globo dataset. The diversity of our method is not as good as SASRec and GRU4Rec in Globo but the HR of SASRec is only 0.1409 while for us it is 0.1852, because there is a trade-off between the precision and diversity. On the other hand, as we discussed in paper, when ILD/unEXP is over a threshold (like 0.80), it’s hard for users to distinguish the difference, thus the ILD/unEXP score of our model is bearable. To further investigate the trade-off ability of our method, we can use F1-score (also called harmonic mean) to measure it, which is computed as: F1-(P*D)=2*P*D/(P+D). P means the precision, including HR and NDCG, and D is the diversity, including ILD and unEXP. The F1 results of overall performance are listed as follows. Note the following are not new results, but merely a different perspective of the existing results we have got before.

4 scores are: 
F1-(HR*ILD) | F1-(NDCG*ILD) | F1-(HR*unEXP) | F1-(NDCG*unEXP)
Dataset Adressa
SGHH-HN | 0.2229 | 0.1053 | 0.2217 | 0.1050
STAMP --- | 0.2233 | 0.1076 | 0.2101 | 0.1044
Ours ------ | 0.2752 | 0.1339 | 0.2763 | 0.1342
Dataset Globo
SGHH-HN | 0.2459 | 0.1148 | 0.2461 | 0.1148
STAMP --- | 0.2432 | 0.1284 | 0.2455 | 0.1291
Ours ------ | 0.3054 | 0.1690 | 0.3032 | 0.1684
Dataset MIND
SGHH-HN | 0.0703 | 0.0241 | 0.0678 | 0.0238
STAMP --- | 0.0711 | 0.0296 | 0.0708 | 0.0295
Ours ------ | 0.0938 | 0.0412 | 0.0937 | 0.0412

We list the score of strong baselines and ours (SASRec and GRU4Rec have even lower score due to their low precision), 
and we can add the full table in our final version.
From the result, we can see that our method outperforms all the baselines on three datasets and the four F1-scores, 
which indicates that our model can better alleviate the trade-off between precision and diversity.

Response to O3: ablation study.
R3: In ablation study, the random setting means only replacing our negative sampling strategy based on negative feedback with the random sampling method, but keeping our other modules the same, which means in the random sampling method, our positive module and neutral module are still working. According to the ablation of "pos" and "neutral", the decline shows the effectiveness of "pos" and "neutral module". As for the negative module, the results show it also works because the whole model is better than the random sampling one. The improvements of the negative module are relatively small, mainly because we reconstruct the "exposed but not clicked" list according to the publishing time for Adressa and Globo dataset, the signal is quite weak and very implicit. And for MIND dataset, the drop after ablating the negative module is more significant and consistent, because the "exposed but not clicked" list is explicitly provided in MIND dataset.

2. Please provide answers to the following questions for each of the reviews separately, indicating whether: (a) They were constructive (i.e., helpful to improve your paper); (b) They were professional (e.g., language was polite). Here are the instructions we asked our reviewers to follow to ensure constructive and professional reviews: https://docs.google.com/document/d/1NXgppEWth1OFXx1vEois5feAVicc6HzkjllrTHvBQ5s/edit?usp=sharing. Please provide specific responses to this question keeping these guidelines in mind, and identifying technical remarks from the reviewers that are not constructive and/or professional. Please avoid generic remarks here since they tend not to be actionable. These will be visible to the area chairs, but not the reviewers, during the discussion and evaluation phase.
To reviewer #2: (a) yes (b) yes
To reviewer #3: (a) yes (b) yes, but suggested a dataset that is not relevant to our scenario
To reviewer #4: (a) yes (b) yes, but was mistaken to think that our overall results are not significant and misunderstood our ablation settings.
