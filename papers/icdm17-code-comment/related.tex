\section{Related Work}

%\subsection{Source Code}

Mining of source code repositories becomes increasingly popular in
recent years. Existing work in source code mining include
code search, clone detection, software evolution,
models of software development processes, bug localization,
software bug prediction, code summary and so on.

%\subsubsection{Code Summary}
G. Sridhara et al.~\cite{sridhara2010towards} proposed a automatic comment generator that identifies the content for the summary and generates natural language text that summarizes the method¡¯s overall actions based on some template. And L. Moreno et al.~\cite{moreno2013automatic} also proposed a template based method but it is used on summarizing Java classes.
P. W. McBurney and C. McMillan~\cite{mcburney2014automatic}  presented a novel approach for automatically generating summaries of Java methods that summarizes the context surrounding a method, rather than details from the internals of the method.
These summarization techniques \cite{murphy1996lightweight}\cite{sridhara2011generating}\cite{moreno2013automatic}\cite{haiduc2010use} work by selecting a subset of the
statements and keywords from the code, and then including
information from those statements and keywords in the
summary. To improve them, P. Rodeghero et al.~\cite{rodeghero2014improving} presented an eye-tracking study of programmers
during source code summarization, a tool for selecting keywords
based on the findings of the eye-tracking study.

D. Movshovitz-Attias and W. W. Cohen~\cite{movshovitz2013natural} predicted comments using topic models and n-grams. And like source code summary, M. Allamanis et al.~\cite{allamanis2015suggesting} proposed a continuous embedding model to suggest accurate method and class names.


%\subsubsection{Other Area of Source code}


Iyer et al.~\cite{iyer2016summarizing} proposed a new model called CODE-NN
that uses Long Short Term Memory (LSTM) networks with attention
to produce sentences that can describe C\# code snippets and SQL queries.
Iyer et al.'s work has strong performance on two tasks,
code summarization and code retrieval.
Adrian et al.~\cite{kuhn2007semantic} utilized the information of
identifier names and comments to mine topic of source code repositories.
Punyamurthula~\cite{punyamurthula2015dynamic} used call graphs to extract the metadata and dependency information from the
source code and used these information to analyze the source code
and get its topics.

In code search, most search engines solve the problem by keyword extraction
and signature matching. Maarek et al.~\cite{maarek1991information} used keywords extracted form man pages written in natural language and their work is an early example of the work based on keywords. Rollins and Wing~\cite{rollins1991specifications} proposed an approach to find code with the signatures present in code. And Mitchell~\cite{mitchell2008hoogle} combined signature matching with keyword matching. Then Garcia et al.~\cite{garcia2016semantic} focused on querying for semantic characteristics of code and proposed a new approach which combines semantic characteristics and keyword matching.

In other related domains of source code mining, Cai~\cite{cai2016code} proposed a new method
for code parallelization through sequential code search. That method also
can be used for clone detection. Williams and Hollingsworth~\cite{williams2005automatic}
described a method to use the source code change history of a
software project to drive and help to refine the search for bugs.
Adhiselvam et al.~\cite{adhiselvam2015enhanced} used MRTBA algorithm
to localize bug to help programmers debug.

%\subsection{RNN}

In our paper, we totally use two kinds of RNN, one is Recursive Neural Network and the other one is Recurrent Neural Network. These two neural networks are all widely used now.

%\subsubsection{Recursive Neural Network}

R. Socher did many works
 on Recursive Neural Network and proposed many kinds of Recursive Neural Network, for example, basic RNN~\cite{socher2011parsing}, Recursive Autoencoders (RAE)\cite{socher2011semi}, Unfolding Recursive Autoencoder~\cite{socher2011dynamic}, Recursive Matrix-Vector Model~\cite{socher2012semantic} and Recursive Neural Tensor Network~\cite{socher2013recursive}.
 O. Irsoy and C. Cardie~\cite{irsoy2014deep} introduced an architecture called deep RNN that constructed by stacking multiple recursive layers.

 Recurrent Neural Network is much more popular than Recursive Neural Network, there are many kinds of Recurrent Neural Network such as GRU~\cite{cho2014learning}, LSTM~\cite{hochreiter1997long} and Hierarchical RNN~\cite{schmidhuber1992learning}~\cite{paine2005hierarchical}. It is widely used in Summarization~\cite{nallapati2016abstractive}, QA~\cite{malinowski2015ask}, Action Recognition~\cite{du2015hierarchical}~\cite{veeriah2015differential} and so on.


%\subsubsection{Recurrent Neural Network}

