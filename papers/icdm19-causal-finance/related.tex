\section{Related Work}
\label{sec:related}
%We will review the related work from three perspectives: causal knowledge
%representation and reasoning, knowledge discovery, and some other related works.
\subsection{Knowledge Representation and Reasoning}
Most of the symbol-based works take the specific event as a key component, which fails to infer unseen causal events without generality, since they can not represent a class of causal events, such as ConceptNet \cite{Speer2016}, CausalNet \cite{Luo2016a}, BECauSE 2.0 \cite{Dunietz2017}.
%which represents the event with a word. According to the definition of expressiveness, CausalNet \cite{Luo2016a}, ConceptNet \cite{Speer2016} and BECauSE 2.0 \cite{Dunietz2017} lack generality, since they only focus on specific causal event pairs instead of a class of causal event pairs. For example, we can use a general causal pair (watching\_entertaining\_video, /r/Causes, fall\_asleep), which has more expressive power, to represent specific causal event pairs in ConceptNet, such as (watching\_movie, /r/Causes, fall\_asleep) and (watching\_television, /r/Causes, fall\_asleep). 
Although the approaches in \cite{Zhao2017,Baker1997,Radinsky2012} achieve some success in representing abstract events, they suffer from several other problems.
%In terms of expressiveness, \cite{Zhao2017} lacks concreteness since their scheme cannot determine the subject, object and predicate of the events, which will lead to some confusing results, such as (`shock',`therapy'). Also, \cite{Baker1997} fails to determine the specific participants in the events, which makes the expressive power weak.
%Besides, 
\cite{Zhao2017} and FrameNet \cite{Baker1997} do not add constraints during generalization, which will lead to errors. 
%as explained in \ref{sec:intro}. Besides, their methods fail to discover implicit relations which cannot be extracted from corpora. 
For example, given the event ``the price of corn rises.'', their method cannot predict the event that ``the price of alcohol will rise.'', since they can not reason under a concrete level, while it can be easily achieved through our method by adding the constraints such as ``madeOf'' relation. 
FrameNet also requires the pre-defined frames, which needs a large human effort.
%\cite{Baker1997} is also unfriendly to reason as analyzed in Section \ref{sec:intro}, which 
%also requires the pre-defined ontology and cannot discover implicit relations between elements. 
%The problem of unfriendliness for the machine to reason is also with ATOMIC \cite{sap2018atomic} and BECauSE 2.0 \cite{Dunietz2017} since their data is semi-structured or unstructured. 
Since the datasets in ATOMIC \cite{sap2018atomic} and BECauSE 2.0 \cite{Dunietz2017} are semi-structured or unstructured, they are hard to use in the machines.
Some researches choose to build relations between concepts with predicates \cite{schoenmackers2010learning, carlson2010toward}, but the ontology is pre-defined and hand-crafted, which can only represent a limited scope of events, since relations on Web are explosive and new relations are emerging. Moreover, predicates, such as athleteInLeague(X, NBA) in NELL \cite{carlson2010toward}, AMIE \cite{Galarraga2013} and AMIE+ \cite{Galarraga2015}, lack fine-grained granularity, which is hard to represent abstract events of different levels. 
\cite{Radinsky2012} uses clusters of causal event pairs to represent general causal knowledge, however, the general knowledge expressed in each cluster is implicit due to the blurred boundaries of each cluster.  
Notably, most of the current methods do not contain confidence of the rule, which is crucial to do high-accuracy predictions demonstrated in Section \ref{sec:experiment}.

\subsection{Rule Acquisition} 
Different ways of knowledge representation adopt different knowledge acquisition methods.
Here, we mainly review how to acquire knowledge of the logic rule. 
%The Inductive Logic Programming(ILP)\cite{Quinlan1990,Bergadano1996,Muggleton1997} makes strong assumptions, such as high-quality training data, closed-world assumption, and so on, which are inappropriate to handle the extracted data from Web text.%
This has been studied extensively in Inductive Logic Programming (ILP) \cite{Quinlan1990,Muggleton1997}. However, the strong assumptions made by ILP, such as high-quality training data, closed-world assumption, are unmet in the task of rule extraction from Web text.
For example, SHERLOCK system \cite{schoenmackers2010learning} learns the first-order horn clauses in a top-down manner, which first identifies the classes (concepts in our rules) and relations (predicates in our events), enumerates all their combinations, and keeps good ones as final rules. 
However, due to a large number of predicates and concepts in web text, as well as the complexity of the rule structure, their combination will be explosive in our case. Therefore, this method is not applicable for open-domain knowledge acquisition. Instead, we propose a bottom-up framework based on MDL to learn rules.

%\subsection{Misc}
%\paragraph{Event-based Graph Construction}
%Event Extraction task has beed a long-standing problem in information Extraction which typically include two subtasks, event detecting and classification. In this paper, we mainly detect the events with a open form, which means we have no predefined event type constrains. many researchers use the parser to do event detection subtasks, for example, \cite{Huang2017} use the AMR parsing\cite{Wang2015e} or Semantic Role Labeling (SRL) to extract the event candidate, \cite{Ding2016} use the Open IE\cite{Fader2011} and dependency parsing to extract the structured events.

%Event-based Graph construction   
%\cite{Saleh2018} learns the narrative event chains from raw newswire text. Further
%\cite{Glavas2015} formally proposes the concept of event graphs where events are structured and concrete. Later, a hierarchical event network using event abstract duples (verbs and nouns) as nodes and causality to represent edges is proposed in \cite{Zhao2017}. \cite{Li} constructs the Narrative Event Evolutionary Graph and the graph neural network is used to predict the subsequent events. Our rules can also be seen as an abstract event graph, but it is a logical form that is easy to reason.

%\paragraph{Financial Market Price Prediction} There are many works on financial market price forecasting using text information, mainly on stock prices. \cite{Ding} attempts to use structured event information to predict stock prices. 
%Furthermore, \cite{Ding2016} enriches event representation with the knowledge base to improve prediction accuracy.

%deductive database \\
\section{Conclusion and Outlook}
\label{sec:conclusion}

In this paper, we design a novel and powerful causal knowledge representation scheme based on the logic rule with the ability to do uncertain reasoning and we propose a rule learning framework for obtaining rules from large unstructured text. The experiments show that the rules learned are reasonable and effective.
In the future, we would like to improve the main components in the rule learning framework, such as rule instance extraction, external knowledge bases, and rule induction. Besides, we will also explore other downstream applications based on this reasoning system, such as consumption intent prediction, stock or futures price prediction, and reasoning-based information retrieval, etc.




