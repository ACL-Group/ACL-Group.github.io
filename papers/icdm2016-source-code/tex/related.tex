\section{Related work}
\subsection{Tag Recommendation}
%As mentioned earlier, in our definition the most important components for an action are the arguments of the predicate.
%Argument conceptualization tries to abstract the subject and object arguments of a verb by categorizing them into set of noun concepts.
%For example, for the verb ``accept'', the set of subject noun concepts might contain ``person'', ``community'' and
%the set of object noun concepts might contain ``document'', ``payment''.
%
%Earlier efforts of such tasks including Semantic role labeling (\cite{gildea2002automatic} and
%\cite{palmer2005proposition}), which labels the semantic meaning of the arguments of the verb, for example
%in the sentence ``He killed the enemy with a rifle.'' ``He'' is the agent, ``enemy'' is the patient and ``rifle'' is the instrument.
%However the choices of such role labels are rather limited and could be further expanded through Knowledge graphs. Especially in our
%application we hope the role to be more specific than it is in Semantic role labeling.
%
%Selectional constraints studies what are appropriate arguments for a particular verb.
%\cite{resnik1996selectional} proposed class-based selectional preference which decides if a class of terms is
%prefered to a verb. For example ``water'' is more prefered than ``table'' for the verb ``drink''. The main problem with this
%method is it does not consider overlap between classes which results in very similar classes.
%
%\cite{gong2015representing} proposed a data-driven approach which models the conceptualization problem as
%finding $k$-clique with maximum combined weights. They managed to build up an inventory of arguments concepts for
%more than 1,700 unique verbs. Our work is a further development of their project by converting action concepts into
%noun concepts.
Our object is quite similar to tag recommendation, a topic many researchers have
been interested in. The task of tag recommendation is to produce some descriptive
tags of texts or images.
There are two kinds of such recommendations, one is
personalized tag recommendation while the other one is non-personalized.
The method which consider users' interest and other features is called personalized
tag recommendation.

Rendle et al\cite{rendle2010pairwise} has proposed a tag recommendation method
based on Tucker Decomposition (TD) and Canonical Decomposition (CD) called Pairwise
Interaction Tensor Factorization (PITF). This method can produce tags which the
user have never seen, however, related to the user's hobbies. Song et
al\cite{song2008real} work on a real-time way and their method is a non-personalized one. Also there are some people working on tagging pictures, such
as Sigurbj{\"o}rnsson et al\cite{sigurbjornsson2008flickr}. They contributed on
recommending the description of pictures on Flickr.

\subsection{Probabilistic Model}
Probabilistic models are used to solve problems in natural language processing, too. Hindle et al\cite{hindle2012naturalness} and Tu et al\cite{tu2014localness}
showed that n-gram model can improve the ability for automatically
complement when people are coding. 
Movshovitz-Attias et al\cite{movshovitz2013natural} used a model similar to n-gram,
to predict annotations from given source code pieces.
Maddison et al\cite{maddison2014structured} proposed a code-generating system.
However, such kind of probabilistic models are introduced to mine the motivation of
writing code, instead of what it means. This is the difference from our work.

\subsection{Topic Model}
There are many researchers using ways which process natural language text to 
work on source code repositories. Maletic and Marcus\cite{maletic2000using} were
the first people who introduced LSI, Laten Semantic Indexing, to analyze software
systems. Adrian et al\cite{kuhn2007semantic} worked on the improvement of Maletic's
analysis. They first extracted the hidden semantics from source code repositories,
using LSI. After that, they used hierarchical clustering from the hidden semantics
extracted above. Such kind of processing can classify the source code by their
function. After all a tag will be added onto each method in the repositories.

Latent Dirichlet Allocation(LDA) was also used on source code analysis. Trevor
Savage\cite{savage2010topic} and Girish Maskeri\cite{maskeri2008mining} are two
examples.