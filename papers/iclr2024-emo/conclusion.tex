\section{Conclusion}
In this work, we introduce EMO, a novel approach for training auto-regressive language models by optimizing a differentiable upper bound of the earth mover distance between the model distribution and human text distribution. Experiments on open-ended text generation demonstrate that EMO consistently outperforms MLE and its robust baseline methods across diverse domains in terms of how human-like the texts generated from fine-tuned models are. 
Through a highly lightweight continual fine-tuning phase on unsupervised corpora, EMO can significantly enhance downstream performance compared to pre-trained models and exhibits commendable scaling properties regarding the amount of training data, rendering it favorable for general-purpose continual fine-tuning.