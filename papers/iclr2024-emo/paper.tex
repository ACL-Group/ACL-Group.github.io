
\documentclass{article} % For LaTeX2e
\usepackage{iclr2024_conference,times}

% Optional math commands from https://github.com/goodfeli/dlbook_notation.
\input{math_commands.tex}

\usepackage{hyperref}
\usepackage{url}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{wrapfig}
% \usepackage{float}
\usepackage{graphics}
\usepackage{graphicx}
\newcommand{\KZ}[1]{\textcolor{blue}{(Kenny: #1})}

\title{EMO: Earth Mover Distance Optimization for Auto-regressive Language Modeling}

% Authors must not appear in the submitted version. They should be hidden
% as long as the \iclrfinalcopy macro remains commented out below.
% Non-anonymous submissions will be rejected without review.

% \author{Siyu Ren\\
% Shanghai Jiao Tong University, China\\
% \texttt{roy0702@sjtu.edu.cn} \\
% \And
% Zhiyong Wu\\
% Shanghai Artificial Intelligence Laboratory\\
% \texttt{wuzhiyong@pjlab.org.cn} \\
% \And
% Kenny Q. Zhu\thanks{Corresponding author, partly supported by
% National Science Foundation (NSF) Grant No. 2349713, and University of Texas STARs program.}\\
% University of Texas at Arlington\\
% \texttt{kenny.zhu@uta.edu} \\
% }

\author{Siyu Ren\textsuperscript{12}\thanks{Work done during an internship at Shanghai AI Laboratory.}, Zhiyong Wu\textsuperscript{2$\dagger$}, Kenny Q. Zhu\textsuperscript{3}\thanks{Correspondence to: Zhiyong Wu, Kenny Q. Zhu, partly supported by National Science Foundation (NSF) Grant No. 2349713, and University of Texas STARs program.}\\
\textsuperscript{1}Shanghai Jiao Tong University
\textsuperscript{2}Shanghai AI Laboratory
\textsuperscript{3}University of Texas at Arlington \\
\texttt{roy0702@sjtu.edu.cn},~\texttt{wuzhiyong@pjlab.org.cn},~\texttt{kenny.zhu@uta.edu}\\
}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\iclrfinalcopy % Uncomment for camera-ready version, but NOT for submission.
\begin{document}


\maketitle

\begin{abstract}
    Neural language models are predominantly trained using maximum likelihood estimation~(MLE), which is equivalent to minimizing the forward cross-entropy between the empirical data distribution and the model distribution. However, various degeneration phenomena are still widely observed when decoding from the distributions learned by such models. We establish that the forward cross-entropy is suboptimal as a distance metric for aligning human and model distribution due to its (1) recall-prioritization (2) negative diversity ignorance and (3) train-test mismatch. In this paper, we propose \textbf{E}arth \textbf{M}over Distance \textbf{O}ptimization~(EMO) for auto-regressive language modeling. EMO capitalizes on the inherent properties of earth mover distance to address the aforementioned challenges. Due to the high complexity of direct computation, we further introduce a feasible upper bound for EMO to ease end-to-end training. Upon extensive evaluation, EMO demonstrates a consistently better language modeling performance than MLE across domains.
    Moreover, EMO shows noteworthy enhancements in downstream performance with minimal fine-tuning on merely 25,000 sentences, highlighting its potential as a lightweight calibration method for enhancing large-scale pre-trained language models. Code available at \url{https://github.com/DRSY/EMO}.
\end{abstract}

\input{intro}
\input{background}
\input{method}
\input{experiment}
\input{conclusion}
\bibliography{iclr2024_conference}
\bibliographystyle{iclr2024_conference}
\input{appendix}

% \appendix
% \section{Appendix}
% You may include other additional sections here.

\end{document}
