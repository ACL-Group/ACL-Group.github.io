\section{Related work}
%\KZ{\textcolor{red}{This section needs to be expanded a bit more more. Need to cover
%code search of various types. You should start with works most relevant to
%this paper, that is topic modeling for code, code search, code mining etc..
%then navigate to other less related work such as tag recommendation, and topic
%models for general text.}}

%\KZ{\textcolor{red}{You definitely need to talk about work on coding mining or code search that
%has leveraged NL semantics, code structure as well as call graph info.
%You should also mention work that has splitted identifiers like we did before,
%if any.}}

\subsection{Code Mining}
Mining of source code repositories becomes more and more popular recent years, and commonly explored areas of source code mining include code search, clone detection, software evolution, models of software development processes, bug localization, software bug prediction and so on. And our concerned areas are code search and duplicated code detection.


Iyer et al \cite{iyer2016summarizing} propose a new model called CODE-NN that uses Long Short Term Memory(LSTM) networks with attention to produce sentences that can describe C\# code snippets and SQL queries. And Iyer et al's work have strong performance on two tasks, code summarization and code retrieval.
Adrian et al \cite{kuhn2007semantic} utilizes the information of identifier names and comments to mine topic of source code repositories. And Punyamurthula et al \cite{punyamurthula2015dynamic} uses call graph that is also utilized in our paper to extract the metadata and dependency information from the source code and use these information to analyze the source code and get its topic.

Especially in the domain of code search, most code search engines solve this problem based on keyword extraction and signature matching. Maarek et al \cite{maarek1991information} used keywords extracted form man pages written in natural language and their work is an early example of the work based on keywords. Rollins and Wing \cite{rollins1991specifications} propose an approach to find code with the signatures present in code. And Mitchell \cite{mitchell2008hoogle} combines signature matching with keyword matching. Then Garcia et al \cite{garcia2016semantic} focus on querying for semantic characteristics of code and propose a new approach which combines semantic characteristics and keyword matching.

In other domains, Cai \cite{cai2016code} find a new method for code parallelization through sequential code search, and his method also can be used for clone detection. Williams et al \cite{williams2005automatic} describe a method to use the source code change history of a software project to drive and help to refine the search for bugs. And Adhiselvam et al \cite{adhiselvam2015enhanced} use MRTBA algorithm to localize bug to help programmers debug.
%Semantic clustering \cite{kuhn2007semantic} utilizes identifier names and comments to mine topic of source code. (using LSI) \textcolor{red}{Identifier}

%Summarizing Source Code \cite{iyer2016summarizing} using LSTM to describe C\# code snippets and SQL queries. And this paper preform on two tasks code summarization and code retrieval.

%An Enhanced Approach for Software Bug Localization using Map Reduce Technique based Apriori (MRTBA) Algorithm \cite{adhiselvam2015enhanced} is about bug localization, one domain of code mining. \textcolor{red}{Bug Localization}
%\subsubsection{Code Search}
%Semantic Code Browsing \cite{garcia2016semantic} combines the two approaches of semantic and keyword-based search (we can find some related work about code search here which are based on keyword and signature). \textcolor{red}{Semantic}

%Semantics-Based Code Search \cite{reiss2009semantics}, there are some related works about code search based on semantic information. \textcolor{red}{Semantic}

%Dynamic model generation \cite{punyamurthula2015dynamic} uses call graph to search code and there are mostly all related work about code search. \textcolor{red}{Call Graph}

%Code Parallelization through Sequential Code Search \cite{cai2016code}. \textcolor{red}{clone detection}

\subsection{Tag Recommendation}
%As mentioned earlier, in our definition the most important components for an action are the arguments of the predicate.
%Argument conceptualization tries to abstract the subject and object arguments of a verb by categorizing them into set of noun concepts.
%For example, for the verb ``accept'', the set of subject noun concepts might contain ``person'', ``community'' and
%the set of object noun concepts might contain ``document'', ``payment''.
%
%Earlier efforts of such tasks including Semantic role labeling (\cite{gildea2002automatic} and
%\cite{palmer2005proposition}), which labels the semantic meaning of the arguments of the verb, for example
%in the sentence ``He killed the enemy with a rifle.'' ``He'' is the agent, ``enemy'' is the patient and ``rifle'' is the instrument.
%However the choices of such role labels are rather limited and could be further expanded through Knowledge graphs. Especially in our
%application we hope the role to be more specific than it is in Semantic role labeling.
%
%Selectional constraints studies what are appropriate arguments for a particular verb.
%\cite{resnik1996selectional} proposed class-based selectional preference which decides if a class of terms is
%prefered to a verb. For example ``water'' is more prefered than ``table'' for the verb ``drink''. The main problem with this
%method is it does not consider overlap between classes which results in very similar classes.
%
%\cite{gong2015representing} proposed a data-driven approach which models the conceptualization problem as
%finding $k$-clique with maximum combined weights. They managed to build up an inventory of arguments concepts for
%more than 1,700 unique verbs. Our work is a further development of their project by converting action concepts into
%noun concepts.
Our object is quite similar to tag recommendation, a topic many researchers have
been interested in. The task of tag recommendation is to produce some descriptive
tags of texts or images.
There are two kinds of such recommendations, one is
personalized tag recommendation while the other one is non-personalized.
The method which consider users' interest and other features is called personalized
tag recommendation.

Rendle et al\cite{rendle2010pairwise} has proposed a tag recommendation method
based on Tucker Decomposition (TD) and Canonical Decomposition (CD) called Pairwise
Interaction Tensor Factorization (PITF). This method can produce tags which the
user have never seen, however, related to the user's hobbies. Song et
al\cite{song2008real} work on a real-time way and their method is a non-personalized one. Also there are some people working on tagging pictures, such
as Sigurbj{\"o}rnsson et al\cite{sigurbjornsson2008flickr}. They contributed on
recommending the description of pictures on Flickr.

\subsection{Probabilistic Model}
Probabilistic models are used to solve problems in natural language processing, too. Hindle et al\cite{hindle2012naturalness} and Tu et al\cite{tu2014localness}
showed that n-gram model can improve the ability for automatically
complement when people are coding.
Movshovitz-Attias et al\cite{movshovitz2013natural} used a model similar to n-gram,
to predict annotations from given source code pieces.
Maddison et al\cite{maddison2014structured} proposed a code-generating system.
However, such kind of probabilistic models are introduced to mine the motivation of
writing code, instead of what it means. This is the difference from our work.

\subsection{Topic Model}
There are many researchers using ways which process natural language text to
work on source code repositories. Maletic and Marcus\cite{maletic2000using} were
the first people who introduced LSI, Laten Semantic Indexing, to analyze software
systems. Adrian et al\cite{kuhn2007semantic} worked on the improvement of Maletic's
analysis. They first extracted the hidden semantics from source code repositories,
using LSI. After that, they used hierarchical clustering from the hidden semantics
extracted above. Such kind of processing can classify the source code by their
function. After all a tag will be added onto each method in the repositories.

Latent Dirichlet Allocation(LDA) was also used on source code analysis. Trevor
Savage\cite{savage2010topic} and Girish Maskeri\cite{maskeri2008mining} are two
examples.
