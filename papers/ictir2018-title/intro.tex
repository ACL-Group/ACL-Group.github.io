\section{Introduction}

% motivation
Mobile Internet is fast becoming the primary venue for E-commerce.
People have got used to browsing through collections of products and making
transactions on the relatively small mobile phone screens. 
All major E-commerce giants such as Amazon, 
eBay and Taobao offer mobile apps that are poised to supersede the conventional websites. 

\begin{figure}[th]
	\centering
	\epsfig{file=fig/intro_demo.eps, angle=0, width=1.0\columnwidth}
	\caption{A cut-off long title on an E-commerce mobile app, vs. a corresponding
short title.}
	\label{fig:compare}
	%\vspace{-10pt}
\end{figure}

When a product is featured on an E-commerce website or mobile app, it is often
associated with a textual title which describes the key characteristics of
the product. These titles, written by merchants,
often contain gory details, so as to maximize
the chances of being retrieved by user search queries.
Therefore, such titles are often verbose, over-informative, and hardly 
readable. 
%Sometimes, it even becomes more like a combination of several key words 
%rather than a complete and fluent sentence.
While this is okay for display on a computer's web browser, it becomes a
problem when such longish titles are displayed on mobile apps.
Take \figref{fig:compare} as an example. 
The title for a red sweater on an E-commerce mobile app is 
``ONE MORE文墨2017夏装新款印花连帽上衣长袖短款喇叭袖百搭卫衣女''.
%``ONE MORE$|$文墨$|$2017$|$夏装$|$新款$|$印花$|$连帽$|$上衣$|$长袖$|$短款$|$喇叭袖$|$百搭$|$卫衣$|$女'',
%which says ``ONE MORE$|$ONE MORE$|$2017$|$summer wear$|$new$|$printed$|$
%hoody$|$tops$|$long sleeve$|$short$|$flare sleeve$|$$|$sweater$|$woman''.
Due to the limited display space on mobile phones, 
original long titles (usually more than 20 characters) will be cut off, 
leaving only the first several characters ``ONEMORE文墨2017夏装... 
(ONE MORE 2017 summer woman...)'' 
on the screen, which is completely incomprehensible, unless the user
clicks on the product and load the detailed product page.  

Thus, in order to properly display product listing on a mobile screen,
one has to significantly simplify (e.g., to under 10 characters) 
the long titles while keeping the most important information.
This way, user only has to glance through the search result page
to make quick decision whether they want to click into a particular 
product.
\figref{fig:compare} also shows as comparison an alternate display
of a shortened title for the same product.
The short title in the left snapshot is ``印花$|$连帽$|$短款$|$喇叭袖$|$卫衣'',
which means ``printed$|$hoody$|$short$|$flare sleeve$|$sweater''. 

% problem
In this paper, we attempt to extract short titles from 
their longer, more verbose counterparts for E-commerce products.
%To the best of our knowledge, this is the first attempt that attacks the 
%E-commerce product short title extraction problem.
%\yu{How to argue ``A Multi-task Learning Approach for Improving Product Title Compression with User Search Log Data''？}
% describe summary a bit
This problem is related to text summarization, 
%which is a task of producing a condensed representation 
%of an input document or sentence 
%that captures the core meaning of the original.
which generates a summary by either {\em extracting} or {\em abstracting}
words or sentences from the input text. 
Existing summarization methods have primarily been applied to news or 
other long documents, which may contain irrelevant information. 
Thus, the goal of traditional summarization is to identify
the most essential information in the input and condense
it into something as fluent and readable as possible. 

% why extractive
We would attack our problem with an \textit{extractive} summarization 
approach, rather than an {\em abstractive} one for these reasons.
First, our input title is relatively shorter and contains less noise,
(average 27 characters; see \tabref{tab:data}).
Some words in the long title may not be important but they are all relevant 
to the product. Thus, it is sufficient to decide if each word should or 
should not stay in the summary. 
Second, the number of words in the output is strictly constrained in 
our problem due to size of the display. 
Generative (abstractive) approaches do not perform as well when there's
such a constraint.
Finally, for E-commerce, it is better for the words in the summary to come 
from the original title. 
Using different words may lead to a change of original intention of
the merchant.

% different senario -> different model
State-of-the-art neural summarization models
\cite{cheng2016neural,narayan2017neural}
are generally based on attentional RNN frameworks and have been applied
on news or wiki-like articles.
However, in E-commerce, 
customers are not so sensitive to the order of the words in a product title. 
Besides using deep RNN with attention mechanism to encode word sequence, 
we believe other single-word level semantic features such as NER tags and 
TF-IDF scores
%\KZ{What do you mean by outside?} \xusheng{Features focusing on a single word, and can be calculated in preprocess step such as NER tags and tf-idf, not from RNN model which need the whole sequence. Then we combine all the features together in the last step to output a score. See the figure, just want to say those ``outside'' features are important in this problem.} 
will be as just as useful and should be given more weights in the model.
In this paper, we propose a wide and deep neural summarization model, 
which is not only deep but also wide, 
aiming to effectively shorten original long titles.

% contribution (problem, dataset, model, result)
The contributions of this paper are summarized below:
\begin{itemize}
	\itemsep0em
	%\item We are the first to define the problem of short title extraction
	%for E-commerce product (\secref{sec:problem});
	\item We collect and will open source a product title summary dataset known as LESD4EC (\secref{sec:data}).
	\item We present a novel Wide and Deep Neural Extractive Model, 
	combining three different types of word level features
	(\secref{sec:model}), and the results 
	show the model outperforms 
	several strong baseline methods, with $ROUGE-1_{F1}$ score of 
	0.725 (\secref{sec:eval_offline}). 
	\item By deploying the framework on an E-commerce mobile app, 
	we witnessed improved online sales 
	and better turnover conversion rate
	in the popular 11/11 shopping season (\secref{sec:eval_online}).
	%and question answering. Furthermore, our schema representation is
	%on par with the popular word embedding model in computing relation similarity (\secref{sec:eval}).
\end{itemize}
