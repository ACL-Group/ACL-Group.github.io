\section{Task Description}
In this section, we give a formal problem definition of our task and introduce the dataset we constructed for this task. 
\label{sec:problem}
\subsection{Problem Definition}
%There are two participants in an online health counselling dialgue: a patient and a doctor. In most cases, both participants will raise questions and ask for information from the other. 
Our work aims at identifying QA relations by matching Q and NQ in such informal online real dialogues.
The whole task can be formulated as a sentence matching problem. Given a dialogue $C=[(P,U_1),(D,U_2),...,(D,U_T)]$, P and D represents the role of two participants. We also know the label $L=\{Q,NQ\}$ for each utterances, which categories all the utterances into Q and NQ. 
Our job is to match each $Q_i$ with corresponding ${NQ_j}$, where:
\begin{equation}
\begin{aligned}
j&>i\\
role(Q_i)&\not=role({NQ_j})\\
\end{aligned}
\end{equation}
$role(\cdot)$ refers to the speaker of the utterances. The matched NQ will be named ofter $A_i$, while the rest which do not have corresponding Q will be regarded as others($O$).

%\subsection{Challenges}

% they assume that the questions are always raised by one participant and try to align among the utterances from the other to generate QA pairs.

% Utterances alignment in the multi-round conversations is much more difficult besides mixing of different kinds of utterances. 
% %\KZ{I don't see how this is more difficult than the three things you mentioned in the prev para.}
% Two or more questions may be proposed at the same time which causes the order of the answers a mystery. For example, in Figure \ref{fig:sample}, the doctor raises question U2 and U3 continuously, while the patient may answer the latter one first. In the recent work from He, they consider multiple alignment issue which means one answer may align with multiple questions. Different from their problem definition, we don't allow such one-to-many alignments for each non-question utterance. The fragmentation phenomenon of answers and long-range QA pair matching are the main difficulty in our dataset. 

%QA matching in online dialogues is not an easy task.The challenges are as follows:
%\begin{itemize}
%    \item Several questions may be raised continuously instead of solving one by one, and the order of answers may be not the same. For example, in Figure \ref{fig:sample} the doctor ask the question U2 followed by a question U3. The patient can answer U2 first and then U3, or conversely.
%   \item The participants may ignore some of the questions as well. As a result, these questions like U9 has no related answers.
 %  \item For IQA and FQA cases, the distances between Q and NQ are large. This cause the long distance QA matching problem.
   %\item Since the dialgoues come from the real online discussion forum, the utterances are quite noisy and informal with punctuation misuses, wrongly written characters and other informal expressions. 
   
    %\item There also exits some questions can not be answered directly without acquiring more information from the other paricipant. IQA matching exits.  
    %\item Based on above statistics, around 22.67\% questions have more than one answer. It doesn't mean that the question has been answered by the other again and again, but that the complete answers tends to be broken into several pieves. The fragments of a complete answer maybe show up one by one in one's sequential utterances, and may be interrupted by the other participant.

    % This happens when the original question can not be replied directly, so the other participants need to ask for more information and may give the final answer to the original question after many turns.
%\end{itemize}

 %After all, the questions, answers and other utterances are mixed together and cause the great challenges of the task.



\subsection{Data}
We crawled nearly 160,000 distinct dialogues from an online health forum\footnote{\url{https://www.120ask.com/}}. After some basic data cleaning methods such as deleting the unknown characters and irrelavant sentences like ``Please pay ** coins to continue consultation'', we randomly labelled 1000 two-party multi-turn dialogue sessions. The Fleiss' Kappa was 0.75. For each session, it owns 19.68 doctors' utterances with 6.92 words and 17.32 patients' utterances with 7.91 words on average. In the annotated dataset, there are 9.80 questions with 8.89 words, 10.78 answers with 6.62 words, 16.41 casual chit chats with 6.99 words in each session. The distribution of questions and answers is almost balanced. There are totally $21.9\%$ questions which has no answers, $22.7\%$ questions have more than one answer and the rest questions have only one answer. For each question which has answers, it can match to 1.41 answers on average. 

We divide the 1000 sessions into training set and test set by 8:2. In traning set, 453 non-questions which belong to the IQA pairs, while 8223 non-questions are not. Corresponding statistics for test set are 122 and 1995 respectively. More details of distance between QA pairs in our dataset are shown in Table \ref{tab:dataInfo}.

\begin{table}[h]
	\small
    \centering
    \begin{tabular}{cccccc}
    \toprule[1.2pt]
    Dataset & 1 & 2 & 3 & 4 & $\geq5$ \\
    \midrule[1pt]
    Training Set & 3893 & 2399 & 1205 & 526 & 653\\
    \hline
    Test Set & 947 & 592 & 274 & 136 & 168 \\
    \bottomrule[1.2pt]
    \end{tabular}
    \caption{The distribution on QA pairs of variable distances.}
    \label{tab:dataInfo}
\end{table}

