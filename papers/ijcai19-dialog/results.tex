\section{Results and Analysis}
\label{sec:results}
%We first show the end-to-end results on QA matching. Then, we present the results on QA pairs as distance varies and the results on the incremental QAs.

In this section, we first show the end-to-end results on QA matching. Then, we analyze two special cases: QA on variable distance and IQA.

\subsection{Overall Performance}
The main results of different model are shown in Table \ref{tab:mainResults}. The last row shows the human performance, which can be regarded as the upper bound of this task due to some ambiguities of answers. 

\begin{table}[h]
	\small
	\centering
	\begin{tabular}{p{1cm}<{\centering}p{1cm}<{\centering}ccccc}
		\toprule[1.5pt]
		Models &Tacc(R)&Facc& Acc& P& F1\\
		\midrule[1pt]
		GD1&44.73&91.74&73.26&69.84&54.53\\
		GDN  &69.11&86.05&79.39&70.03&69.57\\
		GD1+J&50.40&90.70&74.86&70.38&58.74\\
		GDN+J&\textbf{82.90}&55.03&65.99&51.47&63.51\\
		\hline
		Distance&69.34&87.34&80.26&71.57&70.44\\
		mLSTM&4.20&\textbf{99.27}&61.90&58.17&7.84\\
		RPN&76.57&87.92&83.46&73.88&75.20\\
		\hline
		DM&71.61&92.69&84.40&\textbf{79.62}&75.40\\
		HM&78.18&88.38&84.37&75.30&76.71\\
		HDM&78.51&89.66&\textbf{85.28}&77.09&\textbf{77.79}\\
		\hline
		Human & 84.21&91.57&87.64&85.11&84.66\\
		\bottomrule[1.5pt]
	\end{tabular}
	\caption{The \textbf{P}recision(\%), \textbf{R}ecall(\%), \textbf{F1}-score(\%) and \textbf{Acc}uracy(\%) of all methods on test dataset.}
	\label{tab:mainResults}
\end{table}

%The first four rows are the results of rule-based methods. The next three lines are the results of baseline methods. Then, the results of our proposed models are listed in three lines. 


From the Table \ref{tab:mainResults}, we get following conclusions:
\begin{itemize}
	
	\item The results of the rule-based methods are not bad, which indicate that questions are followed by their answers in most cases. The GDN increases the F1-score and accuracy to 69.57\% and 79.39\% compared with Greedy-1 because it can solve the case of simple FQA. For GDN+J, the recall obtains the best score among all the methods while accuracy and F1-score reduce. The reason is that GDN tends to match NQ with Q as much as possible, so many chit chats will be regarded as answers and F-accuracy reduces.
	
	\item Model mLSTM fails while the Distance obtains outstanding performance. It shows that it is difficult to solve the QA matching problem with only two short texts. The word distribution between the questions and answers are quite different without back knowledge. Besides, the distance information is significantly important when identifying QA relations in dialogues. People tend to answer the question at the moment they see it except in IQA condition.
	% While combing the sentence information together with other models, the result improves.
	
	\item RPN obtains great improvements. It mainly benefits from taking the dialogue session as a whole which contains all the information in a session. However, it can't effectively identify the useful features and may bring more noise into the model. 
	
	\item Our proposed models achieve the best results compared with above models while the HDM increases the F1-score to 77.79\% and the accuracy to 85.28\%. Although the recall and precision of both models are not better than GDN+J and DM respectively, the overall quantity and quality of QA pairs we identified are the best based on the highest F1-score. In addition, the results demonstrate that QA matching not only depends on the distance but also relies on the history information. Our model successully combine the dialogue context into the basic pairwise model.
	
\end{itemize}



\subsection{Variable Distance Matching}

 Since distance is a really important feature for QA matching, we also compute the accuracy on QA pairs with different distances. The results are shown in Table \ref{tab:longrangeResults}.

\begin{table}[h]
	\small
	\centering
	\begin{tabular}{p{1.5cm}<{\centering}ccccc}
		\toprule[1.3pt]
		 Models &1&2&3&4&$\geq5$\\
		\midrule[1pt]
		GD1     &100.0&0.0&0.0&0.0&0.0\\
		GDN     &100.0&66.89&32.48&14.71&6.55\\
		GD1+J&100.0&16.39&6.57&2.97&0.60\\
		GDN+J&100.0&83.28&69.34&53.68&30.95\\
		\hline
		Distance      &100.0&88.01&0.0&0.0&0.0 \\
		mLSTM   &5.91&3.55&1.82&2.21&2.38\\
		RPN  &95.78&80.57&\textbf{61.31}&32.35&14.88\\
		\hline		
		DM &94.40&\textbf{87.16}&30.66&11.03&4.17\\
		HM &\textbf{95.99}&81.93&59.49&\textbf{38.24}&\textbf{27.38}\\
		HDM &95.88&85.64&\textbf{61.31}&37.50&16.67\\
		\bottomrule[1.3pt]
	\end{tabular}
	\caption{The matching accuracy(\%) on variable distances. The highest scores among last 4 rows are in bold.}
	\label{tab:longrangeResults}
\end{table}

As for rule-based methods, it is no doubt that they will achieve the accuracy with 100\% when distance=1. As distance getting longer, the performance of GDN and GDN+J surpass GD1 and GD1+J. Although GDN+J obtains the highest accuracy among these models, according to the Table \ref{tab:mainResults}, the quality of QA pairs identified by this method is bad because of redundant answers to the questions. Distance model fails when the distance is longer than 2. 


Here, we mainly compare the models which guarantee the quality of QA pairs. Their results are listed in the last four rows in Table \ref{tab:longrangeResults}. Comparing these four neural-based models, although they can't guarantee 100\% accuracy on distance=1, their accuracy is still comparable. It shows that the neural-based models with dialogue context information including RPN, HM and DHM perform well with distance longer than 3. Although RPN takes the whole session into consideration, the accuracy with distance=4 and $\geq5$ obviously lower than HM. It indicates that RPN can not work well in long-distance situations while our model achieves. When bring distance information into our model, it harms the accuracy on QA pairs with longer distance while increases with shorter distance. 




\subsection{IQA Matching}

It is no doubt that the distance of Q-NQ pair with IQA relation is naturally longer than 3 (It only has one question with the only answer between Q and NQ). Since IQA pairs are significantly important, we divide all the NQ utterances into two categories by whether it belongs to an IQA pair. We calculate the accuracy separately. The experiment results are shown in Table \ref{tab:IQAResults}.

\begin{table}[h]
	\small
	\centering
	\begin{tabular}{ccc}
		\toprule[1.1pt]
		Models &IQA Acc& Non IQA Acc\\
		\midrule[0.75pt]
		GD1&0.0&47.47\\
		GDN  &0.0&53.48\\
		GD1+J&0.0&73.33\\
		GDN+J&0.0&87.97\\
		\hline
		Distance&0.0&73.58\\
		mLSTM&2.46&4.31\\
		RPN&22.13&79.90\\
		\hline
		DM&9.84&75.38\\
		HM&\textbf{36.07}&80.75\\
		HDM&30.33&\textbf{81.45}\\
		\bottomrule[1.1pt]
	\end{tabular}
	\caption{The matching accuracy on IQA and non IQA pairs. The highest scores among last 4 rows are in bold.}
	\label{tab:IQAResults}
\end{table}
 %Besides, it can not solve the cases when there exists gap between question and its answers.

Table \ref{tab:IQAResults} shows that most models fail in matching IQA relations except the ones considering the dialogue context. The rule-based methods obtain a good accuracy with non IQA relations especially with "Jump". However, it can not solve IQA relations and the conditions when answers are disordered. Therefore, the IQA accuracy is zero on these models.

As for IQA matching, our methods significantly increase the accuracy from 22.13\% obtained by RPN to 36.07\% with history information. Meanwhile, the non IQA accuracy of HDM also increases by 0.85\%. The main reason why our approach performs much better than RPN model is that we consider the utterances in history with different weights by attention mechanisms, but RPN treats all the utterance equally. The interleaving way of adding history information also can extract the interactive features between communicators which benefit for IQA matching. Comparing HDM with HD, the IQA accuracy declines. The reason is that the effect of distance harms the matching probability of Q-NQ pairs with long distance. 





