Review #211019
Comments to Authors.
This paper examines the alignment of questions and answers in dialog. The authors posit that there are two forms of Q/A in dialog, and concentrate on the incremental question answering (IQA) type that they aim to formulate, formulating it as a sentence matching problem.

As in dialog, context matters so the authors consider what they term question (Q) and non-question (NQ) turns in the dialog.  They devise a NN based encoding/decoding method to do the alignment (Match-LSTM).

There are many different ways of integrating length modeling into your RNN architecture, so why is your formalism better than others?  It would be good to discuss the architecture motivation for introducing this at the final level of the decision.  Also, a 1-hot representation drops any relative distance notion between classes.  It seems a suboptimal representation.  Can you discuss this implication?

Are the contents of the forum activity actually cleared for use?  Just because you can crawl the data doesn't necessary mean that it is allowed or sanctioned.  It would be good to explicitly mention that this data is cleared for research use.

There are various small problems with fluency in the work.  Occasionally it creates difficulties with interpreting the exact operationalization of the work.  It would be good if the authors could do a good and thorough proofreading run to correct for such errors, above and beyond those called out in this review

I appreciated the breakdown of IQA with respect to longer lengths.  It would be good to also describe the number of Q/A pairs that fall in each bin, as I would guess this follows a power-law or log normal distribution.  Are the results on the higher lengths statistically valid given that there would be fewer data points?  (This is particularly important since the performance numbers vary significantly).

I appreciate the work on the discussion rather than end with just the results.  However, the discussion still needs to be further developed beyond just the discussion of empirical results.  Why do the models have the effects they have?  Can you connect the performance with specific architectural decisions?  E.g., why does HM and DM work to achieve better performance than the whole model?  To me it looks like there is some overfitting going on with the heavy parameterization in the full model.

With all NN models, random initialization affects results significantly.  It's not clear whether the results are cherry-picked from specific good runs or (correctly) averaged over many runs.  This needs to be explicitly noted in the output.

The results show that different variants of the DM, HM, or HDM perform well, but the variance is high and it is difficult to know whether the results generalize beyond the dataset in the paper and between runs.  For these reasons, although I find the model interesting and motivated, I'm unsure of the empirical veracity of the experimental results and its generalizability beyond the specific corpus studied.   

Since you only experiment with one dataset, I think you need to better scope your title.  This work is not representative of all online discussions.

Detailed comments (Page X, and Column Y)

5,2 Taccuracy and Faccuracy don't make sense.  Please expand these tokens.

5,2 Once *we have* identified all *of* the QA pairs,

6,1 Why the choice of the dimension sizes?






Review #254651
Comments to Authors.
This paper focuses on the problem of matching question and answer in disordered real-world online dialogues. The problem is very good and deserves to be discussed. However, the dataset collected from a medical website is not consistent with the data on the website. The proposed model as well as other base models are evaluated on this dataset, which is not convincing enough. The experiments are complete but the paper is not clearly written enough. I also noted some language problems in the paper.


Other comments:

1. I went to the website (www.120ask.com) where the data was collected from, but couldn't find any real dialogue like the example in Figure 1 in the paper. Every question-answer pair in those dialogues are one-to-one matched, which means that there is no incremental QA and fragmented QA in these dialogues. The real example (in Chinese and the translated version) should be provided in your paper.

2. Some results in table 5 and 6 are wrongly bolded.

3. If there is any public dataset that can be used to evaluate your model, you should use it. The dataset proposed in you paper is not convincing enough.

4. There are too many abbreviations in the paper, it is difficult to read.

5. It is unclear that the contribution of this paper is a new real-world dataset or a new model that fits the problem.




Review #256645 New
Comments to Authors.
Relevance:8

Significance:5

Originality:5

Technical Quality:6

Clarity:3

Citations:7

Overall:5

Confidence:7



Summary

=======

Authors tackled the problem of finding answers to the questions asked in a dialog. Both questions and answers are limited to the utterances in the dialog. The paper assumes that each utterance is mapped to either a question or non-question (answer or other [chit-chat]) category. They used crawled data from 120ask Chinese website and annotated the data with .75 kappa score which is pretty good agreement. They proposed a new neural approach that takes advantage of attention networks and incorporated all utterances between the question and the candidate answer as context fed into their DNN architecture. Results suggested the advantage of their approach over rule-based techniques and two basic neural approaches. 



Strengths:

+ The problem of finding proper Q&A pairs in online data is of great interest to the community as it allows easy aggregation of knowledge base for building new Q&A domains.

+ The paper uses real online web data for their task. 

+ The idea of using the utterances between the question and target answer is interesting.



Room for improvement:

- Writing of the paper requires major rework. I left suggestions in the comments but they do not capture all as there were too many. Highly recommend getting a native english speaker to help with the writing of the paper.

- There is no discussion about the limitation of assuming each utterance to be a question or non-question. Some utterances can answer other questions while posing a new question (see comments). 

- Ablation study is weak. Experiments done but not accompanied with much discussion or insight.

- Experimental results lack statistical significance test despite claiming significant improvements. Highly recommend watching Joelle's video (https://videoken.com/embed/jH0AgVcwIBc) to improve your experimental setup.

- Some of the decisions made in the paper lack justification (see comments)

Comments:

=========

P1: 

- "U3 and U4": Did you mean U4 and U5?

- What about sentences that are answers to some question but also include a question? Example:

U1: What are your symptoms?

U2: I have fever and chill. Should I be worried?



P2:

- "RPN-based": always introduce your acronym before using it

- "None of the above approaches perform well with long distance QA pairs.": Is this conjecture or shown in the past. It sounds like latter, which requires citation.

- What about Dev set for parameter optimization?

- "In traning set, 453 non-questions which belong to the IQA pairs, while 8223 non-questions are not": training. also the sentence is not grammatically correct.

- In Table 1, you should also add a label for row 1. For example Dataset/Distance instead of Dataset.

- "As for each non-question utterance, we extract it with each question from the other participant before it to combine a sample for the model": ?

- "Distance refers to the number of utterances between the question and non-question in a sample, and history is made up of the utterances between them.": You should put the explanation before its use. You already used distance in Table 1.



P3:

- History Attention add(s)

- Prediction Layer bring(s)

- "into consider": consideration?

- "We name the participant who raised the ques- tion utterance as role_Q(RQ)": you already used P and D as the roles. Why not use that? Also you have not introduced RQ yet to define role_Q() function on top of it.

- "Besides, we utilize two parallel": bad English

- What does "combining H_RP into Q" mean? Did you mean bringing the context?

- "if p > 0.5": How did you pick .5 as the threshold for finding an answer



P4:

- "A simple baseline Greedy is that, when a question is posed by roleQ, we can directly match the following several non-question sentences said by role_P as the answer until meeting another question or roleQ said a non-question sentence": English. Recommend breaking it into multiple sentences.

- "The rules with Jump (J) is that, we can jump the non-question sentence said by role_Q when matching the answers.": You can not define the term jump by using the word jump...

- "choose the one that can get the best performance on our dataset": which dataset specifically? training or testing?

- "Taccuracy", "Faccuracy": You explained the True (T) and False (F) later. You should bring that earlier so the reader is not confused.



P5:

- Table 3: Ah, so you do have a dev set. Why do you give the impression that you dont in Table 1? You should bring your Dev set into Table 1.

- "last 4 rows are in bold": why last 4 rows? "which guarantee the quality of QA pairs": What do you mean by quality?

- Table 5, same comment with Table 1 about labeling first row

- Table 5, how significant are these numbers compared to each other? For example is your highlighted 95.99 is significantly bigger than 95.78 on the first column? Have ran any statistical significance on these numbers?



P6:

- "It is no doubt that the distance of Q-NQ pair with IQA relation is naturally longer than 3 (It only has one question with the only answer between Q and NQ)": Shouldn't this be distance 2?

- "Comparing HDM with HD": HD? Did you mean DM?

- "all different from us": all different from ours.

- "can not be inaccessible": Did you mean can be inaccessible?

- "Both results show that our models are significantly better than previous methods.": I dont recall seeing any significance test discussion in the paper.


Review #257096
Comments to Authors.
People usually utilize the online forum to exchange information. The basic form is someone post questions and others to answer those question. This paper devote to match the questions and answers in dialogues from online discussions. It is an very interesting problem. And the authors found there are many incremental QA (IQA, IQA pairs are usually long distance ones, in the sense that the answer is a distance away from the Question) in conversations. To address the issue of IQA, this paper proposed a pairwise matching models which are able to combine the dialogue history in an interleaving way.

 

However, I am not sure the IQA (long distance QA pairs) are widespread in the dialogues of online discussions. By checking the data website of this paper (https://www.120ask.com/), I found the most IQA are the last answer (which are wrote by doctors) math the first question (which are posted by “patient”).  Therefore, the addressed issues in this paper is a particular case.