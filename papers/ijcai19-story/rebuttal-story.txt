Review #255023:
Thank you for your valuable comments.
Q1: The paper limits KR …
In fact, we divided our related works not by different forms of knowledge representation, but the ways of obtaining the representation, i.e., either manually, or automatically (see more in Q1 of Review #53092). Lierler et al. proposed a methodology for building a QA system that uses KRR techniques related to the representation of actions. This logic-based approach can be classified into the first category of our related works. However, they specifically target the representation of questions and answers whereas we focus on representing stories. We therefore didn't cover this paper in the related work.  

Review #256474: 
Thank you for your valuable comments.
Q1: The paper uses negative sampling …
Thank you for pointing out this mistake on our part. Our approach is indeed supervised classification using negative sampling. We will modify the wordings in the revised version and also adjust the headers in Table 4 to ”Unsupervised” and ”Supervised” respectively. 

Q2: This paper relies on ConceptNet … 
The framework proposed in this paper, which is text simplification plus structured commonsense knowledge, is general and can be applied to other commonsense knowledge graph than ConceptNet. We used ConceptNet here due to its comprehensive coverage and relatively high quality. Our contribution here is this framework that makes good use of the knowledge in ConceptNet. If there were a similarly structured but better knowledge source, we are certain it could be plugged into the framework and yield better results. For example, when we use half of ConceptNet in a separate experiment, the results are.... 

Q3: The paper needs to spend … 
We will describe ConceptNet and NumberBatch more clearly in the revised version and proofread the whole paper carefully. “word length” means the number of words in a concept. We will rephrase this term to “length of a concept”. 

Q4: The paper mischaracterizes … 
Actually in Sec 4, para 2, we were discussing a number of end-to-end techniques for SCT using ”manually chosen features”. SeqMANN is one such technique making use of a feature called SemLM, which is trained on external resources. So what we are categorizing is really SeqMANN, not SemLM. We will rephrase the sentence to make it clearer in the revision. 

Q5: This paper covers story cloze … 
Though the work by Orr, Ferraro, and Pichotta provide ways to represent events and consequently sentences, they represent sentences using special data structures such as semantic frames or 5-tuples. These representations are fundamentally different from our representation of sentences which is sequences of words. Hence they cannot be used as text simplification in our framework. Furthermore, the tools they used to extract the event such as SEMAFOR has poor accuracy and recall in our preliminary studies. Therefore, these works were excluded from our quantitative evaluation. However we will add some discussion about them in the related work in the revised version. 

Review #258210:
Thank you for your valuable comments.
Q1. In Sec 1., authors say-“Predicting… 
Our abstract says “Predicting ending for narrative stories is a grand challenge for machine commonsense reasoning,” and this is what we really wanted to say. We will fix this erroneous sentence in the introduction in revised version. 

Q2. In Sec 1, “Instead, we propose to define … 
Please refer to Q1 of Review #256474. 

Q3. The proposed approach is dependent on …
Our preliminary study shows that only 0.034% of the sentences from ROCStories that do not contain any ConceptNet concepts. Furthermore, fewer than 0.017% of the ending sentences contain no concept at all. Therefore we consider the OOV problem to be statistically insignificant and choose to ignore it. We will add the above discussion to the Sec 3. 

Q4. In Sec 3,.. “Then we present … 
As we pointed out in Sec 3.2, we are not saying all previous methods are invalid. Rather, because they were all trained on the validation set which has information leak, their evaluation results are invalid. 

Q5. In Sec 3.2,.. “The fact that humans score … 
In Table 3, we show the result for models trained only with story endings. However, ISCK requires sentiment and commonsense features which cannot be trained using the last sentence of a story alone. Thus it is not included in Table 3. Table 3 is there to illustrate the information leak problem and is not our main result. We did compare with ISCK in Table 4, which is our main results. We didn’t compare with ISCK without sentiment because according to Chen 2018, that setup is worse than the ISCK model itself. 

Q6. The results of FTML on SCT …
What we report in this paper are indeed results on the SCT test set, same as the previous work. As we explain in Sec 3, the numbers for FTML are different from what was reported previously mainly because of the use of different training data. 

Q7. In sec 3.3., “In fact we logged 5% … 
RNN-BC should be SKBC. We will fix this typo.


Review #53092:
Thank you for your valuable comments.
Q1. Also, there is a lot of work in the literature that makes the point that the use of symbolically-represented knowledge is a central component in both human and computational story understanding…
“Story Understanding…Calculemus!” and “Knowledge Activation in Story Comprehension” are logic-based framework which can be used in certain tasks that are relevent to story understanding. They define specific knowledge structure as the representation(e.g., “Story Understanding…Calculemus!” uses predicates, states, etc. as the formal representation of stories). We divided our related works by the ways of obtaining the representation, i.e., either by manual feature selection or by machine learning. These two papers belong to the first category and will be added in the revised paper. We agree that we didn't specifically target causality in this work. But thank you for the suggestion and we will consider it in future work.

Q2. I found it very difficult to follow the paper… The paper must be checked for the proper use of English. 
Thank you for the suggestions. We will carefully proofread the paper, improve English and clarify important details in the revised version.

Q3. A minor point: Claiming that …
In this paper, our main contribution is in fact the discovery that commonsense concepts plays an important role in understanding the logic of stories. Hence we choose to ignore other parts of the sentences such as pronouns and person names.
