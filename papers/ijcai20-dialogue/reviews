Reviewer #1
Questions

* 4. Comments to authors
    * This paper proposes to train neural based multi-response dialogue agents. The motivation of the paper is that previous works mostly rely on concatenating representations of dialogue turns — ignoring dependencies between turns. The tone of this rationale should be relaxed because that is not totally true — many related works take dependencies into account, though not necessarily parsing-wise. On the one hand, one claimed contribution is a rather simplistic dialogue extraction algorithm. On the other, a Thread-Based Encoder model is proposed. Experimental results show that the combined contributions outperform state-of-the-art results. This is however a strong claim because the paper does not report a human evaluation, and because the metrics used in this paper only provide preliminary results — there is no automatic metric that can replace human evaluations. The paper also does not report an ablation study. It is unclear where the gains come from, which may come from the Transformer architecture rather than the claimed contributions. It would have been more convincing to show the benefits of both claimed contributions, where other models can benefit from the individual contributions as well as combining both. Last but not least, the dialogue dependency relations were not explicitly elaborated in the paper to reproduce results using such kind of resource. Again, an ablation study together with a human evaluation could have helped to find the individual contributions of Dialogue Extraction vs. Thread-Based Encoder vs. Dependency Relations.

======================================================

Reviewer #2
Questions

* 4. Comments to authors
    * This paper proposed a dialogue extraction algorithm to transform a dialogue history into threads based on the
dependency relations as well as a Thread-Encoder model to encode threads and candidates into compact representations by pretrained Transformers. Experiments showed that dependency relations are helpful for dialogue
context understanding.


Considering the dialogue dependency relations is one of the contributions in this paper. However, finding the previous utterance in a multi-party conversations is an old problem. The thread extractor adopted in this paper is from other researchers' work, and hence the contribution is limited here. In other words, only with the idea of considering the use of threads is a bit incremental.


This paper adopts the threshold-based thread extractor. However, it is possible that the window-based thread can provide the same result. The window-based methods should be compared in experiments.


Using the term "dependency relations" is ambiguous and misleading as they also refer to the relations in the dependency parsers. Authors should consider using another term.

======================================================

Reviewer #3
Questions

* 4. Comments to authors
    * The article Multi-turn Response Selection using Dialogue Dependency Relations
proposes an algorithm for multi-turn response selection. This is a subtask of Dialogue parsing. This subject is very recent and we do not have clear results. This work appear to me very useful and interesting. I also think that the subject is mainly important in order to develop more natural AI.


From a global view the paper is well written and very interesting. I really appreciate it and I definitively think that authors are on a very good track.


My main concern the task itself. The authors try to find some dialogical relations based on the idea of SDRT.

The approach use a wide board definition of dialogue dependency information. It seems that this corresponds to the type of dialogue use in the data, but I’m not convince that can really fit to real life conversation which are more complex.

I also believe that a classification of these relations can be useful. Especially dialogue is composed of turn that have specific relation with the context in a very different way that what we found in discourse. This should be considered in the definition of the algorithm.

To sum up here it seems to me that the goal is to find an attachement point for a unique relation. The complexity of the task will dramatically increase if you use a more realistic description.



I am a bit confuse with the result of the table 6. It shows that the average thread value for UbuntuV2 and DSTC7 is between 1.39 and 1.5. This seems to me that you only need the previous turn and sometimes the one before in order to decide the attachment. This is really against the idea of dialogical structure. So either the proposal does not correspond to the notion of a dialogue or the data are very unrepresentative of what a dialogue is. This weakens the fact that we have particularly good results for these datasets. In the end, it comes close to the previous remark, the notion of dialogue is not sufficiently integrated in the description.



Once again, I’m not sure that the last sentence of the conclusion is really a good point.



Some more minor remarks about the work:

- I’m quite surprise about the footnote number 2. Turn and utterance are different things and you should choose

- In the algorithm 1 C_{tmp} is define with the goal of the algorithm directly… I would prefer a more accurate definition.

- Equation 4, a link with s_m would be helpful.

- Table 1 about the statistics of the datasets is not clear. It is turns? words? characters? be more precise.



typos

- section 2.2 thead

- section 4.3 first paragraph, last sentence starts with an extra space.

* 5. Why should this paper be presented at IJCAI-PRICAI 2020?
    * The track is really important and challenging for AI.

	* The results are good and the experiment very interesting.

======================================================

Reviewer #4
Questions

* 4. Comments to authors
    * Summary

In this paper, the dependency information of dialogue is included in the multi-turn response selection task. First, a novel concept thread is introduced in the article, which refers to a collection of sentences that have dependencies in the dialogue history. Secondly, a dialogue extraction algorithm is proposed to transform the dialogue history into threads. Then, the threads are used as the input of the Thread-Encoder model, and the threads and candidates are encoded into a compact representation through a pre-trained Transformer. Finally, the matching score is obtained through the attention layer. The experiments are based on DSTC7, DSTC8 and UbuntuV2 datasets, and the results verify the validity of this model.



Contributions

1.The paper introduces the dialogue dependency information into the response selection task, and reveals the role of the dependency relationship in the dialogue history in predicting the dialogue response.

2.It designs an algorithm that extracts several threads from the conversation history. This algorithm can better use the predicted dependencies to segment the conversation.

3.The proposed thread encoder model uses multiple threads obtained by segmenting the conversation to generate corresponding representations using a pre-trained language model, thereby realizing the response selection task. The model incorporates dialogue dependency information and obtains good experimental results.



Weaknesses

1.In the experimental results shown in table 3 (1) On the UbuntuV2 dataset, the result of Thread-Enc is slightly worse than the result of Poly-Enc. What is the reason? (2) UbuntuV2 and DSCT7 are both two-party dialogues. Why does the result of UbuntuV2 drop slightly while the result of DSCT7 does not appear to be this way?

2.Combining table3, table4, and the analysis of table6, the method proposed in the article is not so prominent in the two-party dialogues? It is difficult to say that the model is equally valid for two-party dialogues and multi-party dialogues.

* 5. Why should this paper be presented at IJCAI-PRICAI 2020?
    * (1)For the first time, this paper introduces the dialog dependency into the response selection task and proposes the thread encoder model.

(2)The author's idea is novel while achieving better experimental results in multi-party conversations.

======================================================

Reviewer #5
Questions

* 4. Comments to authors
    * - It is good to see that the paper integrates the discourse analysis results to improve the dialog next turn prediction task. In terms of using the discourse labels, it could be expensive to consider all 16; however, there could be other ones being strong indicator of "thread-ship" as well, especially for multi-party dialog. Is it possible to share a bit more insight that if "reply-to" is sufficient for the thread extraction for the task?



- Does each turn only belong to only one thread?



- How are the results comparing to what's reported for DSTC8 track 2 subtask 2 (https://arxiv.org/pdf/1911.06394.pdf)?



- Are Figure 1 and Figure 2 based on the same example? Maybe improve the indexing to make the reference easier.
