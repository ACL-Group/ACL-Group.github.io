rebuttal 

#20228
Thank you for your suggestions and the issues raised about our manuscript, especially with the presentation.

- The numbers in Table 7 is an average of cosine similarities between translations and the source terms, so there is no scale.

- Yes, we focus on socio-linguistic terms to i) reduce the size of the lexicon and ii) take advantage of sentiment and opinion words because we believe these words better reflect general cultural differences. For other domain specific applications, more specialized lexicons may be used.

- We will explain word2vec and the numbers in Table 7 in the revised paper. Thank you very much again.

#22886
Thank you very much for your comments and suggestions.

- The bilingual social-linguistic lexicon (BSL) contains a list of L English-Chinese word pairs which are direct translations. The SocVec of an English word W is an L-dimensional vector, where each dimension is the cosine similarities between W's word vector and an English word in the bilingual lexicon. Similarly, the SocVec of a Chinese word is also an L-dimensional vector. The two vectors are comparable because of the one-to-one correspondence between English and Chinese words in the BSL. This is explained in Fig. 1 and Sec "Projecting EnVec and CnVec into SocVec Space". We can make it more explicit in the revision.

- Yes, we should make it clear that our framework is generally applicable to any pair of languages, so long as we have a bilingual lexicon for the pair and the social-linguistic lexicon for one of the languages.

- There is no overlap in terms of entities and slang terms. 

- We made these statements based on our experimental results. In the revision, we will clarify that our findings are from the three popular translation services on our own set of slang terms.

- We will do thorough proofreading over the whole paper in the revision.

#26453
- Both tasks compute cultural differences, one on named entities and the other on slang terms. Their common challenge is the incompatible semantic spaces between two languages. We attack this by building a BSL from which a shared vector space is induced.

- Opinion related words are better at capturing perceptions. Also, our BSL contains not only polarized words but also neutral and objective terms.

- Chinese/English pair because, i) the differences between eastern and western cultures are salient; ii) authors are familiar with these languages. Note our approach requires no specific knowledge of the languages, except that word embedding for each is required.

- Symbols are correct (see para 1).

- We meant *commonly* used words.

- C_U/E_W are defined in caption.

- The construction of BSL is asymetrical. An English social word is translated into N Chinese words that combine into a pseudo word. BSL contains no original Chinese words.

- All four annotators are native Chinese speakers but bilingual. Two of them lived in the US extensively.

- Wikipedia calls 0.531 kappa moderate agreement. Moreoever, kappa for the binary class labels (1/2 -> neg, 4/5 -> pos) is 0.672 and significant.

- Our BSL was constructed from general purpose resources, that are *not* specially tailored to slang terms. Table 7a not only compared with standard translators, e.g., Google and Bing, but also CC-CEDICT, which is specialized for slang. Our approach outperforms all of the peers.


#27738
Thank you for the precious comments.

- Indeed there are existing projection methods. Our motivation is to leverage a bilingual social-linguistic lexicon containing opinion and sentiment words. We did compare with a representative projection method (LTrans).

- The paper you mentioned shows that translation of textual datasets and sentiment lexicons can benefit sentiment analysis of low-resource languages. But our reason(ii) is about the translation of the entities and all the common words.

- we use the Bing Translator API, which offers additional confidence scores and many translation options not shown on the web site.

- We offered some example words in socio-linguistic lexicons in 3.1 and detailed descriptions are in the reference. We chose these because they are popular sentiment analysis text and contain a wide range of classes.

- Our annotators are educated with many examples and they have shared understanding of the five grade levels. Ranking based annotation method demands annotators to look at 40+40 words for the two terms in two languages before a decision, which is expensive and hard to administer in our opinion. Please refer to rebuttal for review #26453 for more on the annotation.

â€” We use MAP for classification problems. The classification problem is illustrated in 3.2.1 "For classification problem" 

- Our goal is a bilingual lexicon induction for slang terms, so the final result should be their slang meaning. We will clarify more.

