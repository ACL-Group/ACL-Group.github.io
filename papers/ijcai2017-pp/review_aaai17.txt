Dear Kangqi Luo,

Thank you for your submission, Paraphrasing Natural Language Relations to Knowledge Base Schemas (#1831), to AAAI-17. Author responses will be accepted between now (Thursday, October 27) and 11:59 PM PDT Saturday, October 29. No extensions will be granted. During this time, you will be able to read the current reviews for your paper and have the option to submit a response of up to 500 words.

PLEASE READ THE FOLLOWING POINTS:

* An effective response will identify any factual errors in the reviews and focus on any questions posed by the reviewers. It is normally ineffective to attempt to provide new research results, dispute matters of judgment, or reformulate the presentation. Try to be as concise and to the point as possible.

* Submitting an author response is optional; it is not a requirement.

* The reviews are provided as submitted by the PC members, without any coordination between them. Thus, there may be inconsistencies. Furthermore, these are not the final versions of the reviews, since they will be updated to take into account your feedback and any discussions among PC members.  It might also be necessary to solicit additional reviews after the author response period has closed.

* The program committee will take author responses into account during the discussion period. We will strongly encourage reviewers to update their reviews to reflect the discussion and react to your response; however, we cannot guarantee that all reviews will be so updated.

* No edits or deletion of comments are possible after the response has been submitted on EasyChair. We urge you to write your response offline and insert the text of your final version. Only a corresponding author is able to enter the response.

* Only the corresponding author(s) receive this message.

The reviews on your paper are attached to this letter.  To submit your response you should log on the EasyChair Web site https://easychair.org/conferences/?conf=aaai17 and select your submission on the menu.

Thank you,

Satinder Singh and Shaul Markovitch
AAAI-17 Program Co-chairs

===========================
Scales used in the reviews:

Significance of the Contribution
Does the paper contribute a major breakthrough or an incremental advance?
3: substantial, novel contribution
2: modest or incremental contribution
1: minimal or no contribution

Soundness
Is the technical development correct or does the paper exhibit inaccuracies?
3: correct
2: minor inconsistencies or small fixable errors
1: major errors

Scholarship
Is the work well positioned with respect to the existing literature? If relevant references are missing, please provide examples in your comments to the authors.
3: excellent coverage of related work
2: relevant literature cited but could expand
1: important related work missing or mischaracterizes prior research

Clarity
Assess the clarity of the presentation and reproducibility of the results.
3: crystal clear
2: more or less readable
1: hard to follow

Breadth of Interest
Would the paper attract broad interest or is it targeted to a narrow audience?
4: broad interest across AAAI audience
3: some interest beyond specialty area
2: interest limited to specialty area
1: out of scope

SUMMARY RATING
Scores from + to +++++ indicate that the submission could be accepted (with either a poster presentation or a talk). The stronger your feeling, the higher your score. Scores from - to ----- indicate that the submission should be rejected. The summary rating does not need to be an "average" of the other ratings.
Range: +++++ (= Best), ++++, +++, ++, +, -, --, ---, ----, ----- (= Worst)

==============================================================
----------------------- REVIEW 1 ---------------------
PAPER: 1831
TITLE: Paraphrasing Natural Language Relations to Knowledge Base Schemas
AUTHORS: Kangqi Luo, Xusheng Luo and Kenny Zhu

Significance: 2 (modest or incremental contribution)
Soundness: 2 (minor inconsistencies or small fixable errors)
Scholarship: 2 (relevant literature cited but could expand)
Clarity: 2 (more or less readable)
Breadth of Interest: 3 (some interest beyond specialty area)
SUMMARY RATING: 1 (+ (weak accept))

----------- Summarize the Main Contribution of the Paper -----------
The paper describes a method for aligning open-IE-style lexical relations with the predefined relation types in a curated Knowledge Base. The approach assumes relation arguments have been successfully linked to KB entities and then uses these entity pairs to search for relational path patterns in the KB. Once a set of path patterns for a given textual relation has been pruned based on coverage of the training data, the paths are specialized by adding adjunct relations and entity properties as constraints. These specializations leverage recurring knowledge in the KB about the seed entities to avoid overly general mappings.

----------- Comments for the Authors -----------
The work addresses a fairly common task: how to align corpus-based semantic representations with an curated KB schema. Using seed entity pairs to search for relational paths is not particularly novel, but it works on this dataset. Specializing the patterns by adding adjunct relations and entity properties is a nice extension, and appears to improve precision without affecting recall. The paper would benefit from careful editing for grammar. The list of errors below is not exhaustive.

In section 4.1, you state that the skeleton baseline did not have "acceptable" precision and that the schema approach produced "a much better result" because its F1 was higher. These are judgements based on assumptions about preferences between precision and recall. The judgements are not really necessary. Simply state the factual results (skeleton has better recall, schema has better precision and F1).

The example skeleton in footnote 2 would be much more intuitive if you included the relation types.

The "singer" example in section 4.3 is strange. Is the relation really "(singer) is performed in (LOC)"? Should it be "performed in"? If not, then the strangeness of the example is distracting.

Grammar/spelling/typos

p1: "extract binary relation" --> "relations"
p3: "Due the lack" --> "Due to the lack"
p3: "existing entity linking tool" --> "tools"
p3: "hundreds of different predicate" --> "predicates"
p3: "With candidate schemas been generated" --> delete "been"
p3: "produce less irrelevant entities" --> "produce fewer irrelevant entities"
p4: "takes a relation instances" --> delete "a"
p4: "and predict whether" --> "and predicts whether"
p4: "we use Freebase dump in June" --> "we use the Freebase dump of June"
p4: "manually inspect top 1,007" --> "manually inspect the top 1,007"
p4: "compare our approach with state-of-the-art" --> "... the state-of-the-art"
p5: "close world assumption" --> "closed world assumption"
p5: "semantic different but lexical similar" --> "semantically different but lexically similar"
p5: "instances represents" --> "represent"
p5: "lacks of necessary" --> delete "of"
p5: "Markov Logical Network" --> "Markov Logic Network"
p5: "One branch of QA techniques are semantic parsing based, it translates" --> "Some QA techniques are semantic parsing based; they translate"
p6: "Another branch of QA techniques are" --> "Other QA techniques are"
p6: "which first retrieves" --> "retrieve"
p6: "who also uses" --> "use"
p6: "a set of input table" --> "tables"
p6: "three-steps technique" --> "step"
p6: "and finally ranks" --> "rank"
p6: "Though first two steps" --> "Though the first two steps"
p6: "support more complex relations" --> "supports"
p6: "in proportional to" --> "in proportion to"
p6: "size of input" --> "size of the input"

----------------------- REVIEW 2 ---------------------
PAPER: 1831
TITLE: Paraphrasing Natural Language Relations to Knowledge Base Schemas
AUTHORS: Kangqi Luo, Xusheng Luo and Kenny Zhu

Significance: 2 (modest or incremental contribution)
Soundness: 3 (correct)
Scholarship: 2 (relevant literature cited but could expand)
Clarity: 2 (more or less readable)
Breadth of Interest: 3 (some interest beyond specialty area)
SUMMARY RATING: 1 (+ (weak accept))

----------- Summarize the Main Contribution of the Paper -----------
The paper studies the problem of discovering structures in knowledge bases that can represent complicated relations. It generalizes path representation by adding constrains along paths.

----------- Comments for the Authors -----------
The paper studies the problem of discovering structures in knowledge bases that can represent complicated relations. It generalizes path representation by adding constrains along paths.

The paper is well organized and is very easy to follow. The problem is interesting---providing readable and explicit relation schema is useful in many scenarios. 

My main concerns about the paper is the discussion of related literature and adequacy of comparison with previous work.

While this work aims to extract explicit graph structures to represent relations, there have been a large volume of work using implicit information and structures (e.g., word and relation embedding) to augment relations using structured, unstructured data, or both, which should be discussed more carefully in the literature review.

There is no direct comparison designed to compare the current model with recent work that uses neural nets, which leaves some major open questions about the effectiveness of proposed methods; e.g., if learning explicit structures/schema comes with the sacrifice of performance on knowledge graph inference/completion; particularly, there have been much previous work on KBC that have not been compared. 

Could some complicated relations have no explicit or symbolic structures/schema? Some discussion would be helpful.

----------------------- REVIEW 3 ---------------------
PAPER: 1831
TITLE: Paraphrasing Natural Language Relations to Knowledge Base Schemas
AUTHORS: Kangqi Luo, Xusheng Luo and Kenny Zhu

Significance: 2 (modest or incremental contribution)
Soundness: 2 (minor inconsistencies or small fixable errors)
Scholarship: 2 (relevant literature cited but could expand)
Clarity: 1 (hard to follow)
Breadth of Interest: 2 (interest limited to specialty area)
SUMMARY RATING: -1 (- (weak reject))

----------- Summarize the Main Contribution of the Paper -----------
In this paper, the authors first define a generalized representation of natural language relations in a knowledge base, called schema, then propose a method to generate such schemas, and apply the schema to do inference over the KB.

----------- Comments for the Authors -----------
This work is targeted to deal with the problem of knowledge completion, they claim that one limitation of the path ranking algorithm is that a path of predicates may not be accurate enough to represent a complex relation. So they proposed to define the notion of a schema to provide a generalized representation of relations. The idea looks interesting. However, it is not clear what are the difference between their approach and the approach for schema induction or approach for rule induction, where logical schemas are generated and can be applied to do inference, see the following:

Statistical Schema Induction by J Völker et.al.

Fast Rule Mining in Ontological Knowledge Bases with AMIE+ by L Galárraga et.al.

A comparison with these approaches is needed.

Also, there are many approaches for knowledge completion, which are missing from the references, such as the following ones:

Knowledge Base Completion via Coupled Path Ranking by Quan Wang et. al.

Holographic Embeddings of Knowledge Graphs by M Nickel et.al.

Some formulas are provided in section 3.2, but they are not analyzed, it is not clear why they are reasonable. Furthermore, it is hard to understand these formulas. It is said that \theta is the vector of schema probability distribution, but what is schema probability distributions? how can we make a vector for the distribution? What is sc_j in formula (2)?

The experiments should be extended by comparing the new method with some others, such as the related approaches listed before (Gardner et al. (2015) is just one of the methods for KBC, not really the state-of-the-art). For example, they should consider generate rules by AMIE+, then apply the rules to generate new relations. Furthermore, instead of comparing the precision and recall, they should also compare the overlap of the result of their method and those of other methods. Furthermore, the authors should evaluate the quality of generated schemas.
