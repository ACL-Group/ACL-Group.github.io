# 12747:
Thank you for the suggestion. We will definitely improve the English and revise some of the wordings particularly in the approach and the evaluation sections.

# 23310:
1. “This paper proposes a novel unsupervised framework to … some employed existing approaches are conventional … since the aspect taxonomy could be regarded as a knowledge graph, the recent well-performed knowledge representation and reasoning approaches should be used instead such as deep random walk” 
Response:
After constructing the aspect taxonomy, we have the observation that the 
hubs that have many supporters in the taxonomy tend to be more important. 
The proposed personalized random walk algorithm is more suitable to handle 
this situation. To the best of our knowledge, we are first to define and
propose a solution for the prominent aspect extraction problem and our 
unsupervised framework achieves a satisfactory performance on this task. 
The deep random walk algorithm is worth further investigation in the 
future work.

2.“Minor error”
Response: Thank you for your careful reading, and we will definitely fix 
minor errors in the revised version. 

# 25520:
1.“the three syntactic patterns are a bit limited...”
It is a good idea to use other patterns. However, for our problem, the prominent aspects are always modified by some adjectives. 
2."why not starting from a more performing WSD algorithm than Lesk?"
We use a popular WSD toolkit (pywsd) for the comparison results. For the WordNet synset matching problem, Lesk is one of the best-performing algorithms available in that toolkit by preliminary evaluation. Thus, we use it as a strong baseline for our WSD method.
3."..representation of the context: how are these vectors computed?.."
The computation of the context vector is described in equation 1. We use GloVe embeddings for the context vector computation.
We use the Skip-gram trained embeddings in the k-means clustering algorithm. We will improve the presentation of this part.
4. "..the lack of a proper reference dataset.."
We did provide a URL of our evaluation dataset in the paper. If that URL is inaccessible, you can also download the dataset from: 
https://www.dropbox.com/s/hrhkk7q3kfh8z46/eval-dataset.txt?dl=0 . We did not remove the duplicate labels for the qualitative evaluation. We formalize our hard accuracy metric as follows and will revise accordingly in the revised version.
Formally, A(m, c) = [a_1,.., a_5] denotes the 5 prominent aspects generated from model m given the category c. 
[l_1,.., l_{25}] is the 25 ground-truths annotated by humans. 
The hard accuracy is defined as:
	hit(A(m, c), l_i) = 1 ,if l_i\in A(m, c); 0, otherwise.
	hacc(m, c) = 1/25 * \sum_{i=1}^{25}{hit(A(m, c), l_i)}
5. “..in that it convinced me that.., but the overall quality is still uncertain”
Table 3 shows the performance of the proposed framework outperforms the AmodExt baseline. Our approach beats AmodExt in all product categories by hard accuracy and loses to AmodExt only in restaurant category by soft accuracy by a narrow margin. Please refer to the released evaluation dataset for validation.


# 26621:
1. “There are many grammatical errors and typos”
Thanks for your careful reading. We will definitely fix all 
the typos and grammatical errors.

2. “Some unexplained or suddenly appeared terms and symbols ...”
Yes, we will improve the representation. $a_i$ represents the 
aspect candidate, and $n$ is the number of synset candidates.

3. “ABAE model is mentioned without citation.”
Yes. There is supposed to be a reference of He. et. al (2017) there, 
which was unintentionally omitted. 

4. “I were also confused by the evaluation method about the aspect 
extraction ...”
We will definitely improve the representation. Please refer to the response of 
Q4 for review #25520.

5. “Another quite confusing part is the word embedding. Did you use SkipGram or Glove, or both of them?”
We will improve the description of the embedding usage in the 
revised version. To compute the context vector, we use the GloVe embeddings 
with 300 dimensions, trained from 840B tokens using common crawl data.
For more details, please refer to the response of Q3 for review #25520.

4. “Important or state-of-the-art related works are missed for discussion 
or comparison.”
Thank you for pointing out a few relevant papers. Our goal in this paper is to extract top K prominent aspects, which is a new problem different from the traditional aspect extraction problem studied by the papers you mentioned. 
Also, the state-of-the-art neural network model for traditional aspect extraction problem is not directly applicable in our problem. Therefore, we picked the most recent work (i.e. [6]) among these and discussed
it in the related work.

The prominent aspects are more important and well-generalized to represent 
the key characteristics of the product/service. The most recent and 
comparable work is ABAE by He et al.(2017). We will further clarify the 
differences between our work and the papers you mentioned in the final version.

