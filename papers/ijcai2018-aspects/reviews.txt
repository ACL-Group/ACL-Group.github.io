Review #12747

Comments to Authors.

This paper tackles the issue of reviews summarization with respect to different review aspects. To this aim an unsupervised method is proposed, aimed at extracting from textual reviews the prominent aspects (words and phrases) for a given type of product.

The considered research issue is interesting, however the paper presents some limitations:

1) the writing style is not accurate; there are in fact several mistakes and typos

2) form a technical point of view the proposed method is not well presented. The main phases in which it is articulated are only superficially reported and sometimes confusingly developed, and some technical aspects are not sufficiently explained.

3) the experiments are not well presented  



Review #23310

Comments to Authors.

This paper proposes a novel unsupervised framework to aspect extraction task. Experimental results show that the proposed framework is effective and achieves better performance.

The proposed four-stage approach is simple and straightforward.

Overall, I have several comments as follows:

First, the framework seems to be the combination of existing techniques and some employed existing approaches are conventional and not the state-of-the-art approach. For example, since the aspect taxonomy could be regarded as a knowledge graph, the recent well-performed knowledge representation and reasoning approaches should be used instead such as deep random walk (Li et al., 2016, Dallmann et al., 2016), neural networks (Socher et al., 2013)

Li J, Zhu J, Zhang B. Discriminative Deep Random Walk for Network Classification[C]// Meeting of the Association for Computational Linguistics. 2016:1004-1013.

Dallmann A, Niebler T, Lemmerich F, et al. Extracting Semantics from Random Walks on Wikipedia: Comparing learning and counting methods[C]// Tenth International AAAI Conference on Web and Social Media. 2016.

Socher R, Chen D, Manning C D, et al. Reasoning with neural tensor networks for knowledge base completion[C]// International Conference on Neural Information Processing Systems. Curran Associates Inc. 2013:926-934.

Second, in Experiments section, the implementation of baseline model ABAE is not clear, is it exactly the model proposed by He et al., 2017? Besides, some recent baseline approaches are missed, for instance Wang et al., 2015.

Linlin Wang, Kang Liu, Zhu Cao, Jun Zhao, and Gerard de Melo. 2015. Sentiment-aspect extraction based on restricted Boltzmann machines. In Proceedings of ACL-2015.

Minor error:

(1)    Sec 2.3 import -> important




Review #25520

Comments to Authors.

This paper presents work related to aspect-based sentiment analysis, a task that gathered great interest from onlint businesses and review sites recently. In particular, this work is concerned with the automatic discovery of the aspects in a set of reviews.

At the motivation level, I am still not entirely convinced that this task is significant, when in practice all the websites that offer faceted reviews propose fixed sets of aspects based on the product type.

The proposed approach follows a pipeline architecture: candidate aspects are extracted from reviews with simple syntactic patterns, then the WordNet taxonomy is used to filter out aspects in a hypernym-hyponym relation, and finally they are ranked with a page-rank-like algorithm on the WordNet sub-tree.

Concerning the first step, the three syntactic patterns used for candidate extraction are a bit limited, considering only adjective-noun constructions, and thus excluding any other possibility (e.g. "the room is filthy", "this camera does not cost much"). I wonder how many candidates are lost due to this oversimplificaiton. Some discussion would be interesting here.

In the second step, the Lesk WSD algorithm is used and then extended by including the glosses as additional context ti improve the disambiguation. A number of questions arise: why not starting from a more performing WSD algorithm than Lesk, which is considered practically a baseline? Word embeddings are used to compute a representation of the context: how are these vectors computed? Is the GloVe resource used at this step? Or are the embeddings computed on the review corpus, as it seems from reading 3.2? This section is a bit confusing on the details, which should be clarified. The presentation in general, besides the lack of detail in some points, suffer from a language at times a bit sloppy (e.g. word2vec and GloVe are both misspelled).

The other steps of the pipeline are more clearly explained, and in my opinio nthey represent the main contribution of this paper. 

The quantitative evaluation is straightforward, but it suffers from the lack of a proper reference dataset. From the few details on the construction of the gold standard, I have doubts on its quality. For instance: who are the annotators? Why 5 aspects and not 3 or 10? What indications were they given? How are the duplicates processed?

The qualitative evaluation is also limited, in that it convinced me that overlapping aspects are eliminated, but the overall quality of the aspect extraction is still uncertain. In some cases, the aspects extracted by AmodExt seem to me better than ExtRA in Table 4.

To summarize, I think that the contribution of this work is interesting but limited, and the presentation can be improved.




Review #26621

Comments to Authors.

The paper proposes an unsupervised approach to extracting prominent aspects for a product/service from user reviews. To achieve that, the authors developed a four-step framework that consists of aspect candidate extraction, aspect taxonomy construction, aspect ranking, and aspect generation. The idea of extracting (top K) prominent aspects is interesting and well motivated. However, some important issues remain in this paper. My detailed comments are listed below.

 

1. There are many grammatical errors and typos. I hope the authors can make effort to avoid them in the future version of this paper. I list some of (but not limited to) them below:

(a) but are actually discuss similar aspects -> but actually discuss similar aspects

(b) our framework, ExtRA, extract -> extracts

(c) is very import for -> is very important for

(d) most probable word -> words

2. Some unexplained or suddenly appeared terms and symbols in section 2 make the technical part somewhat unclear. For example, following Equation (1), the “embedding” of $a_i$ is mentioned but without any introduction or explanation. Where is the embedding from? In section 2.4, what is $V_b$? It is also not clear what the symbol $n$ means in Equation (4).

3. The experiment section should also be improved for clarity. ABAE model is mentioned without citation. I were also confused by the evaluation method about the aspect extraction, given the sentences like “we calculate the percentage of the 25 labels that match one of the 5 aspect terms…”. I were not sure about where “the 25 labels” come from, nor do the “the 5 aspect terms”. Do you mean the top 5 aspect terms? Another quite confusing part is the word embedding. Did you use SkipGram or Glove, or both of them? You mentioned SkipGram in section 3.2 but Glove in 3.3. If you have used both of them but for different purposes, you should justify this clearly. If so, you also need to give which set of pre-trained vector in Glove you have used in section 3.3, as Glove provides 100, 200, 300 dimensional vectors. In addition, SkipGram is from the word2vec package but Glove is not (notice that you mentioned pre-trained wrod2vecs (Glove 2014)).

4. Important or state-of-the-art related works are missed for discussion or comparison. I list some of them below. The author introduced and grouped the related works in section 4, which is good, but the cited works are in fact insufficient. The topic models discussed in section 4 and compared in section 3 are not focused and not state-of-the-art enough. For example, [1][2] are more recent and specific topic models designed for the aspect extraction purpose, but they are not cited, discussed or compared in this paper. Likewise, [3][4] are state-of-the-art neural network based methods. Also, [5] (not cited) used random walk and [6] (though cited) used semantic similarity for aspect extraction, which is technically related to the proposed approach in this paper. A comparison or discussion is thus needed.

 
[1] Mukherjee and Liu. Aspect extraction through semi-supervised modeling. ACL 2012

[2] Chen et al. Exploiting domain knowledge in aspect extraction. EMNLP 2013

Minor issues

[3] Wang et al. Sentiment-aspect extraction based on restricted boltzmann machines. ACL 2015

[4] Poria et al. Aspect extraction for opinion mining with a deep convolutional neural network. Knowledge-Based Systems 2016

[5] Liu et al. Opinion Target Extraction Using Partially-Supervised Word Alignment Model. IJCAI 2013

[6] Liu et al. Improving Opinion Aspect Extraction Using Semantic Similarity and Aspect Associations. AAAI 2016

