\section{Introduction}
\label{sec:intro}
Commonsense represents the worldly knowledge that is agreeable to most people.
For example, it is commentsense that if it snows then it's cold. 
One can hardly find complete records nor cite the origin of such knowledge.
Commonsense causality is one kind of commonsense knowldge which 
encodes causal dependencies between actions, states or events.
Causality is an asymmetric relation as the relation is directed
from \emph{cause} to \emph{effect}.
Commonsense causality is repeatedly mentioned in all kinds of text corpus but hard to mine out because of the sparsity. 
Commonsense causal reasoning aims to find out the most possible causality between events, measuring whether one event can lead to another.

Prior works on commonsense knowledge base include WordNet~\cite{miller1995wordnet}, ConceptNet~\cite{havasi2007conceptnet} and 
WebChild~\cite{tandon2017webchild}.
WordNet is a handcrafted ontology which encodes both semantic 
and lexical relations between word senses. WordNet contains less than 
5.5 thousand causal relation pairs, all of which between verb synsets. 
Besides, the causality among those pairs are usually not commonsense 
but more like entailment. For example, synset $use\_v\_1$ causes 
synset $apply\_v\_2$ and $spark\_v\_1$ causes $happen\_v\_1$.
ConceptNet is a larger semantic network constructed by community efforts.
It contains many relations like $IsA$, $AtLocation$, $HasProperty$ and so on. 
Among all the relations, $causes$, $CausesDesire$ and 
$HasPrerequisite$ assume commonsense causality. ConceptNet contains around 
17 thounsand cause pairs and most events in such pairs are phrases 
rather than words.  WebChild proposed a framework to automatically harvest 
commonsense knowledge from large web corpus. It includes 19 
relations such as $hasProperty$, $isMemberOf$ and so on. 
However it contains no knowledge about causality.

Because there's no high quality, large-scale commonsense causal knowledge base, 
researchers work actively on the causality acacquisition problem. 
Current work on this area focuses on extracting causality between events, 
such as causality between verbal events~\cite{bethard2006identification,beamer2009using,riaz2010another,riaz2013toward}, nouns~\cite{girju2002mining,girju2003automatic}, noun-verb/predicate-argument events~\cite{riaz2014recognizing,hashimoto2014toward,zhao2017constructing} and entities~\cite{radinsky2012learning}.
Restricted by the definition of events, the number of output causal 
relation pairs are too limited -- ranging from thousands to millions-- 
to be used in large scale reasoning tasks. 
Luo~\cite{luo2016commonsense} proposed a data-driven method to 
extract cause-effect terms of nouns, verbs, adjectives and adverbs which 
include around 62.6 million causal facts. They give a score for 
each causal pair to solve the problem of causal reasoning between short texts. 
However, such method~\cite{luo2016commonsense,zhao2017constructing,gordon2011commonsense,roemmele2011choice} relies more on statistical features, 
which means only frequently 
co-occurring word pairs~\cite{zhao2017constructing} get a score. 
Our method skips the definition of event, instead generates 
vector representations of cause/effect role for each word and 
those vectors can then be used to calculate the word-level causality scores. 
In this paper, we name the amount of causality between events 
as \emph{causal strength}, and  $SC$ in short.

For word $w$, we assume that it plays the cause(effect) role 
when it appears in the causal(effect) span in one cause-effect pair. 
For example:
\begin{example}
\noindent
\label{eg:sen}
\begin{itemize}
	\item[(1)] In 1998 the Pont du Gard was hit by major \textbf{flooding} which caused widespread damage in the area.
	\item[(2)] Rainfall is occurring as heavy downpours that cause \textbf{flooding}.
\end{itemize}
\end{example}
In the first sentence, ``flooding'' plays a cause role while in the second sentence it plays an effect role. Therefore, we propose two vectors, $\overrightarrow{c_w}$ and $\overrightarrow{e_w}$ to represent word $w$ for cause role and effect role.
\KZ{Mark the cause and effect spans in the above example. I think the above para about our solution can be expanded a bit, to say we use CBOW and an iterative
algorithm to train two matrix, blah.}

Our main contributions are:
\begin{itemize}
	\item We develop a framework to train two embedding spaces for
two types of causal roles (cause and effect) from large text corpus 
(\secref{sec:approach}).
	\item Causal strength between any two words in the vocabulary can be 
computed by the causal embedding even if they ever co-occurr in the 
training corpus (\secref{sec:experiment}). \KZ{Give examples in the experiment section.}
	\item Our dataset shows good ability for reasoning and predicting 
the most possible cause given effect or vice versa (\secref{sec:app}).
\end{itemize}
