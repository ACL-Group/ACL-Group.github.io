\section{Introduction}
%\KZ{Generally speaking, the English in the whole paper is still sloppy.
%You need to carefully proofread the whole thing at least twice!}

Commonsense knowledge, lying in the core of human cognition,
can be represented as short-phrase concepts and relations among those concepts. 
Commonsense knowledge can underpin a commonsense reasoning process. 
%For example, 
%given a dress made for 5-year-old girl, it is common for human to tell that ``cute'' is a more appropriate term than ``sexy'' for describing the dress.  
\begin{example}
	Given a dress made for 5-year-old girls, it is common for human to tell that ``cute'' is a more appropriate term than ``sexy'' for describing the dress. 
\end{example}

\begin{example}
	For the material of making an umbrella, human will mostly choose polyester rather than cotton since umbrella should be waterproof.
\end{example}

Such inference backing on commonsense knowledge may be 
trivial for humans, but it is not easy for 
machines to make the right choice even if they have been trained on 
large scale textual corpora.

In recent years, 
%technique of machine learning include deep neural networks develop fast. 
machine learning models especially deep neural networks have 
achieved remarkable success. 
%之前这里列的是相关任务，然后感觉给reviewer造成了误解，于是直接改成surpass的文章
The performance of machines even surpass humans on some tasks
such as machine reading comprehension~\cite{lan2019albert,zhang2019dual}, image classification~\cite{he2015delving}, and question answering~\cite{ju2019technical}.
%such as machine reading comprehension\cite{he2018dureader,rajpurkar2016squad,lai2017race}, image classification\cite{he2015delving}, and question answering~\cite{reddy2019coqa}.
%(CoQA)
Particularly, with the introduction of large pre-trained language models 
such as BERT~\cite{devlin2018bert}, 
state-of-the-art performances on a wide range of benchmarks in NLP are refreshed.
However, how much commonsense knowledge this kind of pre-trained models actually learn still remains a question.

An intuitive way
is to test the pre-trained models on different commonsense reasoning tasks.
Previous datasets include COPA~\cite{roemmele2011choice}, ROCStories~\cite{mostafazadeh2016corpus} and SWAG~\cite{zellers2018swag}, which all focus on inference between sentences or passages. 
For example, SWAG needs model to select the most plausible continuation among four choices given a sentence.
In these datasets, pre-trained language models like BERT may take advantage of rich contexts and perform well~\cite{devlin2018bert}. However, with the development of mobile devices and applications, there is a tendency that user-generated contexts become shorter and shorter.
We believe it is necessary to conduct the same experiments on datasets formed by short phrases with limited context.
 
In general, the majority of short phrases such as search queries contain less than 5
English words~\cite{hua2015short} or 3 Chinese words.
It is challenging to understand such short texts.
First, they lack contextual information. On the one hand, 
statistical methods such as word co-occurrence are not that effective when dealing
with short texts~\cite{chen2019research}. On the other hand, there is data sparsity problem since 
semantic features are scarce. % in short text. 
Second, short texts do not reflect the syntax of a written language. 
Therefore, the traditional natural language processing methods such as Part-Of-Speech tagging or dependency parser cannot be easily applied. 
Last, words in short text are more likely to be ambiguous. 
%For example, in a search query "watch Harry Potter", "watch" can either be a noun or a verb, and "Harry Potter" can be a movie, a book or the character in that movie. However, we humans can easily understand the query intent is searching for the movie resource according to our commonsense knowledge.
For example, in a search query ``basket of apples", ``apple" can either be a kind of fruit or a brand. We humans will mostly agree that the query intent is searching for fruit according to our commonsense knowledge as ``basket of electronic devices" is rare to most people.

%Unfortunately, none of the existing commonsense reasoning dataset targets on short texts. 
%感觉和commonses reasoning还是不太一样。
Unfortunately, none of the existing dataset targets on common sense in short texts.
To fill the gap, we propose a new dataset called Commonsense Contradiction (\textbf{CoCon}), consisting of 9,229 pairs of short phrases in Chinese. 
Each pair of phrases contains at least one contradictory phrase judged by the commonsense of humans, such as \textit{(children's sexy dress, children's cute dress)}.
%For example, one phrase pair is ``girl supplementary food" and ``baby supplementary food", where the latter one is more plausible based on the knowledge that complementary food aims at little baby less than 2-year-old.
All the phrases are collected from search queries on a popular e-commerce platform.
% 检测常识性矛盾的重要性
%Once machine can identify commonsense contradiction, it can friendly remind user of inputting implausible queries. It can also detect errors in machine auto-generated texts to make it more real, like written by humans. % 拟人化的
Once machine can identify commonsense contradiction, it can realize more useful applications and improve numerous web applications, such as:
\begin{itemize}
	\item reminds users when they input implausible queries
	\item detects errors in machine auto-generated texts to make it more real, like written by humans
	\item identifies meaningless concept in existing knowledge graph
\end{itemize}

Due to limited annotation resources, we first propose a novel framework to %preprocess raw queries and 
increase the percentage of raw search queries containing commonsense contradiction from 2.92\% to 86.48\% by filtering those with high possibilities to be plausible.
Crowd-sourced annotators are then asked to pick out phrases which are 
implausible from the filtered queries according to their common sense. 
For each implausible short phrase,
% which contains some sort of contradictory knowledge,
we next automatically generate a relative plausible phrase to form 
a phrase pair which share most words.
%Finally, five other annotators are asked to choose the more plausible phrase between each phrase pair. 
%Finally, each pair are annotated by 5 different annotators to choose the more plausible phrase in the pair.
%Only those phrase pairs successfully distinguished by four out of five annotators are added to our final CoCon dataset. 
Finally, each pair will be annotated by 5 different annotators and form our final CoCon dataset.

With the CoCon dataset, we propose a task called \textit{Contradiction Identification on short phrase}.
%On this task, 
The most representative model, BERT,  
without fine-tuning can only reach an
accuracy of 59.92\% on this new benchmark and 74.71\% after find-tuned using our constructed train set.
Meanwhile, human logs a 95\% accuracy, which shows that there is a long way to go for this task. 
% 也是应用
%Those future models which can achieve great result on our proposed task, can further help to improve numerous web applications, including the filtering of implausible web queries, identification of meaningless concept in existing knowledge graph and etc.  

We summarize our contribution as follows:
%, our contributions are:
\begin{enumerate}
	%\item We construct a new benchmark named CoCon using a novel method to generate short commonsense phrase pairs with limited annotation resources. The dataset is designed for evaluating the capability of commonsense reasoning for machines on short phrases.
	%\item We propose a novel method to generate short commonsense phrase pairs with limited annotation resources. \KZ{Negative sample generation is just one step in the whole
	%dataset construction framework. Why single it out here as a major contribution? Can this method be used for other more general tasks?}
	\item We propose a framework to construct dataset containing short commonsense phrase pairs with limited annotation resources. The methodology can be extended to other languages, see Section~\ref{sec:cocon}. 
	\item We release a new benchmark named CoCon for evaluating the capability of commonsense reasoning for machines on short Chinese phrases. 
	\item We conduct an empirical evaluation of state-of-the-art language models on CoCon dataset, showing that the performances of current models  are still lagging behind the human performance, see Section~\ref{sec:exp}.
	%\item We intend to release CoCon dataset, which can  benefit the research community for developing better machines to understand commonsense knowledge.
\end{enumerate}

