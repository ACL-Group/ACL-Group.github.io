\section{Related Work}

There are numerous datasets for evaluating machine intelligence on commonsense reasoning. COPA~\cite{roemmele2011choice} is made up of instances of one premise and two alternatives, asking for the correct answer by causal reasoning. SWAG~\cite{zellers2018swag} and HellaSwag~\cite{DBLP:journals/corr/abs-1905-07830} also focus on the causal inference. 
The task is to choose the best one from four alternative choices given the statement. ROCStories~\cite{mostafazadeh2016corpus} 
provides more context information and asks participants to choose plausible ending given a four-sentence story. SQUABU~\cite{davis2016write} and ARC~\cite{clark2018think} are two QA tasks for testing the scientific knowledge. CommonsenseQA~\cite{talmor2019commonsenseqa} is also a QA dataset asking model to select the correct concept as the answer of given question.% from four candidates using background knowledge.

%It should be noticed that the existing commonsense datasets are mostly concerned with either causal relation between two sentences, or an answer to a question which requires commonsense. 
%Those datasets all offer a relatively longer context different from short phrases in our released dataset. 
%However, as far as we know, there are no public dataset which focuses on short text for commonsense reasoning. 

It should be noticed that the existing datasets mostly provide a relatively longer context different from short phrases in our released CoCon dataset. As far as we know, there is no public dataset which focuses on short text for commonsense reasoning.

%Short text has several challenges: absent of context information, not standard on syntax and more ambiguous, which makes understanding short text be a more challenging task.
 
%Some previous researches used twitter posts\footnote{http://trec.nist.gov/data/tweets}, Chinese Weibo\cite{he2016extracting}, product review\cite{pang2005seeing} or news title\cite{vitale2012classification} where the average word numbers in each sample are mostly more than ten or even much longer. They did short text classification by integrating external knowledge\cite{wang2017combining,chen2019deep} or adapting memory network\cite{zeng2018topic} for reducing ambiguity. 

Previous short text researches use data from twitter posts\footnote{http://trec.nist.gov/data/tweets}, Chinese Weibo~\cite{he2016extracting}, product review~\cite{pang2005seeing} or news title~\cite{vitale2012classification}. Compared to their data samples' length, web search queries~\cite{pass2006picture,liu2011users,he2018dureader} are more close to our definition of short text.
However, those technologies use in web query understanding~\cite{hua2015short,wang2015query} may hardly be directly applied on our dataset. AOL query analysis\footnote{https://github.com/wasiahmad/aol\_query\_log\_analysis} shows that most queries are searching for person/location/organization entity, fact or an opinion. We also sampled 100 queries in one-day query log~\cite{liu2011users} from Sougou\footnote{https://www.sogou.com/}, which is one of the largest Chinese search engine. Only 3\% of them contain commonsense knowledge. 
Our constructed CoCon dataset % is extracted from user query on E-commerce platform, and contain
requires model not only understand semantic or syntactic structure of query, but also abundant commonsense knowledge to do the contradiction identification.

%However, the current public web query dataset~\cite{pass2006picture,liu2011users,he2018dureader} can hardly be used to construct a dataset that contains common sense. According to the analysis of AOL query log\footnote{https://github.com/wasiahmad/aol\_query\_log\_analysis}, 25.17\% queries contain person/location/organization entity. The rest queries also mostly focus on searching a fact or an opinion, which is irrelevant with commonsense. 
%Researches on short text mainly aimed at web search query understanding \cite{hua2015short,wang2015query}. 
%The length of web search query is more close to the definition of our short text. 
%However those public web query dataset~\cite{pass2006picture,liu2011users,he2018dureader} is quite different from samples in our dataset. According to the analysis of AOL query log\footnote{https://github.com/wasiahmad/aol\_query\_log\_analysis}, 25.17\% queries contain person/location/organization entity such as "michigan sex offender". For the rest queries, they also mostly focus on searching a fact or an opinion, which is irrelevant with commonsense. 
%\mx{does it need to get statistics for randomly select 300 queries from sougou query?}. 
%We also sampled 100 queries in one-day query log~\cite{liu2011users} from Sougou\footnote{https://www.sogou.com/}, which is one of the largest Chinese search engine. Among which, 
%43\% of queries asks for a source of video, song, essay or website; 
%13\% for an opinion, and
%10\% for an occurred effect. 
%34\% queries are about a concrete object, while only 3\% of them are associated with commonsense modifiers.
%In our dataset, commonsense phrases are in the majority as all samples are constituted by a thing with one or more modifiers, such as ``children's cute dress" or ``cotton swimwear".

%According to web query statistics in the paper of He et al.\shortcite{he2018dureader},  

%Compared to the previous commonsense dataset, 

%Current researches make great efforts for solving difficulties on short texts. Wang et al. \shortcite{wang2015query} and Hua et al. \shortcite{hua2015short} apply graph structure and Probase \cite{wu2012probase} to understand short query. The methods of \cite{dai2006detecting}, \cite{shen2006query} and \cite{sun2012short} extract auxiliary context information using search engines. Other methods integrate external knowledge such as \textit{isA} or \textit{isPropertyOf} relation in Probase or Yago \cite{suchanek2007yago} to help the neural network get better performance, such as CNN \cite{wang2017combining}, attention-based LSTM \cite{chen2019deep}. Zeng et al. \shortcite{zeng2018topic} proposed topic memory network which encodes latent topic representations for short text classification. For better measuring distance between short texts, Li et al. \shortcite{li2019classifying} adapt and optimize the original Word Mover's Distance \cite{kusner2015word} to get a competitive and efficient performance.
