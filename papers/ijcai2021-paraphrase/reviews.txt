Reviewer #4
Questions
1. [Summary] Please summarize the main claims/contributions of the paper in your own words.
In this paper,
authors propose a framework to refine paraphrase generation,
where a set2seq model is introduced to enhance the semantic information of commonly-used back-translation technology.
This set2seq model takes word set as input to generate target sentence.
Besides, the proposed framework can be used in any domain.
2. [Relevance] Is this paper relevant to an AI audience?
Likely to be of interest to a large proportion of the community
3. [Significance] Are the results significant?
Significant
4. [Novelty] Are the problems or approaches novel?
Somewhat novel
5. [Soundness] Is the paper technically sound?
Technically sound
6. [Evaluation] Are claims well-supported by theoretical analysis or experimental results?
Somewhat weak
7. [Clarity] Is the paper well-organized and clearly written?
Good
8. [Detailed Comments] Please elaborate on your assessments and provide constructive feedback.
Although this framework achieves good performance, there still exist some weaknesses:
1. This paper proposes a framework which can be applied in any domain, and set2seq-common indeed performs well in the low-resource domain (Twitter). However, the set2seq-common model is weak in other domains (such as MSCOCO).
2. In section 'Application on Translation Tasks', author does not compare the proposed framework with any other previous models. For example, UPSA model (Liu et al. 2020. Unsupervised paraphrasing by simulated annealing. In ACL).
Therefore, it cant not demonstrate the advantage of the proposed framework on data augmentation.
3. The formats of evaluation metrics shown in Table 1 are different. "rouge-1,2" <----> "R-1,2"
9. [QUESTIONS FOR THE AUTHORS] Do you have questions for authors to address during the author feedback period?
1.Finetuning is a commonly-used technology to solve the problem of low-resource domain adaptation. Why not finetune set2seq-common model on the target domain dataset?
2.Under the proposed framework, the combination of set2seq and seq2seq models is very simple. Have you try to enhance the interaction of them, for example, sharing the same decoder ?
10. [OVERALL SCORE]
5 - Marginally below threshold
11. [CONFIDENCE]
Confident


Reviewer #10
Questions
1. [Summary] Please summarize the main claims/contributions of the paper in your own words.
The authors proposed a method for paraphrasing, which consists of two modules: (1) a set2seq module used for generating sequence according to an unordered input set; (2) the back-translation module (BT), that generate candidates from L2 to L1. When decoding, a hybrid strategy is used on the two modules.
The authors conducting experiments on paraphrasing and NMT and achieved improvements.
2. [Relevance] Is this paper relevant to an AI audience?
Relevant to researchers in subareas only
3. [Significance] Are the results significant?
Moderately significant
4. [Novelty] Are the problems or approaches novel?
Somewhat novel
5. [Soundness] Is the paper technically sound?
Seems OK
6. [Evaluation] Are claims well-supported by theoretical analysis or experimental results?
Sufficient
7. [Clarity] Is the paper well-organized and clearly written?
Good
8. [Detailed Comments] Please elaborate on your assessments and provide constructive feedback.
** Pros
(1) A light idea that can bring more insights to future work;
(2) Code and results are all attached;
(3) Good improvement over the listed baselines;
** Cons
(1) BT in paraphrasing is not new, which limits the novelty of this work. It looks like an ensemble of two models. Therefore, a natural baseline is to ensemble two BT models and compare the results.
(2) The experiments on NMT are not convincing. As shown in Table 1 of [ref1], the results reported in this paper are not good enough.
[ref1] Exploiting Monolingual Data at Scale for Neural Machine Translation, https://www.aclweb.org/anthology/D19-1430/
9. [QUESTIONS FOR THE AUTHORS] Do you have questions for authors to address during the author feedback period?
    1. Are the results sensitive to $lambda$ in equation (3)?
    2. Since on set2seq, the input is permutation invariant. Is there any discussion with [ref2]?
    [ref2] Set Transformer: A Framework for Attention-based Permutation-Invariant Neural Networks, https://arxiv.org/pdf/1810.00825.pdf
10. [OVERALL SCORE]
6 - Marginally above threshold
11. [CONFIDENCE]
Confident


Reviewer #29
Questions
1. [Summary] Please summarize the main claims/contributions of the paper in your own words.
The paper proposes a paraphrasing model that’s based on (1) a Transformer model without position embeddings trained as a denoising auto-encoder and (2) round-trip machine translation (which the paper somewhat misleadingly refers to as “back translation”). The main contribution of the paper is that it shows the combination of these previously proposed techniques to yield a good experimental performance for the paraphrase generation task, outperforming all of the studied unsupervised baselines as well as the supervised baselines except for DNPG.
2. [Relevance] Is this paper relevant to an AI audience?
Likely to be of interest to a large proportion of the community
3. [Significance] Are the results significant?
Significant
4. [Novelty] Are the problems or approaches novel?
Not novel
5. [Soundness] Is the paper technically sound?
Technically sound
6. [Evaluation] Are claims well-supported by theoretical analysis or experimental results?
Sufficient
7. [Clarity] Is the paper well-organized and clearly written?
Good
8. [Detailed Comments] Please elaborate on your assessments and provide constructive feedback.
I generally enjoyed reading the paper. The paper reads very well, the proposed techniques are well motivated, and the experimental results (including an ablation study) are convincing.

The main issue of the paper is that all of the proposed techniques have been proposed before but the paper mostly fails to cite these prior works. In particular:
    1. Training a Transformer model without position embeddings has been proposed in “Language modeling with deep transformers” (https://arxiv.org/pdf/1905.04226).
    2. Similar seq2seq-based DAE has been proposed previously, e.g., in “Unsupervised Natural Language Generation with Denoising Autoencoders” (https://arxiv.org/pdf/1804.07899.pdf) and in “Rapformer: Conditional Rap Lyrics Generation with Denoising Autoencoders” (https://www.aclweb.org/anthology/2020.inlg-1.42.pdf).
    3. Round-trip translation has been shown to improve performance for MT in “Augmenting Neural Machine Translation through Round-Trip Training Approach” (https://www.degruyter.com/document/doi/10.1515/comp-2019-0019/pdf).

Moreover, the paper refers to round-trip translation as “back translation” which typically only refers to generation of synthetic source-target pairs by taking examples from the target domain and running them through a reverse model to generate synthetic source texts. Therefore, I think the title of the paper should be updated as well as the references to “back translation”.

Assuming the above issues are addressed, this paper can make a nice focused contribution, proposing a combination of existing techniques that works well for paraphrase generation in practice.
9. [QUESTIONS FOR THE AUTHORS] Do you have questions for authors to address during the author feedback period?
-
10. [OVERALL SCORE]
5 - Marginally below threshold
11. [CONFIDENCE]
Confident


Reviewer #43
Questions
1. [Summary] Please summarize the main claims/contributions of the paper in your own words.
This paper proposed a novel method for paraphrasing. The authors first choose some words from the original sentence to construct a key words set. Then, a set2seq model is trained to recover the original sentence. At the same time, this original sentence is back translated to get another representation. Thus, the paraphrase will obtain two probability distributions when choosing the next token during the decoding. The experimentanal results show the power of their method. Furthermore, they improve the mt for low-resource language by argumating the training data with their method.
2. [Relevance] Is this paper relevant to an AI audience?
Relevant to researchers in subareas only
3. [Significance] Are the results significant?
Significant
4. [Novelty] Are the problems or approaches novel?
Somewhat novel
5. [Soundness] Is the paper technically sound?
Seems OK
6. [Evaluation] Are claims well-supported by theoretical analysis or experimental results?
Sufficient
7. [Clarity] Is the paper well-organized and clearly written?
Satisfactory
8. [Detailed Comments] Please elaborate on your assessments and provide constructive feedback.
1 The lambda in equ. (3) is crucial. How you get the best setting?
2 The number of key words will make an impact on the results. Please show this impact.
3 The human evaluation about fluency ihardly measures the common sense is conformed or not.
4 The writting should be improved, for example,
A sentence is repated in section 4.1 "For each experiment, we train the model with the original data as the baseline." The title of section 4 could be "experiments".
9. [QUESTIONS FOR THE AUTHORS] Do you have questions for authors to address during the author feedback period?
N/A
10. [OVERALL SCORE]
7 - Accept
11. [CONFIDENCE]
Confident


Reviewer #97
Questions
1. [Summary] Please summarize the main claims/contributions of the paper in your own words.
This paper proposed a new paraphrase generation method based on decoder using wordset-to-sequence model and a back-translaton model. This study compared with many supervised, unsupervised strong baselines for paraphrasing and shows good performance.
2. [Relevance] Is this paper relevant to an AI audience?
Likely to be of interest to a large proportion of the community
3. [Significance] Are the results significant?
Significant
4. [Novelty] Are the problems or approaches novel?
Novel
5. [Soundness] Is the paper technically sound?
Seems OK
6. [Evaluation] Are claims well-supported by theoretical analysis or experimental results?
Sufficient
7. [Clarity] Is the paper well-organized and clearly written?
Satisfactory
8. [Detailed Comments] Please elaborate on your assessments and provide constructive feedback.
The difference between three categories of paraphrasing methods: unsupervised fine-tuning for supervised model, unsupervised methods based on word/phrase replacement, and distantly-supervised methods based on bilingual data is not clearly described. Does the propose method belong to the third category? Was the back-translation model trained on out-of-domain data?

In Experiments, please explain why DNPG outperforms the proposed method set2seq+BT. Which common-domain dataset was used in set2seq+common+BT? In Table 2, set2seq+common+BT performs better than set2seq+BT only on Twitter data. Please explain why common-domain data help with lack of in-domain training data on Twitter.

The proposed model is used as a data augmentation tool in machine translation. If the paraphrasing and machine translation datasets are in different domains, how out-of-domain training data benefits the translation task.

The set2seq and back-translation models need to be pre-trained before they are used for paraphrasing. The proposed method is computational expensive. Please provide more details of computational time of other baseline methods.

Minor issues
Please use consistent expression of Rouge1 and Rough2 instead of R1 and R2 in Table 2.
9. [QUESTIONS FOR THE AUTHORS] Do you have questions for authors to address during the author feedback period?
N/A
10. [OVERALL SCORE]
7 - Accept
11. [CONFIDENCE]
Confident