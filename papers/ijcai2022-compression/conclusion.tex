\section{Conclusion}
In this paper, we propose a two-stage learning framework LCD based on a novel two-branch container to compress large language models into compact 
counterpart. Based on the experimental results and analysis, we highlight the key findings: (1) the collaboration between teacher and student layers offers better knowledge transfer than traditional KD due to 
finer-grained interaction. (2) adding explicit teacher demonstrations allows the student to refine its representation to be more similar to the teacher, thereby achieving better generalization than learning from 
task label alone.
