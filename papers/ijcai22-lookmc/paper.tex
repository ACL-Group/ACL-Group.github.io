%%%% ijcai22-multiauthor.tex

\typeout{IJCAI--22 Multiple authors example}

% These are the instructions for authors for IJCAI-22.

\documentclass{article}
\pdfpagewidth=8.5in
\pdfpageheight=11in
% The file ijcai22.sty is NOT the same as previous years'
\usepackage{ijcai22}

% Use the postscript times font!
\usepackage{times}
\renewcommand*\ttdefault{txtt}
\usepackage{soul}
\usepackage{url}
\usepackage[hidelinks]{hyperref}
\usepackage[utf8]{inputenc}
\usepackage[small]{caption}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{bbding}
\usepackage{color}
\usepackage{makecell}
\usepackage{subcaption}
\urlstyle{same}


\newcommand{\ft}[1]{\textsc{#1}}

\newtheorem{example}{Example}
\newcommand{\secref}[1]{Section \ref{#1}}
\newcommand{\figref}[1]{Figure \ref{#1}}
\newcommand{\eqnref}[1]{Eq. (\ref{#1})}
\newcommand{\tabref}[1]{Table \ref{#1}}
\newcommand{\exref}[1]{Example \ref{#1}}
\newcommand{\KZ}[1]{\textcolor{blue}{Kenny: #1}}
\newcommand{\Roy}[1]{\textcolor{red}{Roy: #1}}
\newcommand{\Ss}[1]{\textcolor{blue}{Shanshan: #1}}

\newcommand{\crosssymbol}{{ \XSolidBrush} }
%{{\color{red} \XSolidBrush} }
\newcommand{\checksymbol}{{\Checkmark} }
%{{\color{green} \Checkmark} }
\newcommand{\cut}[1]{}
%\usepackage[table]{xcolor}
%\aclfinalcopy % Uncomment this line for the final submission
%\def\aclpaperid{138} %  Enter the acl Paper ID here

%\setlength\titlebox{5cm}
% You can expand the titlebox if you need extra space
% to show all the authors. Please do not make the titlebox
% smaller than 5cm (the original size); we will check this
% in the camera-ready version and ask you to change it back.


\pdfinfo{
/TemplateVersion (IJCAI.2022.0)
}


\title{Data Augmentation for More Robust Natural Language Reasoning}

\author{
%First Author$^1$\footnote{Contact Author}\and
%Second Author$^2$\and
%Third Author$^{2,3}$\And
%Fourth Author$^4$\\
%\affiliations
%$^1$First Affiliation\\
%$^2$Second Affiliation\\
%$^3$Third Affiliation\\
%$^4$Fourth Affiliation\\
%\emails
%\{first, second\}@example.com,
%third@other.example.com,
%fourth@example.com
}

\begin{document}

\maketitle

\begin{abstract}
%For multiple-choice natural language reasoning problems, 
Biases in training data may lead to the fragility in neural models
that makes choices in natural language reasoning questions without
referring to the context or premises. 
To encourage models to learn more from the logical connections between 
premises and choices, we propose two biologically inspired operations 
that can generate new training data that ``forces'' the model
to look at the premises. They can augment
any type of multiple choice reasoning dataset, and can be applied to
any supervised learning models. Results show that models trained
with the augmented data become more robust against both stress test cases and original
test data, beating the strong back-translation baseline.

\end{abstract}

\input{intro}
\input{method}
\input{experiments}
\input{related}
\input{conclude}

\bibliographystyle{named}
\bibliography{aaai22}
\end{document}
