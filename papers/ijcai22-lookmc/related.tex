\section{Related Work}
% Our work is  related to three lines of research: spurious feature analysis, data augmentation, and model probing.


\textbf{Spurious Feature Analysis.}~~Prior studies~\cite{endingonly1,zellers2018swag} have discovered that NLP models can achieve surprisingly good accuracy on natural language understanding tasks in MCQs form even without looking at the context. 
Such phenomenon is identified via the so-called ``hypothesis-only'' test. \citeauthor{sanchez2018behavior} further showed that models sometimes bear insensitivity to certain slight but semantically significant perturbations in the hypothesis, leading to suspicions that the high hypothesis-only performance  stems from statistical correlations between spurious cues in the hypothesis and the label. Such spurious cues can be categorized into lexicalized~\cite{naik2018stress} and unlexicalized~\cite{bowman2015large}: the former mainly contains n-gram and cross-ngram spans that are indicative of certain labels, while the latter involves word overlap, sentence length and BLUE score between the premise and the hypothesis. Instead of unearthing the specific cues in the dataset, we directly diagnoses if models are exploiting the short circuit in hypothesis alone and mitigates such reasoning behavior accordingly.

\textbf{Data Augmentation.}~~Data augmentation is a widely used technique to enhance the robustness of neural network models. In many cases, augmentation with one kind of example improves accuracy on that particular case, but does not generalize to other cases, suggesting that models overfit to the augmentation set~\cite{Iyyer2018,Liu2019a}. In particular, \citeauthor{mccoy2019right} found that augmentation with HANS examples may generalize to a different word overlap challenge set, but only for examples similar in length to HANS examples. We reduce the hypothesis-only short circuit inference behavior of models via several simple yet scalable augmentation methods aiming at teaching models to reason over relations between context and hypothesis.

\textbf{Model Probing.}~~Ever since the emergence of large pretrained language models, much works have focused on the analysis of their inner workings. As a result, a considerable amount of linguistic properties are shown to be encoded in the contextualized representations and attention heads~\cite{goldberg2019,clark2019,liu-etal-2019-linguistic,tenny2019}. In contrast, we are concerned with model's higher level reasoning capability, in particular the short circuiting behavior, as reflected in downstream performance through diagnostic stress test.

