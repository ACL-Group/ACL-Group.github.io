\begin{abstract}
Image search engine returns results in a mixed bag of different
entities and concepts without meaningful ordering or grouping because
it doesn't understand the semantics or recognize the objects in the images.
This poses inconvenience for users who are looking for a particular
entity without knowing the exact right term to search.
Existing image clustering techniques attempt to solve this
problem by distinguishing images using either their low level
visual signals or the distribution of words in the text
surrounding the images, or both. None of these techniques
works well because i) techniques for visual recognition of objects
are still immature; ii) modeling text context by bag-of-words is insufficient
for the understanding of the context; and iii) there is a
disconnect between visual cues and the actual semantics of the image.
This paper proposes a novel framework that understands
the context by disambiguating the terms in the context
into the corresponding concepts from an external knowledge
base in a process called conceptualization. The
framework also incorporates any type of visual signals to complement
the text signals in a tri-stage clustering algorithm
which produces better clustering results than state-of-the-art
approaches. Specifically, our approach outperforms the best competing
techniques by 20.8\% in F1-measure but by 41.3\% in NMI score.
In addition, the framework automatically
annotates each cluster of images by its key concepts which
allows users to quickly identify the images they want.
\end{abstract}
