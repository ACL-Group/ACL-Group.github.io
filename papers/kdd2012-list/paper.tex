\documentclass[conference,letterpaper]{sig-alternate}
\usepackage{times,amsmath,epsfig,proof,url}
\usepackage{algorithmic}
\usepackage{textcomp}
%\usepackage[lined,algonl,ruled]{algorithm2e}
\usepackage{subfigure}
\newcommand{\tab}{\hspace*{2ex}}
\newcommand{\shrink}{\vspace*{-2ex}}
\newcommand{\cut}[1]{}

\newtheorem{newproperty}{Property}
\newtheorem{newrule}{Rule}

\begin{document}
\conferenceinfo{KDD'12,} {August 12--16, 2012, Beijing, China.}
\CopyrightYear{2012}
\crdata{978-1-4503-1462-6 /12/08}
\clubpenalty=10000
\widowpenalty = 10000
%\title{Automatic Extraction of Top-k Lists from the Web}
\title{A System for Extracting Top-K Lists from the Web}
\numberofauthors{3}
\author{
\alignauthor
Zhixian Zhang\\
       \affaddr{Shanghai Jiao Tong University}\\
       \affaddr{Shanghai, China}\\
       \email{zzx1989@sjtu.edu.cn}
\alignauthor
Kenny Q. Zhu \titlenote{This work was partially supported by NSFC Grant 61100050
and MOE New Faculty Award No. 20110073120023.\vspace*{-5mm}}\\
       \affaddr{Shanghai Jiao Tong University}\\
       \affaddr{Shanghai, China}\\
       \email{kzhu@cs.sjtu.edu.cn}
\and
\alignauthor
Haixun Wang\\
       \affaddr{Microsoft Research Asia}\\
       \affaddr{Beijing, China}\\
       \email{haixunw@microsoft.com}
}
\maketitle

\begin{abstract}
List data is an important source of structured data on the web. 
This paper is concerned with ``top-$k$'' pages, which are
web pages that describe a list of $k$ instances of a
particular topic or concept. Examples include ``the
10 tallest persons in the world'' and ``the 50 hits of 2010 you 
don't want to miss''. 
Compared to normal web list data, 
``top-$k$'' lists contain richer information and are easier to understand.
Therefore the extraction of such lists can help
enrich existing knowledge bases about general concepts, or
act as a preprocessing step to produce facts for a fact answering engine.
We present an efficient system
that extracts the target lists from web pages with high accuracy.
%Generally the system contains the following components:
%1) title recognition to identify a ``top-k'' page by its title;
%2) list extraction to extract the target list in the ``top-k'' page;
%3) content processing and understanding.
%To evaluate the performance of the system, 
We have used the system to process up to 160 million, or
1/10 of a high-frequency web snapshot from Bing, and obtained
over 140,000 lists with 90.4\% precision. 
\end{abstract}

%% A category with the (minimum) three required fields
\category{H.3.3}{Information Storage and Retrieval}{Information Search and Retrieval}
\category{H.2.8}{Database Management}{Database Applications}[Data Mining]
%%A category including the fourth, optional field follows...
%\category{D.2.8}{Software Engineering}{Metrics}[complexity measures, performance measures]
%
%\terms{Algorithm, Information extraction}


\begin{keywords}
Web information extraction, top-k lists, list extraction, web mining
\end{keywords}


\input{intro}
%\input{problem}
\input{approach}
\input{eval}
\input{demo}
%\input{related}
%\input{conclude}

\bibliographystyle{abbrv}
%{\renewcommand{\baselinestretch}{0.9}
\bibliography{list}
%}
% sigproc.bib is the name of the Bibliography in this case
\end{document}
