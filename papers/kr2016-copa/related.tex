\section{Related Work}
\label{sec:related}

We start by discussing previous work that extracts causal relation term
pairs from open domain text. Then we present various past attempts to
solve the causality reasoning problem.
\cut{We start by discussing previous work that extracts causal relation term pairs
from open domain text.
Then we present various past attempts
to solve the commonsense causal reasoning problem.
}

\subsection{Causal Relation Extraction}
Causal relation recognition and extraction
can be seen as a pre-processing step of causal reasoning.
It naturally boils down to a binary classification problem of
causal/non-causal relations. Existing approaches focus on developing
hand-coded patterns and linguistic features and learning the
classifier to recognize and extract causal relation for their
systems.
Moreover, previous work are specific with
the type of causal pairs and extracted either
noun-noun, verb-verb or verb-noun causation.
Girju et al. \cite{girju2003automatic} were the first to work on
causal relation discovery
between nominals. They semi-automatically extracted causal cues, but only
extracted noun category features for the head noun. Chang et al.
\cite{ChangC04} developed an unsupervised method and
utilized lexical pairs and cues contained in noun phrases as
features to identify causality between them. Both of them ignored
how the text spans surrounding the causal cue
affects the semantics.  Our causal relation extraction
step, instead,  benefits from these contexts and
constructs a much larger and more powerful causal network.
Blanco et al. \cite{blanco2008causal} used
different patterns to detect the causation in long sentences that
contain clauses.
Kozareva~\cite{kozareva2012cause} collected causality relations
between nominals using a bootstrapping method.

Do et al. \cite{do2011minimally} introduced a form of association
metric into causal relation extraction. They mainly focus on
detecting causality between verbs and also worked with verb-noun
causality in which nouns are drawn from a small predefined list.
They used discourse connectives and similarity distribution to
identify event causality between predicate, not noun phrases, but
achieved a F1-score around 0.47. Riaz et al.
\cite{riaz2014recognizing} focus on noun-verb causality detection
and extraction.

None of the previous work except for Do's provides a
causality metric, hence cannot be extended to commonsense causal
reasoning task. Do's work is also of limited help because it only
measures causality strength between verbs.
And most recently, Hashimoto~\cite{hashimoto2015generating} propose
methods to generate reasonable event causalities,
though limited in scale on the event space.  Our CausalNet are
constructed out of all types of words in web corpus, and as a result
the framework on top of it can model the causal strength between
arbitrary text units.
\cut{
Much of the work ignored how the text spans surrounding the causal cue
affects the semantics. Our causal relation extraction
step, instead,  benefits from these contexts and
constructs a much larger and more powerful causal network.
Moreover, previous work
extracted specific types of causal pair, of either noun-noun, verb-verb or verb-noun
\cite{do2011minimally,riaz2014recognizing}
causality. None of the previous work except for
Do's~\shortcite{do2011minimally}
provides a numerical metric to measure causal strength,
hence cannot be extended to causal reasoning between short texts.
Do's work is also of limited help because it only
measures causal strength between verbs.
Recently, researchers \cite{hashimoto2015generating} also propose methods to
generate reasonable event causalities, though limited in scale.
Our CausalNet contains causal strength between arbitrary texts,
by using general web corpus and
extracting nouns, verbs, adjectives and
adverbs.}

\subsection{Commonsense Causal Reasoning}
The causal knowledge which encodes the causal implications of
actions and events is useful in many applications.
Commonsense causal reasoning is thus a
grand challenge in artificial intelligence. Earlier attempts on the
problem were largely linguistic, for example, developing formal
theories to capture temporal or logical properties in causal
entailment \cite{LascaridesAO92,lascarides:asher:1993a}, but
they do not scale to %board-ranging
open domain reasoning \ZY{across the board}.

The NLP community has explored knowledge based approaches
that leverage structural representations of the general world knowledge.
Much of the knowledge is hand-coded~\cite{lenat1995cyc}
or crowd-sourced, such as the OMCS project by MIT~\cite{singh2002open}.
Some relations such as ``causes'' and
``causesDesire'' in the ConceptNet \cite{liu2004commonsense},
which is a sub-project under OMCS, can be used to identify causal
discourse in COPA task.
However, such human curated knowledge
has limited size and comes with no or unreliable causal strength
scores (e.g., the votes in ConceptNet).
Recently, several automatic, data-driven methods have
been attempted to acquire commonsense
knowledge\cite{schubert2002can,gordon2010learning,gordon2010mining,akbikweltmodell}.
These approaches focused on the acquisition of general
worldly knowledge expressed as factoids, and not causality knowledge
per se. Hence their coverage of causality knowledge is also very limited.

More successful efforts arise from data-driven approaches
using correlational statistics \cite{gordon2012copa} such as pointwise mutual
information (PMI) between unigrams (words) or bigrams from large
text corpora \cite{Mihalcea2006:CKM}. Corpora attempted include LDC
gigaword news corpus \cite{goodwin2012utdhlt}, Gutenberg e-books
\cite{roemmele2011choice}, personal stories from Weblogs
\cite{gordon2011commonsense} and Wikipedia text
\cite{jabeen2014exploiting}.
This paper follows a similar direction, but instead proposed to extract
causal signals from a more general, much larger web text corpus.
CausalNet can be seen as a large graph-based representation of general
causality knowledge and can provide the relatively reasonable computation of
causal strength between terms.
