% @string{icassp = "Proceedings of IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)"}
@string{interspeech = "Proceedings of Conference of the International Speech Communication Association"}
@string{asru = "Proceedings of IEEE Workshop on Automatic Speech Recognition and Understanding (ASRU)"}
@string{lrec = "Proceedings of International Conference on Language Resources and Evaluation (LREC)"}
@string{ieee-taslp = "IEEE Transactions on Audio, Speech, and Language Processing"}
@string{ieee-acm-taslp = "IEEE/ACM Transactions on Audio, Speech and Language Processing"}
@string{ieee-pami = "IEEE Transactions on Pattern Analysis and Machine Intelligence"}
@string{mlsp = "Proceedings of International Workshop on Machine Learning for Signal Processing (MLSP)"}
@string{waspaa = "IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)"}
@string{ijcnn = "International Joint Conference on Neural Networks (IJCNN)"}
@string{csl = "Computer speech \& language"}
string{slt = "Proceedings of IEEE Spoken Language Technology Workshop (SLT)"}
% @string{naacl = "Proceedings of Conference of the North {A}merican Chapter of the Association for Computational Linguistics (NAACL)"}
@string{emnlp = "Proceedings of Conference on Empirical Methods in Natural Language Processing (EMNLP)"}
@string{prcv = "Proceedings of Chinese Conference on Pattern Recognition and Computer Vision (PRCV)"}
@string{ismir = "Proceedings of International Society for Music Information Retrieval"}
@string{aaai = "Proceedings of the AAAI Conference on Artificial Intelligence"}

@string{icassp = "Proc. IEEE ICASSP"}
% string{interspeech = "Proc. ISCA Interspeech"}
% string{asru = "Proc. IEEE ASRU"}
% string{waspaa = "Proc. IEEE WASPAA"}
% string{lrec = "Proc. LREC"}
@string{icml = "Proc. ICML"}
% @string{mlsp = "Proc. MLSP"}
@string{nips = "Proc. NIPS"}
% string{csl = "Comput. Speech Lang."}
% @string{slt = "Proc. IEEE SLT"}
@string{acl = "Proc. ACL"}
@string{naacl = "Proc. NAACL"}
@string{dcase = "Proc. DCASE"}
@string{iclr = "Proc. ICLR"}
@string{cvpr = "Proc. CVPR"}
@string{iccv = "Proc. ICCV"}
@string{eccv = "Proc. ECCV"}
@string{bmvc = "Proc. BMVC"}
@string{cikm = "Proc. CIKM"}
@string{ism = "Proc. ISM"}
% string{emnlp = "Proc. EMNLP"}
% @string{eusipco = "Proc. IEEE EUSIPCO"}
@string{cvprw = "Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)"}
@string{iccvw = "Proceedings of the IEEE International Conference on Computer Vision Workshops (ICCVW)"}
@string{bmvc = "British Machine Vision Conference (BMVC)"}
@string{acm-mm = "Proceedings of ACM International Conference on Multimedia"}
@string{conll = "Proceedings of Conference on Computational Natural Language Learning (CoNLL)"}
@string{eacl = "Proceedings of the European Chapter of the Association for Computational Linguistics"}
@string{iscslp = "Proceedings of the International Symposium on Chinese Spoken Language Processing (ISCSLP)"}
@string{sigir = "International ACM SIGIR Conference on Research \& Development in Information Retrieval"}

%Entries

@article{van2018representation,
  title={Representation learning with contrastive predictive coding},
  author={Van den Oord and others},
  journal={arXiv preprint arXiv:1807.03748},
  volume={2},
  number={3},
  pages={4},
  year={2018}
}

@article{kong2020panns,
  title={Panns: Large-scale pretrained audio neural networks for audio pattern recognition},
  author={Kong, Qiuqiang and others},
  journal=ieee-acm-taslp,
  volume={28},
  pages={2880--2894},
  year={2020},
  publisher={IEEE}
}

@inproceedings{gong2021audio,
  author = {Gong, Yuan and Chung, Yu An and Glass, James},
  booktitle = interspeech,
  pages = {56--60},
  title = {AST: Audio Spectrogram Transformer},
  year = {2021},
  publisher={ISCA}
}

@article{turc2019well,
  title={Well-read students learn better: On the importance of pre-training compact models},
  author={Turc, Iulia and others},
  journal={arXiv preprint arXiv:1908.08962},
  year={2019}
}

@inproceedings{devlin2019bert,
  title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristin},
  booktitle=naacl,
  pages={4171--4186},
  year={2019}
}

@inproceedings{kim2019audiocaps,
  author = {Kim, Chris Dongjoo and others},
  booktitle=naacl,
  pages = {119--132},
  title = {AudioCaps: Generating Captions for Audios in The Wild},
  year = {2019}
}

@inproceedings{drossos2020clotho,
  title={Clotho: An audio captioning dataset},
  author={Drossos, Konstantinos and others},
  booktitle=icassp,
  pages={736--740},
  year={2020}
}

@inproceedings{martin2021diversity,
    author = "Martin, Irene and others",
    title = "Diversity and Bias in Audio Captioning Datasets",
    booktitle = dcase,
    year = "2021",
    pages = "90--94",
}

@inproceedings{font2013freesound,
  title={Freesound technical demo},
  author={Font, Frederic and Roma, Gerard and Serra, Xavier},
  booktitle=acm-mm,
  pages={411--412},
  year={2013}
}

@article{loshchilov2016sgdr,
  title={Sgdr: Stochastic gradient descent with warm restarts},
  author={Loshchilov, Ilya and others},
  journal={arXiv preprint arXiv:1608.03983},
  year={2016}
}

@inproceedings{zhou2021can,
  title={Can Audio Captions Be Evaluated with Image Caption Metrics?},
  author={Zhou, Zelin and others},
  booktitle=icassp,
  year={2022}
}

@inproceedings{guzhov2022audioclip,
  title={Audioclip: Extending clip to image, text and audio},
  author={Guzhov, Andrey and others},
  booktitle=icassp,
  year={2022}
}

@inproceedings{zhao2022connecting,
    title = "Connecting the Dots between Audio and Text without Parallel Data through Visual Knowledge Transfer",
    author = "Zhao, Yanpeng and others",
    booktitle = naacl,
    year = "2022",
    pages = "4492--4507",
}

@inproceedings{wu2022wav2clip,
  title={Wav2CLIP: Learning Robust Audio Representations From CLIP},
  author={Wu, Ho-Hsiang and others},
  booktitle=icassp,
  year={2022}
}

@inproceedings{bengio2015scheduled,
  title={Scheduled sampling for sequence prediction with recurrent Neural networks},
  author={Bengio, Samy and Vinyals, Oriol and Jaitly, Navdeep and Shazeer, Noam},
  booktitle=nips,
  pages={1171--1179},
  year={2015}
}

@inproceedings{szegedy2016rethinking,
  title={Rethinking the inception architecture for computer vision},
  author={Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jon and Wojna, Zbigniew},
  booktitle=cvpr,
  pages={2818--2826},
  year={2016}
}

@article{izmailov2018averaging,
  title={Averaging weights leads to wider optima and better generalization},
  author={Izmailov, Pavel and Podoprikhin, Dmitrii and Garipov, Timur and Vetrov, Dmitry and Wilson, Andrew Gordon},
  journal={arXiv preprint arXiv:1803.05407},
  year={2018}
}

@article{koizumi2020audio,
  title={Audio Captioning using Pre-Trained Large-Scale Language Model Guided by Audio-based Similar Caption Retrieval},
  author={Koizumi, Yuma and others},
  journal={arXiv preprint arXiv:2012.07331},
  year={2020}
}

@inproceedings{eren2020semantic,
  author = {Eren, Ay≈üeg{\"{u}}l {\"{O}}zkaya and others},
  booktitle = ism,
  title = {{Audio Captioning Based on Combined Audio and Semantic Embeddings}},
  year = {2020}
}

@inproceedings{zhang2021enriching,
  title={Enriching Ontology with Temporal Commonsense for Low-Resource Audio Tagging},
  author={Zhang, Zhiling and others},
  booktitle=cikm,
  pages={3652--3656},
  year={2021}
}

@inproceedings{lin2014microsoft,
  title={Microsoft coco: Common objects in context},
  author={Lin, Tsung-Yi and others},
  booktitle=eccv,
  pages={740--755},
  year={2014},
  organization={Springer}
}

@inproceedings{sharma2018conceptual,
  title={Conceptual captions: A cleaned, hypernymed, image alt-text dataset for automatic image captioning},
  author={Sharma, Piyush and others},
  booktitle=acl,
  pages={2556--2565},
  year={2018}
}

@inproceedings{chen2020uniter,
  title={Uniter: Universal image-text representation learning},
  author={Chen, Yen-Chun and others},
  booktitle=eccv,
  pages={104--120},
  year={2020},
  organization={Springer}
}

@inproceedings{li2020oscar,
  title={Oscar: Object-semantics aligned pre-training for vision-language tasks},
  author={Li, Xiujun and others},
  booktitle=eccv,
  pages={121--137},
  year={2020},
  organization={Springer}
}

@inproceedings{lu2019vilbert,
  title={Vilbert: Pretraining task-agnostic visiolinguistic representations for vision-and-language tasks},
  author={Lu, Jiasen and others},
  booktitle=nips,
  year={2019}
}

@inproceedings{su2019vl,
  title={VL-BERT: Pre-training of Generic Visual-Linguistic Representations},
  author={Su, Weijie and others},
  booktitle=iclr,
  year={2019}
}

@article{krishna2017visual,
  title={Visual genome: Connecting language and vision using crowdsourced dense image annotations},
  author={Krishna, Ranjay and others},
  journal={International journal of computer vision},
  volume={123},
  number={1},
  pages={32--73},
  year={2017},
  publisher={Springer}
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and others},
  booktitle=icml,
  pages={8748--8763},
  year={2021}
}

@inproceedings{jia2021scaling,
  title={Scaling up visual and vision-language representation learning with noisy text supervision},
  author={Jia, Chao and Yang, Yinfei and Xia, Ye and Chen, Yi-Ting and Parekh, Zarana and Pham, Hieu and Le, Quoc and Sung, Yun-Hsuan and Li, Zhen and Duerig, Tom},
  booktitle={International Conference on Machine Learning},
  pages={4904--4916},
  year={2021},
  organization={PMLR}
}

@article{wang2021simvlm,
  title={Simvlm: Simple visual language model pretraining with weak supervision},
  author={Wang, Zirui and Yu, Jiahui and Yu, Adams Wei and Dai, Zihang and Tsvetkov, Yulia and Cao, Yuan},
  journal={arXiv preprint arXiv:2108.10904},
  year={2021}
}

@article{wang2022unifying,
  title={Unifying Architectures, Tasks, and Modalities Through a Simple Sequence-to-Sequence Learning Framework},
  author={Wang, Peng and Yang, An and Men, Rui and Lin, Junyang and Bai, Shuai and Li, Zhikang and Ma, Jianxin and Zhou, Chang and Zhou, Jingren and Yang, Hongxia},
  journal={arXiv preprint arXiv:2202.03052},
  year={2022}
}

@inproceedings{chen2020vggsound,
  title={Vggsound: A large-scale audio-visual dataset},
  author={Chen, Honglie and Xie, Weidi and Vedaldi, Andrea and Zisserman, Andrew},
  booktitle=icassp,
  pages={721--725},
  year={2020}
}

@inproceedings{drossos2017automated,
  title={Automated audio captioning with recurrent neural networks},
  author={Drossos, Konstantinos and Adavanne, Sharath and Virtanen, Tuomas},
  booktitle=waspaa,
  pages={374--378},
  year={2017}
}

@inproceedings{oncescu21audio,
    author = "Oncescu, Andreea-Maria and Koepke, A and Henriques, Jo{\~a}o F and Akata, Zeynep and Albanie, Samuel",
    title  = "Audio Retrieval with Natural Language Queries",
    booktitle = interspeech,
    year = "2021"
}

@article{akbari2021vatt,
  title={Vatt: Transformers for multimodal self-supervised learning from raw video, audio and text},
  author={Akbari, Hassan and Yuan, Liangzhe and Qian, Rui and Chuang, Wei-Hong and Chang, Shih-Fu and Cui, Yin and Gong, Boqing},
  journal=nips,
  volume={34},
  year={2021}
}

@article{alayrac2020self,
  title={Self-supervised multimodal versatile networks},
  author={Alayrac, Jean-Baptiste and Recasens, Adria and Schneider, Rosalia and Arandjelovi{\'c}, Relja and Ramapuram, Jason and De Fauw, Jeffrey and Smaira, Lucas and Dieleman, Sander and Zisserman, Andrew},
  journal=nips,
  volume={33},
  pages={25--37},
  year={2020}
}

@inproceedings{miech2019howto100m,
  title={Howto100m: Learning a text-video embedding by watching hundred million narrated video clips},
  author={Miech, Antoine and Zhukov, Dimitri and Alayrac, Jean-Baptiste and Tapaswi, Makarand and Laptev, Ivan and Sivic, Josef},
  booktitle=iccv,
  year={2019}
}

@article{fonseca2022fsd50k,
  title={Fsd50k: an open dataset of human-labeled sound events},
  author={Fonseca, Eduardo and Favory, Xavier and Pons, Jordi and Font, Frederic and Serra, Xavier},
  journal=ieee-acm-taslp,
  volume={30},
  pages={829--852},
  year={2022},
  publisher={IEEE}
}

@inproceedings{mesaros2018multi,
  title={A multi-device dataset for urban acoustic scene classification},
  author={Mesaros, Annamaria and Heittola, Toni and Virtanen, Tuomas},
  booktitle=dcase,
  pages={9--13},
  year={2018}
}

@inproceedings{gemmeke2017audio,
  title={Audio set: An ontology and human-labeled dataset for audio events},
  author={Gemmeke, Jort F and others},
  booktitle=icassp,
  pages={776--780},
  year={2017}
}

@inproceedings{cakir2015polyphonic,
  title={Polyphonic sound event detection using multi label deep neural networks},
  author={Cakir, Emre and Heittola, Toni and Huttunen, Heikki and Virtanen, Tuomas},
  booktitle=ijcnn,
  pages={1--7},
  year={2015}
}

@article{gong2021psla,
  author = {Gong, Yuan and others},
  journal = ieee-acm-taslp,
  pages = {3292--3306},
  title = {{PSLA: Improving Audio Tagging With Pretraining, Sampling, Labeling, and Aggregation}},
  volume = {29},
  year = {2021}
}

@inproceedings{antol2015vqa,
  title={Vqa: Visual question answering},
  author={Antol, Stanislaw and others},
  booktitle=iccv,
  pages={2425--2433},
  year={2015}
}

@inproceedings{zellers2019recognition,
  title={From recognition to cognition: Visual commonsense reasoning},
  author={Zellers, Rowan and others},
  booktitle=cvpr,
  pages={6720--6731},
  year={2019}
}

@inproceedings{kazakos2021slow,
  title={Slow-fast auditory streams for audio recognition},
  author={Kazakos, Evangelos and others},
  booktitle=icassp,
  pages={855--859},
  year={2021}
}

@techreport{chen2019integrating,
    Author = "Chen, Hangting and Liu, Zuozhen and Liu, Zongming and Zhang, Pengyuan and Yan, Yonghong",
    title = "Integrating the Data Augmentation Scheme with Various Classifiers for Acoustic Scene Modeling",
    institution = "DCASE2019 Challenge",
    year = "2019",
    month = "June",
}

@inproceedings{saeed2021contrastive,
  title={Contrastive learning of general-purpose audio representations},
  author={Saeed, Aaqib and others},
  booktitle=icassp,
  pages={3875--3879},
  year={2021}
}

@inproceedings{al2021clar,
  title={Clar: Contrastive learning of auditory representations},
  author={Al-Tahan, Haider and Mohsenzadeh, Yalda},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={2530--2538},
  year={2021},
  organization={PMLR}
}

@article{baevski2020wav2vec,
  title={wav2vec 2.0: A framework for self-supervised learning of speech representations},
  author={Baevski, Alexei and Zhou, Yuhao and Mohamed, Abdelrahman and Auli, Michael},
  journal=nips,
  volume={33},
  pages={12449--12460},
  year={2020}
}

@article{hsu2021hubert,
  title={Hubert: Self-supervised speech representation learning by masked prediction of hidden units},
  author={Hsu, Wei-Ning and Bolte, Benjamin and Tsai, Yao-Hung Hubert and Lakhotia, Kushal and Salakhutdinov, Ruslan and Mohamed, Abdelrahman},
  journal=ieee-acm-taslp,
  volume={29},
  pages={3451--3460},
  year={2021},
  publisher={IEEE}
}

@article{chen2022wavlm,
  title={Wavlm: Large-scale self-supervised pre-training for full stack speech processing},
  author={Chen, Sanyuan and Wang, Chengyi and Chen, Zhengyang and Wu, Yu and Liu, Shujie and Chen, Zhuo and Li, Jinyu and Kanda, Naoyuki and Yoshioka, Takuya and Xiao, Xiong and others},
  journal={IEEE Journal of Selected Topics in Signal Processing},
  year={2022},
  publisher={IEEE}
}

@inproceedings{niizumi2021byol,
  title={BYOL for audio: Self-supervised learning for general-purpose audio representation},
  author={Niizumi, Daisuke and Takeuchi, Daiki and Ohishi, Yasunori and Harada, Noboru and Kashino, Kunio},
  booktitle={International Joint Conference on Neural Networks (IJCNN)},
  pages={1--8},
  year={2021}
}

@article{koutini2021efficient,
  title={Efficient training of audio transformers with patchout},
  author={Koutini, Khaled and others},
  journal={arXiv preprint arXiv:2110.05069},
  year={2021}
}

@article{elizalde2022clap,
  title={CLAP: Learning Audio Concepts From Natural Language Supervision},
  author={Elizalde, Benjamin and others},
  journal={arXiv preprint arXiv:2206.04769},
  year={2022}
}

@techreport{xu2022sjtu,
    Author = "Xu, Xuenan and Xie, Zeyu and Wu, Mengyue and Yu, Kai",
    title = "The {SJTU} System for {DCASE2022} Challenge Task 6: Audio Captioning with Audio-Text Retrieval Pre-training",
    institution = "DCASE2022 Challenge",
    year = "2022",
}

@inproceedings{xu2021investigating,
  title={Investigating local and global information for automated audio captioning with transfer learning},
  author={Xu, Xuenan and others},
  booktitle=icassp,
  pages={905--909},
  year={2021}
}

@inproceedings{chen2020audio,
  title={Audio Captioning Based on Transformer and Pre-Trained CNN.},
  author={Chen, Kun and others},
  booktitle=dcase,
  pages={21--25},
  year={2020}
}