We appreciate the valuable comments from the reviewers. Thank you all for the time and effort. Below are our responses to your questions or concerns.

#1
Section 1:
We are going to release our code and datasets when the paper is published. We'll revise it with the real URLs.

Section 2.1:
(1) We'll give the definition in detail in the revision.
(2) The objective of our paper is to test the transfer learning framework, not as a novel CWS model. So we select (Huang et al., 2015) as our base model, which uses character embedding.

Sec 3.4:
The mean negative log-likelihood loss is often used in CWS tasks. Our objective with adaptive loss is somewhat similar to MIRA. 

Sec 3.5.2:
(1) Domain-specific embedding means each domain maintain a specific set of parameters for a layer in the neural network.
(2) In Table 7 & 8, Model-2 w/o Adap. and Model-3 w/o Adap. are two variants of the model proposed by Ruder 2017, since layers of two tasks share parameter, as you can see in Figure 1. 

Sec 3.5.3:
âŠ• stands for a concatenation of two vectors. We argue that domain-specific information and shared information won't be biased.

Sec 4.5:
For the three data sets annotated by medical experts, we randomly choose 60%, 20%, 20% from each for train, dev, and test set. The statistic is shown in Table 3.

Sec 4.6:
(1) In our experiment setting, we treat experiments in Table 7 as transfer learning between detailed division in a domain, e.g. different departments in the medical domain or different genres of novels. We would like to explore how we can exploit data from a different detailed division in the multi-task learning task. Experiments in Table 8 are treated as transfer learning between different domains (medical-news/weibo). So we set different scenes for the experiments and we only use open source datasets in Table 8 and use all medical datasets in Table 7.
(2) It is true that Mou et al.(2016) also proposed MULT methods. However, the key idea of MULT methods is just sharing parameters (layers) in the neural network. And it doesn't specify which layer should be shared. So in this paper, we propose two models with shared layers, as you can see in Figure 1.b/1.c. It is mentioned from line 555 to 558.

Sec 4.7:
The hyper-parameter is determined by using the development set.

Sec 4.8:
We will add the t-test and p-values to the revision. (Gavin, if you can compute this now, tell them straight away.)

#2
(1) There are several reasons why we choose the task with datasets of high disparity to conduct the ablation test. The first reason is that in the real-world application, we concern more about transfer learning tasks with a high disparity between domains. The second reason is that .., (I can't comment on this. Do you have a second reason? If not just one reason.)

(2) 10% available data from target domain and all of the data from source domain were used for training. We used this schema to simulate the scenario of improving the performance of low resource domain (target domain with little annotated data, e.g., 10%) by exploiting high resource domain (source domain with much annotated data, e.g., 100%).
