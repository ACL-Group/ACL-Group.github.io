\section{Conclusion}

In this paper, we investigate how to solve the natural language inference generation task in a few-shot setting. We propose a new model LM-PDD, which combines a PLM with prompts and demonstrations. We propose a novel template selection method, which takes full use of the development set for conditional generation tasks, and a dynamic demonstration method, which tunes the sentence embeddings with training examples. Our experiments show our methods outperform previous prompt selection and demonstration methods. Our model outperforms the vanilla fine-tuning method 8\% on average.