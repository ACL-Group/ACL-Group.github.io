\section{Approach}

% \KZ{Put a little preamble here.} \MY{never start a subsection after a section without saying anything. that is the preamble}
In this section, we first define objectives for both psychiatrist and patient chatbot, followed by the design of prompts aligning with these objectives.

\subsection{Objective Identification}
\label{sec:objectives}
Given the lack of formal definition for what constitutes a good psychiatrist chatbot in diagnosis conversations, we sought input from five experienced psychiatrists and seven individuals with mental disorders to gather their opinions. Following this, we conducted a thorough literature review \cite{yao-etal-2022-d4,bao-etal-2021-plato,sun-etal-2023-moraldial} and meticulously compiled a set of objectives that will serve as our guiding framework throughout the study.\footnote{These psychiatrists come from top-ranked national mental health centers. 
Their professional titles and areas of expertise can be found in 
Appendix \ref{apd:psych_info}. Patients were recruited through online advertisements.}. 

The objectives are organized as follows.
\paragraph{Psychiatric Chatbot}

% The objectives are derived from the first two phases. In phase 1, the psychiatrists are encouraged to freely express their opinions, allowing us to summarize a set of objectives.  In phase 2, as we iteratively refine the prompts, we consult the psychiatrists for their input and identify any additional objectives to consider based on the performance of chatbot. 

% \MY{how do we know that at last stage, this is the final standard? do we have a comment from doctors that the defined objectives are exhaustive and up to application standard?}

% \KZ{The following is a bit weird. Shall we change our title to include depression? Since this paper focuses on bots to diagnose depression only?}
% Considering the variation in diagnosis standards and symptoms for different mental disorders, we concentrate on depressive disorders for this study, while leaving the scaling to include other disorders as future work.

As a psychiatrist chatbot, the primary task is to conduct a professional diagnostic process for the patient and provide an \textbf{accurate diagnosis}. To achieve this, a good psychiatrist chatbot should possess the following four capacities: 
% \KZ{These four dimensions must be evaluated in the experiments.}
% \MY{I don't think empathy-related stuff is only for user experience, it also serves the purpose of building inter-personal relation and trust for the patients, and eased their nerves for the purpose of better revealing truthful feelings and symptoms, hence a more accurate diagnosis}
\begin{itemize}
    \item \textbf{Comprehensiveness:} Inquire about the key symptoms of depression, including sleep, mood, diet, and other relevant aspects that are required for diagnosis, as defined in DSM-5~\cite{american2013diagnostic}. Comprehensive inquiring can better eliminate certain possibilities, resulting in more accurate diagnostic outcomes.
    \item \textbf{In-depth Questioning:} Conduct thorough questioning, delving into details like the duration of symptoms, based on the patient's responses. Recognizing the challenge patients face in articulating their mental state, the psychiatrist chatbot should aim to understand and clarify their descriptions.
    \item \textbf{Empathy:} Demonstrate empathy and provide emotional support to patients to establish trust and ease their nerves. This helps patients feel more comfortable in expressing their genuine feelings and symptoms, leading to a more accurate diagnosis.
    \item \textbf{Engagement:}\cite{bao-etal-2021-plato} Facilitate smooth transitions between topics to optimize conversation efficiency, ensuring patients remain interested and connected, encouraging them to continue the discussion.
    % \item Provide examples to guide patients to articulate their symptoms, rather than just asking, "Do you have any other symptoms?", the latter often causing patients to overlook important symptoms and forget to mention to the doctor.
\end{itemize}

\paragraph{Patient Chatbot} The basic requirement for a patient chatbot is \textbf{honesty}, which entails presenting an accurate and rational description of symptoms in the provided symptom list, without reporting any non-existent ones.

Additionally, to make the chatbot more resemble real patients, psychiatrists also describe some behaviors commonly exhibited by real patients during consultations. 
\begin{itemize}
    \item \textbf{Emotion:} Patients in a depressed mental state may experience emotional fluctuations during the conversation.
    % while the chatbot's presentation of symptoms is too calm and polite. 
    \item \textbf{Expression:} Patients use colloquial expressions when describing symptoms, and may have difficulty expressing themselves clearly. They often talk about their daily life experiences. While current chatbots tend to explicitly list out the symptoms~\cite{Llanos2021Lessons} using formal language, which is too sane and professional for a patient.
    % However, the chatbot tends to use formal language similar to the official diagnostic criteria (DSM-5).
    \item \textbf{Resistance:} Patients may be reluctant to seek help. They may remain silent and refuse to communicate, or downplay their symptoms to avoid being perceived as a burden. 
    % In contrast, the chatbot is overly cooperative, readily acknowledging and providing detailed descriptions of its symptoms.
\end{itemize}

\subsection{Prompt Designing}
\label{sec:prompt}
To harness the capabilities of the Language Model (LLM) for psychiatric diagnosis, we design prompts closely aligned with the proposed objectives for both the psychiatrist chatbot and the patient chatbot as follows.
\paragraph{Psychiatrist Chatbot} In this prompt, we include examples (highlighted in colored boxes) to guide the chatbot in asking \textit{in-depth} questions and demonstrating \textit{empathy}. These examples can be considered as extra domain knowledge to help LLM comprehend these behaviors in clinical contexts.

% are crucial because LLMs may struggle to comprehend these behaviors in clinical contexts. Consequently, providing examples can be a promising approach to help LLMs grasp certain specialized skills within professional domains.
\begin{prompt}
    \ding{192} Please play the \uline{role} of an \uline{empathetic and kind} \textbf{psychiatrist}. 
    \ding{193} Your \uline{task} is to conduct a professional diagnosis conversation with me based on the DSM-5 criteria. 
    \ding{194} Your questions should \uline{cover at least the following aspects}: [\ldots]\protect\footnotemark. 
    % You are free to choose the order of questions, but you must collect complete information on all aspects in the end. 
    \ding{195} Please only ask \uline{one question at a time}.
    % , and each question should only cover one symptom.
    \ding{196} You need to ask \uline{in-depth questions}, such as the \Blue{duration}, \Blue{causes} and specific \Blue{manifestations}. 
    \ding{197} You need to use various \uline{empathetic strategies}, such as \Yellow{understanding}, \Yellow{support} and \Yellow{encouragement}. 
\end{prompt}
\footnotetext{The aspects include ``emotion'', ``sleep'', etc. We provide the full list in Appendix \ref{apd:prompts}.}

\paragraph{Patient Chatbot} In this prompt, we instruct LLM to emulate patients with depression, exhibiting emotional fluctuations or resistance.
\begin{prompt}
    \ding{192} Please play the \uline{role} of a patient, who is currently chatting with a doctor. 
    \ding{193} \uline{You are experiencing the following symptoms}: [\texttt{Symptom List}]\protect\footnotemark 
     % \KZ{Instead of giving the full list of symptoms in the prompt, shouldn't we give a random subset of those symptoms?}
    \ding{194} Please talk to me based on the above symptom list. 
    \ding{195} You can only mention \uline{one symptom per round}. 
    \ding{196} You should \Blue{express} your symptoms in a \uline{vague and colloquial} way, and relate them to your \uline{life experiences}.
    \ding{197} You can have \Blue{emotional fluctuations} during the conversation. 
    \ding{198} You have a \Blue{resistance} towards doctors, and do not want to reveal some feelings easily.
\end{prompt}
\footnotetext{The symptom list is summarized by ChatGPT and revised by psychiatrists. See Appendix \ref{apd:symp_list} for details.}
However, as these instructions are not align with LLM's training objective to be a helpful, polite AI assistant, the patient chatbot can easily forget certain instructions (e.g., resistance). To address this issue, we covertly append the following words as reminder at the end of the most recent sentence in the dialogue history without users' awareness.
\begin{prompt}
    (\Yellow{Attention:} colloquial language, life experience, low mood or mood swings, refuse or answer briefly due to resistance)
\end{prompt}

% \KZ{I added the following para.} \MY{This targets at possible attacks that our prompting strategy is old-fashioned, explain that it serves the purpose but complexed prompting can futher elevate the performance. But the core objectives and framework we setup here is valuable}
We acknowledge the existence of various potential prompt designs that may serve our purpose. The prompt we present here may not be the most optimal one nor is it intended to be one. 
% But the core objectives and framework we setup here is valuable.
What we want to demonstrate here is the objectives and framework for psychiatric diagnosis dialog represent a promising research direction for future endeavors.
% promising research direction in AI-driven psychiatric diagnosis that opens up more opportunities in the future.

% In the first iteration, we describe the task (sentence \ding{192}\ding{193}), provide a symptom list (sentence \ding{194}) in the prompt, and add sentence \ding{195} to avoid listing all the symptoms in one turn. 
% This prompt enables the chatbot to meet the basic requirement of providing \textit{honest} responses in most cases.
% However, feedback from psychiatrists indicates that the chatbot lacks resemblance to real patients as it does not effectively convey \textit{emotions}, use colloquial \textit{expressions}, or demonstrate \textit{resistance} to seeking help. 

% Therefore, we add sentence \ding{196}, \ding{197}, \ding{198} to address these issues in the second iteration.
% However, we observe that the effect of adding these sentences is most prominent in the initial rounds of conversation, suggesting that the patient chatbot tends to forget some of the instructions given at the beginning. 
% This behavior is reasonable considering ChatGPT's training objective to be a helpful, polite AI assistant that provides detailed responses. Consequently, there can be a potential mismatch between the desired behavior of the patient chatbot, including resistance and emotional fluctuations, and the training objective, making it more likely for these instructions to be forgotten.

% To address this issue, we insert new reminders during the conversation. Inspired by the fact that the latter part of the prompt has the greatest impact on the responses generated by ChatGPT, our method is straightforward yet effective. Without users' awareness, we covertly append the following words at the end of the most recent sentence in the dialogue history.

% \begin{prompt}
%     (\Yellow{Attention:} colloquial language, life experience, low mood or mood swings, refuse or answer briefly due to resistance)
% \end{prompt}

% We aim to use simple phrases or words as reminders during the conversation to ensure that the sentences are not overly long. Moreover, these reminders are only temporarily attached to the most recent round, and will not persist in the dialogue history for subsequent rounds.

% In this prompt, we provide a clear description of the task and establish the role to be simulated by the chatbot. Then, we list the specific aspects that the doctor chatbot should cover during the interview process. This serves as a guideline to ensure the \textit{comprehensiveness} objective. 
% What's more, we include examples (highlighted in colored boxes) in the prompt to guide the chatbot in asking \textit{in-depth} questions and demonstrating \textit{empathy}. These examples are crucial because, without them, the chatbot tends to ask superficial questions and  rely on generic phrases like ``thank you very much for your answer'' to show empathy. This arises from ChatGPT's limited comprehension of ``in-depth questioning'' and ``empathy'' in clinical contexts. Consequently, providing examples can be a promising approach to help ChatGPT grasp certain specialized skills within professional domains.