% !TEX root = ../main.tex

\begin{abstract}
%Recently, there has been a growing interest in utilizing large language models (LLMs) in mental health research, with studies showcasing their remarkable capabilities, such as disease detection. 
%However, there is currently a lack of a comprehensive benchmark for evaluating the capability of LLMs in this domain. Therefore, we address this gap by 
%\MY{add 1-2sentences from intro, say that why LLM in mental health is important and different from previous tasks.}
Distinguishing mental health from other domains, the evaluation of Large Language Model (LLMs) in mental health demands a nuanced approach, given the subtle and highly subjective nature of symptoms that exhibit significant variability among individuals. This paper presents the first comprehensive benchmark for evaluating LLMs in the mental health domain. 
%tailored to the unique characteristics of the mental health domain. 
It encompasses a total of six sub-tasks, covering three dimensions.
%systematically assess the capabilities of LLMs in the realm of mental health. 
We have designed corresponding concise prompts for each sub-task. 
We evaluate a total of twelve advanced LLMs using this benchmark. 
Experiment results not only demonstrate significant room for improvement in current LLMs concerning mental health but also unveil potential directions for future model optimization.
PsyEval and full evaluation protocols are open-sourced.\footnote{https://github.com/KaguraRuri/Psy-Eval}
%\MY{add a footnote and an anonymous github link, saying that the full dataset and experimental details are open-sourced.}

\end{abstract}