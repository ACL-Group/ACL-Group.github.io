\section{Introduction}

% dialogue summarization task
Dialogue summarization is a specialized summarization task that takes
a series of utterances from multiple speakers in the first person as input,
and outputs fluent and concise summaries in third persons as shown in 
\figref{fig:example}. 
%It helps people be acquainted with the gist of a dialogue 
%when they jump into a conversation, or review
%the key points after a conversation.
Different from previous monologue inputs such as news~\cite{narayan2018don} and scientific publications~\cite{cohan2018discourse}, dialogues are always less well-organized. They usually contain complicated reference relations, inconsecutive inter-utterance dependencies, informal expressions, and so on, making dialogue summarization a more challenging task.

\begin{figure}[th]
	\centering
	\includegraphics[width=0.75\columnwidth]{example.pdf}
	\caption{An example from SAMSum dataset. %Different colors are used to identify different speakers.
	}
	\label{fig:example}
\end{figure}


%Compared with previous text summarization tasks which
%mostly focus on news~\cite{narayan2018don} and scientific 
%publications~\cite{cohan2018discourse}, dialogue summarization has
%a few additional challenges: i) the input dialogue is a mix of multiple
%persons' viewpoints, making it difficult to track the co-reference and hence
%\textit{who does what}; ii) dialogues are less organized, and 
%may contain ambiguous or inconsistent inter-utterance dependences; 
%and iii) if the dialogue is oral, the language used maybe less 
%formal and comes with errors and redundancies. 

% pretrain models
The most obvious characteristic of this task is the difference in the format and language styles 
between dialogue and its narrative summary.
Liu, Shi and Chen~\shortcite{liu2021coreference} mentioned
that coreference resolution models trained on general narrative text 
underperforms by about 10\% on dialogue corpus, 
demonstrating the inherent gap between dialogue and narrative text. 
As a result, popular PLMs such as BART~\cite{lewis2020bart} and 
PEGASUS~\cite{zhang2020pegasus} which excel on news summarization 
perform mediocrely on dialogue summarization.
%Therefore, models trained on a single text format, e.g., narrative text, 
%are sub-optimal for cross-format tasks, including dialogue summarization.

% makes models trained on narrative text sub-optimal for dialogue-related tasks. 
% previous work
To narrow this gap, previous work on dialogue summarization mainly 
resort to injecting dialogue features into PLMs to enhance dialogue 
understanding. These features include dialogue acts~\cite{goo2018abstractive}, topic transitions~\cite{chen2020multi}, coreference relations~\cite{liu2021coreference}, discourse graphs~\cite{chen2021structure}, etc, leading to the rule-based
conversion from dialogues to plain text~\cite{ganesh2019restructuring}.
However, they suffer from three weaknesses. 
First, collecting or extracting these features becomes an additional step
in the summarization pipeline, complicating the inference procedure 
at runtime. 
Second, oracle feature labels are hard to collect and 
errors can propagate from wrong labels to poor summaries.
%Most features are annotated by labeling models trained on other corpora. 
%Carefully designed rules or hyper-parameters are needed for transferring 
%these models to different dialogue summarization datasets, which is 
%time-consuming and labor-intensive.
Third, additional layers or more encoders are required to incorporate 
features into PLMs, increasing the GPU memory footprint both during 
training and inference.

%First, data labeling approaches are transferred from their original designed domains and need human labors to design different hyper-parameters or rules for adapting to different dialogue summarization datasets, such as the
%weights between two views in Multi-view~\cite{chen2020multi} and 
%rules in~\citet{liu2021coreference}.
%Second, features may not generalize well to different dialogue scenarios. For example, the argument graph~\cite{fabbri2021convosumm} for capturing key argumentative contents is not suitable for e-mail threads as mentioned in their paper. 

% our approach
A more natural way to bridge this gap is to give the model 
more dialogue-narrative pairs to train on. Due to the scarcity of dialogue
summarization data, one approach~\cite{zhu2020hierarchical} is 
to convert other text summarization
pairs into dialogue to summary pairs via some template, but such work
requires additional data~\footnote{More related work is in \apxref{sec:relatedwork}.}.

In this paper, we propose an alternative approach that 
doesn't use any more data than the original dialogue summarization dataset. 
We convert each existing data pair into many ``\textbf{pseudo-paraphrase}'' pairs 
between a dialogue and a narrative sentence. Then we post-train a pre-trained
seq2seq language model using a \textbf{prefix-guided generation} (PGG) task 
on the augmented paraphrase dataset.
After that, the post-trained model is further fine-tuned as usual 
for dialogue summarization. 
%Since there is no dialogue-to-text rephrasing task or related datasets as far as we know, we consider two ways for enhancing the rephrasing ability based on the existing dialogue summarization data.
%We enhance the rephrasing capability of the PLM by first
%constructing a ``pseudo-paraphrase'' dataset which consists of pairs of
%dialogue and its partial paraphrase, and then refining the pretrained
%seq2seq model using a prefix-guided generation (PGG) task, using the first several tokens 
%in the output as supervision, and thus leveraging more unpaired data.
To this end, no human efforts on crafting complicated 
rules or hyper-parameter tuning, or additional memory 
costs, as well as additional training data, is required.
In sum, our contributions are:
%Then, training the model to learn sentence completion in the third-person point of view for rephrasing ability.

%We designed different operations to 
%construct paraphrasing dataset extracted from the existing dialogue-to-summary pairs. 
%One option is to fix the input dialogue and manipulate the utterances into 
%indirect speech by simple rules as the output. Another option is to 
%fix the output, in the form of either a summary or a sentence in the summary, 
%and treat it as a paraphrase of partial dialogue utterances.\KZ{Are we claiming
%both options to be our innovation? And our best approach actually can be seen
%as option 1 also?} 
%with highest Rouge scores.
%The whole summary can be separated into sentences to 
%get more elementary rephrasing pairs.\KZ{Is this option 1 or option 2?} 
%\KZ{I don't think this is necessary:
%All of these operations are done only on the training set and validation set, 
%avoiding the information leak for final dialogue summarization.}
%we construct such data based on dialogue-summary pairs from the original training and validation sets.
%Inspired by~\cite{ganesh2019restructuring},
%On the other hand, we can fix the output summary and regard it as a paraphrase of the combination of dialogue utterances with highest Rouge scores, borrowed from the idea of oracle extraction for news summarization~\cite{zhou-etal-2018-neural-document}.
%These rephrasing datasets are trained with normal auto-regressive generation task.


%To enable the PLM with dialogue-to-narration rephrase capability, we 
%design a novel prefix-guided generation (PGG) task in the post-training. 
%The prefix, which are the first few tokens of a sentence, 
%are given to the decoder as hints and will not be used for computing losses. 
%This way, the model can learn to select some designated information (guided by
%the prefix) from the input and rephrase it into third-person narratives.

%Comprehensive experiments show that post-training for rephrasing 
%indeed narrows the understanding gap between dialogue and narrative text.  
%Among several alternative designs, post-training with PGG on dialogue-sentence pairs works best, 
%and it also beats previous state-of-the-art approaches on dialogue summarization.

%based on the success of sketch supervision for controllable summarization~\cite{wu-etal-2021-controllable}, we hypothesis that the above mentioned extraction operation can be done implicitly by the given tokens to the decoder.
%The number of prefix tokens is determined by POS tags or dependency parsing tags sample by sample. 
%constributions
\begin{itemize}
\item We propose a novel and effective post-training processing to close 
the format and linguistic style gap between dialogues and narrative texts ($\S$~\ref{sec:approach}).
%(see \secref{} compare with vanilla BART);
%\item Unlike existing dialogue summarization methods, our approach requires no other training data than the existing dialogue summarization data (see \secref{sec:approach});
\item PGG with pseudo-paraphrase pairs requires no extra training data or 
labeling tools for features extractions ($\S$~\ref{sec:pggablation}).
\item Extensive experiments show that the proposed approach compares favorably with current SOTA models using less human efforts and computational costs ($\S$~\ref{sec:end2end}).
% (see \secref{} end to end
%and results that show the params tuning and memory costs).
%As far as we know, we are the first to do post-training based on PLMs to learn the rephrasing ability without specific dialogue features. The improvements on dialogue summarization show the effectiveness of this idea for solving cross-format problems. 
%	\item PGG with dialogue-sentence samples performs best among rephrasing approaches. Ablations on PGG showing that the prefix tokens guide generation especially within a sentence and the number of tokens can be simply determined by POS tags or dependency tags.
%	\item The favorable results of our best approach over the state-of-the-art models on dialogue summarization datasets show the strong dialogue summarization ability. Besides, our approach is easier to implement with less human efforts and computation costs.
%
\end{itemize}
