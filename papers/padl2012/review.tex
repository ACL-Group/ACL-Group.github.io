\section{Review of \pads{} and \learnpads{}}\label{sec:review}
\begin{figure*}
{\small
\begin{verbatim}
207.136.97.49  - - [05/May/2009:16:37:20 -0400] "GET /README.txt HTTP/1.1" 404 216
ks38.kms.com - kim [10/May/2009:18:38:35 -0400] "GET /doc/prev.gif HTTP/1.1" 304 576
\end{verbatim}
}
\caption{A Fragment of a Simple Web Server Log \ai{}}
\label{fig:ai} 
\end{figure*}

The data in \figref{fig:ai} is a fragment of a simple web server log.
We use this format, which we call
\ai{}, to illustrate the principal features of the \pads{} data
description language. The data 
is made up of a sequence of records, separated by newlines.
Each record contains a number of fields delimited by white spaces. 
For example, the first record starts with an IP address, 
then has two dashes, a time stamp enclosed in
square brackets, a quoted HTTP message, and finally two
integers. The second record shows some variation:
the IP address becomes a hostname and the second dash becomes an identifier.

\pads{} uses a type-based metaphor to
describe ad hoc data.  Each \pads{} type plays a dual role: it
specifies a grammar by which to parse the data and a data-specific
data structure in which to store the results of the parse. 
\padsc{} is the variant of \pads{} that uses \C{} as its host
language, and therefore is syntactically similar to \C{}. 
When compiled, the generated data structures and parsing code 
are in \C{}.

\figref{fig:ai.p} shows a \padsc{} specification that describes the
records in \figref{fig:ai}.  
The specification consists of a
series of declarations. Types must be declared before they are used,
so the last declaration \cd{entry\_t} describes the entirety of a
record, while the earlier declarations describe fragments of the record.  
Type \cd{entry\_t} is a \kw{Precord}, meaning it comprises a full line in
the input, and is a \kw{Pstruct}, meaning it consists of a sequence of
named fields, each with its own type.  For convenience, \kw{Pstruct}s
can also contain anonymous literal fields, such as \cd{" ["}, which
denote constants in the input source.  The generated representation
for \cd{entry\_t} will be a \C{} struct with one field for each of the
named fields in the declaration.
The type \cd{client\_t} is a \kw{Punion}, meaning the described data
matches \textit{one} of its branches, by analogy with \C{} unions. In
particular, a \cd{client\_t} is either an IP address (\cd{Pip}) or a
host name (\cd{Phostname}), where \cd{Pip} and \cd{Phostname} are
\padsc{} \textit{base types} describing IP addresses and hostnames,
respectively.  

\begin{figure}[t]
{\small 
\begin{code}
\kw{Punion} client_t \{
  Pip       ip;      // 207.136.97.49
  Phostname host;    // ks38.kms.com
\};
\kw{Punion} auth_id_t \{
  Pchar unauthorized : unauthorized == '-'; 
  Pstring(:' ':) id;                        
\};
\kw{Pstruct} request_t \{
   "GET ";    Ppath    path;
   " HTTP/";  Pfloat   http_ver; 
   '"';
\};
\kw{Precord} \kw{Pstruct} entry_t \{
         client_t       client;          
   ' ';  auth_id_t      remoteID;        
   ' ';  auth_id_t      auth;            
   " ["; Pdate          date;   
   ':';  Ptime          time;     
   "] "; request_t      request;         
   ' ';  Pint           response;     
   ' ';  Pint           length; 
\};
\end{code}
\vskip -2ex
}
\caption{\padsc{} description for the \ai{} format}
\label{fig:ai.p}
\end{figure}


In general, base types describe atomic pieces of data such as integers
(\cd{Pint}) and floats (\cd{Pfloat}), characters (\cd{Pchar}) and
strings (\cd{Pstring(:' ':)}), dates (\cd{Pdate}) and times
(\cd{Ptime}), paths (\cd{Ppath}), \etc{} Strings represent an
interesting case as in theory they could go on forever, so
\cd{Pstring} takes a parameter which specifies when the string stops:
in this case, when it reaches a space character. To account for more general
stopping conditions, a programmer may use the base type \cd{Pstring_ME}, which 
takes a regular expression as a parameter.  With this type, the corresponding
string is the longest that matches the regular expression.
The first branch of the \kw{Punion} \cd{auth\_id\_t} illustrates the
use of a \textit{constraint}.  It specifies that the \cd{unauthorized}
character must be equal to \cd{'-'}.  If the constraint fails to hold,
the next branch of the union will be considered.  

In addition to the features illustrated in \figref{fig:ai.p}, \pads{}
provides arrays, which describe sequences of data all of the same
type; options, which describe data that {\em may} be present; and
switched unions, which describe unions where a value earlier in the
data determines which branch to take.  Such unions illustrate that
\pads{} supports \textit{dependencies}: earlier portions of the data
can determine how to parse later portions.

\begin{figure}[t]
{\small
\begin{verbatim}
<entry_t>
  <client>
    <ip>
      <elt><val>207</val></elt>
      <elt><val>136</val></elt>
      <elt><val>97</val></elt>
      <elt><val>49</val></elt>
      <length>4</length>
    </ip>
  </client>
  <remoteID>
    <unauthorized><val>-</val></unauthorized>
  </remoteID>
  <auth>
    <unauthorized><val>-</val></unauthorized>
  </auth>
  <date><val>2009-05-05</val></date>
  <time><val>16:37:20</val></time>
  <timezone><val>-0400</val></timezone>
  <request> ...  </request>
  <response> ... </response>
  <length> ... </length>
</entry_t>
\end{verbatim}
}
%%     <meth><val>GET</val></meth>
%%     <req_uri><val>/README.txt</val></req_uri>
%%     <version>
%%       <major><val>1</val></major>
%%       <minor><val>1</val></minor>
%%     </version>
%% <val>404</val>
%% <len><val>216</val></len>
\caption{XML translator output from one record of \ai{} format}\label{fig:xml}
\vskip -2ex
\end{figure}

From a description like the one in \figref{fig:ai.p}, the \pads{}
compiler can automatically produce a suite of data processing tools
such as an XML translator that converts the raw data into XML and
statistical reporter that computes the various statistics of each types
in the data source. \figref{fig:xml} presents the output of such an XML
translator when applied to the first data records in \figref{fig:ai}.
Note that every data field has been tagged with a corresponding 
\pads{} data type. \figref{fig:accum} shows a snippet of the statistical
report on a \ai{} data source. 


\begin{figure}[th]
{\small
\begin{verbatim}
*************************************************
<top> : struct entry_t
*************************************************
good vals: 3000  bad vals: 0  pcnt-bad: 0.0

[Describing each field of <top>]
=================================================
<top>.client : union client_t
=================================================
good vals: 3000  bad vals: 0  pcnt-bad: 0.0
  min ip 1  max host 2
  distribution:
  val: ip (1)   count: 1704 pcnt-of-good: 56.800
  val: host (2) count: 1296 pcnt-of-good: 43.200
                . . . . . . . . . . . . . . . . .
  SUMMING       count: 3000 pcnt-of-good: 100.000
=================================================
<top>.length.len : uint32
=================================================
good vals: 2651  bad vals: 0  pcnt-bad: 0.000
  min 35  max 37947 avg 3896.320
  distribution:
    val: 3082 count: 80  pcnt-of-good: 3.018
    val:  178 count: 55  pcnt-of-good: 2.075
    val:  170 count: 54  pcnt-of-good: 2.037
    val:  518 count: 50  pcnt-of-good: 1.886
    val:   43 count: 49  pcnt-of-good: 1.848
    val: 9372 count: 49  pcnt-of-good: 1.848
    val: 1277 count: 45  pcnt-of-good: 1.697
    val: 1425 count: 45  pcnt-of-good: 1.697
    val:  536 count: 43  pcnt-of-good: 1.622
    val: 1027 count: 42  pcnt-of-good: 1.584
              . . . . . . . . . . . . . . . .
    SUMMING   count: 512 pcnt-of-good: 19.313
\end{verbatim}
}
\caption{Fragment of statistical report of a \ai{} data source}\label{fig:accum}
\vskip -2ex
\end{figure}


\paragraph*{\learnpads{}}The goal of the \learnpads{} format inference engine is to infer 
\pads{} descriptions like the one in \figref{fig:ai.p} from raw data.
The algorithm is
designed to be {\em sound} in the sense that the generated description describes
{\em all} of the training data, including data that a human might deem to be erroneous.
We might have automatically deemed very low occurrence data erroneous and pruned the
corresponding elements of the description, but we felt
such decisions were best left in human hands.  The \pads{} statistical reporter
(automatically generated from the learned description, along with other \pads{} tools) 
can help with this task, if a user
chooses, by reporting the distribution of data that match each portion of the generated description.
A full description of the
\learnpads{} algorithm appears in an earlier
paper~\cite{Fisher+:dirttoshovels}. We give only a brief summary
here. 

\learnpads{} assumes that the input data is a sequence of
newline-terminated records and that each record is an instance of the
desired description.  From such an input, it uses a three-phase
algorithm to produce a description.  In the {\em tokenization} phase,
\learnpads{} converts each input line into a sequences of tokens,
where each token type is defined by a regular expression.
Intuitively, these tokens correspond to \pads{} base types.
For example, the sequences of
tokens (shown in brackets) converted from the two data lines 
in \figref{fig:ai} are:

{\small
\begin{verbatim}
[ip] [ ] [-] [ ] [-] [ ] [[] [date] [:] 
   [time] []] [ ] ["] [str] [ ] [path] [ ] 
   [str] [/] [float] ["] [ ] [int] [ ] [int]

[host] [ ] [-] [ ] [str] [ ] [[] [date] [:] 
   [time] []] [ ] ["] [str] [ ] [path] [ ] 
   [str] [/] [float] ["] [ ] [int] [ ] [int]
\end{verbatim}
}

Note that there are data sources in which the major unit of
repetition is something other than a single line of text. Our
system allows the use of other record delimiters through a
regular expression. Automatic inference of such a delimiter
does not seem worthwhile because it normally does not take
the user more than a few seconds to look at the data source and
determine the appropriate delimiter.

In the {\em structure discovery} phase, \learnpads{} computes a
frequency distribution for each token type and then uses that
information to determine if the top-level structure of the data source
is a base type, \kw{Pstruct}, \kw{Parray}, or \kw{Punion}.  Based on
that determination, the algorithm partitions the data 
and recursively analyzes each of those partitions, constructing
the corresponding description as it recurses.  This phase terminates
with a candidate description.  

The \learnpads{} system decides the current top-level structure must
be a \kw{Punion} only if the frequency distribution does not look like
a base type, a \kw{Pstruct} or a \kw{Parray}.  Having decided for a
\kw{Punion}, the algorithm must partition the records of the data into
buckets; each bucket corresponds to one branch of the new
\kw{Punion}.  The original \learnpads{} partitioned the records
based on the first token of each record: all records starting with
\kw{Pint} into one bucket, \kw{Pdate} into a second, \etc{}  
Although this approach is very effective for some formats, for others
it fails to capture useful structure, because two semantically very
different records may incidentally have the same type of token as their first
token. And conversely records with similar meaning may not share the same
first token. To address this lack, we added
a second mechanism for partitioning records in a \kw{Punion}
context: edit distance.  With this approach, two records are placed in
the same bucket if the number of token ``edits'' (insertions and
deletions) required to morph the token sequence of one record into the
other is less than a threshold percentage of the length of the
sequences.   This second approach is also very successful in many, but
not all formats.  As a result, the current \learnpads{} system
provides both options; the user selects the desired mechanism using a
command-line switch.


In the {\em format refinement} phase,
the algorithm uses an information-theoretic scoring function to guide the
application of rewriting rules.
These rules seek to minimize the size of the description while
improving its precision by performing structural transformations (such
as merging adjacent \kw{Pstruct}s),  adding data dependencies ({\em e.g.}
converting regular unions into switched unions), and
constraining the range of base types, \eg{}, converting a
general integer to a 32-bit integer.  

The scoring function, which is based on the \textit{minimum
  description length principle}~\cite{mdlbook}, 
measures how well a description describes data by calculating
the number of bits necessary to transmit both the description and the
data \textit{given the description}.  We use the terms \textit{type complexity}
  and \textit{data complexity} to refer to the number of bits necessary to
encode the description and the data given the description,
respectively.  This function penalizes overly
general descriptions, such as \kw{Pstring}, which have a
low type complexity but a very high data complexity.  It also
penalizes overly specific descriptions that are extremely verbose.
Such descriptions have a low data complexity but a high type 
complexity.

%This algorithm produces good results for the small
%log files that we have experimented with, but it has two limitations:
%performance and adaptability.  In terms of performance, the algorithm
%requires space quadratic in the input file size to perform the data
%dependency analysis, so it cannot be used on data sources larger than the
%square root of the size of usable memory. In terms of adaptability, the
%algorithm only learns a description from a fixed amount of data.
%If the data changes over time,
%the algorithm cannot modify the existing description; 
%it must start from scratch. This prevents the user from adapting
%descriptions to manage evolving data sources.


%
% - PADS description
%
% - How LearnPADS works
%
% - LearnPADS Limitations: 
%	1) main-memory algo can't handle very large data sources
%        2) formats learned from a subset of data may not be correct (ai.3000 with a POST)
%	3) can't handle continuous data
%	4) formats learned can be un-intuitive (needs some human guidance)
%
% - hence we developed the incremental learning algorithm
