% This is samplepaper.tex, a sample chapter demonstrating the
% LLNCS macro package for Springer Computer Science proceedings;
% Version 2.21 of 2022/01/12
%
\documentclass[runningheads]{llncs}
%
\usepackage[T1]{fontenc}
% T1 fonts will be used to generate the final print and online PDFs,
% so please use T1 fonts in your manuscript whenever possible.
% Other font encondings may result in incorrect characters.
%
\usepackage{graphicx}

% Used for displaying a sample figure. If possible, figure files should
% be included in EPS format.
%
% If you use the hyperref package, please uncomment the following two lines
% to display URLs in blue roman font according to Springer's eBook style:
%\usepackage{color}
%\renewcommand\UrlFont{\color{blue}\rmfamily}
%
\usepackage{times}
\usepackage{soul}
\usepackage{url}
\usepackage{microtype}
\usepackage[hidelinks]{hyperref}
\usepackage[utf8]{inputenc}
\usepackage[small]{caption}
\usepackage{subcaption}
%\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{courier}
\usepackage{color}
\usepackage{epsfig}
\usepackage{booktabs}
\usepackage{array}
\usepackage{multicol}
%\usepackage{threeparttable}
\usepackage{epstopdf}
\usepackage{listings}
\usepackage{multirow}
%\usepackage{subfigure}
\usepackage{ragged2e}
\usepackage{xassoccnt}
%\usepackage{amsmath,amsfonts,amssymb,amsthm,amsopn}
\usepackage{colortbl}
\definecolor{mygray}{gray}{.9}
%\newcommand{\ft}[1]{\textsc{#1}}
%\newtheorem{example}{Example}
\newcommand{\secref}[1]{Section \ref{#1}}
\newcommand{\figref}[1]{Figure \ref{#1}}
\newcommand{\eqnref}[1]{Eq. (\ref{#1})}
\newcommand{\tabref}[1]{Table \ref{#1}}
\newcommand{\exref}[1]{Example \ref{#1}}
\newcommand{\cut}[1]{}
%\newcommand{\citealp}[1]{\citeauthor{#1}~\shortcite{#1}}
\newcommand{\KZ}[1]{\textcolor{blue}{Kenny: #1}}
\newcommand\BibTeX{B\textsc{ib}\TeX}
\usepackage{amsmath}
\newcommand{\sgn}{\text{sgn}}
\usepackage[section]{placeins}
\usepackage{afterpage}
%\newcommand{\sgn}{\operatorname{sgn}}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

%
\begin{document}
%
\title{Statistically Profiling Biases in Natural Language Reasoning Datasets and Models}
%\title{Analyzing and Mitigating Biases in Natural Language Understanding: A Lightweight Statistical Framework with ICQ (I-See-Cue)}
%
%\titlerunning{Abbreviated paper title}
% If the paper title is too long for the running head, you can set
% an abbreviated paper title here
%
%\author{First Author\inst{1}\orcidID{0000-1111-2222-3333} \and
%Second Author\inst{2,3}\orcidID{1111-2222-3333-4444} \and
%Third Author\inst{3}\orcidID{2222--3333-4444-5555}}
%
%\authorrunning{F. Author et al.}
% First names are abbreviated in the running head.
% If there are more than two authors, 'et al.' is used.
%
%\institute{Princeton University, Princeton NJ 08544, USA \and
%Springer Heidelberg, Tiergartenstr. 17, 69121 Heidelberg, Germany
%\email{lncs@springer.com}\\
%\url{http://www.springer.com/gp/computer-science/lncs} \and
%ABC Institute, Rupert-Karls-University Heidelberg, Heidelberg, Germany\\
%\email{\{abc,lncs\}@uni-heidelberg.de}}

\maketitle
\begin{abstract}
%Deep neural models have exhibited strong performance in natural language understanding (NLU) tasks, 
%yet they often display fragility when faced with minor perturbations. 
%This fragility can stem from reliance on artificial 
%spurious cues within datasets. 
%%Large language 
%%models like ChatGPT have revolutionized natural 
%%language processing, but 
%A robust evaluation 
%method is needed to understand the impact of 
%artificial spurious cues on these systems. 
%Current evaluation approaches 
%have limitations in addressing these concerns. 
%To improve the understanding and optimization of 
%models like ChatGPT, we introduce ICQ (I-See-Cue), 
%a lightweight statistical analysis framework that 
%identifies biases in multiple-choice NLU datasets 
%and assesses models' exploitation of these biases 
%through black-box testing. By validating ICQ's 
%effectiveness on various NLU datasets and models, 
%we provide valuable insights into ChatGPT's 
%learning of potential biases and offer guidance 
%for designing appropriate prompts and 
%%optimizing large language models.
%ecent work has revealed that many natural language 
%understanding and reasoning datasets contain statistical 
%cues that NLP models may exploit, leading to an 
%overestimation of their capabilities. 
%Existing methods, such as ``hypothesis-only'' tests and CheckList, 
%have limitations in identifying these cues and 
%assessing model weaknesses. To address these 
%challenges, we propose ICQ (I-See-Cue), a lightweight 
%and general statistical profiling framework that automatically 
%identifies potential biases in multiple-choice NLU datasets 
%without the need for additional test cases. 
%ICQ evaluates the extent to which models exploit 
%these biases through black-box testing. 
%Furthermore, we examine ChatGPT's bias through a case 
%study and offer valuable recommendations for practical applications.
%
Recent studies have shown that many natural language understanding and reasoning datasets contain statistical cues that can be exploited by NLP models, resulting in an overestimation of their capabilities. Existing methods, 
such as ``hypothesis-only'' tests and CheckList, 
are limited in identifying these cues and evaluating model weaknesses.
We introduce ICQ (I-See-Cue), a lightweight, general statistical profiling framework that automatically identifies potential biases in multiple-choice NLU datasets without requiring additional test cases. ICQ assesses the extent to which models exploit these biases through black-box testing, addressing the limitations of current methods. In this work, we conduct a comprehensive evaluation of statistical biases in 10 popular NLU datasets and 4 models, confirming prior findings, revealing new insights, and offering an online demonstration system to encourage users to assess their own datasets and models.
Furthermore, we present a case study on investigating ChatGPT's bias, providing valuable recommendations for practical applications.







%we showcase a case study on selecting prompts 
%that can investigate ChatGPT's bias, 
%providing useful recommendations for practical applications.

%Recent work has indicated that many natural language understanding and 
%reasoning datasets contain statistical cues that
%may be taken advantage of by NLP models whose
%capability may thus be grossly overestimated. 
%However, none of the work has been able to
%easily pinpoint what these cues are. 
%Inspired by black-box test in software engineering, 
%To discover the potential weakness in the models, some human-designed 
%stress tests have been proposed but they are expensive to create 
%and do not generalize to arbitrary models. 
%We propose a light-weight and general statistical profiling framework, 
%ICQ (I-See-Cue), which automatically identifies possible biases
%in any multiple-choice NLU datasets without 
%the need to create any additional test cases, and further evaluates
%through black-box testing the extent to which models may exploit these biases. 
%%
%Natural Language Understanding (NLU) datasets and models are susceptible to underlying biases, which may lead to an overestimation of their capabilities and impact their real-world performance. Current approaches to uncovering potential weaknesses in models involve human-designed stress tests, which are expensive to create and do not generalize well to arbitrary models. To address this issue, we introduce ICQ (I-See-Cue), a lightweight and versatile statistical profiling framework that automatically identifies potential biases in multiple-choice NLU datasets without requiring additional test cases. Furthermore, ICQ assesses the extent to which models exploit these biases through black-box testing. We validate the effectiveness of ICQ on various NLU datasets and demonstrate how it can be employed to detect and mitigate biases in models, ultimately contributing to more robust and reliable NLU systems.
\keywords{nature language processing  \and model robustness \and bias analysis.}
\end{abstract}

\input{intro}
\input{formulation}
\input{approach}
\input{experiment}
\input{case}
\input{related}
\input{conclusion}

\bibliographystyle{splncs04}
\bibliography{aaai21}

\end{document}
