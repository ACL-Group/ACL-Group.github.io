\section{Problem Definition}
\label{sec:prob}

In this section, the problem of partial suppression is formally described,
and before which, some preliminary mathematical concepts are defined as
follows.

%\subsection{Notations and Definitions}
%A {\em multiset} $S$ is a set which allows repetitive elements, while the
%{\em power multiset} $\mathbb{N}^S$ is the set of all subsets of the multiset
%$S$.
%Examples or formal definitions of these are given below.
%\begin{description}
%  \item[Multiset] $[a,a,b]$ is the same as $(\{a,b\},\{(a,2),(b,1)\})$
%  \item[Power set] $2^S$ is the power set of the set $S$
%  \item[Power multiset] $\mathbb{N}^S$ is the power multiset of the set $S$
%\end{description}

A {\em multiset} is a set which allows repetitive elements, while a {\em
power set} is the set of all subsets of a set. Examples or formal definitions
of these are given below.
\begin{description}
  \item[Multiset] \hspace{2em} $[a,a,b]$ is the same as
      $(\{a,b\},\{(a,2),(b,1)\})$
  \item[Power set]  \hspace{2em}  $2^S$ is the power set of the set $S$
  \item[Power multiset] \hspace{4em} $\mathbb{N}^S$ is the power multiset
      of the set $S$
\end{description}

\begin{table}[th]
\centering
\caption{Notations for Problem Definition}
\label{table:problem_notations}
\begin{tabular}{m{0.28\columnwidth}|m{0.6\columnwidth}}
  \hline
  \textbf{Symbol} & \textbf{Definition} \\
  \hline
  $D = D_S \cup D_N$ & the domain, which is the set of all possible items \\ \hline
  $D_S$ & the sensitive domain \\ \hline
  $D_N$ & the non-sensitive domain \\ \hline
  $T\in\natnum^{2^D}$ & a set-valued table, which is a multiset of $m$ transaction records \\ \hline
  $T[i]\in T$ & the $i$-th record of $T$ \\ \hline
  $R\in T$ & a transaction record %, which is a set of items drawn from $D$
  \\ \hline
  $|R|$ & the number of items contained in $R$ \\ \hline
  $I$ & an itemset, which is a subset of $D$\\ \hline
  $q$ & a \emph{quasi-identifier} (also \qid), which is a set of items (\textbf{sensitive items also allowed}) taken from any record in table $T$ \\ \hline
  $\enum(R) = 2^R - \{\emptyset\}$ & the \qid enumeration of $R$, which is the power set of $R$ except the $\emptyset$ \\ \hline
  $\displaystyle Q(T)=\bigcup_{R\in T} \enum(R)$ & the set of all \qids in table $T$ \\ \hline
  $\rho$ & the strong inference/association rule threshold \\ \hline
  $\mathcal{A}(q,e)$ & an inference/association rule $q\rightarrow e$\\  \hline
  $\SA(q,e)$ & a sensitive association rule $\mathcal{A}(q,e)$  if $e$ contains at least one sensitive item\\  \hline
  $sup_{T}(I)$ & the support of $I$ is the number of transactions $t\in T$ such that $I\subset t$\\ \hline
  $conf_{T}(q,e)$& the confidence of inference $\mathcal{A}(q,e)$ is $\frac{sup_T(q\cup e)}{sup_T(q)}$\\ \hline
\end{tabular}
\end{table}
%A set-valued table $T$ is a multiset of transaction records,
%  each record $R \in T$ is a set of items drawn from domain $D$.
%  $D$ is the union of two non-intersecting set, sensitive domain $D_S$ and non-sensitive domain $D_N$.
%We follow the step of \cite{Sweeney2002:k-anonymity} and
%  extend the definition \emph{quasi-identifier} ($qid$) in relational database for set-valued data.
%Then we give a series of other definitions related with $qid$.
%As simple as you can imagine, a $qid$ is just a set of items taken from $D$.
%$Q$ is a set of $qid$s, $\Omega(R_i)$ is the $qid$ enumeration of $R$ which is the power set of $R$ except the $\emptyset$.
%The column count $cc$ of row $R$ is the number of items contained in $R$.
Table \ref{table:problem_notations} lists the detailed notations used in the
rest of this paper. Next we define a number of important notations before
presenting the problem definition.

\begin{definition}[Container]
The \emph{container} of an itemset $I$ in table $T$ is defined as \[
\container_T(I) = \{ i \in \natnum : I \subseteq T[i], 1 \leq i \leq |T| \}
.\]
\end{definition}

\begin{definition}[Linked Items]
All sensitive items linked by a \qid $q$ in table $T$ is defined as \[
\linked_T(q) = \{ e \in D_S-q : sup_{T}(q\cup\{e\}) > 0 \} .\]
\end{definition}
 According to the definition, $sup_{T}(I)$=$|\container_T(I)|$.
 Also we will use $\container(I)$, $\linked(q)$, $sup(I)$,
$conf(q,e)$ to represent $\container_T(I)$, $\linked_T(q)$, $sup_{T}(I)$ and
$conf_{T}(q,e)$ respectively when $T$ is the only table within discussion.

\subsection{Privacy Model}
We reuse the $\rho$-uncertainty privacy model
proposed by Cao \etal \cite{Cao:2010:rho} which requires that the confidence of any sensitive
association rules is not above $\rho$. Next we formalize the
privacy requirement.
%Let $T$ be a set-valued table and the domain $D$ is
%divided into two subsets: the sensitive domain $D_S$ and the non-sensitive
%domain $D_N$. We assume that an attack will know any \qids $q$ such that
%$q\subset R, where~ R \in T$. The dataset is safe if and only if the attack
%will not infer any items , with a high probability (e,g,$\geq \rho$),
% $e$ from $D_S$ such that if $q \subset R$ then $e\in R$. Such an inference can be defined
%as a sensitive inference or sensitive association rule if $e \in D_S$,
% Our objective is to prevent the attack from mining any sensitive association rules.

%The model defined is immune to
%{\em
%record/attribute linkage attack} \cite{FungWCY10:Survey}
%However, we  prove that our technique promises a strong privacy result immune from  {\em Minimalitiy
%attack} \cite{Wong:2007:Minimality} and {\em Composition attack}
%\cite{Ganta:2008:Composition}
%To reach our objective, we have to keep the $conf(q,e)$ lower than $\rho$
%for any $\mathcal{A}(q,e)$. Therefore, we introduce the following definitions.
\begin{definition}
\label{def:safety_rule} A sensitive association rule $\SA(q,e)$ is safe
\wrt~$\rho$ if and only if $conf(q,e)\leq\rho$ .
\end{definition}

The $\rho$-uncertainty privacy model requires that all sensitive association
rules are safe.

\begin{definition}[Breach Probability]
\label{def:probability} The \emph{breach probability} of a \qid $q$ is \[
\breach(q) = \max_{e\in\linked(q)} conf(q,e) \]
%where $P(e|q) = P(q\rightarrow
%e) = \csize(q\cup \{e\})/\csize(q)$, and $P(e|q) = conf(e,q)$.
\end{definition}

\begin{definition}%[Safety of qid]
\label{def:safety_qid}
A \qid $q$ is safe \wrt~$\rho$ if and only if $\breach(q)\leq\rho$.
\end{definition}

\begin{definition}%[Safety of Table]
\label{def:safety_table}
A table $T$ is safe \wrt~$\rho$ if and only if $q$ is safe \wrt~$\rho$ for any \qid $q\in Q(T)$.
\end{definition}

As proved by Cao \etal \cite{Cao:2010:rho}, by ensuring confidences of all
sensitive association rules with one consequent below $\rho$,
confidences of all sensitive association rules with more consequents are also
made below $\rho$. As a result, Definition \ref{def:safety_table} can satisfy
the $\rho$-uncertainty privacy model.

\begin{definition}[Suppressor]
\label{def:suppressor}
A function $S : \natnum^{2^D}\times[0,1]\rightarrow\natnum^{2^D}$ is a \emph{suppressor} if and only if $S(T,\rho)$ is safe \wrt~$\rho$ for any table $T$.
\end{definition}
%\begin{property}
%\label{prop:container_size} For two\qids $p$ and $q$, if $p\subseteq q$ then
%$\container(q)\subseteq\container(p)$ and $\csize(q)\leq \csize(p)$.
%\end{property}
%
%\begin{proof}
%  $\forall i\in\container(q), q\subseteq T[i]\Rightarrow p\subseteq q\subseteq T[i] \Rightarrow i\in\container(p)$,
%  so $\container(q)\subseteq\container(p)$. Hence, $\csize(q)\leq \csize(p)$.
%\end{proof}
%
%Property \ref{prop:container_size} guarantees that $P(e|q)$ in Definition
%\ref{def:probability}, we can only consider sensitive association rules with
%a singleton consequent then all

\subsection{Information Loss}
\begin{definition}[Information Loss]
\label{def:infoloss}
Let $T^\prime = S(T)$ be the suppression result of table $T$ by the suppressor $S$.
The information loss of an item $e$ is defined as
\[ IL(e) = sup_{T}(\{e\}) - sup_{T^\prime}(\{e\}), \]
and the information loss of a suppression from $T$ to $T^\prime$ is defined as
\[ IL(T,T^\prime) = \frac{\sum_{e\in D}IL(e)}{\sum_{e\in D}sup_{T}(\{e\})}. \]
\end{definition}

Information loss of $T$ is essentially the number of items deleted in $T$
divided by total number of items in $T$. Our aim is to find a suppressor
defined in Definition \ref{def:suppressor} which reduces information loss as
much as possible. Information
loss is caused by suppression of items, and the best way to consider it
depends on the specific downstream utility \cite{Xu:2008:ATD}. Xu \etal
\cite{Xu:2008:ATD} requires the data publisher assigning a certain
information loss function to the global suppression of an item $e$, denoted
$IL(e)$.
%\textcolor{red}{ \emph{Classification Metric}
%\cite{Iyengar:2002:TDS} is better for anonymizing data for classifier
%training. \emph{Normalized Certainty Penalty} \cite{Xu:2006:UAU} is proposed
%for anonymization using generalization. Remove them?}
Cao \etal
\cite{Cao:2010:rho} introduces a metric for computing the information loss
caused by generalization.
We adopt the information loss metric used in \cite{Xu:2008:ATD}
and revised it in order to be consistent with the metric introduced in \cite{Cao:2010:rho}.
%\PC {We have to mention that actually this metric of information loss makes sense, since the value of it is exactly the value
%calculated by the avgloss\cite{Cao:2010:rho} under the condition that only suppression is executed}
%Because most of the existing metrics of information loss are proposed
%for anonymization using generalization,

To make a summary,
we use three metrics to measure the effectiveness of our partial suppression
algorithm and peers. The first one is the \emph{information loss}. The second
one is the \emph{symmetric relative entropy} which measures the change in
data distribution. The third one is the \emph{number of rules mined}
(including original and spurious rules) from the anonymized data. The first
measure is more general and used by other work. The last two metrics target
the utility of the anonymized data for statistical analysis and rule mining,
and they will be introduced in Section \ref{sec:eval}.

%\textcolor{red}{ We'll consider these three metrics in our
%heuristic solution later. }
%\begin{definition}[Optimal Suppression Problem]
%\label{def:osp}
%The optimal suppression problem is to find an optimal suppressor $S_\text{OPT}$ for a given table $T$ such that
%\[ IL(T,S_\text{OPT}(T))\leq IL(T,S(T)) \] for any suppressor $S$.
%\end{definition}
%\begin{definition}[Minimum suppression]
%Minimum occurrence suppression of item type $t$, to make confidence of
%inference $\mathcal{A}(q,e)$ below $\rho$:
% \hspace{4mm}
%\[MS(t,\mathcal{A}(q,e))=
%\begin{cases}
%sup(q\cap \{e\})-sup(q)\rho & t=e  \\
%\frac{sup(q\cap \{e\})-sup(q)\rho}{1-\rho} & t\in q \\
% \infty & otherwise
%\end{cases} \]
%\end{definition}
%\PC {
%\begin{definition}[Remaining probability of item $i$]
%The Remaining probability of item $i$ is defined as
%\[ remain(i)=\frac{\kappa_{T^\prime}(\{i\})}{\kappa_T(\{i\})} \]
%where $T$ is the original
%dataset and $T^\prime$ is the current dataset processed by suppression but
%not finished
%\end{definition}
%}

\subsection{The Problem}
The problem is to find a {\em Partial Suppressor} which anonymizes the input
set-valued table $T$ to satisfy the $\rho$-uncertainty privacy model and
minimizes item deletions.
%preserves the original data distribution or retains mineable useful
%association rules with limited spurious rules invented, and also minimizes
%item deletions.

\begin{definition}[Optimal Partial Suppressor]
The \emph{optimal partial suppressor} $S_\text{OPT}$ is the suppressor such that
\[ IL(T,S_\text{OPT}(T))\leq IL(T,S(T)) \] for any suppressor $S$.
\end{definition}

% \begin{definition}[Optimal Partial Suppressor for Distribution]
% \label{def:distribution}
% \[ Dist_{distance}(S_\text{OPT}(T), T) \leq  Dist_{distance}(S(T), T)\]
% while
% \[ IL(T,S_\text{OPT}(T))\leq IL(T,S(T)) \] for any suppressor.
% \end{definition}
% \begin{definition}[Optimal Partial Suppressor for Mining]
% \[ Spurious(S_\text{OPT}(T)) \leq  Spurious(S(T)) \] and
% \[OriginalRule(S_\text{OPT}(T)) \geq OriginalRule(S(T))\]
% while
% \[ IL(T,S_\text{OPT}(T))\leq IL(T,S(T)) \] for any suppressor.
% \end{definition}
