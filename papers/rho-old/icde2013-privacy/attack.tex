\section{Attacks}
\XH{
Safeness of our anonymization technique
}

\XH{
 Firstly, our privacy criteria is
the same as the $\rho$-uncertainty
 \cite{Cao:2010:rho}
privacy model, the confidence of any sensitive inference is made below the
probability threshold.
}
\XH{
Minimalitiy attack \cite{Wong:2007:Minimality} is proposed for relational
data. Assume an adversary knows the whole original quasi-identifer values as
external data, also knows the privacy model and anonymization technique, by
comparing the generalized version of quasi-identifier values with the
original quasi-identifier values, the adversary can successfully predict some
privacy. The Minimality attack relies on the generalization anonymization
technique, while our method uses suppression technique. Also for set-valued
data it doesn't have fixed combination of items as quasi-identifiers, so it's
unrealistic for an adversary to obtain the
 satisfactory external data.
 }
\XH{
Composition attack \cite{Ganta:2008:Composition} is proposed for relational data by using the
overlap population of multiple organizations' independent release of
anonymized data, through intersection the privacy can still be
breached in relational data.
For example $l$-diversity \cite{Ganta:2008:Composition} model can be violated by
composition attack.
The reason why composition attack can success is that
quasi-identifier attribute values are generalized and
sensitive attribute values are retained, when performing intersection the
probability of a correlation between quasi-identifier and sensitive values
will definitely increase.
}
\XH{
On the contrary, our partial suppression algorithm anonymizes set-valued data by
randomly suppressing some sensitive items.
In the same way to perform intersection,
 the probability that a sensitive item correlated with quasi-items can
both be higher or lower than before, which made the composition attack untrusted.
So in a summary our partial suppression technique is ideal to avoid composition attack
depending on the randomized characteristic of suppression.
}
\XH{
To consider the reverse-engineer attack,
for instance, that an
attacker knows that the presence of a certain item implies the presence of
another with a certain probability.
This could help an attacker figure out
the amount of suppressions that were performed, and possibly reverse-engineer
the anonymization process.
However knowing
the number of items deleted is useless since for each sensitive inference
we're using randomized suppression technique which suppresses certain number
of items according to the real situation and obviously not uniformly. To the
worst case, if an adversary knows all probabilities of inferences, he may
spend exponential time to enumerate all possible deletions to
reverse-engineer the original data from the anonymized data. It's obviously
not a kind of risk.
}
