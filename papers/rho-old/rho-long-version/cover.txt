This paper is an extended version of the best paper award winning work published at DASFAA 2014. The following are the major changes we have made to revise the paper significantly from the previous version.

1) The original paper, in Springer format was 14 pages. The current submission, in the similar Springer format, stands at 27 pages, which represents almost 90% percent increase in content.

2) In section 2.1, we amend the definition of KL in Table 2, the function to calculate KL divergence between two datasets. To prevent zero denominators, we further improve the function by a symmetric form in section 4.1. In section 2.2, we revise the definition of objective function f(T,T') in the rule mining scenario. In the former paper, we used the reverse of Jaccard similarity of sets of non-sensitive rules as a factor of f(T,T'). In the revised version, we replace it with the reverse of Jaccard similarity of sets of both sensitive and non-sensitive rules. The revision makes sense because sensitive and non-sensitive rules are of same importance to ordinary users, so we should take into account both when assessing the utility of datasets.


3) In section 3, we give the proof on the definition of number of suppressions. In section 3.2, we explain how we deal with possible regression in Buffer Sanitation. In section 3.3, we specify how we split data under divide-and-conquer frame. We add the analysis of algorithm in section 3.4. We prove that the PartialSuppressor algorithm always terminates and the divide-and-conquer optimization is correct.

4) In section 4, we specify the design of the metric "info loss". In section 4.1, we run experiments using our algorithm with various rho and analyze the performance of the algorithm. We also explain the values of parameters we used in experiments. In section 4.3, we add experiments with various rho and add analysis on the performance in terms of KL divergence and Jaccard similarity. 

5) In section 5, we added some related works. In section 5.1, we add introduction of the k-anonymity model, the l-diversity model, and differential privacy. In section 5.3, we analyze possible adversarial attacks.

* Notice that all the pictures showed in our paper are grayscale.