\section{Problem Definition}
\label{sec:prob}

This section %defines a few preliminary concepts and then
introduces the privacy model and data utility before formally describing
the problem of partial suppression.
%\cut{%%%%%%%%%%%%%%% BEGIN CUT %%%%%%%%%%%%%%%%%
%\subsection{Preliminaries}
%A {\em multiset} $S$ is a set which allows repetitive elements, while the
%{\em power multiset} $\mathbb{N}^S$ is the set of all subsets of the multiset
%$S$.
%Examples or formal definitions of these are given below.
%\begin{description}
%  \item[Multiset] $[a,a,b]$ is the same as $(\{a,b\},\{(a,2),(b,1)\})$
%  \item[Power set] $2^S$ is the power set of the set $S$
%  \item[Power multiset] $\mathbb{N}^S$ is the power multiset of the set $S$
%\end{description}

%A {\em multiset} is a set which allows repetitive elements, while a {\em
%power set} is the set of all subsets of a set. Examples or formal definitions
%of these are given below.
%\begin{description}
%  \item[Multiset] \hspace{2em} $[a,a,b]$ is the same as
%      $(\{a,b\},\{(a,2),(b,1)\})$
%  \item[Power set]  \hspace{2em}  $2^S$ is the power set of the set $S$
%  \item[Power multiset] \hspace{4em} $\mathbb{N}^S$ is the power multiset
%      of the set $S$
%\end{description}

\subsection{Privacy Model}
Let $T$ be a set of records, each containing a set of items. 
Some item types are designated as sensitive, others are not. 
$X \rightarrow Y$ is 
a {\em sensitive association rule} iff $Y$ contains at least one sensitive 
item. The privacy model of this paper
stipulates that, a dataset $T$ is {\em safe} iff no sensitive rules 
can be inferred from it with a confidence higher than 
$\rho$~\cite{Cao:2010:rho}. 

%It is clear that,
%if all sensitive association rules with a consequent of exactly one item 
%can't be inferred from $T$ with a confidence higher than $\rho$, 
%then all sensitive association rules can't be inferred with a confidence 
%higher than $\rho$, and hence $T$ is safe. 
\begin{lemma}
Let $R_S(T)$ be a set of all sensitive association rules minable from $T$.
If every rule with a consequent of exactly one item in $R_S(T)$ is safe,
then every rule in $R_S(T)$ is safe. 
\end{lemma}
\begin{proof}
By the definition of the confidence of association rules,
if $e$ is a sensitive item and $e \in Y$, then $conf_T(X \rightarrow Y) \le
conf_T(X \rightarrow e)$. If every sensitive rule of the form $X \rightarrow e$ is safe,
i.e., $conf_T(X \rightarrow e) \le \rho$, then every other sensitive rule also has
a confidence less than or equal to $\rho$. Hence they are safe, too.
\qed
\end{proof}


Formally, we define {quasi-identifier} (a.k.a. \qid) to be any itemset
(including sensitive items) drawn from any record in table $T$. A \qid $q$ is safe \wrt~$\rho$ iff $conf(q \rightarrow e)\leq\rho$, for any sensitive item $e$ in $T$.
We say $T$ is safe \wrt~$\rho$ iff $q$ is safe \wrt~$\rho$ for any \qid $q$ in $T$.
A \emph{suppressor} is a function $S : T \mapsto T'$ where $T'$ is a suppressed table which is safe \wrt~ $\rho$.
There are many different ways to suppress a table. The goal
is to find a suppressor that maximizes the {\em utility} of the suppressed
table without losing too much information. We will elaborate this idea
in the rest of this section. 
%We discard such precepts of relational anonymization. 
\tabref{table:notations} includes the
notations used in this paper.

\begin{table}[th]
\centering
\caption{Notations}
\label{table:notations}
\begin{tabular}{m{0.28\columnwidth}|m{0.6\columnwidth}}
  \hline
  \textbf{Symbol} & \textbf{Definition} \\  \hline
  $T$ %\in\natnum^{2^D}$
	& a set-valued table, which is a multiset of $m$ transaction records \\ \hline
  $N$ & the total number items in $T$ \\ \hline
  $D(T)$ & the domain of all items in $T$ \\ \hline
  $D_S(T)$ & the domain of sensitive items \\ \hline
  $D_N(T)$ & the domain of non-sensitive items \\ \hline
   % $T[i]\in T$ & the $i$-th record of $T$ \\ \hline
 % $R$ & a transaction record in $T$ \\ \hline
 % $|R|$ & the number of items contained in $R$ \\ \hline
  $I$ & an itemset, which is a subset of $D(T)$\\ \hline
  $e$ & an item in $T$ and $e \in D(T)$ \\ \hline
  $q$ & a \emph{quasi-identifier} (also \qid), which is any itemset
(\textbf{including sensitive items}) drawn from any record in table $T$ \\ \hline
  $R(T)$ & the set of rules minable from dataset $T$ \\ \hline
  $R_S(T)$ & the set of sensitive rules minable from dataset $T$ \\ \hline
  $T(t)$ & the probability of item type $t$ in $T$, which is computed by $\frac{sup_T(t)}{|T|}$ (see below)  \\ \hline
  $Items(T)$ & the number of items in dataset $T$ \\ \hline
  %$ X \rightarrow Y $ & an association rule where $X \subset R$, $Y \subset R$ and $X \cap Y = \emptyset$ \\ \hline
  %$\displaystyle Q(T)=\bigcup_{R\in T} \enum(R)$ & the set of all \qids in table $T$ \\ \hline
  $\rho$ & the strong association rule threshold \\ \hline
  %$\mathcal{A}(q,e)$ & an inference/association rule $q\rightarrow e$\\  \hline
%  $\SA(q,e)$ & a sensitive association rule $\mathcal{A}(q,e)$  if \KZ{$e$ contains at least one sensitive item, or is a sensitive item?}\\ \hline
  $sup_{T}(I)$ & the support of $I$ is the number of transactions in $T$ that 
contain $I$\\ \hline
  $conf_{T}(X \rightarrow Y)$ & the confidence of $X \rightarrow Y$ from table $T$, given by $sup_T(X \cup Y)/sup_T(X)$ \\ \hline
  $KL(T'~||~T)$ & K-L divergence between two probability distributions:
  $\sum_{e\in D(T)}sup_T(e)log\frac{sup_T(e) }{sup_{T'}(e)}$ 
  \\ \hline
  $J(A, B)$ & Jaccard similarity between two sets A and B:
  $\frac{|A \cap B|}{|A \cup B|}$ 
  \\ \hline
  % $e\in D$ & \KZ{a data item} \\ \hline
  % $nr(T)$ & set of all non-sensitive associations rules mineable from $T$ with sufficient support and confidence \\ \hline
  % $\enum(R) = 2^R - \{\emptyset\}$ & the \qid enumeration of $R$, which is the power set of $R$ except the $\emptyset$ \\ \hline
\end{tabular}
\end{table}


%A set-valued table $T$ is a multiset of transaction records,
%  each record $R \in T$ is a set of items drawn from domain $D$.
%  $D$ is the union of two non-intersecting set, sensitive domain $D_S$ and non-sensitive domain $D_N$.
%We follow the step of \cite{Sweeney2002:k-anonymity} and
%  extend the definition \emph{quasi-identifier} ($qid$) in relational database for set-valued data.
%Then we give a series of other definitions related with $qid$.
%As simple as you can imagine, a $qid$ is just a set of items taken from $D$.
%$Q$ is a set of $qid$s, $\Omega(R_i)$ is the $qid$ enumeration of $R$ which is the power set of $R$ except the $\emptyset$.
%The column count $cc$ of row $R$ is the number of items contained in $R$.

\cut{%%%%%%%%%%%%%%% BEGIN CUT %%%%%%%%%%%%%%%%%
Table \ref{table:notations} lists some notations used in the
rest of this paper. We define {\em container} and {\em linked items}
as follows.
\begin{definition}[Container]
The \emph{container} of an itemset $I$ in table $T$ is defined as
\begin{equation}
\container_T(I) = \{ i ~|~ I \subseteq T[i],~ 1 \leq i \leq |T| \}
.
\end{equation}
\end{definition}

\begin{definition}[Linked Items]
The set of all sensitive items linked by a \qid $q$ in table $T$ is defined as
\begin{equation}
\linked_T(q) = \{ e ~|~ e \in D_S(T) ~\backslash~ q,~ sup_{T}(q\cup\{e\}) > 0 \}.
\end{equation}
\end{definition}

According to the definition, $sup_{T}(I)$=$|\container_T(I)|$.
Also we will use $\container(I)$, $\linked(q)$, $sup(I)$,
$conf(X \rightarrow Y)$ to represent $\container_T(I)$,
$\linked_T(q)$, $sup_{T}(I)$ and $conf_{T}(X \rightarrow Y)$ respectively
when $T$ is the only table within discussion.
}%%%%%%%%%%%%%%%%%% END OF CUT %%%%%%%%%%%%%%%%%%%%


\cut{%%%%%%%%%%%%%%% BEGIN CUT %%%%%%%%%%%%%%%%%
\subsection{Privacy Model}
$X \rightarrow Y$ is a {\em sensitive association rule} iff $Y$ contains
at least one sensitive item.
The privacy model of this paper
stipulates that, a dataset $T$ is {\em safe} iff no sensitive rules can be inferred from it
with a confidence higher than $\rho$ \cite{Cao:2010:rho}.
It is clear that,
if all sensitive association rules with a consequent of exactly one item can't be inferred from $T$ 
with a confidence higher than $\rho$, then all sensitive association rules 
can't be inferred with a confidence higher than $\rho$, and hence $T$ is safe.

Formally, we define {quasi-identifier} (a.k.a. \qid) to be any itemset
(including sensitive items) drawn from any record in table $T$.
A \qid $q$ is safe \wrt~$\rho$ iff $conf(q \rightarrow e)\leq\rho$,
for any sensitive item $e$ in $T$.
We say $T$ is safe \wrt~$\rho$ iff $q$ is safe \wrt~$\rho$ for any
\qid $q$ in $T$.
A \emph{suppressor} is a function
$S : T \mapsto T'$ where $T'$ is a suppressed table which is
safe \wrt~ $\rho$.
There are many different ways to suppress a table. The goal
is to find a suppressor that maximizes the {\em utility} of the suppressed
table.
}%%%%%%%%%%%%%%%%%% END OF CUT %%%%%%%%%%%%%%%%%%%%


\subsection{Data Utility}
\label{sec:du}
In this paper, we identify two major uses of an anonymized table:
{\em statistical analysis} and {\em association rule mining}.
In the first case, we want the anonymized table to have a distribution
as close to the original table as possible;
in the second case,
we would like the anonymized data to
retain all non-sensitive association rules while introducing few
or no spurious rules.
In both scenarios, besides the different objective in data utility,
another common goal is to minimize the {\em information loss}, i.e.,
the total number of items suppressed. 
 
Notice that the above two scenarios are orthogonal. That is, 
when we prefer to preserve the useful association rules in the transaction,
we are inclined to delete more of the same type of items instead of 
different types since the latter may affect more rules. 
However, such strategy will
change the distribution of output data. 
%So we have to define different objective functions for them.
With these two potentially conflicting scenarios in mind, 
we define two variants of an objective function $f(T, T')$ as:
\begin{equation}
f(T, T') =
\begin{cases}
TS(T, T')\cdot KL(T'~||~T) & \rm{(data~ distribution)} \\
& \\
\frac{TS(T, T')}{J(R(T), R(T'))} & \rm{(rule~ mining)}
\end{cases}
\end{equation}
where
\begin{eqnarray}
TS(T,T') &=& \frac{\sum_{e\in D(T)}(sup_T(e) - sup_{T'}(e))}{\sum_{e\in D(T)}sup_{T}(e)} %\\
%KL(T'~||~T)&=&\sum_{e\in D(T)}sup_T(e)log\frac{sup_T(e) }{sup_{T'}(e)} \label{eq:kl}\\
%J(A, B) &=& \frac{|A \cap B|}{|A \cup B|}\\
%R(T)&=& \text{ set of rules minable from dataset } T
%\label{eq:kl-dis}
\end{eqnarray}
%Here the meaning of these symbols could be found in table 2.
The functions $TS$, $KL$ and $J$ represent
total number of suppressions (normalized to 1),
K-L divergence\cite{kl-divergence} and
Jaccard similarity\cite{jaccard-sim}, respectively 
(see \tabref{table:notations}). $TS$ represents the common goal of
minimizing information loss, while the $KL$ and $J$ aims at the 
two scenarios of data utility.
%K-L divergence measures the distance between two probability distributions.
%\cite{Kifer:l-diversity} first used K-L divergence in the privacy research.
%Jaccard similarity measures the similarity between two sets.
%$R(T)$ is the set of rules mined from dataset $T$ with a given confidence. In this paper, we set the this confidence to be
%$\rho$, same as the parameter of our privacy model.
%\DX{In our model, $\rho$ denotes that an attacker is only
%interested in mining sensitive rules with at least a
%confidence of $\rho$.}

%
%The exact definition of $f$ depends on specific downstream utility of
%the data \cite{Xu:2008:ATD}. In this paper, we assume there are two variants of
%$f$, namely $f_{mine}$ which focuses on preserving the association rules
%mineable from the data, and $f_{dist}$ which focuses on preserving the
%data distributions. These two variants can be defined as,
%
%where $J$ is the Jaccard similarity function:
%\[J(A, B) = \frac{|A \cap B|}{|A \cup B|}\]
%and $KL$ is the Kullback-Leibler divergence which measure the
%similarity between two distributions:
%\[KL(P||Q)=\sum_{i}Q(i)log\frac{Q(i)}{P(i)}.\]
%
%is the \emph{symmetric relative entropy} which measures the change in
%data distribution. The third is the \emph{number of rules mined}
%(including original and spurious rules) from the anonymized data. The first
%measure is more general and used by other work. The last two metrics target
%the utility of the anonymized data for statistical analysis and rule mining,
%and they will be introduced in Section \ref{sec:eval}.

%Information loss of $T$ is essentially the number of items deleted in $T$
%divided by total number of items in $T$.
%Our goal is to find a suppressor
%defined in Definition \ref{def:suppressor} which reduces information loss as
%much as possible.


%\textcolor{red}{ We'll consider these three metrics in our
%heuristic solution later. }
%\begin{definition}[Optimal Suppression Problem]
%\label{def:osp}
%The optimal suppression problem is to find an optimal suppressor $S_\text{OPT}$ for a given table $T$ such that
%\[ IL(T,S_\text{OPT}(T))\leq IL(T,S(T)) \] for any suppressor $S$.
%\end{definition}
%\begin{definition}[Minimum suppression]
%Minimum occurrence suppression of item type $t$, to make confidence of
%inference $\mathcal{A}(q,e)$ below $\rho$:
% \hspace{4mm}
%\[MS(t,\mathcal{A}(q,e))=
%\begin{cases}
%sup(q\cap \{e\})-sup(q)\rho & t=e  \\
%\frac{sup(q\cap \{e\})-sup(q)\rho}{1-\rho} & t\in q \\
% \infty & otherwise
%\end{cases} \]
%\end{definition}
%\PC {
%\begin{definition}[Remaining probability of item $i$]
%The Remaining probability of item $i$ is defined as
%\[ remain(i)=\frac{\kappa_{T^\prime}(\{i\})}{\kappa_T(\{i\})} \]
%where $T$ is the original
%dataset and $T^\prime$ is the current dataset processed by suppression but
%not finished
%\end{definition}
%}

\subsection{Optimal Partial Suppression Problem}
The optimal partial supression problem is to find a {\em Partial Suppressor} $S$ which anonymizes an input set-valued table $T$ to minimize the objective function:
\[\min_S f(T, S(T))\]
such that $S(T)$ is {\em safe} w.r.t. to our privacy model.
In the following section, we will present the algorithm which 
includes two important heuristic 
methods for minimizing the objective function.

In effect, this is a multi-objective optimization problem 
that attempts to minimize the
number of supressions while maximizing changes to the set 
of mineable non-sensitive rules, or 
minimizing the disturbances to the data distributional, after the suppression.

%preserves the original data distribution or retains mineable useful
%association rules with limited spurious rules invented, and also minimizes
%item deletions.
%\begin{definition}[Optimal Partial Suppressor]
%The \emph{optimal partial suppressor} $S_\text{OPT}$ is the suppressor such that
%\[ IL(T,S_\text{OPT}(T))\leq IL(T,S(T)) \] for any suppressor $S$.
%\end{definition}

%\PC {We have to mention that actually this metric of information loss makes sense, since the value of it is exactly the value
%calculated by the avgloss\cite{Cao:2010:rho} under the condition that only suppression is executed}
%Because most of the existing metrics of information loss are proposed
%for anonymization using generalization,
% \begin{definition}[Optimal Partial Suppressor for Distribution]
% \label{def:distribution}
% \[ Dist_{distance}(S_\text{OPT}(T), T) \leq  Dist_{distance}(S(T), T)\]
% while
% \[ IL(T,S_\text{OPT}(T))\leq IL(T,S(T)) \] for any suppressor.
% \end{definition}
% \begin{definition}[Optimal Partial Suppressor for Mining]
% \[ Spurious(S_\text{OPT}(T)) \leq  Spurious(S(T)) \] and
% \[OriginalRule(S_\text{OPT}(T)) \geq OriginalRule(S(T))\]
% while
% \[ IL(T,S_\text{OPT}(T))\leq IL(T,S(T)) \] for any suppressor.
% \end{definition}
