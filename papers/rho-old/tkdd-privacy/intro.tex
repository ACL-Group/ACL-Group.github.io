\section{Introduction}
\label{sec:intro}

Set-valued data sources are valuable in many data mining and
data analysis tasks. For example, retail companies may want to know what
items are top sellers (e.g., milk), or whether there is an association
between the purchase of two or more items (e.g., people who buy flour also
buy milk). 
According to our observation there are two main categories of set-valued
data analysis: one is {\em statistical analysis} such as
computing max, min and average values; 
the other is {\em mining of association rules} between items. 
In many cases, analysis tasks 
are {\em outsourced} to other external companies or
individuals, or simply {\em published} to the general
masses for scientific and public research purposes.

Publishing set-valued, and especially transactional data,
can pose significant privacy risks.
Set-valued transactions consist of one or more data items, which can be divided into two categories: {\em non-sensitive} and {\em sensitive}.
Privacy is in general associated with the sensitive items.
Table \ref{tab:orig-sample} shows
an example of retail transactions in which each record (row) represents
a set of items purchased in a single transaction by an individual.
All the items are non-sensitive, except the {\em condom}
which is sensitive. An individual's privacy is breached if he or she can be
{\em re-identified}, or associated with a record in the data which contains
one or more sensitive items. 
Past research has shown that such breach is
possible through {\em linking attacks} \cite{FungWCY10:Survey}, e.g.
linking beer with condom in Table \ref{tab:orig-sample}. 

\begin{table}[th]
\centering
\tbl{A Retail Dataset and Anonymization Results\label{tab:sample}}{
\subtable[Original Dataset]{
\begin{tabular}{|c|l|}
\hline
% after \\: \hline or \cline{col1-col2} \cline{col3-col4} ...
{\bf ID} & {\bf Transaction} \\ \hline
1 & bread, beer, {\em condom} \\ \hline
2 & coffee, fruits  \\ \hline
3 & beer, {\em condom}  \\ \hline
4& coffee, fruits  \\ \hline
5& flour, {\em condom}\\ \hline
6& bread, coffee  \\ \hline
7& fruits, {\em condom}  \\ \hline
\end{tabular}
\label{tab:orig-sample}
}
\subtable[Global Suppression]{
\begin{tabular}{|c|l|}
\hline
% after \\: \hline or \cline{col1-col2} \cline{col3-col4} ...
{\bf ID} & {\bf Transaction} \\ \hline
1 & bread, beer, \sout{\em condom} \\ \hline
2 & coffee, fruits  \\ \hline
3 & beer, \sout{\em condom}  \\ \hline
4& coffee, fruits  \\ \hline
5& flour, \sout{\em condom}\\ \hline
6& bread, coffee  \\ \hline
7& fruits, \sout{\em condom}  \\ \hline
\end{tabular} 
\label{tab:sample2}
} 
\subtable[Our Approach 1]{
\begin{tabular}{|c|l|}
\hline
% after \\: \hline or \cline{col1-col2} \cline{col3-col4} ...
{\bf ID} & {\bf Transaction} \\ \hline
1 & bread, beer, \sout{{\em condom}} \\ \hline
2 & coffee, fruits  \\ \hline
3 & beer, {\em condom}  \\ \hline
4&coffee, fruits  \\ \hline
5& \sout{flour}, {\em condom} \\ \hline
6& bread, coffee  \\ \hline
7& fruits, {\em condom}  \\ \hline
\end{tabular}
\label{tab:sample3}
}
\subtable[Our Approach 2]{
\begin{tabular}{|c|l|}
\hline
% after \\: \hline or \cline{col1-col2} \cline{col3-col4} ...
{\bf ID} & {\bf Transaction} \\ \hline
1 & bread, beer, \sout{{\em condom}} \\ \hline
2 & coffee, fruits  \\ \hline
3 & beer, {\em condom}  \\ \hline
4&coffee, fruits  \\ \hline
5& flour, \sout{{\em condom}}\\ \hline
6& bread, coffee  \\ \hline
7& fruits, {\em condom}  \\ \hline
\end{tabular}
\label{tab:sample4}
}
}
\end{table}

The privacy model we want to achieve is called $\rho$-uncertainty, where
no sensitive association rules can be inferred with a confidence higher than
$\rho$ \cite{Cao:2010:rho}.
%
The most popular approach to achieve $\rho$-uncertainty is called ``global
suppression'' \cite{Cao:2010:rho} in which once an occurrence of an item $t$ is
determined to be removed from one record, all occurrences of $t$ are
removed from the whole dataset. We instead opt to {\em partially}
suppress the data set so only {\em some} occurrences of item $t$ are
deleted.
Table \ref{tab:sample} shows the example dataset
and three anonymized datasets produced by global suppression and our approaches.
The orginal dataset is not safe because sensitive rules such as
$\text{beer} \rightarrow condom$ and $\text{flour} \rightarrow condom$
can be inferred with confidence 100\%, which is greater than our threshold $\rho=50\%$.
Table \ref{tab:sample2} is the anonymized dataset where all the occurrences of
the sensitive item {\em condom} are deleted due to global suppression.
Table \ref{tab:sample3} shows the anonymized dataset produced by our first
approach, which is optimized to preserve data distribution, so different
items ({\em condom} and flour) are deleted to make the dataset safe.
Table \ref{tab:sample4} is the result of our second approach, which is optimized
to preserve important data association in the original dataset, so only
two occurrences of the item {\em condom} are deleted for safety.
Even in such a small dataset, both our approaches outperform global suppression
in the number of deletions (2 vs. 4) while retaining useful information at the same time.

To the best of our knowledge, the partial suppression technique
has not been studied in the context of set-valued data anonymization before.
We choose to solve the set-valued data anonymization problem by partial
suppression because global suppression tends to 
delete more items than necessary,
and the removal of all occurrences of the same item not only changes the
data distribution significantly but also makes mining association rules
about the deleted items impossible.
%
The problem of anonymization by suppression (global or partial) is very
challenging \cite{atallah99:disclosure,Xu:2008:ATD}, exactly because, (i) the number of possible inferences from
a given dataset is exponential, and (ii) the size of the search space, i.e.
the number of ways to suppress the data is also exponential to the number of
data items. We therefore propose two heuristics in this paper to anonymize
input data in two different ways, giving rise to the two kinds of output
in \tabref{tab:sample}.

The main contributions of this paper are as follows.
\begin{enumerate}
\item To the best of our knowledge, we are the first to propose an
    effective \emph{partial} suppression framework for anonymizing
    set-valued data (Section \ref{sec:prob} and
    \ref{sec:algo}). 
\item We adopt a ``pay-as-you-go'' approach based on divide-and-conquer,
    which can be adapted to achieve both space-time and quality-time
    trade-offs (Section \ref{sec:algo} and \ref{sec:eval}). Our two heuristics
    can be adapted to either preserve data distribution or retain useful
    association in the data (Section \ref{sec:algo}).
\item Experiments show that our algorithm outperforms 
    the peers in preserving the
    original data distribution (more than 100 times better
    than peers)
    or retaining mineable useful association
    rules while reducing the item deletions 
    by large margins (Section \ref{sec:eval}).
\end{enumerate}
