\documentclass{sig-alternate}
%\documentclass{vldb}
%\documentclass[10pt,conference,letterpaper]{IEEEtran}
\usepackage{amsmath}
\usepackage{multicol}
\usepackage{algorithm}
\usepackage{algorithmic}
%\usepackage{hyperref}%[colorlinks, citecolor=blue, hyperindex]
\usepackage{graphicx,subfigure}
\usepackage{url}
\usepackage{color}
%\usepackage{algorithm2e}
%\usepackage{subfigure}
\graphicspath{{figures/}}
\newcommand{\KZ}[1]{\textcolor{blue}{[KZ: #1]}}
\renewcommand{\sim}[2]{\textsc{sim}(\textit{#1}, \textit{#2})}
\newcommand{\pair}[2]{$\langle #1, #2 \rangle$}
\newcommand{\LP}[1]{\textcolor{red}{[LP: #1]}}
\newcommand{\secref}[1]{Section \ref{#1}}
\newcommand{\figref}[1]{Figure \ref{#1}}
\newcommand{\eqnref}[1]{Eq. (\ref{#1})}
\newcommand{\argmin}{\operatornamewithlimits{argmin}}
\newcommand{\argmax}{\operatornamewithlimits{argmax}}
%\newcommand{\exref}[1]{Example \ref{#1}}

%\usepackage{caption}


\begin{document}
\title{Computing Term Similarity by Knowledge from Big Data}
\author{%
% author names are typeset in 11pt, which is the default size in the author block
{Peipei Li{\small $~^{\#*1}$}, Haixun Wang{\small $~^{*2}$}, Kenny Q. Zhu{\small $~^{\dag3}$}, Zhongyuan Wang{\small $~^{*2}$}, Xindong Wu{\small $~^{\#4}$} } %
% add some space between author names and affils
\vspace{1.6mm}\\
\fontsize{10}{10}\selectfont\itshape
$~^{\#}$Hefei University of Technology\\
%Hefei, China\\
\fontsize{9}{9}\selectfont\ttfamily\upshape
$~^{1}$v-pli@microsoft.com\\
\fontsize{9}{9}\selectfont\ttfamily\upshape
$~^{4}$xwu@uvm.edu
% add some space between email and affil
\vspace{1.2mm}\\
\fontsize{10}{10}\selectfont\rmfamily\itshape
$~^{*}$Microsoft Research Asia\\
\fontsize{9}{9}\selectfont\ttfamily\upshape
$~^{2}$\{haixunw,zhy.wang\}@microsoft.com\\
\fontsize{10}{10}\selectfont\rmfamily\itshape
$~^{\dag}$Shanghai Jiao Tong University\\
%, Shanghai, China\\
\fontsize{9}{9}\selectfont\ttfamily\upshape
$~^{3}$kzhu@cs.sjtu.edu.cn\\
}
\maketitle
\begin{abstract}
  Computing semantic similarity between two terms is essential for a
  variety of text analytics and understanding applications.
  Currently, there are two main approaches for this task,
  namely the knowledge based and the corpus based approaches.
  However, these approaches are more suitable for measuring
  semantic similarity between two words rather than the more general multi-word
  expressions (MWEs), and scalability issues from manual tagging as well
  as corpora dependency and availability also limit their applicability.
  Contrary to these existing techniques,
  we propose a lightweight and effective approach
  for semantic similarity using a large scale semantic network
  automatically acquired from billions of web documents. The semantic
  network consists of millions of concepts, which explicitly model the
  context of semantic relationships.  Given two terms, we map them
  into the concept space, and compare their similarity in that
  space. Furthermore, we introduce a clustering approach to
  orthogonalize the concept space in order to improve the accuracy of
  the similarity measure. %  identify potential senses of terms instead
  % of manually tagging, and then compare the term's sense based
  % contexts to get the semantic similarity between terms.
  Extensive studies demonstrate that our approach can accurately
  compute the semantic similarity between terms with MWEs and ambiguity.
  Comparison with 12 similarity methods
  shows that our approach on average outperforms the best existing
  method by 17.6\% on word pairs and 34.6\% on MWEs
  in terms of accuracy in similarity, and reaches an average of 0.77
  on word pairs and 0.67 on MWE pairs by the Pearson Correlation Coefficient.
%
%  The pearson correlation coefficient is
%  improved by the range of [0.07, 0.41] \LP{The difference of PCC between our RCP approach with the best one of other competing methods is 0.056, 0.03, 0.105 respectively on three data sets while the PCC in RCP is 0.921, 0.725, 0.735 respectively on three data sets. The improvement percent is 0.065, 0.043 and 0.167.}compared to the state-of-the-art approaches
%  for the semantic similarity measurement between terms.
  Meanwhile, our approach is very efficient and can be applied on computing
  semantic similarity in a large scale.
\end{abstract}

% , and knolnumber
  % of conceptualization In order Meanwhile, in a massive corpus, a
  % substantial fraction of extractions appear infrequently. It is hence
  % a challenge for traditional information extraction techniques to
  % assess these large scale sparse extractions. Motivated by this
  % challenge, this paper shows how to assess the correctness of sparse
  % extractions by utilizing the semantic context-based assessment
  % approach. In our proposed method, we adopt three different semantic
  % contexts. Firstly, we use the conceptualization method to get a set
  % of representative concepts from the sentences as the
  % context. Secondly, we extract the attributes as the
  % context. Thirdly, we collects the isA concepts as the context. In
  % terms of these semantic contexts, we implement a similarity
  % evaluation to rank extractions by the likelihood that they are
  % correct. Lastly, we apply our approach into the Hearst pattern
  % database of Probase, which contains 2425558 concepts and 15805500
  % extractions extracted using Hearst patterns from 1.68 billion web
  % pages and two years' worth of Microsoft Bing's search
  % log.


% A category with the (minimum) three required fields
%\category{H.4}{Information Systems Applications}{Miscellaneous}
%A category including the fourth, optional field follows...
%\category{D.2.8}{Software Engineering}{Metrics}[complexity measures, performance measures]

%\terms{Theory}

%\keywords{ACM proceedings, \LaTeX, text tagging} % NOT required for Proceedings

\input{introductionNew.tex}
\input{knowledge}
\input{BaselineApproach}
%\input{Knowledge}
%\input{semanticSimilarityFormula}
\input{Refined}
\input{Experiments}
\input{RelatedWork}
\input{Conclusions}
%\input{ThreeExamples}
%
% The following two commands are all you need in the
% initial runs of your .tex file to
% produce the bibliography for the citations in your paper.
\bibliographystyle{abbrv}
\bibliography{similarity}  % sigproc.bib is the name of the Bibliography in this case
% You must have a proper ".bib" file
%  and remember to run:
% latex bibtex latex latex
% to resolve all references
%
% ACM needs 'a single self-contained file'!
%
%APPENDICES are optional
%\balancecolumns
%\appendix
%Appendix A
%\balancecolumns
% That's all folks!
%\end{multicols}
\end{document}
