SUBMISSION: 168
TITLE: Modeling Implicit User Feedback in Anonymous Session-based News Recommendation

-------------------------  METAREVIEW  ------------------------ This paper looks at the problem how implicit session side information in item browsing can help with recommendation (of news).  The model proposes a system for using implicit session information in terms of clicks, session time, click intervals, along with an attended vector encoded representation of the articles and their publishing time.

The authors do a good job of doing model component ablation and discussion of their work at a macro level.  My concerns about the work surround the comparison against work that does not adequately use the resources that the authors have access to, and as such, may not represent fair SOTA comparison points.  Our primary reviewers who know this area well share this sentiment and highlight several useful and relevant works that may make better comparison points.

There are two concerns that I have that lead me not to strongly endorse this work:
- The method that the authors have proposed is a straightforward porting of existing attentional methods but brought to bear on the current problem of incorporating side information into the problem.  The choices made by the authors are reasonable, but other possible methods are not explored in sufficient detail to ensure that the solution given is really optimal.  It would have been good to propose variations and study their effectiveness in the discussion too.
- There are flaws in the writing and claims (but these can probably be fixed by careful editing), as per the claims that were mentioned by the primary reviewers.  Methods taken with respect to the modeling decisions should be clearly corroborated by the evidence in the paper's experiments.

What do the authors mean by the "publish time"?  Not sure that the representation in S3.1.4 is helpful.  Do you show the effectiveness of this area?

S3.1.5 do you have cited results for this?
S3.1.6 how about a differential representation rather than some form of absolute representation?  I understand you are using the attention mechanism to try to manufacture these features.

S4.1.2 Not clear why you need the different methodology in Globo.  Is it due to the replication of other's experimentation?

S4.5 (g) could be compared versus a more simple negative baseline sampling than random, which I feel is too weak to be considered a fair comparison.

S4.6.2 do your results suggest some form of hybrid ensemble where the larger the data gap is, the more the system should attend to CBF?  This seems reasonable.

S4.6.4 this seems like a reverse inference problem and may not generalise well.  Wouldn't this depend on how the particular platform exposes (recommends) news articles to the user?



----------------------- REVIEW 1 ---------------------
SUBMISSION: 168
TITLE: Modeling Implicit User Feedback in Anonymous Session-based News Recommendation
AUTHORS: Shansan Gong and Kenny Zhu

----------- Relevance to SIGIR -----------
SCORE: 4 (Relevant: Interesting to some SIGIR participants.)
----------- Quality of Presentation -----------
SCORE: 3 (Missing a few important details but the major points were clear.)
----------- Originality of Work -----------
SCORE: 3 (Somewhat conventional: A number of people could have come up with this if they thought about it for a while.)
----------- Technical Soundness -----------
SCORE: 4 (The authors mostly use appropriate description of technical facts but there are some minor mistakes.)
----------- Impact of Contributions -----------
SCORE: 3 (Interesting but not too influential. The work will be cited, but mainly for comparison or as a source of minor contributions.)
----------- Adequacy of Citations -----------
SCORE: 4 (Mostly comprehensive: Review written well; there are one or two papers missing, but they aren't crucial omissions.)
----------- Reproducibility of Methods/Findings -----------
SCORE: 4 (Could be reproduced: Researchers could reproduce the methods and results with some effort.)
----------- Overall evaluation -----------
SCORE: -2 (Reject (the paper has substantial problems relative to possible strengths, and it should be rejected))
----- TEXT:
Comments to the author(s):

This paper proposes an approach for session-based news recommendation, i.e., ITCAR, which leverages users’ implicit feedback and other content as well as temporal information. They first encode a session with sequential information, temporal information as well as article content information with several attention modules. Then they propose to sample negative samples for training from user impression list which can help to jointly learn hidden vectors of user interests. The experiments demonstrate the utility of ITCAR model by beating the performance of several state-of-the-art models on three datasets. However, the motivation of this paper, i.e., combining content as well as temporal information for session-based news recommendation, is not innovative enough. In addition, the comparisons with baseline models are unfair since some of these baselines are not applied with those useful external information. Thus the experimental results are not convinced. There are also some !
 other comments listed below. In conclusion, I would vote for a reject. 
Some comments are as follows:
1.In Section 3.1, the attention mechanism has been applied several times when calculating the final representation of the session. Could you give detailed explanations for each attention score calculation.
2.In Section 3.1.6., you have mentioned that “Meanwhile, we apply this article encoder and publish time encoder to all candidate articles to build the candidates matrix [v_1,v_2,...,v_K]”. However, you do not give detailed analysis for this. Is it a concatenation or multiplication?
3.In Section 3.2.2, for the loss function, it aims to minimize the pairwise similarity between s_u and negative samples with the \sigmoid (1-) part. Could you give an explanation for this? I don’t think it is a pairwise similarity since there is no comparison between positive and negative samples. Also, did you do normalization? Why not use BPR[1] or TOP1[1] pairwise loss function with the negative samples?
4.In Section 4.1.2, it is not clear for the dataset splits as shown in Figure 5. Why do you split the three datasets with different ratios?
5.In Section 4.1.3, the definition of the diversity evaluation metric is confusing. Do you have any reference for it? What dose  mean?
6.In Section 4.2, for the baselines to compare with, as far as I known, SR-GNN is not the state of the art approach. SGNN-HN [2] shows better performance than SR-GNN, you should add it to your baselines. 
7.It is unfair to compare your approach with those simple session based algorithms which are not applied with the external information, e.g., temporal as well as content information. You should compare with several session-based news recommendations approaches, e.g., [3, 4]. Thus the results in Table 3 are not convinced to verify the effectiveness of your approach.
8.In Section 4.5, from Table 4 we can see that applying Pub (publication time) knowledge can boost the performance of your approach. Without Pub information, the performance of ITCAR (a, b, c) is worse than the baseline SASRec. I am wondering that if SASRec can beat ITCAR with Pub information.
9.There is a trade-off parameter \lambda in your loss function, i.e., Eq. (14). You should give experiments and analysis to show the impact of this parameter on the performance of your approach. 

[1] Balázs Hidasi and Alexandros Karatzoglou. 2018. Recurrent neural networks with top-k gains for session-based recommendations.
[2] Zhiqiang Pan, Fei Cai, Wanyu Chen, Honghui Chen, and Maarten de Rijke. 2020. Star Graph Neural Networks for Session-based Recommendation. Proceedings of the 29th ACM International Conference on Information & Knowledge Management. Association for Computing Machinery, New York, NY, USA, 1195–1204. DOI:https://doi.org/10.1145/3340531.3412014
[3] Symeonidis, P., Kirjackaja, L. & Zanker, M. Session-aware news recommendations using random walks on time-evolving heterogeneous information networks. User Model User-Adap Inter 30, 727–755 (2020). https://doi.org/10.1007/s11257-020-09261-9
[4] Gabriel de Souza Pereira Moreira, Felipe Ferreira, and Adilson Marques da Cunha. 2018. News Session-Based Recommendations using Deep Neural Networks. In Proceedings of the 3rd Workshop on Deep Learning for Recommender Systems (DLRS 2018). Association for Computing Machinery, New York, NY, USA, 15–23. DOI:https://doi.org/10.1145/3270323.3270328



----------------------- REVIEW 2 ---------------------
SUBMISSION: 168
TITLE: Modeling Implicit User Feedback in Anonymous Session-based News Recommendation
AUTHORS: Shansan Gong and Kenny Zhu

----------- Relevance to SIGIR -----------
SCORE: 4 (Relevant: Interesting to some SIGIR participants.)
----------- Quality of Presentation -----------
SCORE: 2 (Important questions were hard to resolve even with effort.)
----------- Originality of Work -----------
SCORE: 1 (Significant portions have actually been done before or done better.)
----------- Technical Soundness -----------
SCORE: 3 (There are some mistakes in the description of techniques but the main idea is generally solid.)
----------- Impact of Contributions -----------
SCORE: 3 (Interesting but not too influential. The work will be cited, but mainly for comparison or as a source of minor contributions.)
----------- Adequacy of Citations -----------
SCORE: 2 (Not good enough: Authors have written a review, but its coverage misses many important past papers.)
----- TEXT:
1. Fine-grained Interest Matching for Neural News Recommendation 2. Graph Enhanced Representation Learning for News Recommendation 3. Graph Neural News Recommendation with Unsupervised Preference Disentanglement 4. KRED: Knowledge-Aware Document Representation for News Recommendations 5. User Modeling with Click Preference and Reading Satisfaction for News Recommendation 6. Embedding-based News Recommendation for Millions of Users 7. Neural News Recommendation with Long- and Short-term User Representations
----------- Reproducibility of Methods/Findings -----------
SCORE: 3 (Limited reproducibility: Researchers could reproduce the methods and results with much effort.)
----------- Overall evaluation -----------
SCORE: -2 (Reject (the paper has substantial problems relative to possible strengths, and it should be rejected))
----- TEXT:
This paper presents a session-based news recommendation approach that considers the implicit user feedback in a session. The authors use clicked news to learn session representations, and propose to incorporate news publish time, user active time and session start time to enhance session representations. The authors also suggest incorporating negative samples to improve model training. 

Strengths:
1.	News recommendation studied in this paper is an interesting and important research problem.
2.	The proposed method can fully consider the temporal information.
3.	The experiments are conducted on multiple datasets.


Weaknesses:
1.	The motivation of this paper is not convincing.
2.	The contribution is limited.
3.	The coverage of related work is not sufficient.
4.	Many techniques used in this paper are out-of-dated, and not well introduced.
5.	Many experimental settings and results are problematic.

Detailed comments:

1.	This paper claims to handle the user cold-start and item cold-start problems in session based recommendation. However, since in existing news recommendation methods, the news articles are modeled based on their content. Why is item cold-start a problem in news recommendation? In addition, why can the implicit feedbacks like active time and session start time can help handle the user cold-start problem? For example, the number of active time depends on the number of click behaviors. When the click behaviors are very limited, the active time feedbacks are also very limited.
2.	The contribution of this paper is limited. First, the unclicked news shown in the impression are widely used in existing news recommendation works such as NPA and LSTUR as negative feedbacks for model training. Why can this paper claim this common practice as its own contribution? Second, some existing works such as CPRS (User Modeling with Click Preference and Reading Satisfaction for News Recommendation) have used active time for news recommendation. Thus, many ideas proposed in this paper are not new.
3.	Related works are poorly covered in this paper. Many recent works in news recommendation such as LSTUR (ACL 2019), FIM (ACL 2020), GERL (WWW 2020), GNUD (ACL 2020), and KRED (RecSys 2020), are not mentioned nor compared in this paper. 
4.	Many modules in the proposed method are not well-motivated. For example, why the temporal embeddings need to be selected with the help of news content? What is the benefit of the proposed negative sampling strategy? Why do you choose a combination of both binary and categorical cross-entropy functions for model training? 
5.	It seems that the two core problems raised in the introduction section, i.e., “When a user clicks an article, does he/she really like it?” and “If a user hasn’t clicked an article, does it mean that he/she doesn’t like it”, are not addressed in this paper.
6.	Many techniques used in this paper are out-of-dated. For example, the average of Word2Vec embeddings is used to represent news. Why not try some more advanced method for text representation such as those used in existing news recommendation methods?
7.	Some experimental settings and results are quite problematic. First, for the MIND dataset, the time period is in fact 6 weeks (rather than 1 week mentioned in this paper). It is not clear whether the authors use this dataset correctly. Second, the diversity metric used in this paper is quite odd. Please provide proper explanations. Third, it is quite strange that the recommendation performance on users with longer histories becomes worse (as shown in Figure 6), which is very abnormal. Fourth, it is a pity that none of news recommendation method is compared in experiments. In fact, many existing news recommendation methods can be used in session based news recommendation, such as NAML, NRMS, LSTUR, FIM, GERL, GNUD and KRED. They should be compared in the experiments to verify the advantage of the proposed method.
8.	This paper is not well written. There are many writing errors. Just to name a few, “all other previous approches”, “by proper represention”, “in the calculatation” and “active time is not explicitly avaliable”.



----------------------- REVIEW 3 ---------------------
SUBMISSION: 168
TITLE: Modeling Implicit User Feedback in Anonymous Session-based News Recommendation
AUTHORS: Shansan Gong and Kenny Zhu

----------- Relevance to SIGIR -----------
SCORE: 4 (Relevant: Interesting to some SIGIR participants.)
----------- Quality of Presentation -----------
SCORE: 3 (Missing a few important details but the major points were clear.)
----------- Originality of Work -----------
SCORE: 3 (Somewhat conventional: A number of people could have come up with this if they thought about it for a while.)
----------- Technical Soundness -----------
SCORE: 4 (The authors mostly use appropriate description of technical facts but there are some minor mistakes.)
----------- Impact of Contributions -----------
SCORE: 3 (Interesting but not too influential. The work will be cited, but mainly for comparison or as a source of minor contributions.)
----------- Adequacy of Citations -----------
SCORE: 5 (Comprehensive: Excellently written literature review; I can't think of any important papers that they missed.)
----------- Reproducibility of Methods/Findings -----------
SCORE: 3 (Limited reproducibility: Researchers could reproduce the methods and results with much effort.)
----------- Overall evaluation -----------
SCORE: 1 (Weak accept (the paper is near the borderline, but on balance the strengths outweigh the problems, so it should be accepted))
----- TEXT:
In this paper, authors focus on the problem of news recommendation, and propose a method to capture users’ positive and negative implicit feedback to model their behavior and preferences. Implicit feedback is captured leveraging content and temporal information of the articles and user clicks. Negative feedback is based on impressions that have not been clicked.

The approach is based on various assumptions the authors make about the way users consume the news. For example, rather than simply relying on the user’s click, the authors consider the time users spend reading a news (this time necessarily needs to be estimated given the fact that it is not possible, for a recommender system, to capture whether after clicking a news title, the user is really reading the news or doing something else).
Similarly, authors assume that there is correlation between the time readers start reading the news and the topic of the news. These hypotheses are captured in a simple cross-attention network based model. Authors also  show experimentally that the proposed approach provides accurate predictions on the three datasets on which the model is tested.

The paper is well written, the results against the selected baselines seem promising – though the way the mini-session data is created is not entirely convincing. Also, the authors report best results for a range of hyper-parameter configurations, which is a concern in practice. Also, the proposed technique appear to perform rather poorly in terms of the diversity metric for all data sets (btw, Table 3 and the associated discussions are faulty – the proposed technique does not beat the baseline methods on Globo data set in terms of diversity, in contrast to what the authors claim).

My major concern about the paper, however, has to do with its scientific and technical impact. The actual scientific innovation seems to be quite low – the way the authors deal with the implicit feedback appear to be rather common and the proposed cross attention model is quite generic. This appears to be yet-an-other application of neural networks which, with properly tuned parameters and with sufficient data, provides promising results. It is good to see that the proposed (cross-)attention based architecture outperforms other (self-)attention based models, but given the state of the research in cross-attention networks, this is hardly innovative.



