\section{Approaches}
\label{sec:algo}
In this section we first give an overview of a probabilistic taxonomy
that provides the vocabulary of concepts to abstract the verb arguments
as well as probabilistic scores for computing various rankings.
We then present two heuristic algorithms to solve the action
conceptualization problem. Finally, we provide a method to rank the
output action concepts from solution of action conceptualization.
In the rest of this section, the term ``argument'' refers to either
the object or the subject of a verb.

\subsection{A Probabilistic IsA Taxonomy}
In this work, we use a probabilistic isA taxonomy called Probase
\cite{WuLWZ12} which is public for download.
Probase is a large collection of concept-subconcept (e.g., company vs.
tech company) or concept-entity (e.g., company vs. microsoft) pairs
which were extracted automatically by the Hearst pattern \cite{Hearst92}
from a large web corpus.
Probase also associates with each pair: a {\em frequency} in which
the pair appears in the corpus, a {\em typicality score} which is
essentially the conditional probabilities $p(e | c)$ and $p(c | e)$,
where $c$ and $e$ represent ``concept'' and ``entity'', respectively.
This taxonomy provide a large universe of concepts which
our algorithms will search against to find the minimum set of concepts
to cover a verb's arguments. Furthermore, the typicality score allows
the algorithms to determine the importance of a concept given an entity
and vice versa.

\subsection{A Greedy Solution}
\label{sec:greedy}
Our first attempt at the NP-hard action conceptualization problem
is a greedy algorithm.
It follows a heuristic to select one concept from a candidate set
at a time until the final concept set is formed that covers all
the input arguments.
The candidate set can be all concepts in Probase.
The algorithm first creates two argument sets
$L$ and $D$. $L$ contains all arguments waiting to be covered
and $D$ contains all the arguments already covered. Initially,
$L$ is the set of all input arguments, and $D$ is empty.
In each iteration, the algorithm selects and remove a concept from
the candidate set which covers most arguments
in $L$ and least objects in $D$ while satisfy the overlap constraint
(see \eqnref{eq:overlap}) at the same time.

For practical purpose, we use a reduce candidate set which contains only
those concepts that are in Probase and are also in the input
argument set. We do this primarily to speed up the computation and
our experiment shows that it doesn't affect the overall quality of
the solution.
%If an object is a concept in Probase, like ``clothing'', ``jewelry'' for
%verb ``wear'', and ``food'', ``meal'' for verb ``eat'', we put them
%in the candidate concept set for ``wear'' and ``eat''.
% \KZ{But where do we select this concept from? What is the candidate set?}
The newly selected concept is added to the {\em selected concept list}
(SCL) and all the arguments covered by the selected concept are moved
from $L$ to $D$ before the next iteration starts.
The iteration ends when $L$ is empty.
If $L$ is not empty, and there's no concepts in the candidate set
that doesn't violate the overlap constraint, then there's no
solution to the problem. The details of this greedy solution is shown
in Algorithm \ref{vega}.
%no more
%concepts can be added to $SCL$ because all the remaining concepts
%violate the overlap constraint with concepts in $SCL$.
%$L$ may be non-empty when the iteration ends.
%As a special case, objects still in $L$ are selected as
%concepts without considering the overlap constraint.

\begin{algorithm}[th]
\caption{Greedy Solution}
\label{vega}
\begin{algorithmic}[1]
%\Function{CalcCover}{concept,E}
%\State $coverage \leftarrow 0$
%\For {$e \in E$}
%\If {$e\ isA\ concept$}
%\State $coverage \leftarrow coverage+1$
%\EndIf
%\EndFor
%\State \textbf{return} $coverage$
%\EndFunction
%\Statex
%\Function{PickConcept}{leftE,doneE,candidateC}
%\State $pickC \leftarrow NULL$, $masCover \leftarrow 0$
%\For {$c \in candidateC$}
%\State $leftCover \leftarrow calcCover(c,leftE)$
%\State $doneCover \leftarrow calcCover(c,doneE)$
%\State $cover \leftarrow leftCover-doneCover$
%\If {$cover>maxCover$}
%\State $maxCover \leftarrow cover$
%\State $pickC \leftarrow c$
%\EndIf
%\EndFor
%\State \textbf{return} $pickC$
%\EndFunction
%\Statex
\Function{Process}{corpusE,candidateC}
\State $L \leftarrow corpusE$, $D \leftarrow \emptyset$
\State $SCL \leftarrow \emptyset$
\Repeat
\State select $pickedC$ covering most arguments in $L$ and least in $D$ in $candidateC$ which satisfies constaint
\For {$e$ isA $pickedC$}
\State delete $e$ from $L$
\State add $e$ to $D$
\EndFor
\State add $pickedC$ to $SCL$
\State delete $pickedC$ from $candidateC$
\Until{$L = \emptyset$}
\State \textbf{return} $SCL$
\EndFunction
\end{algorithmic}
\end{algorithm}

%When we collect new objects, we need to update our action knowledge. Given
%a set of new collected objects, we first conduct our \emph{Action Extraction}
%on these objects to get a list of proper concepts; then we merge these concepts
%with concepts in our previous action knowledge.

%\input{algo_cluster}

\input{algo_ls}

\input{rank}
