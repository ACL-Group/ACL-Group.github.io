\section{Related Work}

There are many existing work on aspect extraction and they can be roughly divided in two categories. The first kind finds the aspect candidates first and then cluster them, represented by rule-based methods. The second kind clusters the aspect candidates and other words together, then identify the aspects, represented by topic models.

Rule-based methods rely heavily on parsing and the quality of parsing. Based on the parsing result, they use features like frequency and modifying relationship or a set of manually defined rules to identify the aspect candidates. A problem in this kind of method is \emph{implicit aspect extraction}, that is to find those aspect candidates that are expressed without directly mentioning the aspect word. For example in a mobile phone review ``Under heavy usage it will last at least a day'' is about the aspect of battery life. Also co-reference may be a problem like in hotel review: ``I really liked the room. It is large and comfy.'' Rule-based methods need carefully designed rules or other methods for implicit aspect extraction.
\cite{poria2014rule} features the manually set mining rules. 
\cite{qiu2011opinion} also used rules, plus the Double Propagation method to better relate sentiment to aspects. 
\cite{gindl2013rule} also used the Double Propagation method, with the help of anaphora resolution for identifying co-references to improve the performance. 
\cite{su2008hidden} used a clustering method to map the implicit aspect candidates (which were assumed to be noun form of adjectives in the paper) to explicit aspects. 
\cite{zeng2013classification} mapped implicit features to explicit features using a set of sentiment words and by clustering explicit feature - sentiment pairs.

Topic models have been used to perform extraction and clustering at the same time. Most existing work are based on two basic models, pLSA\cite{hofmann1999probabilistic} and LDA\cite{blei2003latent}. Applying topic models on user reviews requires extra attention for the nature of review texts. We note two features of review texts. The first is the length - multiple aspects, corresponding to topics in topic models, are compressed in a typically short reivew. Sentences close to each other may talk about completely different but related topics. For example in hotel reviews we see many reviews like this ``I really liked the room, it is large and comfy. The staff are helpful and also the food is great.'' The other feature is the prominence of sentiment. Since reviews express opinions, naturally there are many sentiments, and also there is a strong relationship between the sentiments and the aspects. Many variations of LDA exploits this feature to improve the mining of aspects.
\cite{lakkaraju2011exploiting} models in parallel aspects and sentiments per review. 
\cite{lin2009joint} models the dependency between the latent aspects and ratings.
\cite{moghaddam2012design} made a nice summarization of some basic variations of LDA for opinion mining.

To improve the accuracy of the aspects or make use of cross-domain knowledge, several work introduced semi-supervised learning for aspect extraction. 
\cite{mukherjee2012aspect} used a set of incomplete aspects as seeds and iteratively find more aspects. 
\cite{andrzejewski2009incorporating} incorporate two forms of prior knowledge from the user: must-links and cannot-links. 
\cite{chen2014aspect} automatically mined such information from cross-domain dataset.

Rule-based methods largely rely on parsing so the performance may vary according to the parser and the quality of dataset. Our method doesn’t need parsing for preprocessing and treat sentence as bag-of-word, so it won’t have that problem. Our method only uses the text from user reviews and is completely unsupervised, so we don’t require that the dataset contains information of ratings or that users provide seeds. 
