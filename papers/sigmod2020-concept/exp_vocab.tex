\subsection{Primitive Concept Mining}
\label{sec:eval_mining}
After defining $20$ different domains in the taxonomy,
we quickly enlarge the size of primitive concepts by introducing knowledges from several existing structured or semi-structured knowledge bases in general-purpose domain.
During this step, vocabulary sizes of domains such as $Location$, $Organization$ and $IntellectulProperty$ can be quickly enlarged.
Other domains are for e-commerce use, and we mainly leverage the existing e-commerce semi-structured data: CPV, since most of $Property$s can be matched to our domains such as $Brand$, $Color$, $Material$, etc.

After rule based alignments and cleaning, 
around $2M$ primitive concepts can be drawn from multiple sources.
We adopt the idea of distant supervision to
generate a large amount of training samples,
in order to mine new concepts.
We use a dynamic programming algorithm of max-matching to match words in the text corpora and then assign each word with its domain label in IOB scheme using existing primitive concepts. We filter out sentences whose matching result is ambiguous and only reserve those that can be perfectly matched (all words can be tagged by only one unique label) as our training data.
We generate around $6M$ training data in this way.
In each epoch of processing $5M$ sentences, 
our mining model is able to discover around $64K$ new candidate concepts on average.
After manually checking the correctness by crowdsourcing services, 
around $10K$ correct concepts can be added into our vocabulary in each round.
The mining procedure is continuously running, 
and the total number of primitive concepts from all $20$ domains 
is $2,758,464$ at the time of writing.







