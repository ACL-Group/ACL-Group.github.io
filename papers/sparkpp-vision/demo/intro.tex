%!TEX root = paper.tex

\section{Introduction}
\label{sec:intro}

Statistical inference is an important technique to express hypothesis and
reason about data in data analytical tasks.  Today, many big data applications
are based on statistical inference.  Examples include topic modeling
\cite{blei2003latent,Titov2008a}, sentiment analysis \cite{Titov2008b,
Jo2011,tsm}, spam filtering \cite{spam}, to name a few.  One of the most 
critical steps of statistical inference is to construct 
a \emph{statistical model} to
formally represent the underlying statistical inference task \cite{cox}. The
development of a statistical model is never trivial because a domain user may
have to devise and implement many  different models before finding a promising
one for a specific task. Developing inference code requires extensive
knowledge in both statistical inference and programming techniques in
distributed frameworks.  Moreover, model definitions, inference algorithms,
and data processing tasks are all mixed up in the resulting code, making it
hard to debug and reason about.  For even a slight alteration to the model in
quest of the most promising one, the model designer will have to re-derive the
formulas and re-implement the inference codes, which is tedious and
error-prone. 

In this demonstration, we present InferSpark, a \emph{declarative Bayesian
inference framework} on top of Spark. Declarative specification of statistical
models belongs to an emerging paradigm called {\em probabilistic programming}
that seeks to unify programming with probabilistic modeling~\cite{pp}.  So far,
the emphasis of probabilistic programming has been put on the expressiveness of
the languages and the development of efficient inference algorithms to handle a
wider range of statistical models. The issue of scaling out the frameworks,
however, has not been addressed. The goal of InferSpark is thus to bring
probabilistic programming to Spark, a predominant distributed data analytic
platform, for carrying out statistical inference at scale.  It allows end users
to succinctly {\em declare} a custom Bayesian network model using random
variables, their prior distributions as well as their inter-dependencies.
InferSpark compiler then takes the model and generates appropriate
parameterized inference code, which is instantiated at runtime by the input
data and run efficiently on Spark distributed system.  Bayesian networks form a
dominant branch of probabilistic graphical models and include such popular
models as naive Bayes, LDA and TSM~\cite{tsm}.  

\begin{figure}
\begin{lstlisting}
@Model
class LDA(K: Long, V: Long, alpha: Double, beta: Double){
	val phi = (0L until K).map{_ => Dirichlet(beta, V)}
	val theta = ?.map{_ => Dirichlet(alpha, K)}
	val z = theta.map{theta => ?.map{_ => Categorical(theta)}}
	val x = z.map{_.map{z => Categorical(phi(z))}}
}
\end{lstlisting}
\label{fig:intro_lda_def}
\caption{Definition of Latent Dirichlet Allocation Model}
\end{figure}

For example, the LDA model can be defined using only 7 lines of code
(\figref{fig:intro_lda_def}) and the inference is automatically handled by the
InferSpark compiler and runtime, while the MLLib implementation (\cite{mllib})
consists of over 500 lines of Scala code. The inference code is based on Apache
Spark so it implicitly exploits the excellent scalability.

InferSpark is different from systems
for implementing inference algorithms such as MATLAB, R, SystemML
\cite{systemml}, which targets inference code developers instead of end-users.
It is also different from machine learning libraries such as Mahout
\cite{mahout}, MLLib \cite{mllib}, MADLib \cite{madlib}, which only supports a
limited number of models. When it comes to customized models, the users cannot
use the libraries but write their own code. InferSpark is similar to MLBase
\cite{mlbase} in the sense that they both provides end-users a declarative
interface but the latter mainly handles frequentist approaches like SVM and
logistic regressions. 

%The remainder of this paper is organized as follows: Section
%\ref{sec:framework} gives an overview of InferSpark.  Section
%\ref{sec:demoplan} shows the demonstration plan of InferSpark.  Section
%\ref{sec:related} discusses some related work.

