\section{Future Directions}
\label{sec:future}

Our prototype InferSpark system only implements the variational message
passing inference algorithm for certain exponential-conjugate family Bayesian
networks (namely mixtures of Categorical distributions with Dirichlet priors).
In our future work, we plan to include support for other common types of
Bayesian networks (e.g. those with continuous random variables or arbitrary
priors). The VMP algorithm may be no longer applicable to these Bayesian
networks because they may have non-conjugate priors or distributions out of
exponential family. In order to handle wider classes of graphical models, we
also plan to incorporate other inference algorithms (e.g. Belief propagation,
Gibbs Sampling) into our system, which could be quite challenging because we
have to 1) deal with arbitrary models 2) adapt the algorithm to distributed
computing framework.

Another interesting future direction is to allow implementation of customized
inference algorithms as plugins to the InferSpark compiler. To make the
development of customized inference algorithms in InferSpark easier than
directly writing them in a distributed computing framework, we plan to 1)
revise the semantics of the Inferspark model definition language and expose a
clean Bayesian network representation 2) provide a set of framework-independent
operators for implementing the inference algorithms 3) investigate how to
optimize the operators on Spark.

