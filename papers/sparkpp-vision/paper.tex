\documentclass{sig-alternate-05-2015}
%\paperwidth=8.5in
%\paperheight=11in
%\usepackage[margin=1in]{geometry}

\usepackage{amsmath,amsfonts,amssymb}
\usepackage{color}
\usepackage{graphicx}
\usepackage{epsfig}
\usepackage{url}
\usepackage{semantic}
\usepackage{subfigure}
\newcommand{\figref}[1]{Figure \ref{#1}}
\newcommand{\tabref}[1]{Table \ref{#1}}
\newcommand{\eqnref}[1]{Equation \ref{#1}}
\newcommand{\KZ}[1]{\textcolor{blue}{(KZ: #1)}}
\newcommand{\ZY}[1]{\textcolor{red}{(#1)}}
\newcommand{\ERIC}[1]{\textcolor{green}{(Eric: #1)}}
\newcommand{\cut}[1]{}
\newcommand{\dd}[0]{\mathrm{d}}
\newcommand{\numberthis}{\stepcounter{equation}\tag{\theequation}}

\usepackage{courier}
\usepackage{listings}
\lstset{ %
	numberstyle=\scriptsize,
	basicstyle=\scriptsize\ttfamily,
	breaklines=true,
	tabsize=1,
	columns=fullflexible,
	numbers=left,
	stepnumber=1
}

\usepackage{etoolbox}
\makeatletter
\patchcmd{\maketitle}{\@copyrightspace}{}{}{}
\makeatother

\DeclareMathOperator*{\var}{var}
\DeclareMathOperator*{\val}{val}
\DeclareMathOperator*{\dom}{dom}

\mathlig{=>}{\Rightarrow}
\mathlig{->}{\rightarrow}

\newcounter{enum}
\newenvironment{packed_enum}{
%\begin{list}{\arabic{enum}.}{
\begin{list}{(\alph{enum})}{
  \setlength{\itemsep}{-0.5pt}
  \setlength{\parskip}{1pt}
  \setlength{\labelwidth}{30 pt}
  \setlength{\leftmargin}{15 pt}
  \setlength{\itemindent}{0pt}
  \usecounter{enum}}
}{\end{list}}


\makeatletter
\newcommand{\Spvek}[2][r]{%
  \gdef\@VORNE{1}
  \left(\hskip-\arraycolsep%
    \begin{array}{#1}\vekSp@lten{#2}\end{array}%
  \hskip-\arraycolsep\right)}

\def\vekSp@lten#1{\xvekSp@lten#1;vekL@stLine;}
\def\vekL@stLine{vekL@stLine}
\def\xvekSp@lten#1;{\def\temp{#1}%
  \ifx\temp\vekL@stLine
  \else
    \ifnum\@VORNE=1\gdef\@VORNE{0}
    \else\@arraycr\fi%
    #1%
    \expandafter\xvekSp@lten
  \fi}
\makeatother

\newcommand\Mark[1]{\textsuperscript{#1}}

\begin{document}
%\pagestyle{empty}

\title{InferSpark: Statistical Inference at Scale}

%\numberofauthors{5}
\author{
Zhuoyue Zhao~\Mark{1}, Jialing Pei~\Mark{1}, Eric Lo~\Mark{2}, Kenny Q. Zhu~\Mark{1}, Chris Liu~\Mark{2}\\
\affaddr{\Mark{1}Shanghai Jiao Tong University \hspace*{4mm}\Mark{2}Hong Kong Polytechnic University}\\
\email{
\{zzy7896321@, peijialing@, kzhu@cs\}.sjtu.edu.cn
\hspace*{2mm}\{ericlo, cscyliu\}@comp.polyu.edu.hk
}
}

\maketitle

%\unitlength1pt
%\begin{picture}(0,0)
%\put(380,190){\mbox{\Large \bf  Paper \#478}}
%\end{picture}
%\unitlength1cm


\begin{abstract}
%\KZ{
The Apache Spark stack has enabled fast
large-scale data processing.
Despite a rich library of statistical models and
inference algorithms, it does not give domain
users the ability to develop their own models.
%}
The emergence of probabilistic programming languages 
has showed the promise of developing sophisticated
probabilistic models in a succinct and programmatic way.
%helps data analysts and machine learning experts to concisely 
%describe the probabilistic models using a programming language. 
These frameworks have the potential of automatically generating
inference algorithms for the user defined models and 
answering various statistical queries about the model. 
It is a perfect time to unite these two great directions to
produce a programmable big data analysis framework. 
We thus propose, InferSpark, a probabilistic programming framework on top of Apache Spark. 
Efficient statistical inference can be easily implemented on this 
framework and inference process can leverage the distributed main memory processing 
power of Spark. This framework makes statistical inference on
big data possible and speed up the penetration of probabilistic 
programming into the data engineering domain. 
\end{abstract}

\input{intro}
\input{background}
\input{framework}
\input{implementation}
\input{eval}
\input{relatedwork}
\input{conclusion}
\input{future}

\bibliographystyle{abbrv}
\bibliography{paper}

\appendix
%\input{syntax}
\input{model}
%\input{vmp}
%\input{syntax}

\end{document}

