%!TEX root = paper.tex

\chapter{Related Work}
\label{chap:related}

Apache Hadoop library \sjtucite{hadoop} is a distributed data storage and
MapReduce framework. Its distributed file system HDFS supports the storage of
large data on a large cluster. MapReduce \sjtucite{dean04} is the programming model for
distributed parallel processing of the large data. It is composed of two key
operations map and reduce. Map operation transforms and filters the data on
different nodes in parallel while reduce operations combines the results from
map operation to produce results grouped by keys. In InferSpark, input data and
checkpoint data can be distribted on an HDFS.

Apache Spark is another distributed data processing framework that provides MapReduce
operations. It differs from Hadoop in that it does not write the intermediate
results to temporary storage. Instead, it caches the results in memory as
resilient distributed dataset \sjtucite{Zaharia:2012:RDD:2228298.2228301}. It
can greatly speed up the processing, especially with iterative jobs.

GraphX \sjtucite{graphx} is Spark's built-in graph
parallel computation API. User can view graphs as normal RDDs of vertices and
edges and perform normal map reduce operations on them or perform graph
operations like compute subgraph, reversing edges, join vertices. The Pregel
operator in GraphX is used to express iterative algorithms. In each step,
vertices aggregates messages along the inbound edges from previous step,
compute its new value and sends messages along outbound edges in parallel. It
terminates when no message is sent during a step. InferSpark is built on
GraphX since it is natural to represent the factor graph in GraphX and
leverage the parallel graph computing to implement message-passing style
inference algorithms. 

Graphframes \sjtucite{graphframes} is a recent effort of graph processing on Spark. It is built on
SparkSQL instead of Spark core. It represents graph as relational tables
called graph frames and utilizes traditional relational database optimization.
However, it does not fit InferSpark's need because it implements the
Pregel-like operations by transforming a graph frame back to GraphX graph and
then calling the GraphX API, which is even slower than the original GraphX
implementation.

MLlib \sjtucite{mllib}, Mahout \sjtucite{mahout}, and MADLib \sjtucite{madlib} are machine
learning \emph{libraries} on top of distributed computing platforms and
relational engines. All of them provide many standard machine learning models
such as LDA and SVM.  However, when a domain user, say, a machine learning
researcher, is devising and testing the customized models with big data, those
libraries cannot help.

MATLAB and R have been the most popular systems for implementing inference
algorithms.  They, however, can hardly scale up when faced with increasing
amount of data because they mostly work on a single machine and thus cannot
easily scale out.  It is possible to first transform a large dataset into a
smaller one using MapReduce or Spark and then load the data to MATLAB or R to
perform inference %on the smaller ones in in some scenarios. But this approach
involves multiple systems, which is hard to develop code for and inefficient
because of the data movement.  SystemML \sjtucite{systemml} provides a similar
interface for implementing inference algorithms and transforms them to Hadoop
MapReduce. It can scale out to large clusters but coding on such a system
still requires extensive knowledge in statistical inference for end-user. 

In contrast to the systems above, MLBase \sjtucite{mlbase} targets end-users
who are not machine learning experts. It exposes a declarative language
interface and provides a cost-based optimizer that selects the best algorithm
and parameters. It also provides MLI \sjtucite{mli}, a set of API for
customizing algorithms on Spark. However, MLBase mainly supports frequentist
approach, such as SVM, and logistic regression. It does not deal with general
Bayesian inference. 

There are a number of probabilistic programming frameworks other than Infer
.NET \sjtucite{InferNET14}. For example, Church \sjtucite{GMR+08} is a
probabilistic programming language based on the functional programming
language Scheme.  Church programs are interpreted rather than compiled.
Random draws from a basic distribution and queries about the execution trace
are two additional type of expressions. A Church expression defines a
generative model. Queries of a Church expression can be conditioned on any
valid Church expressions. Nested queries and recursive functions are also
supported by Church. Church supports stochastic-memoizer which can be used to
express nonparametric models.  Despite the expressive power of Church, it
cannot scale to large dataset and models.  Figaro is a probabilistic
programming language implemented as a library in Scala \sjtucite{Figaro}.  It
is similar to Infer .NET in the way of defining models and performing
inferences but put more emphasis to object-orientation. Models are defined by
composing instances of Model classes defined in the Figaro library.  Infer
.NET is a probabilistic programming framework in C\# for Bayesian Inference. A
rich set of variables are available for model definition. Models are converted
to factor graphs on which efficient built-in inference algorithms can be
applied.  Infer .NET is the best optimized probabilistic programming
frameworks so far.  Unfortunately, all existing probabilistic programming
frameworks including Infer .NET cannot scale out on to a distributed platform.

To the best of our knowledge, InferSpark is the only framework that can
efficiently carry out large-scale Bayesian inference through probabilistic
programming on a distributed in-memory computing platform. It targets
end-users who are not expert in Bayesian inference or distributed computing.
The inference implementation can scale out to a large cluster and scale up to
large datasets.

