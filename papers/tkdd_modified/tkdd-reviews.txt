Dear Dr. Zhu:

I write you in regards to manuscript # TKDD-2014-07-0127 entitled "A Partial Suppression Framework for Rho-uncertainty Privacy Protection" which you submitted to the Transactions on Knowledge Discovery from Data.

In view of the criticisms of the reviewer(s) found at the bottom of this letter, your manuscript has been denied publication in the Transactions on Knowledge Discovery from Data.

Thank you for considering the Transactions on Knowledge Discovery from Data for the publication of your research.  I hope the outcome of this specific submission will not discourage you from the submission of future manuscripts.

Sincerely,
Dr. Philip Yu
Editor in Chief, Transactions on Knowledge Discovery from Data psyu@cs.uic.edu

Editor's Comments to Author:

Associate Editor
Comments to the Author:
We have received three reports on your submission. Two reviewers have raised some major concerns about novelty, depth of technical details, incomplete treatment of related works,  and clarity of presentation. Based on these reviews, I could not recommend publication of the work. I hope you will find the reviews useful for further improvement. Thank you for consideration TKDD.

Reviewer(s)' Comments to Author:

Reviewer: 1

Recommendation: Reject

Comments:
I regret that my recommendation is not to accept this manuscript. In the following, I will first briefly summarize this work, then explain the reasons of my recommendation, and make more comments on this work. 

This paper anonymized set-valued data by partial suppression to achieve the rho-uncertainty (Cao et al 2010) in two scenarios, one for data mining and the other for statistical analysis. A different data utility metric was presented for each scenario, and a heuristic algorithm guided by the corresponding metric was proposed in the paper. Experiments showed that the proposed algorithms outperformed competitors in terms of the proposed data metrics respectively. However, there are a few issues that make this paper unpublishable. 

First, the novelty of this paper is not high. It did not make new insight into adversarial attack models or privacy models, and it was not the first that proposed the partial suppression technique or applied it to anonymize set-valued data although it claimed that. Please refer to the work by (Atallah et al 1999) and (Verykios et al 2004) and the discussion in (Cao et al 2010).

Second, the proposed algorithms are not technically sound and they seem to be efficient only with "fine-tuned", unjustified parameters, such as estimated cost of suppression, tmax (=300), buffer size, bmax (=10E6), and the max record length, cutoff (=5). Those parameters were not clearly explained and not well-founded. The time complexity of each proposed algorithm was not analyzed. 

Third, the experimental evaluation was inappropriate in two aspects. One is that the data utility metric for the data mining scenario was inappropriate. Concretely, you measured the data utility by the Jaccard similarity between nr(T) and nr(T') where "nr(T) denotes the set of all non-sensitive associations rules mineable from T with sufficient supports and confidences" (at line 48 of page 3). In other words, sensitive items are left out in evaluating data utility, which did not make any sense to me. The other aspect was that you should compare with privacy-preserving data mining approaches such as (Evfimievski et al 2003). Moreover, it was not clear how you measured the information loss for TDControl as your information loss is the number of suppressed items (normalized to 1).

The last but not the least reason is that this submission expanded a conference paper as follows.
--- A new subsection, Section 3.4 Analysis of the Algorithm, that proves the correctness of proposed algorithms, which are straightforward proofs. 
--- A new subsection, Section 4.1 Variation of rho, that discusses the performance of proposed algorithms with varying the parameter rho, which is basic performance figure (Figure 2).
--- More discussion on related works (Section 5 was expanded without new insights). 
To my opinion, this submission did not satisfy the TKDD novelty requirement: "A manuscript that is based on one or more previous publications by one or more of the published authors should consist of at least 30% new material in the new submission. The new material should be content material ..." (http://tkdd.acm.org/authors.html#PriorPublicationPolicy). 


In the following, I would like make more comments in addition to those listed in "missing facts", "missing references", and "missing analyses".

a) There were many incorrect citations in this paper in that the original source of an idea was not cited. For example at line 41 of page 1 (also in Section 5.3), you should cite (Samarati and Sweeny 1998) for record link attack in addition to (Fung et al 2011). 

b) The authors got confused with the confidences of the non-sensitive association rules to be mined and the rho of sensitive rules to be sanitized, which was evident in the cross-references: 
At line 30 of page 11, "we … check the rules mined from anonymized data with support equals to 0.05% and confidence equals to 70% and 30%. Figure 5 gives the results." 
And in Figure 5 at page 12, the results are labelled with subtitiles "(a) rho=0.3" and (b) "rho=0.7" respectively. 

c) Theorems, Lemmas, and Corollaries should be numbered consecutively across sections. Therefore, your Lemma 3.3, Theorem 3.4, Corollary 3.5 might be Lemma 1, Theorem 2, and Corollary 3 respectively. Similarly, Definition 3.1 might be Definition 1, and so on.

d) Starting from Definition 3.1 (at line 18 at page 4), you used the term "type" and "the item type" without clearly explaining what "type" means? Do you mean "sensitive" or "non-sensitive" by "type"? If this is the case, then what did you mean by "t=e" and "t in q" where e is a sensitive item and q is a set of items. It seemed to me that you might want to differentiate a distinct item from its occurrences.   

e) As to the algorithmic aspect, I would suggest an algorithm that could be instantiated with any metric in a plugin-and-play mode (i.e., works with many utility metric without hard-coded). 

f) You considered two scenarios that seemed to be orthogonal. I would like to see some justification for this. 

g) I did not agree to your discussion about differential privacy in Section 5.1.5. 

h) Some of typos and expression issues:
--- at line 48 of page 3: "… associations rules…" --> "  ... association rules... "
 
--- at line 26 of page 6: "when data is very large ...":  notice that "data" is a plural noun. 

--- " 5.2.4 Pertubation "  à  "5.2.4 Perturbation"

--- in Section 2.1: You may rephrase your first paragraph as it was unambiguous in explaining what a sensitive association rule is. 

--- The formats of references were inconsistent in your paper.


Additional Questions:
Review's recommendation for paper type: Short technical note

Does the paper present innovative ideas or material?: No

In what ways does this paper advance the field?: This work did not advance the state of the art research in this field. 
There is a plethora of similar works on the topic. The employed privacy notion, rho-uncertainty, is not new. The anonymization technique, partial suppression itself, is not new. The proposed algorithms for applying partial suppression to achieve rho-uncertainty are not that challenging. The experimental evaluation was incomplete.

Rate how well the ideas are presented (very difficult to understand=1 very easy to understand =5): 3

Rate the paper on its contribution to the body of knowledge to this field (none=1, very important=5): 2

Rate the information in the paper is it sound, factual, and accurate?(poor=1 excellent=5): 2

Please explain why.: One claim by this paper, "we are the first to propose an effective partial suppression framework for anonymizing set-valued data" (your first contribution stated at line 44 of page 2), is not factual. 
In fact, (Atallah et al 1999) and (Verykios et al 2004) employed partial suppression in limiting the disclosure of sensitive rules embedded in set-valued data. Concretely, one of their approaches is to decrease the supports of itemsets and confidences of rules by removing items partially, which is exactly partial suppression. Notice that Cao et al 2010 also pointed out this. 

One conclusion by this paper, "the second heuristic which minimizes the K-L divergence between the anonymized data and the original data helps preserve the data distribution, which is a feature largely ignored by the privacy community in the past" (your second conclusion at line 16 of page 18), is also not factual. 
In fact, K-L divergence was first used by (Kifer and Gehrke 2006b) in measuring the data utility. Since then many works on privacy employed this metric. 

Some concepts were not accurately defined, which may confuse readers. In particular, the paper did not make it clear whether the confidence threshold (rho) for sensitive rules is same as the confidence threshold for mining non-sensitive rules in the anonymized data. The questions are: if they were same, what was the rationale; if they were different, how they were set in the experiments. There was no answer to such questions in your definitions (Section 2.2 Data Utility) and in your experimental evaluations (Section 4.2 Data utility). 
Please refer to "Comments to the Author" for more points.

Rate the overall quality of the writing (very poor=1, excellent=5): 2

Does this paper cite and use appropriate references?: No

If not, what important references are missing?: Many related works are missing. 

First of all, as one of your scenarios anonymizes data for data mining, you may explain why your scenario is necessary in the first place. You may compare your scenario with the following scenarios releasing synthetic data or releasing mining results instead of data. 
Y. Wang, X. Wu. 2005. Approximate inverse frequent itemset mining: Privacy, complexity, approximation. In ICDM, 2005 (this work proposed generating a synthetic database from frequent itemsets discovered in the original database). 
M. Atzori, et al. 2008. Anonymity preserving pattern discovery. VLDB Journal, July 2008, 17(4):703-727 (this paper considered privacy violations embedded in data mining results and suggested ways eliminating such violations by means of pattern distortion). 

Second, you may also discuss why your privacy notion is appropriate. For example, the work by (Atzori et al 2008) implies that the knowledge about the absence of items could cause privacy breach even your rho-uncertainty was observed (this argument also holds against Cao et al 2010). 
By the way, your claim "…we do not restrict the size or the type of the background knowledge …" (at line 42 of page 15) was not well-founded. 
Moreover, the work by Zhu et al 2010 proposed the p-linkability notion and a clustering-based approach. You may discuss the connection and difference between Zhu et al 2010's and yours. 
Y. Zhu, et al. 2010. Anonymizing user proﬁles for personalized web search. In WWW, April 2010, pp 1225–1226.

When discussing generalization in Section 5.2.1, the following should be cited and discussed: 
P. Samarati and L. Sweeney. 1998. Generalizing data to provide anonymity when disclosing information. In PODS, 1998, pp.188 (this is the first work about generalization) V. Iyengar. 2002. Transforming data to satisfy privacy constraints. In KDD 2002, 279-288 (this I s the first work about global generalization, a.k.a. full subtree generalization) K. LeFevre, et al. 2006. Mondrian multidimensional k-anonymity. In ICDE 2006 (this is the first work about local generalization, a.k.a. local generalization). 

When discussing suppression in Section 5.2.2, the following should be included: 
M. Atallah , et al. 1999. Disclosure limitation of sensitive rules. Proc. 1999 Workshop on Knowledge and Data Engineering Exchange, 1999 (this work employs partial suppression in sanitizing sensitive rules in set-valued data. So does Verykios et al 2004). 
J. Liu and K. Wang. 2010. Anonymizing transaction data by integrating suppression and generalization. In PAKDD, 2010 (this is the first work that integrates suppression and generalization in anonymizing set-valued data. So does Cao et al 2010 ). 

When discussing perturbation in Section 5.2.4, please discuss the following: 
A. Evfimievski, et al. 2002. Privacy preserving mining of association rules. In KDD 2002, pp.217-228. 
A. Evfimievski, et al. 2003. Limiting privacy breaches in privacy preserving data mining. PODS 2003 (Both papers prevent privacy breach when releasing set-valued data for data mining).

As to data utility metrics, you may cite the following: 
D. Kifer and J. Gehrke. 2006b. Injecting utility into anonymized datasets. In SIGMOD, pp217–228, 2006 (this is the first work using K-L divergence in privacy research).
Moreover, you may cite Iyengar 2002 (listed above) which formally defined the information loss metric, you may use this metric instead of your "number of suppressed items", as it can measure data utility both for generalization and for suppression. By the way, you did not explain how you measured "information loss" for TDControl and Global in your experiments.

Is the treatment of the subject complete?: No

If not, What important details / ideas/ analyses are missing?: A fundamental question is not discussed at the first place: What attacks an adversary may launch and what privacy model is appropriate. In fact, an adversary may launch a privacy attack based on his knowledge about the absence as well as presence of certain items in his or her target transactions. Such an attack is not addressed by the rho-uncertainty (Cao et al 2010). 

Another important question not discussed is whether the sensitive items and non-sensitive items are equally important in each scenario (Xu et al 2008). In particular for the data mining scenario, are the sensitive items important, do we need to consider sensitive items when measuring the data utility?

Moreover, partial (local) suppression as well partial (local) generalization is not a new anonymization technique. There are many criticisms against them, for example false mining results as discussed in Cao et al 2010, Liu and Wang 2010, and Xu et al 2008. The authors should analyze both its strength and its weakness.

This paper simply took the rho-uncertainty, partial suppression, and the devised metrics without adequately analyzing the above questions, and attempted to show that partial suppression is an all-round-winner, which is not convincing. 
 
The authors should show its strength as well as its weakness theoretically and experimentally.

Please help ACM create a more efficient time-to-publication process: Using your best judgment, what amount of copy editing do you think this paper needs?: Heavy

Most ACM journal papers are researcher-oriented. Is this paper of potential interest to developers and engineers?: No


Reviewer: 2

Recommendation: Major Revision

Comments:
Presentation:

1. Partial suppression is not new. The following cited work also uses partial suppression to control rule confidence. It needs to clarify the difference of this work from the cited work.
Vassilios S. Verykios, Ahmed K. Elmagarmid, Elisa Bertino, Y¨ucel Saygin, and Elena Dasseni. 2004. Association Rule Hiding. TKDE (2004), 434–447.

2. Definition 3.1 is more like a lemma, which needs brief proof.

3. Partial suppression has the regression problem as stated in Section 3.2.3. But global suppression does not have such a problem. To give readers a complete view about partial suppression and global suppression, the advantage of global suppression should also be included.

4. In Algorithm 3, how to equally split T (that is, how to split T into T_1 and T_2)? 

Experiments: 

a. In Figure 2 (c), when \rho is bigger, the privacy requirement is lower. Thus, it is reasonable that the information loss as shown in Figure 2(a) decreases as \rho grows. But why the rule mining quality based on Jaccard similarity is very different from the expectation (e.g., when \rho = 0.5, the Jaccard similarity is above 0.2, but when \rho = 0.9, the similarity is 0)? The existing argument is not convincing at all.

2. TDControl generates generalized items. Thus, generalized association rules could be mined from the output data of TDControl. For a fair comparison, the authors need to generalize the rules, which are mined from the anonymized data by their algorithms, and then compare these rules with those mined from the anonymized data by TDControl.

3. The scalability of the proposed solutions needs to be tested by varying the maximum record length. The current cutoff is set to 5, too small.


Additional Questions:
Review's recommendation for paper type: Full length technical paper

Does the paper present innovative ideas or material?: Yes

In what ways does this paper advance the field?: The authors proposed solutions to anonymize set-valued dataset to ensure that the confidence of any sensitive association rule is not bigger than a threshold \rho. Thus, the anonymized dataset satisfies the privacy principle of \rho-uncertainty, proposed earlier by Cao et al.

The experimental results show that the proposed solutions preserve more information than existing approaches, and the quality of mining results from their anonymized data is also better.

Rate how well the ideas are presented (very difficult to understand=1 very easy to understand =5): 4

Rate the paper on its contribution to the body of knowledge to this field (none=1, very important=5): 3

Rate the information in the paper is it sound, factual, and accurate?(poor=1 excellent=5): 4

Please explain why.: 

Rate the overall quality of the writing (very poor=1, excellent=5): 4

Does this paper cite and use appropriate references?: Yes

If not, what important references are missing?: 

Is the treatment of the subject complete?: Yes

If not, What important details / ideas/ analyses are missing?: 

Please help ACM create a more efficient time-to-publication process: Using your best judgment, what amount of copy editing do you think this paper needs?: Moderate

Most ACM journal papers are researcher-oriented. Is this paper of potential interest to developers and engineers?: Maybe


Reviewer: 3

Recommendation: Reject

Comments:
This paper proposes a partial suppression method to satisfy ρ-uncertainty, a privacy guarantee proposed by [Cao et al. 2010]. The authors claim that by only suppressing some instances of items that appear in sensitive association rules, they satisfy ρ-uncertainty while reducing the information loss. 
They propose two heuristics, as the studied problem is NP-hard. The first heuristic (Mine) aims to preserve as many useful rules as possible from the original data and is more suitable for data mining of association rules. The second heuristic (Dist) is more useful for statistical analysis, as it minimizes the K-L divergence between the original and the anonymized data in order to preserve the data distribution. 
They experimentally evaluate their method on real and synthetic datasets, and compare their results to the generalization and global suppression techniques proposed by [Cao et al. 2010]. They also make a comparison with a permutation method by [Ghinita et al. 2011]. 

Strong points:
- The proposed method seems to preserve the utility of anonymized datasets better than the current state-of-the-art
- Focusing on the utility of the anonymized datasets is a problem of importance

Weak points:
- The technical depth is not great. The method is rather straightforward and the contribution is limited.
- Novelty is also limited, since it’s an improvement of an existing approach
- The experiments are not always clear
- The introduction of spurious rules is an important problem that is not investigated sufficiently and no experimental results on the extent of the problem are provided. The number of spurious rules should be traced in the anonymized results, as well as their supports and confidence. 

Minor comments:

-There are several aspects of the experiments that are unclear. For example how you measure information loss (item suppression) for TDControl which uses generalization? How is the anonymization quality affected by DnC? Why are the tests of Figure 5 done with a different dataset and for only 1 mining threshold?

- Do you take duplicates into account? Such as: milk, milk, sugar, cookies. Would they create problems to your method? If yes, could your method be adjusted to take them into account?

- In Section 2.1 the objective function is not well explained. It does not suffice to clarify what each symbol represents; it is useful to add a small discussion explaining why they chose these particular functions. Please explain why/how minimizing f(T,T’) would lead to better data utility. 

- In Section 3.1 and Algorithm 1, it is not explained how the qids are generated in B and why a small bmax would lead to repetitive generation of qids. 
Also in line 6 of algorithm 1, do you scan the entire dataset at every iteration, in order to calculate the supports? Do you keep anything in memory?

- On Page 6, lines 9-10 need rephrasing. 

- In Paragraph 3.2.3, it is not very clear how you deal with regression, I believe it should be further explained. 

- The choice of the Cost function for splitting by DnC algorithm, given by equation (6), should be explained. 


- On Page 8, in the caption of Table II there is a typo: there are “Four Original Datasets”, not “Five”. 


- In the Section 4.5, did you also measure the Jaccard similarity?

- Related work is detailed. However, it should focus more on the differences that this approach has to previous works and on explaining in what ways it is more advanced. I don’t think it is necessary to repeat the definitions of other privacy models. 

- Some minor typos: 
Page 7 line 27: “must scans … and doesn’t …” -> must scan … and not … Page 8 line 25: “To evaluation” -> To evaluate Page 8 line 36: “we gives” -> we give


Additional Questions:
Review's recommendation for paper type: Full length technical paper

Does the paper present innovative ideas or material?: Yes

In what ways does this paper advance the field?: The paper provides a new method that allows guaranteeing \rho-uncertainty with less information loss that existing state-of-the-art

Rate how well the ideas are presented (very difficult to understand=1 very easy to understand =5): 3

Rate the paper on its contribution to the body of knowledge to this field (none=1, very important=5): 2

Rate the information in the paper is it sound, factual, and accurate?(poor=1 excellent=5): 3

Please explain why.: Algorithmic details and experiment procedures are not very clear

Rate the overall quality of the writing (very poor=1, excellent=5): 2

Does this paper cite and use appropriate references?: Yes

If not, what important references are missing?: 

Is the treatment of the subject complete?: No

If not, What important details / ideas/ analyses are missing?: Spurious rules and several other minor comments have to be addressed

Please help ACM create a more efficient time-to-publication process: Using your best judgment, what amount of copy editing do you think this paper needs?: Heavy

Most ACM journal papers are researcher-oriented. Is this paper of potential interest to developers and engineers?: Maybe

