\documentclass{sig-alternate}%[conference][letterpaper]
\usepackage{times,amsmath}
\usepackage{epsfig,algorithm,caption,subcaption,multirow}
\usepackage[noend]{algpseudocode}
\usepackage[normalem]{ulem}
\usepackage{color,url}
\usepackage{balance}
\DeclareCaptionType{copyrightbox}

\newcommand{\secref}[1]{Section \ref{#1}}
\newcommand{\figref}[1]{Figure \ref{#1}}
\newcommand{\equref}[1]{Equation (\ref{#1})}
\newcommand{\exref}[1]{Example \ref{#1}}

\newcommand{\KZ}[1]{\textcolor{green}{[KZ: #1]}}
\newcommand{\HAIXUN}[1]{\textcolor{red}{[HAIXUN: #1]}}
\newcommand{\myurl}[1]{\textsf{\textcolor{blue}{\uline{#1}}}}

\newcommand{\cut}[1]{}
\newcommand{\myskip}{\vspace*{1ex}}
\newcommand{\shrink}{\vspace*{-1ex}}

%\theoremstyle{definition}
%\newenvironment{example}[1][Ex.]{\begin{trivlist}
%\item[\hskip \labelsep {\bfseries #1}]}{\end{trivlist}}
\newtheorem{example}{Example}

\newcommand{\lbb}{{\color{black} \textbf{[}}}
\newcommand{\rbb}{{\color{black} \textbf{]}}}
%
%
\begin{document}
%\conferenceinfo{EDBT'13,} {Mar 18-22, 2013, Genoa, Italy.}
%\CopyrightYear{2013}
%\crdata{978-1-4503-1462-6 /12/08}
%\clubpenalty=10000
%\widowpenalty = 10000
\title{Wikification via Link Co-occurrence}
%
%\numberofauthors{3}
%\author{%
%\alignauthor
%Zhiyuan Cai \hspace*{3mm} Kaiqi Zhao\\
%	\affaddr{Shanghai Jiao Tong University}\\
%	\affaddr{Shanghai, China}\\
%	\email{\small \{luckyvega,kaiqi\_zhao\}@sjtu.edu.cn}
%\alignauthor
%Kenny Q. Zhu\\
%	\affaddr{Shanghai Jiao Tong University}\\
%	\affaddr{Shanghai, China}\\
%	\email{\small kzhu@cs.sjtu.edu.cn}
%\alignauthor
%Haixun Wang\\
%	\affaddr{Microsoft Research Asia}\\
%	\affaddr{Beijing, China}\\
%	\email{\small haixunw@microsoft.com}
%}
\maketitle

\begin{abstract}
Wikification, which stands for the process of linking terms in a
plain text document to Wikipedia articles which represent the correct
meanings of the terms, can be thought
of as a generalized Word Sense Disambiguation problem.
It disambiguates multi-word expressions (MWEs) in addition to single words.
Existing Wikification techniques either models the context of a given
term as well as the Wikipedia article as bags of words, or compute
global constraints among Wikipedia concepts by the link graph or
link distributions. The first method doesn't achieve good results
because the MWEs can have very different meanings than its constituent
words which themselves are ambiguous. The second method doesn't produce
high accuracy because the link structure or link distribution is often
biased or incomplete by themselves due to the fact that Wikipedia pages
are often sparsely linked.
In this paper, we present a simple but powerful framework
of sense disambiguation
using co-occurrences of Wikipedia links in the Wikipedia
corpus. We propose an iterative method to enrich the sparsely-linked
articles by adding more links and then use the resulting
link co-occurrence matrix to disambiguate an input document by a sliding
window algorithm.  Our prototype system achieves about 89.97\% precision
and 83.26\% recall averagely on three data set and compares favorably
with all four state-of-the-art wikification techniques.
\end{abstract}

% NOTE keywords are not used for conference papers so do not populate them
\begin{keywords}
Wikification, phrase sense disambiguation, link co-occurrence, iterative
algorithm
\end{keywords}
\setlength{\floatsep}{3mm plus 2mm minus 2mm}
\setlength{\textfloatsep}{3mm plus 2mm minus 2mm}
\setlength{\intextsep}{3mm plus 2mm minus 2mm}
\input{intro}
\input{overview}
\input{parser}
\input{algo}
\input{implement}
\input{eval}
\input{related}
\input{conclude}

\bibliographystyle{abbrv}
\bibliography{../bibs/wiki}
\end{document}
