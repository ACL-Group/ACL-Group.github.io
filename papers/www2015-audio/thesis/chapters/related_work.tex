\chapter{Related work}
There are some researchers working on related problems. However, some of them only work on sound event detection/classification/recognition. They focus on some specific sound events and do not care about audio context. In the mean time, some of researches focus on recognizing the context, but most of them use one model for each context and directly recognizing the context, without detecting the sound event. Recently, some of great works are using a small set of pre-defined event to infer the context, which may open up a new direction of this research.

Gaunard \et\cite{679661} proposed an HMM-based environmental noise recognition system. It use discrete HMM as model and linear prediction cepstral coefficients (LPCCs) as features. It shows that the system can achieve $95.3\%$ correct rate, which outperforms human listeners who only achieves $91.8\%$ correct rate for classifying 5 types of environmental noise (car, truck, moped, aircraft, and train).

Peltonen \et\cite{5745009} studied the efficiency of different acoustic features, models, and the effect of test sequence length. They proposed two system using different features and models. One was using band-energy ratio as features and trained by 1-NN classifier. The other was using MFCC as features and trained by GMM. The best recognition rate is around $68.4\%$ for 26 different scenes.

Eronen \et\cite{1561288} investigated the feasibility of an audio-based context recognition system. It showed that linear data-driven transformations, \ie Independent Component Analysis (ICA) and Linear Discriminant Analysis (LDA) could improve recognition accuracy slightly. Their system can achieve $58\%$ accuracy for 24 common contexts. They also did some listening tests, and found that human beings can achieve $69\%$ accuracy on the same data set.

Chu \et\cite{5109766} performed an empirical feature analysis and use the matching pursuit (MP) algorithm to obtain effective features from a large feature set, including MFCC, LPCC, band energy ratio, zero-crossing, energy, etc. The recognition rate of their system is $82.3\%$ over 14 audio contexts.

Weninger \et\cite{5946409} focus on animal vocalizations. They compared left-to-right HMM, cyclic HMM, recurrent neural networks, and SVM, and achieve up to $64.0\%$ accuracy on a 5-class task, and $81.3\%$ on a 2-class task.

One of the approaches to consider audio events in context inference is introduced by Cai \et\cite{1621215}. They proposed a flexible framework to recognize 5 audio contexts, including excitement, humor, pursuit, fight and air-attack, using 10 predefined events. The main technologies they used are HMM, Grammar Network, and Bayesian network. Their system can achieve $91.7\%$ accuracy for event detection, and $82.4\%$ accuracy for context inference.

Recently, another event-based audio context recognition is proposed by Heittola \et\cite{heittola2010audio}. They use a histogram of audio events which are detected by GMM/HMM presented in \cite{mesaros2010acoustic}, where an accuracy of $24\%$ was obtained when classifying isolated sound events into 61 classes. After a histogram of audio events was built, context recognition can be performed by using cosine distance to calculate the similarity. Their system can obtain $89\%$ accuracy when recognizing 10 audio contexts.

Giannoulis \et\cite{6701819} described a public evaluation challenge\footnote{http://c4dm.eecs.qmul.ac.uk/sceneseventschallenge/} on acoustic scene classification and detection of sound events within a scene. They provided an overview of systems submitted to the challenge and summarized the results. The challenge is to classify audio clips into 10 different scenes. 
Chum \et\cite{chumieee} proposed a GMM and HMM based system, using magnitude response, loudness, spectral sparsity and temporal sparsity as features. They achieved accuracy of $72\%$. 
Elizalde \et\cite{elizaldevector} proposed an {\em i-vector} system\cite{dehak2009support,5947437}, together with MFCC features, which can achieve an accuracy of $65.8\%$. 
Geiger \et\cite{geigerrecognising} introduced a SVM based system, using many low-level features, such as MFCC, band energy, etc. An accuracy of $73\%$ is achieved by their system using majority voting scheme. 
Krijnders \et\cite{krijnders400tone} proposed a SVM based system using tonalness as feature, achieved $53\%$ accuracy. 
Li \et\cite{liauditory} developed a treebagger classifier using MFCC and other spectral features. It can achieve $72\%$ accuracy. 
Nam \et\cite{namacoustic} introduced the feature learning approach to audio scene classification. They use RBM\cite{lee2007sparse}and perform selective max-pooling to form scene-level feature vector for SVM training. Their system can achieve $75\%$ accuracy. 
Nogueira \et\cite{nogueirasound} proposed a SVM based system using spectral, temporal and spatial features, achieve accuracy of $69\%$. 
Olivetti \cite{emanuele} proposed two approaches, dissimilarity representation and normalized compression distance, to embed audio into a vectorial feature space. A random forest\cite{rf} algorithm was used for classification, and the system can achieve accuracy of $80\%$. 
Patil \et\cite{patil2002multiresolution} proposed a framework that provided a analysis of the spectro-temporal modulations in acoustic signal, and built a SVM classifier, which can achieve accuracy of $73\%$. 
Rakotomamonjy \et\cite{rakotomamonjy} used a constant Q transform in feature extraction. Their system can achieve $75\%$ accuracy by applying a SVM classifier.
Roma \et\cite{romarecurrence} proposed a SVM based classifier with MFCC feature and RQA\cite{zbilut2006recurrence} features. It can achieve accuracy of $71\%$.

