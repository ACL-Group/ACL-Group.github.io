\section{Introduction}
%\KZ{Generally speaking, the English in the whole paper is still sloppy.
%You need to carefully proofread the whole thing at least twice!}

Commonsense knowledge, lying in the core of human cognition,
can be represented as short-phrase concepts and relations among those concepts. 
Commonsense knowledge can underpin a commonsense reasoning process. 
%For example, humans can easily distinguish that the word ``cute'' is much more proper to describe a dress instead of ``sexy'', when this particular dress is made for a 5-year-old girl.
For example, given a dress made for 5-year-old girl, it is easy for human to 
tell that ``cute'' is a much more appropriate term than ``sexy'' for describing
the dress.  Such inference backing on commonsense knowledge may be 
trivial for humans, but it is not easy for %\JQ{today's} 
machines to make the right choice even if they have been trained on 
large scale textual corpora.

%Commonsense is accumulated during one's growth, help to form the cognition and is very important for human to judge things or occurred events. For instance, given the pair ``children cute dress''(儿童可爱连衣裙) and ``children sexy dress''(儿童性感连衣裙), when judge which one is more plausible, one can know that sexy is a much more mature describing word which is not very suitable to appear with children at the same time. This type of thought may be trivial for the human, but is still out of the reach of current state-of-the-art neural model. 

%In recent years, techniques of machine learning include deep neural networks develop fast. The performance of machine surpass human on several dataset of different tasks, such as machine reading comprehension \cite{he2018dureader,rajpurkar2016squad,lai2017race} 
In recent years, 
%technique of machine learning include deep neural networks develop fast. 
machine learning models especially deep neural networks have 
achieved remarkable success. 
The performance of machines even surpasses humans on some tasks
such as machine reading comprehension \cite{he2018dureader,rajpurkar2016squad,lai2017race}, image classification \cite{rajpurkar2017chexnet,deng2009imagenet}, and question answering~\cite{reddy2019coqa}.
%(CoQA)
Particularly, with the introduction of large pre-trained language models 
such as BERT~\cite{devlin2018bert}, 
state-of-the-art performances on a wide range of benchmarks in NLP are refreshed.
%several existing datasets are refreshed by a new record.
%However, surprised by the amazing performance of BERT, we want to measure how much commonsense that this kind of pretrained model indeed learn and store in their delicate neural structure. We argue that commonsense is a vital key to evaluate if a machine could reach the real intelligence.
However, how much commonsense knowledge this kind of pre-trained models actually learn still remains a question.
%how much commonsense knowledge can these pre-trained models truly learn?

An intuitive way %to find the answer\JQ{delete "to...answer"} 
is to test the pre-trained models on different commonsense reasoning tasks.
%As commonsense plays an important role in daily life, 
%Previous work on commonsense dataset construction such as 
Previous datasets designed for such tasks include COPA ~\cite{roemmele2011choice}, ROCStories~\cite{mostafazadeh2016corpus} and SWAG~\cite{zellers2018swag}.
These datasets focus on inference between sentences or passages. 
For example, the SWAG dataset is used for choosing the most plausible continuation among four choices given a sentence.
%the task in the Situations With Adversarial Generations (SWAG) dataset is to decide among four choices the most plausible continuation according to a given sentence.
In these datasets, 
surrounding context of relatively long sentences are rich, 
%\JQ{It is common that the surrounding context are rich in these dataset,}
so that pre-trained language models like BERT may take the advantage 
of it and perform well just like in other tasks~\cite{devlin2018bert}.
%Those tasks led to advances of several methods of integrating external knowledge. Pretrained model such as BERT further improve performance of machine on some datasets such as SWAG or ARCT~\cite{habernal2017argument}
%\mx{weixin那几篇攻击bert的}
%, where statistical clues are found easily during learning.
%Compared to the previous dataset, 
Thus, we believe it is necessary to conduct the same experiments on datasets formed by short phrases with limited context.
%\KZ{Not sure what you mean below.}
%%After all, 
%there is no availabel dataset formed by short phrases with limited context and 
%%it leaves the blackness for testing the reasoning on such datasets. 
%After all, it leaves the blackness for testing the reasoning on short texts and it is necessary to conduct a dataset formed by short phrases with limited context.

% BERT, representative model, evaluate how much commonsense is integrated. encourage

%commonsense is important for human, machine have commonsense is a key for being an artificial intelligence

%recent years, there are several tasks to judge if machine have such commonsense, for example, ... (list those commonsense dataset). 

%Those tasks led to advances of several methods \mx{search methods}, (include how to integrate knowledge), pretrained model such as BERT performs also good(?) \mx{search for evidence}. 

%However, compared to the previous dataset, short phrase is very different, list three major differences.

%There are also some methods to solve short text challenge, such as ... 

%List their data source.\mx{find difference between web query and e-commerce query}

%But no public dataset or standard benchmark \mx{search for evidence}

%Besides, no Chinese available dataset.

%We propose a Chinese dataset for better evaluate.

%Our contribution
%\begin{itemize}
%	\item raise a dataset
%	\item propose a method for annotate data more efficient
%	\item evaluate current SOTA method
%\end{itemize} 


%With the rapid development of Internet, 
%short texts such as search queries and news titles explode in recent years. 
In general, the majority of short phrases such as search queries contain less than 5
English words~\cite{hua2015short} or 3 Chinese words,
and it is challenging to understand such short texts. %which are mostly less than 5 English words  
First, short texts lack contextual information. On the one hand, 
statistical methods such as word co-occurrence are not that effective when dealing
with short texts. On the other hand, there is data sparsity problem since 
semantic features are scarce from short text. 
Second, short texts do not reflect the syntax of a written language. 
Therefore, the traditional natural language processing methods such as Part-Of-Speech tagging or dependency parser %\JQ{are useless}
cannot be easily applied. 
Last, words in short text are more likely to be ambiguous. For example, in a search query "watch Harry Potter", %from an online E-commerce platform, 
"watch" can either be a noun or a verb, and 
"Harry Potter" can be a movie, a book or the character in that movie. 
However, we humans can easily understand the query intent is searching for the movie resource %looking for a watch which the character on it is Harry Potter 
according to our commonsense knowledge.
Unfortunately, among all the existing commonsense reasoning dataset, none of them targets on short texts.%\JQ{delete the next sentence.}
%It remains a doubt whether machines can deal with commonsense reasoning on short texts.

%\KZ{You should show a few example phrase pairs along with the ground truth
%label from the dataset here.}
To fill the gap, we propose a new dataset called Commonsense Contradiction (\textbf{CoCon}), consisting of 9,229 pairs of short phrases in Chinese. 
%The reason we call it ``contradiction'' is that at least one phrase of each pair can be contradictory judging by common sense of humans.\JQ{from "The reason...": Given a phrase pair, one of the phrases is considered to contradict commonsense knowledge, and the task is to tell the conflicting ones from pairs.}
Each pair of phrases contains at least one contradictory phrase judging by the commonsense of 
humans.
For example, one phrase pair is "girl supplementary food"(女童辅食) and "baby supplementary food"(宝宝辅食), where the latter one is more plausible based on the knowledge that complementary food aims at little baby less than 2-year-old.
All the phrases are collected from search queries on a popular e-commerce platform.
Due to limited annotation resources, we first propose a novel framework to preprocess raw queries and increase the percentage of search queries containing commonsense contradiction from 2.92\% to 86.48\%.
Crowdsourced annotators are then asked to pick out those phrases which are 
not plausible from the preprocessed queries
according to their common sense. 
For each implausible short phrase which contains some sort of contradictory knowledge,
we next automatically generate a corresponding plausible phrase to form 
a phrase pair. %according to some rules.
Finally, five other annotators are asked to choose the more plausible phrase between
each phrase pair. 
Only those phrase pairs successfully distinguished by four out of 
five annotators are added to our final CoCon dataset. 
%\KZ{This part is a bit out of place: We also propose a novel framework to automatically extract more commonsense 
%contradiction samples
%learn commonsense contradiction knowledge 
%given limited annotation resources.
%The percentage of search queries containing commonsense %contradiction grows
%from 2.92\% to 86.48\% using the proposed framework.}
%%%among all the pre-annotation samples.  

%\KZ{With the CoCon dataset, we propose a task called ...}
With the CoCon dataset, we propose a task called \textit{Contradiction Identification on short phrase}.
%In terms of contradition identification, 
On this task, the most representative model, BERT,  
without fine-tuning can only reach an
accuracy of 59.92\% on this new benchmark.
%As the most representative model, BERT without fine-tuning could only reach the accuracy of 59.92\%. 
Meanwhile, human logs a 95\% accuracy, which shows there is a long way to go for
this task. Those future models which can achieve great result on our proposed task, can further help to improve numerous web applications, including the filtering of implausible web queries, identification of meaningless concept in existing knowledge graph and etc.  


%\JQ{这里删掉了一段 和第三段重复}
%The commonsense reasoning task on our benchmark is challenging due to the following reasons. 
%Firstly, all the pairs are in the form of short phrases, 
%which is hard to understand with bare contextual information comparing to long sentences as we mentioned above. 
%Secondly, the model has to make use of commonsense knowledge in order to make the correct judgment. 
%For example, one phrase pair in CoCon dataset are ``cotten linen biscuit''(棉麻饼干) and ``whole wheat biscuit''(全麦饼干),
%The model is expected to understand that biscuit is one kind of food first, and then infer that its ingredient should be something humans can eat. 
%Furthermore, it needs to know that ``cotten linen can not be eaten but wheat can''. 
%By combining all the information above, the model can finally reach the correct answer. 


%However, for a human, the answer is direct as it has already became common sense.

%Our benchmark is challenging due to 1)The samples are all short phrases, which introduce several challenges of processing short text, makes the phrase itself harder to understand and more difficult to deal with. 2)The model should make use of its commonsense knowledge to give the correct judge. For example, for one phrase pair in our CoCon dataset "cotten linen biscuit"(棉麻饼干) and "whole wheat biscuit"(全麦饼干), model needs to first understand that biscuit is one kind of food, and then infer that its ingredient should be something that human can eat. It should further fetch from its knowledge storage that "cotten linen can not be eaten but graham can". Integrating all above information, the model can finally get the correct answer. However, for the human, the correct choice is direct as it has already became the commonsense. For another example "girl supplementary food"(女童辅食) and "baby supplementary food"(宝宝辅食), model should first have the knowledge that complementary food aims at little baby less than 2-year-old, and naturally infers that the girl is more unlikely to take it than the baby.

We summarize our contribution as follows:
%, our contributions are:
\begin{enumerate}
	\item We construct a new benchmark named CoCon using a novel method to generate short commonsense phrase pairs with limited annotation resources. The dataset is designed
	for evaluating %machine's commonsense in short phrase.
	the capability of commonsense reasoning for machines on short phrases.
	%\item We propose a novel method to generate short commonsense phrase pairs with limited annotation resources. \KZ{Negative sample generation is just one step in the whole
	%dataset construction framework. Why single it out here as a major contribution? Can this method be used for other more general tasks?}
	\item We conduct an empirical evaluation of state-of-the-art language models on CoCon dataset, showing that the performances of current models  are still lagging behind the human performance.
	\item We intend to release CoCon dataset, which can  benefit the research community %where efforts are devoted to enable machines 
	for developing better machines to understand commonsense knowledge.
\end{enumerate}

