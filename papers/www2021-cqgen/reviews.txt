# Review 1

Relevance to the Web Conference:	
-1: (Not relevant)
Something with question generation and the Web with e-commerce websites may possibly be relevant, but not this particular task (where there's no answer). Also, it takes as assumption there is no ontology, knowledge graph, or known keywords per product, but that's something that those sites do have (as the authors also note). Who doesn't have access to those, yet wants to service the user this way nonetheless? What websurfer has too much time and not read the page links, so as to type a question in a natural language sentence when a simple click to 'product info' or 'product details' will do? or, in this case: how clueless is the user wanting to type a question about something that's not in the product description and still get an answer on it, knowing full well that that information is clearly not in the system? or, if it were, conversely from the seller: why store features and hide that information? So, all in all, quite contrived.
There is indeed an example in section 1 that has to pass for use case scenario, but that's an unrealistic example. why would we even ask that?! products offered for a locale are for that locale and adhere to the specs for the locale. 220V is the standard. If one were to have been delivered a 110V, it is considered defective or deceitful, so a US merchant should not even want to try that in a 220V zone. And vice versa for 220V products in a 110V zone.

Overall evaluation:	
-1: (Weak reject)

Summary:	The paper proposes a new NLG task, being that of generating questions for online products for sale. It takes some techniques. they evaluate variants thereof and two others. their system outperforms the baseline on several measures.

Originality:	
2: (Conventional: Rather straightforward, a number of people could have come up with this)
this particular process is original. Still, it's of the variety "artificially generate problem, then offer a solution", and even within the solution it's mostly "the harvesting is messy and so the other steps aim to clean it up a bit".

Potential impact:	
1: (Low: Will likely have no impact)
There are better ways to generate question for products. Moreover, current e-commerce systems already have a better baseline than this work assumes. The authors have no access to that, and I can imagine that's unpleasant, but that then does not necessitate to devise a strategy to generate questions without a KG or to try to second-guess an idiot user who'd like to ask questions for which there's no answer.

Reproducibility:	
2: (Some but not all code, data or the details of the experimental setup are made available)
It's not reproducible.
algorithms, code, data (after the authors' preprocessing), results, all have not been made available.
Any description of the human evaluation is absent; among others: how was it done? who was recruited for this? how many people participated (just 1, since "We ask human to judge"?)? how many items/questions were evaluated? How is "diversity" measured? What about interannotator agreement, if considered at all?
"logicality"? probably semantics of the sentence is meant?
"grammaticality": syntax?
"Seeking New Information": how is that determined? any information that was not already in the description? but that was the whole point and a precondition, even, according to sect 3.4.1. ("Asking only about things not in the context is the basic requirement of CQGen.")

Quality of execution:	
2: (Poor: Potentially reasonable approach, but certain core claims lack justification)
Sections 2 and 3 are not fully clear to me. p2 says "We extract ground truth keywords and a keyword dictionary", but it doesn't say how or where that came from. There's some partially explained equation, but then only on p3 is a little more is explained about it. 'specificity' in section 2 seems to be is a vague observation. Local diversity remains underspecified. keyword filtering is done manually, but not explained how.

There's evidence of a systematic attempt in the evaluation, but certain details are missing (see above)

section 4 starts with three questions to answer, but the paper does not revert to them. Perhaps because they are not framed well. Q1 ("Can KPCNet generate more specific CQs?") is underspecified: more specific than *what*?
Since the diversity metric is lacking, Q3 is hard to answer. Also, I can't recall reading about the various ways to control the generation of KPCNet.
Quality of presentation:	
3: (Reasonable: Understandable to a large extent, but parts of the paper need more work)
Generally, it is well readable, with missing some details here and there (see afore-mentioned questions).
A better caption of fig2 would help; one that summarises what's going on in the figure. The start sentence of section 3 would fit better near Eq1.
Adequacy of citations:	
2: (Reasonable: Coverage of past work is acceptable, but a few papers are missing)
It being in a semantics track, it would make sense to throw in an ontology, KG, or even just WordNet or the like.

Ethics:	
1: (No)
I don't

Strengths:	The structure of the paper is good in principle and it is helpful that some more examples are given and some results of the sentences generated by the system.

Weaknesses:	The main weakness is that the actual problem is utterly unconvincing.
It's not clear where the initial keywords come from.
The human evaluation lack a proper description of how its done, including how the measures were determined.
The results are not overwhelmingly in favour of the authors' proposed system.

Reasons to accept:	
Reasons to reject:	problem/task unconvincing, major gaps in the description of the evaluation set-up
Rebuttal:	

# Review 2
Relevance to the Web Conference:	
1: (Relevant)
Overall evaluation:	
1: (Weak accept)
Summary:	The paper considers the task of question generation for filling missing information on e-commerce products. The authors propose the task of Diverse CQGen which requires generating a group of diverse clarification questions per context. They also propose a model named KCPNet which predicts relevant product keywords and uses them to generate the questions. Their model is based on sequence-to-sequence architecture. They perform an automatic and human evaluation for their model with different settings on 2 datasets. The results indicate that their model can generate more specific questions and promote better group-level diversity than 2 competing baselines.
Originality:	
2: (Conventional: Rather straightforward, a number of people could have come up with this)
Potential impact:	
3: (Broad: Could help ongoing research in a broader research community)
Reproducibility:	
2: (Some but not all code, data or the details of the experimental setup are made available)
Quality of execution:	
3: (Reasonable: Generally solid work, but certain claims could be justified better)
Quality of presentation:	
3: (Reasonable: Understandable to a large extent, but parts of the paper need more work)
Adequacy of citations:	
2: (Reasonable: Coverage of past work is acceptable, but a few papers are missing)
Ethics:	
1: (No)
No ethical concerns for this study.
Strengths:	* The authors propose and address a new task of Diverse CQs
* They also propose a model for the task and provide reasonable results
* The paper is well written (Experiments section provides a lot of details)
Weaknesses:	* Not sure whether the task itself can be considered as a contribution. Together with the model makes more sense. Also not convinced that the paper will emerge the community to work with the new task

* While the task of generating clarification questions is popular they only evaluate with 2 baseline models. Here they could include more baselines and some of them to be a bit more complicated (e.g. incorporating language models)
Reasons to accept:	
Reasons to reject:	
Rebuttal:	

# Review 3

Review 3
Relevance to the Web Conference:	
1: (Relevant)
Overall evaluation:	
2: (Accept)
Summary:	The paper presents an approach to generate clarification questions in an e-commerce platform to help merchants for listing their products. It is difficult for a merchant to understand the user needs and the specific question a user might have for a listed products, thus, clarification questions help merchants in providing useful details during product listing. The authors proposed a DNN based architecture named "Keyword Prediction and Conditioning Network (KPCNet)" that predicts the important keywords to generate the question around them. Interestingly, the proposed approach makes use of product attributes to identify keywords and optimize for a non overlapping question to address the diversity aspect.
The approach is evaluated on two different domain dataset home & kitchen (used in previous work) and Office products. Results show that the proposed approach generate better clarification questions.
Originality:	
2: (Conventional: Rather straightforward, a number of people could have come up with this)
Clarification question generation is a relatively new field. The approach presented in the paper is an extension in the field and addresses a specific scenario of generating diverse clarification questions.
Potential impact:	
3: (Broad: Could help ongoing research in a broader research community)
Reproducibility:	
2: (Some but not all code, data or the details of the experimental setup are made available)
Quality of execution:	
3: (Reasonable: Generally solid work, but certain claims could be justified better)
Quality of presentation:	
4: (Lucid: Very well written in every aspect, a pleasure to read, easy to follow)
Adequacy of citations:	
3: (Comprehensive: Can't think of any important paper that is missed)
Ethics:	
1: (No)
No
Strengths:	The paper proposed an interesting solution of generating clarification questions using keywords through product attributes and the proposed approach addresses a real world problem of helping merchants in attributing important details around the listed product.
Weaknesses:	Although, it addresses a real world problem but the scope of proposed solution is somewhat limited to specific scenario of an e-commerce platform to help merchants in product listing.
Reasons to accept:	
Reasons to reject:	
Rebuttal:	

