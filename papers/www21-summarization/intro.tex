\section{Introduction}
\label{sec:intro}

Abstractive summarization is the task of creating a short, accurate,
and informative summary from a long text document
without using the exact sentences from the source.
%which can summarize the web page on a search engine results page.
This is useful in generating a snippet or digest for a searched web page or
other web text.
The essence of summarization is to compress information from the input
document and retain only most important information in the output.
This process can be seen as {\em aligning} the salient information
from the source to the output.
Recently, encoder-decoder (enc-dec) 
models with attention mechanism~\cite{NallapatiZSGX16,SeeLM17,Joint18,CelikyilmazBHC18,UniLM19,AbsSnippet20}
have made great progress on abstractive summarization.
The attention mechanism is a way of capturing the \textit{alignment}
between input sequences of the encoder and decoder, trying to tell 
which parts of the source document are relevant to which parts in the summary.
%The alignment in abstractive summarization identifies 
%which parts of the source document are relevant to each token in the summary.
However, since lots of non-essential parts in the source document are 
omitted in the summary, the alignment using only attention mechanism is 
unsatisfactory.  \tabref{tab:example} shows that two state-of-the-art 
enc-dec models, 
i.e., PointGen~\cite{SeeLM17} and BART~\cite{BART19}, both frequently make 
incorrect alignments by either missing some salient parts or including 
redundancies.
%(underlined)
%\footnote{The bold words or phrases in \tabref{tab:example} and \tabref{tab:data} are keywords of reference summary.}. 

\begin{table}[th]
\begin{center}
\small
\begin{tabular}{|p{7.5cm}|}
\hline \bf Source document \\
\hline new delhi, india police have arrested four employees. federal \textbf{education} 
       \textbf{minister} smriti irani was visiting a \textbf{fabindia} outlet in the tourist resort 
	   state of goa on friday when she discovered a surveillance \textbf{camera} pointed
	   at the store 's \textbf{changing room}. four employees of the store have been 
	   arrested, but its manager was still at large saturday . state \textbf{authorities} 
	   found an overhead camera that the minister had spotted and determined 
	   that it was indeed able to take \textbf{photos} of customers. authorities sealed
	   off the store and summoned six top officials from fabindia. the \textbf{arrested} 
	   staff have been charged with voyeurism and breach of privacy. 
	   if \textbf{convicted}, they could spend up to \text{three years} in jail . \\
\hline \bf Reference summary \\
\hline federal \textbf{education minister} smriti irani visited a \textbf{fabindia} store in goa ,
       saw \textbf{cameras}. \textbf{authoroities} discovered the \textbf{cameras} could capture 
	   \textbf{photos} from the store 's \textbf{changing room}. the four store workers 
	   \textbf{arrested} could spend \textbf{three years} each in prison if \textbf{convicted} . \\
\hline \bf PointGen \cite{SeeLM17} \\
\hline four employees of a popular indian ethnic chain have been arrested, 
       but its \underline{manager was still at large} . authorities \underline{sealed off the store} 
	   and \underline{summoned six top officials from fabindia.} \vspace*{0.8mm} \\ 
\hline \bf BART \cite{BART19} \\
\hline federal education minister smriti irani was visiting a fabindia outlet in 
       the tourist resort state of goa . she discovered a surveillance camera 
	   pointed at the changing room . four employees of the store have been 
	   arrested , but \underline{the manager is still at large} . the arrested staff have been 
	   \underline{charged with voyeurism and breach of privacy} \vspace*{0.8mm} \\
\cut{%%%%%%%%%%%
\hline \bf Pretrained Ext (ours) \\
\hline \textit{Set 1.} he 's a blue chip college basketball recruit . trey -- a star on \\
       eastern high school 's basketball team in louisville , kentucky , who 's headed to \\
	   play college ball next year at ball state -- was originally going to take his \\
	   girlfriend to eastern 's prom .\\
	   \textit{Set 2.}: trina helson , a teacher at eastern , alerted the school 's newspaper \\
	   staff to the prom-posal and posted photos of trey and ellie on twitter\\
	   that have gone viral . \\
\hline \bf Pretrained Ext+RL (ours) \\
\hline \textit{Set 1.} federal education minister smriti irani was visiting a fabindia \\
       outlet in the tourist resort state of goa on friday when she discovered \\
	   a surveillance camera pointed at the changing room . state authorities \\
	   launched their investigation right after irani levied her accusation .\\
	   \textit{Set 2.}: four employees of the store have been arrested. \textit{[3]if convicted,} \\
	   \textit{they could spend up to three years in jail.} \\
\hline \bf Ext+Abs+RL (ours) \\
}%%%%%%%%%%%%%
\hline
\end{tabular}
\end{center}
\caption{Summarization results by SOTA models (PointGen and
BART). 
%The incorrectly aligned sentences are \underline{underlined}. 
The \textbf{bold} words or phrases are salient information. 
The underlined parts are redundant information in the output.
Some salient information is also missing from the output.
%The three sentences in source document that most similar to the three sentences
%in the reference (by ROUGE score) are italicized.
}\label{tab:example}  
\end{table}

An alternate view~\cite{FastAbs18, summlevel19} of the summarization process is to
%consider summarization as 
paraphrase the \textit{salient parts} in the source document, i.e.,
summary sentences are aligned to the \textit{salient parts} of source document
(see \tabref{tab:example}).
This gives rise to a two-stage, extractor-abstractor (ext-abs) framework,
which first selects salient sentences from the source
(extractor) and then 
paraphrases the selected ones to generate a summary (abstractor). 
The ext-abs framework has two advantages: i) the input and output
of the abstractor can be better aligned;
ii) reduced size of the input to the abstractor reduces both training and
inference time.
%For ext-abs framework, \KZ{First time using this term: the pseudo extractive 
%reference summaries}
%The ext-abs model requires the intermediate results (the salient sentences) as the training
%data for both the extractor module and the abstractor module.

To train an ext-abs framework, one has first to generate the intermediate
results, i.e., the salient sentences in the input document for all
training samples. 
Since the real salient sentences are not known in practice, we call 
the intermediate result obtained algorithmically the {\em pseudo summary}. 
Pseudo summaries are used for training both the extractor and the abstractor
in the ext-abs framework. 
As the intermediate result, the low-quality pseudo summaries can   
bring noises to the model.
%play an important role as the output of extractor and the input of abstractor during training time.
Better pseudo summaries can reduce the noise and enhance the alignment between 
encoder and decoder of abstractor.
Previously, there are two types of heuristics to create pseudo summaries: 
sentence-level~\cite{FastAbs18}  and summary-level methods~\cite{NallapatiAAAI17, SharmaHHW19}.

%\KZ{To illustrate the sentence-level, summary-level and set level,
%I guess showing a picture with example is easier to understand? I'm not sure
%using words like you do now is the most effective.}
Sentence-level methods assume that there is 
one unique salient sentence in the source that matches each sentence
in the reference summary. To this end,
they extract the sentence with the highest ROUGE score~\cite{rouge}  
for each reference sentence. This simple assumption gives rise to
the design of parallel abstractors (one for each reference sentence)
to achieve speed-up.
%ROUGE score measures the similarity between two sentences in terms of shared
%N-grams. 
However, the very nature of summarization dictates that a sentence in the
summary may be condensed from multiple sentences in the source and not just one.
For example, in \tabref{tab:align_exp}, the first sentence in 
sentence-level pseudo summary is pertinent to both $1^{st}$ and $2^{nd}$ 
reference sentences in \tabref{tab:example}, while the second pseudo sentence 
misses out some information (``changing room'') of $2^{nd}$ reference 
sentence.
In response to this deficiency, summary-level 
methods
were proposed to select the best combination of a subset of input sentences
that maximizes ROUGE score with reference summary as a whole.
Nevertheless, they lose the advantage of parallelism in the sentence-level approach.
Worse still, when mixing all the sentences together, they treat every token
equally in computing the ROUGE, resulting in pseudo summaries that are similar
to the reference only by unimportant words. 
For example, The summary-level pseudo summary in \tabref{tab:align_exp} doesn't
match the information about ``authorities'' and ``arrested'', which are
more important in the story.

\begin{table}[th]
	\begin{center}
		\small
		\begin{tabular}{|l|}%{|p{7cm}|rl|}
			\hline \bf Sentence-level \\
			\hline \textit{1)} federal education minister smriti irani was visiting a fabindia \\
			outlet in the tourist resort state of goa on friday when she discovered \\
			a surveillance camera pointed at the store's changing room. \\ 
			\textit{2)} state authorities found an overhead camera that the minister had spot\\
			-ted and determined that it was indeed able to take photos of customers. \\
			\textit{3)} if convicted, they could spend up to three years in jail. \\
			\hline \bf Summary-level \\
			\hline federal education minister smriti irani was visiting a fabindia outlet in \\
			the tourist resort state of goa on friday when she discovered a \\
			surveillanc camera pointed at the store's changing room. if convicted,  \\
			they could spend up to three years in jail. \\
			\hline \bf Set-level based on Keywords\\
			\hline \textit{Set 1)} federal \textbf{education minister} smriti irani was visiting a \textbf{fabindia} \\
			outlet in the tourist resort state of goa on friday when she discovered \\
			a surveillance \textbf{camera} pointed at the \textbf{changing room}. state \textbf{authorities} \\ 
			found an overhead \textbf{camera} that the minister had spotted and determined \\
			that it was indeed able to take \textbf{photos} of customers. \\
			\textit{Set 2)} four employees of the store have been \textbf{arrested}. if \textbf{convicted}, \\
			they could spend up to \textbf{three years} in jail. \\
			\hline
		\end{tabular}
	\end{center}
	\caption{\label{tab:align_exp} The pseudo summaries produced by different heuristics for the source and reference in \tabref{tab:example}.}
\end{table}

In this paper, we present a novel set-level matching heuristics
that divides the reference summary into a few disjoint clusters of sentences, 
each of which represents a topic or an aspect, and matches a non-overlapping
set of sentences in the source with each cluster of reference sentences.
This new heuristics strives to trade off the pros and cons of
the previous two approaches. Instead of assuming one-to-one or all-to-all
alignment between the pseudo summary and the reference summary,
we are assuming a many-to-many alignment, which allows for more flexible
alignment while still achieving parallelism using multiple abstractors. 
When computing the similarity between the pseudo summary and the reference,
on top of ordinary ROUGE scores, we emphasize keywords in
the reference summary. This amounts to representing summaries not only as a
sequence of words but also as a set of important keywords.
Accordingly, we design a keyword-aware extractor
which includes both an ordinary document encoder and a keyword encoder. 

%%\KZ{Shall we call this a heuristics or a heuristics or a procedure?}
%On the one hand, we select the best combination of document sentences (multi-sentence set) 
%that maximizes ROUGE scores for each reference sentence. 
%On the other hand, we put an eye on the keywords and 
%maximized the number of covered keywords during selection. 
%If the adjacent multi-sentence sets overlap, 
%we merge them and their corresponding reference sentences.
%%More details will be explained in Section *. 
%In this way, we solve the problem of  matching ability and information loss at the same time.
%%\fbox{
%\parbox{0.9\columnwidth}{
%\small{
%\textit{Set 1.} federal \textbf{education minister} smriti irani visited a \textbf{fabindia} store 
%in goa , saw \textbf{cameras} . \textbf{authoroities} discovered the \textbf{cameras} could capture 
%\textbf{photos} rom the store 's \textbf{changing room}. \\
%\textit{Set 2.} the four store workers \textbf{arrested} could spend \textbf{three years}
%each in prison if \textbf{convicted} . 
%}}}

%Recent study~\cite{ZhongLWQH19}
%demonstrates that extractive summarization models and abstractive summarization models 
%can benefit from pretrained language models (LMs)
%, such as BERT and BART. 
%We therefore apply pretrained LMs to ext-abs framework.
%As shown \tabref{tab:align_exp}, keywords are helpful in extracting salient information.
%Thus, we propose the keyword-based extractor. It includes
%a dual encoder consisting of keywords encoder and document encoder
%(HIBERT~\cite{HiBert19})
%to leverage keyword guidance to reduce information loss during salient sentences selection.
%As our set-level pseudo summaries become sequence of multi-sentence sets, 
%the existing extractive models, which extract sequence of sentences, are not suitable. 
%we present an aligned pointer decoder for the extractor.
%%using a $<$SEP$>$ to indicate the set boundaries.
%For abstractor, we fine-tune on the BART~\cite{BART19}, 
%a pretrained model for natural language generation. 
%The sets in a pseudo summary will be encoded and decoded in parallel, 
%which avoids the inaccurate encoding of very long documents and 
%largely increased the speed with less required memory.
%
One natural way to connect the extractor and abstractor into an 
end-to-end trainable model is to use reinforcement learning (RL). 
Previous ext-abs models use sentence-level~\cite{FastAbs18}
or summary-level~\cite{summlevel19} ROUGE scores as the reward.
The sentence-level rewards can not properly reflect the quality of 
overall summary because of overlapping contents~\cite{NarayanCL18,summlevel19},
while summary-level rewards ignore the accuracy of the sentences extracted 
at each step.
Therefore, we propose a comprehensive reward 
which is the weighted sum of sentence/set/summary-level ROUGE scores.
This comprehensive reward can help the extractor select sentences 
that match abstractive reference summaries better.

%As our pseudo summaries become sequence of multi-sentence sets, the existing extractors 
%\cite{FastAbs18, zhangLatent18, SharmaHHW19} 
%are not suitable for our training data.
%We take pointer network as our extractor and
%append a shared special placeholder $<$SEP$>$ 
%between any two consecutive multi-sentence sets of our 
%pseudo summary.
%%Our pseudo summaries are extracted based on keywords.
%%which can guide the generation of summaries~\cite{KeyGuid18}.
%We propose keywords encoder into the pointer network to
%encourage model to select salience sentences corresponding to reference.
%%enhancing salience sentences selection.
%We train our extractor with combinational loss. 
%%including sentence-level loss, set-level loss and keywords loss.
%%The sentence-level loss and keyword loss denote
%%the similarity between the generated representation and corresponding ground truth.
%%The set-level loss means the similarity between the multi-sentence sets
%%in extracted and new reference summary at same ranking.

%As we known, the abstractor based on enc-dec model 
%%\cite{RushCW15,ChopraAR16,SeeLM17,GehrmannDR18,LiuLZ18,KourisAS19}
%always suffer from slow and inaccurate encoding of very
%long documents because of the attention mechanism 
%looking at all encoded words for generating word one by one sequentially. 
%Our pseudo summaries, which is the input of abstractor, is shorter than source document
%and more aligned to the reference summaries.
%The multi-sentence sets in one pseudo summary can be decoded in parallel.


%The extractor and abstractor are independent of each other.
%In order to make ext-abs an end-to-end trainable model,
%we connect the extractor and abstrctor together by reinforcement learning (RL).
%This approach can encourage the model to select more accurate sentences. 
%with weighted sum of sentence-level rewards, set-level rewards, summary-level rewards and keywords rewards.
%In general, the RL used in ext-abs framework took 
%sentence-level ROUGE scores~\cite{FastAbs18} 
%and summary-level~\cite{summlevel19} ROUGE scores as a reinforcement
%learning rewards and the final performance summarization.
%Narayan et al.~\shortcite{NarayanCL18} and Bae et al.~\shortcite{summlevel19}
%shows that sentences with the highest individual ROUGE scores 
%do not lead to an optimal summary because of overlapping contents.
%Thus, we take the weigthed sum of sentence/set/summary-level
%ROUGE scores and keywords coverage as a reward, which help extractor select
%sentences that match abstractive reference summaries better.


%Recent study~\cite{ZhongLWQH19}
%demonstrates that extractive summarization models and abstractive summarizaton models 
%can benefit from pretrained language models (LMs), such as BERT and BART. 
%The pretrained LMs incorporate external knowledge 
%and learning schemas to introduce extra instructive %constraints
%\cite{Bert19, GPT18, UniLM19, BART19},
%which make the word or sentence representation more correct.
%HIBERT~\cite{HiBert19} is a pretrained model for extractive summarization
%consisting of two pretraining stage.
%The first stage is the open-domain pretraining 
%and second stage is the in-domain pretraining on the CNN/Daily Mail dataset.
%BART~\cite{BART19} is a pretrained model for natural language generation,
%which takes BERT~\cite{Bert19} as encoder and GPT~\cite{GPT18} as decoder.
%We fine-tune our extractor and abstractor on HIBERT and BART respectively.

In summary, our contributions are as follows:
\begin{enumerate}
%\item We present a novel set-level matching heuristics based on keywords 
%to extract pseudo summaries as training dataset for extractor and abstractor,
%which enhances the alignment of enc-dec model.
\item Our \textbf{set-level} matching heuristics extracts better 
pseudo summaries as the training data to pretrain both the extractor 
and the abstractor, and subsequently allows the abstractor 
to learn the alignments effectively. (See \secref{sec:preprocess},
\secref{sec:evpseudo})
\item The use of \textbf{keywords} to represent salient concepts and 
entities in documents and summaries provides a significant boost 
in the ext-abs framework. 
(See \secref{sec:ke}, \secref{sec:abs}, \secref{sec:results})
%, which is flexible with respect to the choice of document encoder and abstractor.
%and connect the extractor to abstractor 
%\item We successfully apply the pretrained models and 
%design a comprehensive RL to keyword-aware ext-abs framework.
\item The integration of pretrained language models into a comprehensively
rewarded RL gives a potent end-to-end summarization framework that
outperforms the state-of-the-art (SOTA) methods on 
popular abstractive summarization datasets including CNN/Daily Mail, Webis-TLDR-17, Webis-Snippet-20, 
WikiHow and DUC-2002.(See \secref{sec:results})
\end{enumerate}
