\section{Introduction}
Informational bias broadly exists in news articles. As a sort of framing bias, it always frames a certain entity by specific aspects using narrow, speculative or indicative information  to guide a particular interpretation, thus swaying readers' opinion. 

For most of us, news articles, especially online news articles are the main source of information. Therefore, they play a central role in shaping individual and public opinions. However, news reports often show internal bias. The current research is often limited to the lexical bias. This form of bias rarely depends on the context of the sentence. It can be eliminated by deleting or replacing a small number of biased words. Contrarily, researchers \citet{fan-etal-2019-plain} found that the informational bias is more common and more difficult to detect.
% among which informational bias is found to be one of the most common and difficult to detect.

Different from other types of bias, the sentence-level informational bias detection largely depends on the context and this fact makes the task very challenging. A sentence alone can be expressed in a neutral manner, but it might be revealed as biased in consideration of the context. Take the second row in Table \ref{tab:basil} as example: the sentence \textit{``Mr. Mattis, a retired four-star Marine general, was rebuffed.''} \label{sent:mattis} seems to be a very simple declarative sentence stating a fact. However, if we read the previous sentence \textit{``Officials said Mr. Mattis went to the White House with his resignation letter already written, but nonetheless made a last attempt at persuading the president to reverse his decision about Syria, which Mr. Trump announced on Wednesday over the objections of his senior advisers.''} (the first row in Table \ref{tab:basil}) , we will know that \textit{`a retired four-star Marine general'} indicates a negative, even ironic tone towards Mr. Mattis and his last attempt. Therefore, sentence-level informational bias can only be revealed by collecting information from various sources and analyzing the entire article together with its background. Such subtleties of informational bias are more likely to affect unsuspecting readers, which indicates the necessity of research into new detection methods. 

In this paper, we propose MultiCTX (Multi-level ConTeXt), a model composed of contrastive learning and sentence graph attention networks to encode three different levels of context:  \textbf{1) Neighborhood-context}: adjacent sentences, i.e. sentences in the same article around the target sentence; \textbf{2) Article-context}: the whole article containing the target sentence; \textbf{3) Event-context}: articles from various news media reporting the same event. These three levels encompass the contextual information from the most local to the most global.

In order to make use of the context rather than be overwhelmed by the noise introduced, MultiCTX prioritizes contrastive learning which learns sentence embedings via discriminating among $(target, positive$ $sample, negative$ $sample)$ triplets to distill the essence of the target sentence. The quality of the learned CSE (Contrastive Sentence Embedding) relies on that of triplets. Other than the traditional brute-force way to select triplets only based on their labels, MultiCTX further considers article-level information which creates higher-quality triplets. Such triplet formulation guarantees that our CSEs infuse the context and reflect sentences' inherent semantics instead of the shallow lexical features. 

% Work by \citet{baly-etal-2020-detect} used triplet loss instead of contrastive learning,
% directly within batch 
% Given a dataset of 0/1-labeled sentences, MultiCTX first construct tactically triplets from them. 

MultiCTX then builds a relational sentence graph using CSEs. Edges are connected between two sentences if they are logically related in the same \textit{neighborhood} or if they are continuous in entities or semantically similar within the same \textit{event}. Finally we apply a Self-supervised Graph Attention Network (SSGAT) on our sentence graph to make the final informational bias prediction. The SSGAT structure encodes neighborhood-level and event-level context via edges, making it possible for textually distant but contextually close sentences to connect directly. The flexible graph structure extends beyond the sequential arrangement of traditional LSTMs, which also consider the surrounding context. 

Although document graphs are not rare in NLP tasks, they are often short and built by token-wise dependency parsing. It may suffer from high complexity and considerable noise when applied on long texts which is our case with news articles. Our relational sentence graph uses sentence nodes and focuses on inter-sentence relationships. It recquires only minimal syntax parsing, takes on less noise and has better interpretability.


Few research studies sentence-level informational bias detection by infusing context. \citet{fan-etal-2019-plain} first published a human-annotated dataset on this task, taking the context into account during annotation. However, sentences are still treated sentences individually in their model. \citet{van-den-berg-markert-2020-context} did a primary research on incorporating different levels of context in the informational bias detection. However, they consider only one kind of context in each model. To our best knowledge, our model is the first to incorporate multi-level contextual information in sentence-level classification task.
%  and their results are still not very satisfactory even compared to our ablation models using only one level of context as well

In summary, we present the following contributions:

\begin{itemize}
  \item We are the first to incorporate three different levels of context together in the sentence-level bias detection task. 
  \item We propose a novel triplet formation for contrastive learning in bias detection. The methodology can be generalized for other tasks.
  \item We are the first to use a sentence graph to encode the textual context information in the bias detection task.
  \item Our model MultiCTX significantly outperforms the current state-of-the-art model by 2 percentage points F1 score. It indicates that contextual information effectively helps sentence-level informational bias detection and our model successfully infuses multi-level context.
\end{itemize}