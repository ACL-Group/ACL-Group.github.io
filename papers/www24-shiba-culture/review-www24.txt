Official Review of Submission719 by Reviewer aAEw
Official ReviewReviewer aAEw29 Nov 2023, 06:21 (modified: 02 Dec 2023, 14:26)Program Chairs, Senior Area Chairs, Area Chairs, Reviewers Submitted, Reviewer aAEw, AuthorsRevisions
Review:
This paper studies the influence of language environment and host's vocal patterns and dogs' barking sound. They source a large number of video clips that contain host and dog sound from both English and Japanese hosts from YouTube, then extract the host and dog sound clips using a pretrained sound event detection model. For each pair of host and dog sound clip, additional contexts such as location, activity are also provided. They leverage this dataset to mainly answer two questions: 1. Whether the dog sound hear differently under different language environments? 2. Is their vocalization related to their host’s language? To answer the first question, they build a pairwise classifier to infer the languages from each pair of sound clip. The classification accuracies are all beyond 90%, which is clearly higher than random guess (25%), suggesting that there's a clear distinction of the dog vocalization in different languages. For the second question, they did some feature importance study and correlation analysis to understand the association between host vocalization and dog vocalization. Their results show that dog vocals from two host language environments have distinctive differences in their energy distribution over frequency. In quantitative analysis, vocals from the Japanese language environment have a higher frequency than those from English.

Pros:

A novel and interesting question is under-explored.
A large open-sourced datasets that contain human and dog sound.
The experiments clearly answered the two research questions, providing inspirations of how dog's vocalization is influenced with different hosts and languages.
Cons:

Not sure how much relevant this paper is to WebConf.
The technical content part is straightforward, not contributing new technical insights or novelties.
Questions:
n/a

Ethics Review Flag: No
Ethics Review Description: n/a
Scope: 2: The connection to the Web is incidental, e.g., use of Web data or API
Novelty: 3
Technical Quality: 3
Reviewer Confidence: 3: The reviewer is confident but not certain that the evaluation is correct
Add:
Official Review of Submission719 by Reviewer X18g
Official ReviewReviewer X18g27 Nov 2023, 01:53 (modified: 02 Dec 2023, 14:26)Program Chairs, Senior Area Chairs, Area Chairs, Reviewers Submitted, Reviewer X18g, AuthorsRevisions
Review:
This study releases a dataset of Shiba Inu sound clips collected from YouTube to analyze the impact of dog vocalization and its owner's language. The sound clips include information about the situations and the owners' language. Through classification experiments on this collected dataset, the study analyzes the correlation between a dog's vocalization patterns and its owner's language.

Pros:

This study addresses a novel and intriguing research topic by exploring the correlation between a dog's vocalization and its owner's language.
It introduces a new audio clip dataset specifically designed for this research.
The study provides analysis and discussion points regarding the correlation between a dog's vocalization and its owner's language.
Cons:

The study might attract less attention from the target audience at conferences. Considering that this research focuses on analyzing the language used by dogs and their owners rather than web data mining, it might be more suitable for venues like ICASSP that specialize in such research.
As mentioned in the limitations of the study, it only provides data and analysis for a specific breed of dog and two languages, Japanese and English. To draw more general conclusions, it would be appropriate to conduct research on a more diverse set of dog breeds and owner languages.
Questions:
How can these datasets and research results ultimately be meaningfully applied? Describing this aspect would likely enhance the research's academic impact.

Ethics Review Flag: No
Scope: 2: The connection to the Web is incidental, e.g., use of Web data or API
Novelty: 3
Technical Quality: 3
Reviewer Confidence: 3: The reviewer is confident but not certain that the evaluation is correct
Add:
Official Review of Submission719 by Reviewer eBzn
Official ReviewReviewer eBzn27 Nov 2023, 01:15 (modified: 02 Dec 2023, 14:26)Program Chairs, Senior Area Chairs, Area Chairs, Reviewers Submitted, Reviewer eBzn, AuthorsRevisions
Review:
This paper investigates the correlation between the sound of a dog and its owner (Host). They first created a dataset called EJShibaVoice. They downloaded videos from YouTube where the host's language is English or Japanese, and first tagged the language. For the extraction of dog vocalization, they performed the following three steps:

Collection of "sentences" classified as barking by PANN (audio classifier).
Segments detected with speech or music along with barking were considered noise and removed.
Segments have short pauses in between, and to remove these pauses, a fine-tuned model that outputs the start time and end time was used for precise creation. The singular vocalization from the start time to the end time is referred to as a "word".
In the metadata (scene, location, activity), the scene is provided from dog activity classification, the location is created from Inception-ResNet V2's video frame classification, and the Activity is stored in the form of embedding by averaging the output embedding of the VQA model.

In the host's audio, noise detected as music was eliminated, and a model for speaker separation was also used. Subsequently, they demonstrate that the sound of a dog differs in English and Japanese environments, and they reveal how the sound differs using Shapley value and Pearson Correlation.

Strength

Tackles an interesting hypothesis (dogs of the same breed bark differently in different countries)

Proposes a pipeline for creating a fine-grained sound dataset from YouTube videos containing various sounds.

Weakness

The dataset only supports English and Japanese, and because it only contains the sound of Shiba dogs, it can be difficult for popular use and may lead to biased results.

The novelty is very lacking. They presented sufficient methods to show that dogs of the same breed bark differently in different countries, but it's a problem that anyone can think of and solve.

The problem addressed in this paper seems to have little potential for development as future work.

Questions:
The blue bars on either side of the labels in Figure 2 are difficult to understand.

How does detecting the start time and end time help in removing the pause segment? Do they eliminate the parts detected as pause segments?

In 4.2.1 (6page) In the meantime ~ line, vocalsvocals → vocals.

It is not known whether (a) and (b) in Figure 6 are English or Japanese. The y-axis unit (second) needs to be noted in Figure 7.

What is the word 'ofits' in the first line of the second paragraph in 2.1?

There might be a problem with the accuracy of the deep learning model, is there any evidence to trust and use it?

The grammar of the 345th line is strange. Curious if it is correct to remove those tagged as music from those tagged as speech.

Ethics Review Flag: No
Ethics Review Description: N/A
Scope: 1: The work is irrelevant to the Web
Novelty: 1
Technical Quality: 3
Reviewer Confidence: 3: The reviewer is confident but not certain that the evaluation is correct
Add:
Official Review of Submission719 by Reviewer wJfD
Official ReviewReviewer wJfD15 Nov 2023, 12:00 (modified: 02 Dec 2023, 14:26)Program Chairs, Senior Area Chairs, Area Chairs, Reviewers Submitted, Reviewer wJfD, AuthorsRevisions
Review:
The paper “Does My Dog "Speak" Like Me? The Acoustic Correlation between Pet Dogs and Their Human Owners” curates a dataset and discusses a method for detecting correlations between dog vocalizations and the language of the household where they reside.

This is an interesting paper from a technical point of view though I have a hard time seeing this as a useful use case to explore. I think that substantial additional motivation for the use case would be needed in the introduction.

The dataset curation and interesting and thorough, though it probably results in pretty noisy data - there may be additional features that impact the dogs vocalizations outside of the language spoken in the household, including tone of voice and cultural norms. Still, based on the results, it seems the annotation categories work pretty well.

Shapley values need to be defined (mentioned on line 471 among other places) more explicitly

There needs to be a bit more insight into the audio features (Table 3) - currently there is just a list of acronyms without much motivation for why these are useful/chosen.

“SHAP” on line 519 has not been defined explicitly.

Section 4.4. refers to human evaluation. I have a hard time believing that the annotators were able to perform audio annotations in a consistent way. There is no discussion of agreement between multiple annotators.

Questions:
This is an interesting paper from a technical point of view though I have a hard time seeing this as a useful use case to explore. I think that substantial additional motivation for the use case would be needed in the introduction.

Ethics Review Flag: No
Ethics Review Description: none
Scope: 2: The connection to the Web is incidental, e.g., use of Web data or API
Novelty: 2
Technical Quality: 2
Reviewer Confidence: 3: The reviewer is confident but not certain that the evaluation is correct
