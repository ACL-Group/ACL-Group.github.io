\section{Survey of Answer Ranking}

% answer ranking

Community Question Answering (CQA), which is a special kind of Question Answering (QA) service, enables users to ask questions and answer the questions posted by other users. Usually users also vote and comment on other users' answers. With the increasing popularity of CQA portals such as Baidu Zhidao and Zhihu, huge quantity of user-generated content (UGC) are accumulated, in the form of question-answer pairs (QA pairs). Many questions could be solved by simply querying those user-generated QA pairs, as people tend to have similar questions in their daily lives. However, most of the time there will be multiple answers to the same question, and the quality of the answers varies. To make it more efficient for users to retrieve the information they want, the system should be able to assess answer quality automatically, and try to deliver the best one.

The goal of ranking candidate answers in terms of their quality is a challenging task. Most methods view the problem as a classification problem, addressing it through exploring a rich set of features and employing machine learning techniques. The features could be divided into two groups: textual features such as n-grams, semantic parsing, average sentence length, lexical overlap with the question, punctuation density, and non-textual features such as meta-data of answers like number of votes received, or relationship between users.

Non-textual features prove to be very effective for answer quality prediction. Jeon et al.~\shortcite{jeon2006framework} proposed a framework to predict the quality of answers incorporating non-textual features into a maximum entropy model. Agichtein et al.~\shortcite{agichtein2008finding} extracted a large set of non-textual features and predicted answer quality in Yahoo ! Answers with stochastic gradient boosted trees. In this work, the interactions between users around the questions and answers are modeled by a tri-partite graph, and each feature corresponds with a path in certain subgraph around the focus question/answer/user. To further enhance performance, Agichtein et al.~\shortcite{agichtein2008finding} and Bian et al.~\shortcite{bian2009learning} combined both structure and community features to predict answer quality. Liu et al.~\shortcite{liu2015predicting} proposed a random subspace split-based co-training (RSS-CoT) method together with a content and social-based co-training (CS-CoT) method to leverage surface linguistic features and social features, and reduce the effort for producing labeled examples.

Some relevant works focus on answerers instead of answers directly. These works aim to find the expert or authoritative users in certain topic and identify users with same interests. Jurczyk and Agichtein~\shortcite{jurczyk2007discovering} experimented with using link analysis to discover authorities in question answering communities. Common link analysis algorithms such as PageRank~\cite{page1999pagerank} and HITS~\cite{kleinberg1999authoritative} are widely adapted. Shah and Pomerantz~\shortcite{shah2010evaluating} exploited users' profiles as the major part of features for answer quality classification. The users' profiles include number of questions asked, number of those questions resolved, number of questions answered, number of those answers chosen as the best answers, level achieved in Yahoo ! Answer (1 to 7), number of points earned, and number of stars received, for both the asker and answerer.

There are relatively fewer works which focus on textual features. Wang et al.~\shortcite{wang2010modeling} proposed a deep belief network (DBN) based on a QA reconstruct and joint distribution, and translated the discovery of high-quality answers into semantic computing of QA pairs. Toba et at.~\shortcite{toba2014discovering} proposed a hierarchy of classifiers framework which only makes use of textual features. The authors conjectured that different types of questions require different styles of answers, so their model tries to analyze the content of question to guide the selection of a right model for answer quality prediction. The results showed that the use of intrinsic features alone could achieve comparable performance to systems that utilizes meta-data.

% cite
