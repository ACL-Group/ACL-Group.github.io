\section{Related Work}

%\KZ{First discuss AAAI 2012 and EMNLP 2015, their pros and cons and how
%we stack up with them. Then discuss other less similar work. Finally
%applications that can benefit from this work, eg. QA, etc.}
% introduce AAAI2012, analyze pros and cons
%is based on such a procedure called ontology mapping. Given a user-specified relation along with its labeled instances, ontology mapping actually generates several complex SQL expressions over types and relations on the KB's schema. This procedure is quite difficult since the space of possible SQL views can be extremely large. In order to reduce the search space and select the best views, the authors first generates several constraints (hard rules) described in Markov Logic. This step actually is the a procedure to generate simple candidates schemas. Then, the probability of mappings is described using Markov logic Network after adding different rules into the network. Through weight training and relaxing the optimization problem to a linear problem, those candidate schemas with a high probability form to the mapping result. This work is able to show a set of best schemas for a target relation. However, the authors add several hand-crafted soft rules to Markov Logic Network which limits the dimension of feature space. Besides, the complex SQL views can actually be transformed to simple schemas (paths) which can not be able to handle complex relations in natural language form.
% introduce emnlp 2015 SFE


%Previous work~\cite{zhang2012ontological,gardner2015efficient,gardner2014incorporating,lao2011random} has attempted to map a relation to 
%background KB skeletons. 
%The goal of these works is to complete the imperfectly extracted KB 
%\textit{NELL} \cite{carlson2010toward} by predicting all concept $b$ 
%which potentially have the relation $R(a, b)$ given a concept $a$. 


%However, all of the above work only 
%considers the simple path representations. 
%In contrast, our approach adopts complex schema 
%with constraints, which can describe more sophisticated NL relations. 
%Moreover, when solving KB completion problem, we use only schemas
%of NL relations as features, whereas previous work use many other
%features.

Knowledge base completion is an open research question 
\cite{gardner2014incorporating,lao2011random,gardner2015efficient}
since knowledge bases are far from complete.
These systems aim to complete the imperfectly extracted KB by predicting all entities $e_2$
which potentially have the target relation $rel(e_1, e_2)$ given the input $e_1$. 
Lao et al. \shortcite{lao2011random} proposed Path Ranking Algorithm (PRA),
which used a random walk path finding algorithm to infer new relation instances by 
mapping the target KB relation into a path of several basic relations.
The state-of-art system \cite{gardner2015efficient} 
examined the disadvantage of PRA and proposed a technique called subgraph feature extraction (SFE). 
It first runs local search to characterize the subgraph around each input entity in KB.
Then SFE runs a set of feature extractors over these subgraphs to retrieve
structural and semantic features for each candidate node. 
SFE outperforms other KB completion methods as it used more advanced features.

In traditional KBC tasks, the target relation is an existing predicate in the KB, 
while we extend the definition of KBC into a broader scenario, since one may wish to add
a new predicate (derived from natural language) into existing KB, and the Open IE system
can help provide seed relation instance for further enrichment.
In terms of mapping NL relation into KB, Zou et al.~\shortcite{zou2014natural} proposed an unsupervised algorithm to
figure out the mapping confidence of predicate paths to one relation.
%The algorithm adopted the idea of tf-idf, which combines entity pairs covered by the path
%in a relation (as term frequency)
%and the number of distinct relations that one path could support (as inverted document frequency).
Zhang et al.~\shortcite{zhang2012ontological} also focused on learning path predicates using a Markov Logical Network~\cite{richardson2006markov}. 
%which consists of soft rules
%on both positive and negative entity pair coverage, along with length of paths.
While the above KBC systems focus on path representation, our work aims at understanding
semantically complex relations and adopts complex schema with constraints.

%Natural language relations always have more complex meaning 
%than KB predicates and using our system, 
%a target human raised relation can be mapped into an 
%explicit readable schema graph.

%To solve the paraphrasing problem between natural language relations and KB predicates, we aim to represent a human raised relation with several explicit schemas. One major difference between our technique and others is that during the procedure of generating candidate schemas for target relations, we do not limit the schemas to be simple only. We fully utilize the information of KB, adding extra constraints to the simple schemas and resulting in more complex schemas. Specifically, we perform a breadth-first search to construct the skeleton of a specific relation schema which is similar as the path finding procedure in the previous works \cite{gardner2015efficient,gardner2014incorporating,lao2011random,zhang2012ontological}. Beyond relation path, we use a depth-first search to further add more information attributes to the relation path generated in the first step and transform it into a more specific and complex graph form, under the guidance of \textit{Minimum Description Length} (MDL) \cite{fisher2008dirt,grunwald2007minimum} principle. MDL principle is used as a trade-off since it measures the cost of transmitting both schemas and entity pairs.

% query synthesis

% question and answering via paraphrasing

Our work also intersects with ontology question answering.%~\cite{yahya2012natural,krishnamurthy2012weakly,fader2013paraphrase}.
One branch of QA techniques are semantic parsing based, it translates questions directly into structural query graphs through pre-defined grammars, such as CCG~
\cite{kwiatkowski2010inducing,cai2013large,kwiatkowski2013scaling,reddy2014large}
and $\lambda$-DCS~\cite{liang2011learning,berant2013semantic,berant2014semantic}
, then perform query on SPARQL engine.
Our schema shares the similar backbone structure with query graph, but the key difference between
semantic parsing and our work is how to generate the query graph:
In semantic parsing methods, the query graph is constructed recursively based on combining syntactic components,
%therefore complex semantic can only be generated if the question is \textbf{syntactically} complex;
therefore complex semantics is limited to \textit{syntactically} complex questions;
in contrast, we leverage grouped training data to discover semantic representation
for syntactically simple but \textit{semantically} complex phrases.

Another branch of QA techniques are information retrieval based~
\cite{yao2014information,bordes2014question,yih2015semantic},
which first retrieves a broad set of candidate answers or query graphs by traversing around
question focus entity over the knowledge base, and then design syntactic and semantic features
to capture the latent associations between question surface and the answer.
Closest to our schema generation method is Yih et al.~\shortcite{yih2015semantic} who also
uses depth-first search method to extract candidate query graphs.
However, their constraints relied on handcrafted rules with explicit syntactic components, 
and are available only in certain domains (such as gender, marriage and event time).
While our method is able to summarize more flexible constraints from existing relation instances.

Besides, our work is similar to query synthesis in relational database~
\cite{niehren2013query,das2010synthesizing,cheung2012inferring,cheung2013optimizing}. 
Given a set of input table and an output table,
query synthesis automatically produces a relational query that produces the output when applied to the input. 
This problem is similar to ours as the query is analogous to the schema
while the database is similar to the KB, but the database query is
more close to a decision tree, because the task requires producing the exact output table.
Typically, Zhang and Sun \shortcite{zhang2013automatically} 
address query synthesis using a three-steps technique.
First they create an incomplete query skeleton which captures the basic structure of the result query,
then complete the skeleton by adding some concrete and accurate rules and generate a list of candidates,
and finally ranks the candidates, which simply prefers queries with simpler structures.
Though first two steps share the same intuition with our schema generation procedure,
the techniques cannot be directly applied to NL domain,
due to the different functionalities between relational query and schema.

%In question answering by paraphrasing \cite{harabagiu2006methods,berant2013semantic,fader2013paraphrase,kwiatkowski2013scaling,berant2014semantic}, 
%as a representative, Berant and Liang~\shortcite{berant2014semantic} attack 
%semantic parsing by mapping natural language utterances into logical forms 
%to be executed on a KB using a paraphrase model and furthermore 
%improved QA performance. We compared our results to theirs in the experiments
%section. 

% other parts
%Other related work includes unsupervised systems such as 
%\cite{zou2014natural}, which calculates scores of candidate skeletons
%using TF-IDF and then choose the best one to represent the target relation. 
%%As for concrete mapping format, MapOnto \cite{an2006discovering} uses Horn clauses when produces mapping rules between two schemas. Others \cite{zhang2012ontological} generate complex SQL queries consisting of operations like join, union, project and select as mappings.
%Graph-based representations \cite{reddy2014large} is usually 
%used in exploiting structural and conceptual similarity between NL 
%and KB. Zou et al. \shortcite{zou2014natural} interpret a natural language 
%question as a semantic query graph where each vertex represents an argument 
%and each edge is associated with a relation phrase.  
%Compared to these works, our schema graph is more complex with constraints.
