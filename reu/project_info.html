<!DOCTYPE html>
<head>
    
    <!-- Standard Meta -->
    <meta content='text/html; charset=UTF-8' http-equiv='Content-Type'>
    <meta content='IE=edge,chrome=1' http-equiv='X-UA-Compatible'>
    <meta content='width=device-width, initial-scale=1.0, maximum-scale=1.0' name='viewport'>
    <script src="../static/js/application-393d5b43700222f200dcf15f4c0e5b14.js"></script>
    <link rel="stylesheet" media="all" href="../static/css/reu.css" />
    <link rel="stylesheet" media="all" href="../static/css/application-ae3e0748f68a2f05d3f535bdeb9fa996.css" />
    <script src="../static/js/reu-0bc27e2168727cafa1252f703137df60.js"></script>
    <title>
        ACLGroup - REU
    </title>
    <script>
        (function() {
          $(function() {
            return $('.ui.sidebar').sidebar({
              context: $('.ui.pushable.segment'),
              transition: 'overlay'
            }).sidebar('attach events', '#mobile_item');
          });
        
        }).call(this);
    </script>
</head>
<body>
    <noscript>
        <iframe height='0' src='https://www.googletagmanager.com/ns.html?id=GTM-5TSVHFZ' style='display:none;visibility:hidden' width='0'></iframe>
    </noscript>
    <style>
        #navbar {
          background: #c31f48;
          border-color: #952e46; }
        
        .logo {
          margin: 0px 0; }
        .logo img {
          height: 40px; }
    </style>

<div class="ui pushable segment">
    
    <div class='ui pusher' id='site-content'>
        <div class='ui container'>
        </div>
        <div class='ui container' id='main'>
        <p style="text-align: center;">
        <img style="width: 1000px;overflow: hidden;" src="../static/images/aclgroup.png"/>
        </p>
        <h1>
        <div class='subtitle'>Research Experience for Undergraduates Site</div>
        Arlington Computational Linguistics Group (ACLGroup-REU)
        <div class='meta'>The University of Texas at Arlington</div>
        </h1>
        <div class='ui menu stackable'>
        <a class='item' href='index.html'>REU Site Info</a>
        <a class='active item' href='project_info.html'>Project Info</a>
        <a class='item' href='faulty_mentors.html'>Faculty Mentors</a>
        <a class='item' href='graduate_mentors.html'>Graduate Mentors</a>
        <a class='item' href='projects/index.html'>Projects</a>
        <a class='item' href='faq.html'>FAQ</a>
        <!-- <a class='item' href='/spaces'>Spaces</a> -->
        <div class='right menu'>
        <div class='item'>
        <a class='ui primary button' href='https://etap.nsf.gov/award/193/opportunity/664'>Apply</a>
        </div>
        </div>
        </div>

        <div class='row'>
            <div class='ui segment basic'>
        <div class='ui grid stackable'>
<!--        <div class='row'>-->
<!--        <p>What animals are talking about is a fascinating research topic. Previous work in bio-acousitics studied a handful of species and has suffered from limited scale and high cost. Furthermore, no previous research has attempted to adopt a systematic approach to associate animal vocal sounds with written symbols, and meanings like we do with human languages. </p>-->
<!--        <p>In our preliminary study, we have built a pipeline of acquiring dog videos from YouTube, cleaning and segmenting the audio and video tracks of the animals, and transcribing the vocals into a sequence of predefined phonetic symbols. Based on this pipeline, the undergraduate participants of REU site will make two research thrusts: i) to collect high quality, partially annotated multimedia animal communication data; and ii) to experiment on this data using our animal language processing pipeline to gain insights about the language of a new species. </p>-->
<!--        <p>To achieve these goals, we will recruit student animal lovers with computing or  biology backgrounds. Each year, participants will spend 10 weeks away from UTA learning the basics and collecting data, and 10 weeks summer time at UTA doing experiments, validating their findings and improving the pipeline. Our work eventually will develop into an open-source web-based animal language study platform called AniVoice. </p>-->
<!--        </div>-->
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Project AniVoice</title>
</head>
<body>
    <section id="project-objectives">
        <h1>Objectives of the Project</h1>
        <p>
          The core objective of this research initiative is to decode the complex language of animals, beginning with dogs, by leveraging advancements in machine learning and bioacoustics. This project aspires to translate canine vocalizations into a sequence of phonetic symbols and to associate these sounds with specific behaviors and contexts, creating an innovative framework akin to a lexicon of animal language. The ultimate goal is to build the AniVoice platform, an open-source, web-based resource for animal language studies that can be utilized by researchers, veterinarians, and animal enthusiasts worldwide to foster a deeper understanding of interspecies communication.
            <!-- The full detailed objective description would continue here -->
        </p>
    </section>
    <section id="required-knowledge">
        <h1>Required Knowledge</h1>
        <p>To participate in this cutting-edge research, candidates must possess a blend of technical and scientific knowledge. This includes:</p>
        <ul>
            <li><strong>Computational Skills:</strong> A strong grasp of programming languages, data processing, and machine learning techniques is essential. Experience with audio and video editing software, as well as database management, would be advantageous.</li>
            <li><strong>Biological Insight:</strong> An understanding of animal behavior, particularly in ethology, the study of animal behavior in natural conditions, is crucial. Familiarity with bioacoustics, the study of the production and reception of sounds by animals, will be particularly beneficial.</li>
            <li><strong>Research Aptitude:</strong> Candidates should demonstrate an ability to conduct literature reviews, synthesize information, and engage in critical thinking to contribute meaningfully to the project's research goals.</li>
        </ul>
    </section>

    <section id="project-timeline-venues">
        <h1>Project Timeline and Venues</h1>
        <p>
          The project is structured into a 20-week intensive program that alternates between theoretical learning and practical, hands-on experience. The initial phase of off-campus activities will include seminars and workshops to provide a solid foundation in the necessary technical and biological concepts. The second phase at UTA will immerse participants in rigorous data analysis and experimentation in state-of-the-art laboratories, culminating in the validation of their research findings.
        </p>
    </section>

    <section id="weekly-activities">
        <h1>Activities During the 20 Weeks</h1>
        <p>
            Participants will engage in a variety of activities designed to enrich their academic knowledge, develop technical skills, and foster collaborative research...
        </p>
        <ul>
          <li><strong>Academic Enrichment:</strong> Engaging in seminars that cover a wide array of topics related to the project and beyond, to foster a multidisciplinary understanding.</li>
          <li><strong>Technical Training:</strong> Developing skills in the latest machine learning algorithms and data annotation techniques.</li>
          <li><strong>Collaborative Research:</strong> Working in teams to collect data, develop the AniVoice pipeline, and troubleshoot challenges.</li>
          <li><strong>Professional Development:</strong>Enhancing presentation and communication skills through regular progress reports and feedback sessions.</li>
      
        </ul>
    </section>

    <section id="expected-outcome">
        <h1>Expected Outcome at the End</h1>
        <p>
          Upon completion, the project aims to present a revolutionary approach to animal communication, detailed documentation of the research process, a robust dataset for ongoing studies, and potentially publishable findings that contribute to the scientific community's understanding of animal linguistics.</p>
    </section>

    <section id="evaluation">
        <h1>How They Are Evaluated</h1>
        <p>
          Participants' contributions will be evaluated on the basis of technical proficiency, the accuracy and innovation of their research methods, the quality of their data analysis, and the clarity of their final presentations and documentation. Success in these areas will reflect the participant's ability to apply interdisciplinary knowledge to complex problems and generate reliable, insightful results that advance the field.
        </p>
    <section id="Activity Timetable">
    <div class="row">
      <h2>Activity Timetable</h2>
      <p><b>Weekly REU Group Seminars</b>: These will be hour-long research seminars attended by all REU students, mentors, and their graduate students. Each week, two REU students will give a ten-minute presentation about a topic in their research area (which can be an introductory tutorial or about one or more research papers), and then two graduate students among the mentors will also give a similar presentation. Each mini-talk or presentation will be followed by a short Q&A session and audience feedback about their  presentation delivery. Students will broaden their knowledge of each other’s fields and improve their presentation skills.</p>
      <p><b>Weekly Project Sync-ups</b>: Each project group will meet weekly with their mentors about project progress and to resolve issues that they might have encountered. Groups which have related tasks may hold the weekly sync-ups or sessions together. </p>
      <p><b>Orientation and Lab Tours (Week 1-2)</b>: Assist UGRs to settle in to the UTA house and assign them to the workspace in the PI’s and Co-PI’s labs. Participants will meet mentors’ graduate students and become familiarized with the campus and surroundings. Workshops on research conduct and safety will be held. UGRs will are given a demonstration and a walk-through of the existing AniVoice pipeline and learn how to use it.</p>
      <p><b>Data Filtering, Cleansing, and Annotation (Week 3-4)</b>: UGRs will focus on putting all data collected from Phase 1 together, and apply preprocessing code to extract useful audio/visual data with actual animal communication scenes. The UGRs may also need to annotate both audio and video data for word and sub-word segmentation, video scene recognition and object recognition, etc. In the first year of the project, the group that is tasked with web development will develop a web interface that allows internet users to upload their own recordings, as well as annotate their video clips on the web. In subsequent years, the UGRs will maintain this web interface and integrate the collected data from the web platform with their own data. </p>
      <p><b>Vocal Transcription,  Semantics Discovery (Week 5-6)</b>:  After fine-tuning the word/subword segmentation models and acoustic feature extraction models, UGRs will transcribe the animal vocalizations into sequences of distinct symbols. UGRs will further finetune the video understanding and alignment models to align the words in the transcripts with the video scenes and give them semantics. </p>
      <p><b>Evaluation and Analysis (Week 7-8)</b>: UGRs will test the fine-tuned AniVoice pipeline to evaluate its ability to accurately segment, recognize, and understand animal communications within the data. These tests will help ensure the respective components’ reliability and robustness. Statistical analysis will be performed to infer the possible meaning of the animal words, which will be validated against animal science literature. These activities will provide feedback to assess its usability and effectiveness in annotating and contributing data which will guide refinements and enhancements to AniVoice. </p>
      <p><b>Documentation and Presentation (Week 9-10)</b>: In the final two weeks, UGRs will focus on compiling documentation and preparing presentations to share their findings. UGRs will compile comprehensive documentation that encapsulates the entire research process, including data collection, preprocessing, model development, testing results, and best practices. This documentation will serve as a valuable resource for future researchers. At the same time, UGRs will prepare and deliver final research presentations to showcase their accomplishments and insights gained through the program. UGRs will also produce a detailed research report summarizing their work, findings, and contributions to the AniVoice project. If such reports are deemed publication-worthy, we will carry the UGRs through the paper writing and submission process. </p>

  </div>
</body>
</html>







            


<!--            <h2>REU Site External Mentors</h2>-->
<!--            As part of the REU program, students will engage with and receive feedback from external mentors from internationally recognized human-computer interaction programs.-->
<!--            <div class='ui grid two columns stackable'>-->
<!--            <div class='column'>-->
<!--            <div class='ui list divided'>-->
<!--            <div class='ui item'>-->
<!--            <div class='description'>-->
<!--            <p>-->
<!--            <b>Mengyue Wu</b>-->
<!--            <br>-->
<!--            Associate Professor-->
<!--            <br>-->
<!--            Computer Science-->
<!--            <br>-->
<!--            Shanghai Jiao Tong University-->
<!--            </p>-->
<!--            </div>-->
<!--            </div>-->
<!--            &lt;!&ndash; <div class='ui item'>-->
<!--            <div class='description'>-->
<!--            <p>-->
<!--            <b>Sean Follmer</b>-->
<!--            <br>-->
<!--            Assistant Professor-->
<!--            <br>-->
<!--            Mechanical Engineering-->
<!--            <br>-->
<!--            Stanford University-->
<!--            </p>-->
<!--            </div>-->
<!--            </div>-->
<!--            <div class='ui item'>-->
<!--            <div class='description'>-->
<!--            <p>-->
<!--            <b>Alexandra Ion</b>-->
<!--            <br>-->
<!--            Assistant Professor-->
<!--            <br>-->
<!--            Human-Computer Interaction-->
<!--            <br>-->
<!--            Carnegie Mellon University-->
<!--            </p>-->
<!--            </div>-->
<!--            </div>-->
<!--            <div class='ui item'>-->
<!--            <div class='description'>-->
<!--            <p>-->
<!--            <b>Jennifer Jacobs</b>-->
<!--            <br>-->
<!--            Assistant Professor-->
<!--            <br>-->
<!--            Media Arts and Science-->
<!--            <br>-->
<!--            UC Santa Barbara-->
<!--            </p>-->
<!--            </div>-->
<!--            </div>-->
<!--            <div class='ui item'>-->
<!--            <div class='description'>-->
<!--            <p>-->
<!--            <b>Jeeeun Kim</b>-->
<!--            <br>-->
<!--            Assistant Professor-->
<!--            <br>-->
<!--            Computer Science &amp; Engineering-->
<!--            <br>-->
<!--            Texas A&M University-->
<!--            </p>-->
<!--            </div>-->
<!--            </div> &ndash;&gt;-->
<!--            </div>-->
<!--            </div>-->
<!--            <div class='column'>-->
<!--            <div class='ui list divided'>-->
<!--            &lt;!&ndash; <div class='ui item'>-->
<!--            <div class='description'>-->
<!--            <p>-->
<!--            <b>Stefanie Mueller</b>-->
<!--            <br>-->
<!--            Associate Professor-->
<!--            <br>-->
<!--            EECS/MechE-->
<!--            <br>-->
<!--            MIT-->
<!--            </p>-->
<!--            </div>-->
<!--            </div>-->
<!--            <div class='ui item'>-->
<!--            <div class='description'>-->
<!--            <p>-->
<!--            <b>Nadya Peek</b>-->
<!--            <br>-->
<!--            Assistant Professor-->
<!--            <br>-->
<!--            Human Centered Design &amp; Engineering-->
<!--            <br>-->
<!--            University of Washington-->
<!--            </p>-->
<!--            </div>-->
<!--            </div>-->
<!--            <div class='ui item'>-->
<!--            <div class='description'>-->
<!--            <p>-->
<!--            <b>Valkyrie Savage</b>-->
<!--            <br>-->
<!--            Assistant Professor-->
<!--            <br>-->
<!--            Computer Science-->
<!--            <br>-->
<!--            University of Copenhagen-->
<!--            </p>-->
<!--            </div>-->
<!--            </div>-->
<!--            <div class='ui item'>-->
<!--            <div class='description'>-->
<!--            <p>-->
<!--            <b>Sowmya Somanath</b>-->
<!--            <br>-->
<!--            Assistant Professor-->
<!--            <br>-->
<!--            Computer Science-->
<!--            <br>-->
<!--            University of Victoria-->
<!--            </p>-->
<!--            </div>-->
<!--            </div> &ndash;&gt;-->
<!--            </div>-->
<!--            </div>-->
<!--            </div>-->
        </div>
        
        </div>
        <div class='ui vertical footer segment'>
        <div class='ui center aligned container'>
        <p>
        <a href='/'>
        <strong>ACL-Group</strong>
        </a>
        © The University of Texas at Arlington
        2023-2023
        <br>
        <em>
        Last updated
        2023-09-25 12:32:23 UTC
        </em>
        </p>
        </div>
        </div>
        </div>
</div>
    
</body>
